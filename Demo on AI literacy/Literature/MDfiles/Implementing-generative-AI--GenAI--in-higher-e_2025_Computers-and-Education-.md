# Implementing generative AI (GenAI) in higher education: A systematic review of case studies

## Metadata
- **Author**: Marina Belkina
- **Subject**: Computers and Education: Artificial Intelligence, 8 (2025) 100407. doi:10.1016/j.caeai.2025.100407
- **Creator**: Elsevier
- **Producer**: Acrobat Distiller 8.1.0 (Windows)
- **Creation Date**: D:20250612075802Z
- **Modification Date**: D:20250612075945Z
- **Source File**: Implementing-generative-AI--GenAI--in-higher-e_2025_Computers-and-Education-.pdf
- **Converted**: 2025-10-23 22:46:12

---

## Content

--- Page 1 ---

Implementing generative AI (Gen AI) in higher education: A systematic 
review of case studies
Marina Belkina a,*
, Scott Daniel b
, Sasha Nikolic c
, Rezwanul Haque d
, Sarah Lyden e
,  
Peter Neal a
, Sarah Grundy a
, Ghulam M. Hassan f
a University of New South Wales, Australia
b University of Technology Sydney, Australia
c University of Wollongong, Australia
d University of the Sunshine Coast, Australia
e University of Tasmania, Australia
f University of Western Australia, Australia
A R T I C L E  I N F O
Keywords:
Generative AI
Education
Gen AI
Case study
University
Implementation
A B S T R A C T
The introduction of Generative Artificial Intelligence (Gen AI) tools, like Chat GPT, into higher education heralds 
a transformative era, reshaping instructional methods, enhancing student support systems, and redefining the 
educational landscape. Recent literature reviews on Gen AI highlight a lack of focus on how these tools are being 
practically implemented in educational settings. Addressing this gap, the present study systematically examines 
empirical case studies that demonstrate the integration of Gen AI into teaching and learning in higher education, 
offering actionable insights and guidance for academic practice.
We conducted a search of relevant databases and identified 21 empirical studies that met our inclusion 
criteria. The selected studies cover a diverse range of disciplines, locations, types of participants (from first-year 
students to postgraduates and academics), and a variety of methodologies. We classified the selected publications 
based on the pedagogic theory of Laurillard’s Conversational Framework (LCF) and the Substitution, Augmen-
tation, Modification, and Redefinition (SAMR) framework. We also synthesized definitions from selected 
empirical studies and recent research exploring Technological Pedagogical Content Knowledge (TPACK) in the 
age of Gen AI, providing a comprehensive understanding of Gen AI-TPACK factors. Limitations and future 
research opportunities are also discussed. The paper concludes by providing a Gen AI-TPACK diagram to guide 
educators in effectively incorporating Gen AI tools into their teaching practices, ensuring responsible and im-
pactful use in higher education.
1. Introduction
Generative Artificial Intelligence (Gen AI) is transforming higher 
education, by challenging traditional teaching approaches, improving 
student support systems, and reshaping the educational ecosystem. 
Gen AI can be defined as a technology that leverages deep learning 
models to generate human-like content (e.g., images, words) in response 
to complex and varied prompts (e.g., languages, instructions, questions) 
Lim et al. (2023). The most popular type of Gen AI model, Chat GPT, 
captured widespread attention across the global academic community. 
The claim of the developers that the Chat GPT-4 can pass any exam with 
a score around the top 10 % of test takers (Open AI et al., 2023) led to 
widespread discussions on academic integrity. As the implementation of 
Chat GPT and similar technologies in classrooms becomes more preva-
lent, a comprehensive examination of their effectiveness and integration 
is imperative.
A growing body of research across disciplines such as engineering 
(Nikolic et al., 2023; Nikolic, Sandison, et al., 2024), medical education 
(Currie (2023), Gilson et al. (2023), microbiology (Das et al., 2023), and 
economics (Geerling et al., 2023) has begun to evaluate Chat GPT’s 
performance against university assessments. Findings generally indicate 
that with minimal input modifications, Chat GPT can produce acceptable 
responses, suggesting a need to recalibrate educational practices in 
anticipation of more advanced AI iterations. This evolving scenario 
* Corresponding author. High St, Kensington, NSW, 2052, Australia.
E-mail address: m.belkina@unsw.edu.au (M. Belkina). 
Contents lists available at Science Direct
Computers and Education: Artificial Intelligence
journal homepage: www.sciencedirect.com/journal/computers-and-education-artificial-intelligence
https://doi.org/10.1016/j.caeai.2025.100407
Received 4 July 2024; Received in revised form 23 March 2025; Accepted 7 April 2025  
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 
Available online 10 April 2025 
2666-920X/© 2025 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by- 
nc-nd/4.0/ ). 

--- Page 2 ---

underscores the importance of reassessing our pedagogical approaches 
as these tools become increasingly capable.
Recent investigations have highlighted the advantages of using 
Gen AI in educational settings, with both teachers and students. With 
teachers, it can help in creating assessments (Baidoo-Anu & Ansah, 
2023; Kasneci et al., 2023; Zhai, 2023), enhancing flipped learning 
methodologies (Rudolph, Tan, & Tan, 2023), developing curriculum 
(Simms, 2024), and identifying and developing superior learning re-
sources (Muddam & Reddy, 2023). With students, it can provide per-
sonal tutoring (Mhlanga, 2023), facilitate enhanced learning by 
providing answers to theoretical questions, stimulate creative thinking, 
summarise complex essays into understandable formats, and serve as a 
copyediting 
tool 
to 
aid 
students 
weak 
in 
language 
skills 
(Michel-Villarreal et al., 2023). Learning to use new Gen AI tools is also 
important because students can learn to work more efficiently, accu-
rately and make further advancements (Nikolic, Suesse, et al., 2024).
However, the use of Gen AI is not devoid of challenges. Investigations 
have uncovered issues such as cheating, plagiarism, misleading infor-
mation, and outdated content (Tlili et al., 2023). Overreliance on Gen AI, 
and the ethical and pedagogical issues outlined above, emphasise the 
need for proper guidelines and policies to ensure responsible use of 
Gen AI in education (Chan & Lee, 2023).
With these considerations in mind, understanding the functionality 
of Gen AI within higher education classrooms becomes crucial. Due to 
the massive number of papers published in the field, educators often face 
challenges in finding practical examples of Gen AI implementation. This 
makes it difficult to determine if the wheel is constantly being rein-
vented, or if diversity and originality in Gen AI application is taking 
place. At the same time teachers, universities and regulators are seeking 
to engage and adapt educational offerings to the evolving requirements 
of the future workplace and the rapidly changing capabilities of Gen AI 
technology. This paper aims to systematically review case studies on the 
implementation of Gen AI in higher education, assessing the extent to 
which the current research addresses previously identified gaps. It also 
provides guidelines to academics on the workings and integration of 
these AI applications in higher education settings, emphasizing the need 
for a comprehensive understanding to enhance productivity and pro-
fessional practice readiness.
2. Related literature
2.1. Theoretical frameworks
Effectively leveraging Gen AI capabilities requires more than just an 
understanding of the technology itself. Theoretical frameworks can be 
applied as a structured approach to assess, implement, and evaluate 
their use when integrated into educational contexts. They provide 
theoretical and practical structures to navigate the complexities of 
adoption, ensuring that educational technologies are used effectively, 
ethically, and inclusively (Nikolic, Sandison, et al., 2024). Some of the 
relevant frameworks that can be applied to Gen AI follow.
The first theoretical framework utilised in this paper is Laurillard’s 
Conversational Framework (LCF) and the concept of learning types 
(Laurillard, 2012). This framework was chosen because of its robust 
theoretical foundation in analysing learning processes across diverse 
educational settings. Studies have shown that it enables educators to 
align instructional strategies with desired learning outcomes, particu-
larly in contexts involving emerging technologies (Laurillard (2012); 
Heinze et al. (2007). Laurillard’s work helps emphasise the importance 
of communication and interaction between teachers and learners, 
helping teachers optimize technology-enhanced learning by providing 
theory-informed tools and scaffolding for adopting, adapting, and 
innovating effective pedagogical practices. Laurillard identifies six types 
of learning activities, each representing a fundamental way learners 
engage with material. They are acquisition, inquiry, discussion, practice, 
collaboration and production. By mapping these learning types onto the 
Conversational Framework, educators can evaluate whether all aspects 
of the learning process are being addressed.
The SMAR Model (Substitution, Augmentation, Modification, 
Redefinition) offers a valuable perspective on the transformative 
educational potential of Gen AI by helping to describe and categorize the 
integration of digital technologies (Blundell et al., 2022). This frame-
work categorizes the levels at which technology enhances or transforms 
educational practices, from the basic substitution of existing tools to the 
complete redefinition of learning experiences (Puentedura, 2009). By 
undertaking this analysis, insights can be gathered into whether the 
technology is being used for lower-level enhancement learning activities 
or higher-level transformation activities (Hamilton et al., 2016). When 
applied to Gen AI, the SMAR model can help researchers and practi-
tioners distinguish between superficial uses and more profound trans-
formations, helping guide educators to maximize the value of Gen AI 
technologies while avoiding shallow implementations that fail to 
address deeper educational goals.
The final Technological Pedagogical Content Knowledge (TPACK) 
framework provides a comprehensive lens through which to evaluate 
the interplay of technology, pedagogy, and content in integrating Gen AI 
(Mishra et al., 2023). Gen AI technologies often require educators to 
rethink their pedagogical strategies and the delivery of subject-specific 
content. TPACK facilitates this process by helping educators balance 
these domains effectively. For instance, in teaching with Gen AI-driven 
writing assistants, educators must align the tool’s capabilities with 
sound pedagogical approaches, such as fostering collaborative learning, 
and ensure it supports subject-specific goals like developing critical 
thinking skills in composition. TPACK ensures that technology integra-
tion occurs not in isolation but as part of a holistic educational strategy.
2.2. Recent systematic reviews on Gen AI
The case for this systematic literature review is built upon insights 
from recent literature reviews that examine the role of Generative AI in 
education. The following paragraphs summarise key contributions from 
individual works, which collectively inform the rationale and scope of 
this review.
Bozkurt (2023) conducted an analysis of research trends and patterns 
in Gen AI within the educational sector, utilizing data mining and 
analytical techniques. The study identified seven key themes as prom-
ising areas for future research in educational praxis: interaction with 
Gen AI-powered chatbots, the impact of large language models (LLMs) 
on teaching and learning, opportunities and challenges of conversa-
tional educational agents, the enhancement of social and cognitive 
learning processes through Gen AI, the promotion of AI literacy to unlock 
future opportunities, the expansion of academic capabilities through AI, 
and the augmentation of educational experiences via human-AI inter-
action. These themes underscore the multifaceted potential of Gen AI in 
transforming educational practices that need uncovering.
Building on the advancements of Gen AI technologies, Park and Doo 
(2024) anticipated an increase in research focusing on AI in blended 
learning environments. Their findings suggest that AI is primarily used 
in asynchronous online learning components but is less often applied to 
link these with face-to-face classroom activities. They recommend that 
future research should provide direction for educators on how to inte-
grate Gen AI to optimize blended learning implementations effectively.
Sohail et al. (2023) explored the practical applications of Chat GPT, 
emphasizing its potential to solve real-world educational challenges. 
They highlighted critical issues such as biases and trustworthiness of the 
technology, advocating for further research and development to address 
these concerns. The study also identified potential future research di-
rections, suggesting solutions to current challenges and forecasting ad-
vancements that could enhance the efficacy and reliability of Chat GPT 
in educational settings.
Castillo-Segura, Alario-Hoyos, Kloos, and Fern´andez Panadero 
(2023, 23-27 Oct. 2023) assessed the efficacy of AI tools and their 
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 3 ---

respective LLMs during classification of 596 articles in the screening 
phase of a systematic literature review. The results highlight that while 
GPT-4 demonstrated the best overall performance, it is not yet entirely 
reliable, necessitating additional input from the research team for 
comprehensive classification. This finding points to the ongoing need for 
human oversight in AI-assisted research processes.
Kumar et al. (2024) performed a systematic literature review 
exploring how Gen AI might drive innovation in higher education, and 
identified three main themes: Academic Integrity, Pedagogical 
Techno-Innovation, and Experiential Engagement. The literature review 
highlighted several benefits, including support for digital writing, 
automated writing evaluations, increased productivity, innovative 
assessment design, and enhancement of information literacy instruction. 
Concurrently, the study identified challenges such as managing inde-
terminate data, ensuring the ethical use of student data, distinguishing 
between human-written and AI-generated text, and addressing threats to 
academic integrity. These findings underscore the dual nature of Gen-
AI’s impact, and outlines many potential study directions, including 
exploring the potential of Gen AI tools in enhancing student learning and 
engagement or enhancing readiness and adaptability of educational 
institutions to Gen AI technologies and develop skills of faculty and 
students to handle these tools.
Hobensack et al. (2024) conducted a rapid literature review focusing 
on the current and potential uses of large language models in nursing. 
The review identified significant opportunities for applying these 
models but also highlighted several challenges, including ethical issues 
related to bias, misuse, and plagiarism. This review underscores the 
need for careful consideration of ethical implications in the deployment 
of AI technologies in specialised fields such as nursing.
Suryanto et al. (2023) reviewed the development, achievements, 
challenges, and emerging trends of chatbots, distinguishing between 
rule-based and Gen AI approaches. The study concluded that while each 
approach has its advantages and disadvantages, there is a need for 
ongoing supervision in aspects such as language comprehension, bias, 
and ethical considerations. This highlights the importance of main-
taining ethical standards in the development and deployment of chatbot 
technologies.
Alateyyat and Soltan (2024) analysed 295 articles from the Scopus 
database about Gen AI in higher education, noting a predominant focus 
on providing general overviews with a shortage of research in specific 
topics, including integration with teaching practices, prediction models, 
AI in assessment, and support of administrative processes in higher ed-
ucation institutions. This recommendation points to a need for deeper 
exploration and practical application of AI technologies in educational 
settings.
In response to these identified research gaps, this study seeks to 
provide an overview of empirical research exploring the practical inte-
gration of Gen AI into university teaching and learning. Unlike previous 
reviews, which often focus on broad trends (e.g., Alateyyat and Soltan 
(2024) or specific themes such as ethical considerations (Hobensack 
et al., 2024) or technological advancements (Bozkurt, 2023), this review 
uniquely examines the case studies of Gen AI integration. By systemati-
cally analysing empirical studies, it aims to identify how Gen AI can be 
effectively implemented to enhance student engagement, optimize 
teaching practices, and address the challenges of adoption in diverse 
higher education contexts. Furthermore, this review addresses critical 
gaps by mapping its findings against conceptual educational frameworks 
such as LCF, SMAR, and TPACK, providing a structured lens to evaluate 
Gen AI’s impact. To achieve this, the study seeks to answer the following 
research questions. 
RQ1: What are the characteristics of the research conducted on Gen AI 
implementation within higher education settings, including the 
geographical locations of the first authors, participant characteristics, and 
disciplinary focus?
RQ2: What study designs and research methods are used to evaluate the 
effect of Gen AI integration in higher education?
RQ3: How can the effectiveness of the Gen AI implementation in higher 
education can be analysed and categorised through the lens of the con-
ceptual educational frameworks (LCF, SMAR and TPACK)?
RQ4: What recommendations to academics for the implementation of 
Gen AI can be drawn from the analysis?
RQ5: What are the necessary methodological improvements and future 
research directions to better understand the impacts of Gen AI in higher 
education?
3. Methods
3.1. Research design
This review adopted PRISMA Statement (Preferred Reporting Items 
for Systematic Reviews and Meta-Analyses) approach (Page et al., 2021) 
and proceeded in three steps: (i) article selection, (ii) article screening 
and inclusion, and (iii) data extraction and analysis.
First, we developed a research protocol which specified. 
• The population of interest: Universities, irrespective of geograph-
ical location.
• The phenomenon of interest: Gen AI in education.
• The outcomes: The use of Gen AI in learning and teaching, associated 
examples and case studies, and the factors that helped or hindered it.
To the authors’ knowledge, no similar review has been published or 
is in development. This was confirmed by searching academic databases.
The review is confined to the Scopus database exclusively, selected 
for its status as one of the largest curated abstract and citation databases 
that supports robust academic research in quantitative science studies 
with its comprehensive coverage of high-quality scholarly publications 
aligning with the review’s objectives (Baas et al., 2020). Considering the 
novelty of the research question, book chapters or conference papers 
were not excluded from the search results. Table 1 summarises the in-
clusion criteria for article selection.
3.2. Article selection
Given the massive increase in publications related to Gen AI, the 
keyword structure was specifically designed to capture papers address-
ing the scope of the study. The following keywords were identified. 
• Keywords related to Gen AI: “artificial intelligence” OR “Chat GPT” 
OR “AI” OR “Gen AI"
• Keywords related to integration of Gen AI: “integration” OR “case 
study” OR “application” OR “implementation” OR “example"
• Keywords related to education: “teaching” OR “education” OR 
“classroom"
• Keywords related to university: “college” OR “faculty” OR “post- 
graduate” OR “postgraduate” OR “tertiary” OR “under-graduate” OR 
“undergraduate” OR “university” OR “HE"
Table 1 
Inclusion and exclusion criteria for article selection.
Criterion
Inclusion
Topic
Focusing on the use Gen AI in education or technologies with Gen AI 
characteristics - technology that generates human-like content in 
response to complex and varied prompts
Study 
type
Empirical studies that demonstrate an authentic example of Gen AI 
integration into the university teaching
Source
Journals, Conference papers, Book chapters
Period
January 1, 2023 to February 15, 2024
Language
English
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 4 ---

• Keyword related to the presence of students in the study: 
“student"
To ensure the inclusion of the most recent and relevant insights, 
particularly following the significant advancements in Gen AI marked by 
the launch of GPT-3 in late 2022, the article selection was limited to 
publications from 2023 onwards. Articles not published in English and 
review papers were excluded.
The Boolean search string we used was. 
TITLE-ABS-KEY(“artificial intelligence” OR “Chat GPT” OR “AI” OR 
“Gen AI")
AND
TITLE-ABS-KEY (“integration” OR “case study” OR “application” OR 
“implementation” OR “example")
AND
TITLE-ABS-KEY (“teaching” OR “education” OR “classroom")
AND
TITLE-ABS-KEY (“college” OR “faculty” OR “post-graduate” OR 
“postgraduate” OR “tertiary” OR “under-graduate” OR “undergradu-
ate” OR “university” OR “HE")
AND
TITLE-ABS-KEY(student)
AND
PUBYEAR > 2022 AND PUBYEAR < 2026 AND (LIMIT-TO (LAN-
GUAGE,"English”)) AND (EXCLUDE(DOCTYPE, “re”) OR EXCLUDE 
(DOCTYPE, “cr”)).
3.3. Article screening and inclusion
The article search conducted in February 2024 identified 489 pub-
lications. No ineligible records were identified by the authors, and all 
articles were included for screening (Fig. 1). Titles and abstracts of the 
publications were screened by eight authors to identify articles focused 
on findings from examples or case studies of the integration of Gen AI in 
university teaching and learning. Each article was screened by two au-
thors independently. Differences of opinion were resolved through 
group discussion. The exclusion criteria (EC) established for this review 
were as follows:
EC1: Publications not relevant to the scope of the study, for example, 
research focusing on school students instead of university students.
EC2: Publications lacking a case study with empirical data on Gen AI 
implementation in tertiary education, such as for example, studies 
focusing solely on perceptions (rather than observations) of how Gen AI 
Fig. 1. PRISMA flow diagram of article selection.
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 5 ---

can be used or misused in tertiary education.
EC3: Publication not accessible.
Following the initial title and abstract screening, 74 papers were 
included, 275 papers were excluded based on the exclusion criteria (239 
by EC1 and 36 by EC2), and there was disagreement among the re-
viewers on 140 publications. These papers were then discussed further 
in a group, resulting in an additional 15 papers included and 125 papers 
excluded (73 by EC1 and 52 by EC2). The total number of papers 
excluded through the title and abstract screening process is 400.
After the initial exclusions, the full-text screening of the remaining 
89 reports resulted in further exclusions: 28 reports were not relevant to 
the study’s scope (EC1), 23 lacked evidence of Gen AI implementation 
(EC2), and 1 report was inaccessible (EC3). Subsequently, there were 
differing opinions among reviewers on an additional 9 reports. These 
were discussed by the group of authors, resulting in all 9 being excluded 
(3 by EC1 and 6 by EC2). In total, out of the 89 papers reviewed at this 
stage, 28 were included for further analysis, and 52 were excluded for 
the reasons specified.
Ultimately, 7 studies were excluded post-extraction as they did not 
provide adequate evidence of Gen AI implementation in higher educa-
tion teaching (EC2), leaving a total of 21 studies for the final analysis.
3.4. Data extraction
The final data extraction process was conducted on the remaining 21 
studies. Data from included studies were extracted onto a pre-defined 
Excel data collection form. To address the research questions, data 
from each paper was collated as follows. 
RQ1 – title, author, year, location, number and type of participants, 
the aim of the study; the disciplines represented; reference to Gen AI 
used;
RQ2 – study methods, educational theories, study outcomes and key 
findings;
RQ3 – type of learning activities, study outcomes, summaries of 
Gen AI implementation;
RQ4 
– 
author-identified 
limitations 
and 
future 
research 
opportunities;
RQ 5 - established after the comprehensive study by the authors.
The summary of the included publications classified by the univer-
sity educational level is shown in the appendix (Table A).
4. Results and discussion
4.1. Study characteristics to address RQ1
The first research question, aimed to determine the characteristics of 
the research conducted on Gen AI implementation in higher education 
(including the geographical locations of the first authors, participants’ 
characteristics, and discipline distribution). It is quite central of being 
aware of the characteristics of a research field in order to overcome 
possible methodological deficiencies, for example (Buchner et al., 
2021). This is also important to know to understand the breadth of 
implementation (and any under-studied areas). As shown in appendix 
Table A, first-year students are represented in 4 studies, second and 
third-year students are also featured in 4 studies, postgraduate students 
are involved in 2 studies, mixed undergraduate and postgraduate groups 
appear in 1 study, unspecified undergraduate students are included in 7 
studies, unspecified students are represented in 2 studies, and academics 
are the focus of 1 study.
The geographic distribution of studies summarised in Fig. 2 is rela-
tively diverse, with a significant representation from Asia and Europe 
(29 % each; n = 6), closely followed by Oceania (24 %; n = 5), North 
America (9 %; n = 2), Africa and Middle East (9 %; n = 2). The articles 
reviewed include 18 published in 2023 and three from early 2024, 
consistent with the literature search being conducted in February 2024. 
These data are derived from the included studies listed in Appendix 
Table A.
Discipline distribution (Fig. 3), derived from the date listed in Ap-
pendix Table A, shows that language courses, of all disciplines, have the 
highest number of related articles at 33 % (n = 7). This focus is largely 
due to the significant impact Gen AI tools like Chat GPT have on 
language-related academic tasks, particularly in writing. For example, 
Nikolic et al. (2023) noted that Chat GPT could produce work that sat-
isfies marking rubrics when provided with the right prompts. This 
increased interest in the impact of Gen AI on student writing is driven by 
academic concerns regarding breaches of academic integrity, as edu-
cators seek to understand and mitigate potential issues of academic 
dishonesty while still leveraging the benefits of these advanced tools for 
educational enhancement.
Following Languages, the fields of Information & Communication 
Technologies (29 %; n = 6) and Engineering & Science (19 %; n = 4), 
demonstrate the applicability of Gen AI in more technical academic 
tasks, especially coding. One remarkable example of what Gen AI can 
achieve in the field of coding is its ability to automate the creation of 
complex software applications. Given the many advantages of Gen AI, 
academics are exploring alternative methods to traditional STEM 
education.
Education disciplines (9 %, n = 2), complemented by contributions 
from the Humanities and Social Sciences (5 %, n = 1) and Multidisci-
plinary case studies (5 %, n = 1), reflect the widespread impact of Gen AI 
across the entire education system. This variety suggests that as more 
tailored applications of Gen AI are developed, its influence could extend 
further, enhancing various fields of study.
The aims of the selected research papers (Table A) are diverse, 
reflecting the wide-ranging potential of Gen AI in transforming higher 
education practice across various disciplines. These studies collectively 
focus on leveraging Gen AI to enhance learning experiences, develop 
specific skills, and assess the impact of this technology on both students 
and educators.
For example, in science education, Exintaris et al. (2023) aim to 
enhance problem-solving and critical thinking in chemistry via 
Chat GPT-generated prompts. In engineering, Zhao et al. (2023) assess 
Gen AI’s potential and limitations, focusing on student experiences with 
Chat GPT. Kirwan (2023) in humanities addresses concerns about Large 
Language Models like Chat GPT by exploring their applications and 
related discussions, and in Information Technology, Wang and Feng 
(2024) study the impact of prompt engineering on information retrieval 
skills.
Lu et al. (2024) compare teacher and Chat GPT feedback on Chinese 
writing to understand its effectiveness and student perceptions, while 
Fig. 2. Geographical distribution of selected papers. (n = 21).
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 6 ---

Kuramitsu et al. (2023) evaluate the impact of AI-based assistance in 
programming education, focusing on how Gen AI can supplement 
traditional teaching methods by helping students address unresolved 
errors and clarify unknown terms.
These studies collectively reveal a significant interest in under-
standing how Gen AI can transform teaching and learning practices 
across various disciplines, highlighting both opportunities and chal-
lenges in its integration into university curricula.
4.2. Study designs and research methods to address RQ2
The second research question aimed to determine the study designs 
and research methods used to evaluate the effect of Gen AI integration in 
higher education. This is important to know to gauge the reliability and 
validity of findings that can guide effective implementation and policy 
decisions. The selected publications were classified into qualitative, 
quantitative, and mixed-methods designs (Table 2) according to Cres-
well’s framework (Creswell, 2014). The classification utilised extracted 
data that covered study methods, educational theories, study outcomes 
and key findings.
The majority of publications (15 of the 21 studies) implemented 
mixed-method research designs. For example, Kuramitsu et al. (2023)
conducted qualitative and quantitative analysis of student interactions 
with coding assistant Gen AI tool, and Uddin et al. (2023) combined case 
study quantitative evaluations with qualitative student surveys in a 
construction program.
Solely quantitative research designs were used in two studies 
(Qureshi, 2023; Wang, Wang, et al., 2024) to measure performance 
metrics objectively. Wang, Wang, et al. (2024) assessed the impact of 
prompt engineering on students’ ability to find information using 
Chat GPT by conducting statistical analysis of the task completion 
qualities, and Qureshi (2023) scored performance of student teams in 
programming challenges.
Qualitative observations were conducted in four studies (Kirwan, 
2023; Pitso, 2023; Widiati et al., 2023; Zhao et al., 2023) often involving 
qualitative student surveys and classroom performance observations. 
For example, Pitso (2023) studied how multidisciplinary students tested 
out Chat GPT on their assignments and conducted post-study interviews 
to check lessons learnt and whether students were ready to embrace 
learning based on critical thinking, empowerment theory and Gen AI 
systems.
The most common research methods across the studies were surveys 
and interviews, utilised in fifteen papers, of which fourteen researchers 
reported data from student’s survey (Belda-Medina and Kokoˇskov´a, 
2023; Bernabei et al., 2023; Exintaris et al., 2023; French et al., 2023; 
Guo et al., 2023; Lu et al., 2024; Murillo-Ligorred et al., 2023; Pitso, 
2023; Silitonga et al., 2023; Speth et al., 2023; Uddin et al., 2023; Wang 
& Feng, 2024; Zhao et al., 2023) and Widiati et al. (2023) interviewed 
teachers.
Eight studies evaluated the correlation between subject knowledge 
and Gen AI integration into classroom activities. Five of these studies 
assessed student performance through pre- and post-Gen AI intervention 
subject knowledge tests and assignments (Elkhodr et al., 2023; Guo 
et al., 2023; Qureshi, 2023; Uddin et al., 2023). Assignments completed 
with the assistance of Gen AI were evaluated in two studies: Bernabei 
et al. (2023) and Lu et al. (2024). Exintaris et al. (2023) studied stu-
dents’ ability to critically evaluate solutions generated by Chat GPT and 
to identify errors. Finally, Wang et al. (2024) investigated whether 
subject-related prior knowledge affects the quality of the answers ob-
tained from Chat GPT by the students.
Six publications employed a quasi-experimental design to compare 
groups of students with and without Gen AI interventions. Of these, the 
studies by Wang, Wang, et al. (2024) and Qureshi (2023) focused on 
quantitative assessments, while the studies by Silitonga et al. (2023), 
Elkhodr et al. (2023), Khang et al. (2023) and Guo et al. (2023) used 
mixed methods to provide a more comprehensive analysis of how Gen AI 
enhances student performance and engagement.
4.3. Laurillard’s Conversational Framework (LCF) classification of 
selected studies to address RQ3
The third research question was to determine how can the effectiveness 
of the Gen AI implementation in higher education can be analysed through the 
lens of the conceptual educational frameworks (LCF, SMAR and TPACK)? 
This is important to check the alignment of Gen AI integration with 
established pedagogical theories in seeking to enhance educational 
outcomes.
First we classified the final 21 papers based on the pedagogic theory 
of Laurillard’s Conversational Framework (LCF) and the concept of 
learning types (Laurillard, 2012). This framework has proven effective 
in aiding educators to describe and discuss the student learning process 
comprehensively. Laurillard (2012) identifies six distinct learning types 
that facilitate different aspects of the educational experience, each 
fostering unique skills and competencies in learners:
Fig. 3. Discipline distribution of selected papers. (n = 21).
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 7 ---

Acquisition: This type of learning involves students exploring ideas 
provided by their teachers. It is characterized by the transmission of 
knowledge from educator to student, typically through lectures, read-
ings, or multimedia content.
Investigation: Students engage in learning through investigation 
where they explore, compare, and critique texts, documents, and re-
sources. This process encourages learners to delve deeper into the sub-
ject matter, reflecting on the concepts and ideas being taught and 
developing critical thinking skills.
Practice: Learning through practice requires learners to engage in 
activities where they must apply what they have learned to complete 
specific tasks. This learning type emphasizes the importance of iterative 
feedback and adapting one’s approach based on this feedback to meet 
the learning objectives effectively.
Discussion: This learning type necessitates learners articulating 
their ideas and questions and responding to those posed by their 
teachers or peers. Discussion fosters a deeper understanding through 
dialogue and can often lead to new insights and perspectives.
Collaboration: In collaborative learning, students work together to 
solve problems or complete projects. This type of learning is about the 
process of engaging with others, sharing ideas, and developing solutions 
as a group, which mirrors many real-world work environments.
Production: Production involves students creating a tangible or 
digital product that demonstrates their understanding of the subject 
matter. This type of learning is driven not just by the feedback from 
teachers but also by the motivation to create a public output that has 
real-world application or academic value.
Table 3 demonstrates the varied applications and outcomes of the 
final set of papers integrating Gen AI tools into different learning envi-
ronments across the educational spectrum.
Specific implementations of AI technologies were extracted from the 
selected publications and categorised by the LCF learning types, and 
collated along with the reported outcomes, which commonly range from 
improved student performance to enhanced engagement with course 
content.
For instance, under Acquisition, Wang and Feng (2024) used 
Chat GPT to assist in reading and analysing English literature, high-
lighting the tool’s capacity to facilitate a deeper understanding of 
complex texts. In the Inquiry learning type, multiple studies such as 
those by Kirwan (2023) and Kong et al. (2023) illustrate how Chat GPT 
serves as a powerful tool for enhancing student investigation skills, 
aiding in everything from introductory tutorials to the development of 
methodologies in chemical engineering design. This not only improves 
understanding but also engagement with course material.
Discussion activities, represented by Exintaris et al. (2023) and 
Murillo-Ligorred et al. (2023), focus on utilizing Chat GPT for critical 
thinking and discussing contemporary issues like deepfakes, which plays 
a crucial role in developing students’ analytical skills. In the Practice 
learning type, studies such as those by Wang, Wang, et al. (2024) and 
Kuramitsu et al. (2023) reveal how Chat GPT aids in practical applica-
tions like prompt engineering and programming assistance, significantly 
reducing basic inquiries to instructors and enhancing information 
retrieval effectiveness.
Collaboration is exemplified by Lu et al. (2024), where the combi-
nation of teacher and Chat GPT feedback was found to improve student 
writing, showing the tool’s effectiveness in collaborative settings. And 
finally, studies corresponding to the Production type of learning, such as 
those by Belda-Medina and Kokoˇskov´a (2023)) and Pitso (2023), explore 
how Chat GPT can assist in creating more practical outputs such as 
research reports and assignments, demonstrating its utility in producing 
tangible academic products.
By classifying the selected papers through the LCF framework, we 
can identify how Gen AI tools facilitate various learning types and their 
potential to support holistic educational experiences. For example, 
acquisition learning types benefit from Gen AI’s ability to deliver content 
interactively, while collaborative learning activities leverage Gen AI for 
group problem-solving. For educators, this classification is practical as it 
highlights specific learning types where Gen AI has demonstrated suc-
cess, providing actionable insights to incorporate these tools effectively 
into their teaching practices.
4.4. Substitution, augmentation, modification and redefinition (SAMR) 
analysis to address RQ3
Our next approach to address RQ3 is to analyse the included papers 
against the Substitution, Augmentation, Modification and Redefinition 
(SAMR) framework.
The SAMR framework was developed and first promoted by Dr 
Ruben Puentedura in 2009 (Puentedura, 2009). The four levels are 
grouped in to two main layers representing different degrees of 
Table 2 
Classification of final papers by methodology (n = 21).
Study design
Citation
Research methods
Quantitative
Wang, Wang, et al. 
(2024)
Quasi-experimental research 
(experimental vs control group), 
statistical analysis of student 
performance
Qureshi (2023)
Quasi-experimental research, 
Quantitative evaluation of student 
performance
Qualitative
Zhao et al. (2023)
Qualitative student survey
Kirwan (2023)
Student performance observation
Widiati et al. (2023)
Qualitative teacher interviews
Pitso (2023)
Qualitative Empowering Education 
method called Evaluation Design, semi- 
structured student interviews
Mixed
Silitonga et al. (2023)
Quasi-experimental research, 
qualitative student performance and 
survey motivation evaluations
Bernabei et al. (2023)
Student survey, quantitative and 
qualitative student assignment 
evaluation
Exintaris et al. (2023)
Evaluation of student performance, 
qualitative student interviews, 
metacognitive tools
Lu et al. (2024)
Quantitative evaluation of student 
performance, qualitative student survey 
followed by the quantitative analysis of 
the responses
Kuramitsu et al. (2023)
Qualitative and quantitative evaluation 
of student interaction and engagement 
with Gen AI
Speth et al. (2023)
Student survey, observation of the case 
study
Elkhodr et al. (2023)
Quasi-experimental research, 
qualitative reflective exercise analysis 
and instructor observations, qualitative 
rubric scores
Murillo-Ligorred et al. 
(2023)
Semi-structured student interviews, 
data analysis using the constant 
comparative method
Belda-Medina and 
Kokoˇskov´a (2023)
Qualitative and quantitative student 
surveys and interviews
French et al. (2023)
Qualitative student survey and semi- 
structured interviews, quantitative data 
analysis
Khang et al. (2023)
Quasi-experimental design, student 
observations, inferential statistical 
analysis
Guo et al. (2023)
Quasi-experimental design, student 
performance evaluation through pre- 
test and post-test, student’s survey
Uddin et al. (2023)
Case study observations, results 
evaluation, qualitative student survey
Han et al. (2023)
Quantitative student survey. Student 
performance observations, focus group 
interviews
Wang and Feng (2024)
Student survey and semi-structured 
group interviews, qualitative skills 
assessment
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 8 ---

technology integration into learning experiences: enhancement and 
transformation (for more information see Blundell et al. (2022)).
At the enhancement layer, technology enhances the existing educa-
tional process without fundamentally changing it. The focus is on 
improving efficiency and adding features. Its two levels are. 
- Substitution: Technology acts as a direct substitute for traditional 
tools, with no functional change. For example, a word processor can 
be used to type an essay instead of handwriting it.
- Augmentation: Technology acts as a direct substitute, but with 
functional improvements. For example, using a word processor with 
spell check and grammar suggestions to type an essay.
At the transformation layer, technology transforms the learning 
experience by creating new opportunities and ways of learning that were 
Table 3 
Classification of final papers by Laurillard’s Conversational Framework (n = 21).
LCF Learning 
type
Reference
Learning Activities 
Implemented
Outcome
Acquisition
Wang and Feng 
(2024)
Chat GPT used for 
reading assistance 
and analysis in an 
English reading 
class
Explored whether 
Chat GPT could 
facilitate the 
exploration of 
English original 
masterpieces in a 
comparative study
Inquiry
Kirwan (2023)
Introductory class 
to demonstrate how 
to operate Chat GPT 
and identify the 
affordances and 
limitations
Provided an 
overview of 
Chat GPT in 
academia and 
moderated fears 
about its potential
Elkhodr et al. 
(2023)
Allowing students 
to use Chat GPT in 
tutorials as a tool, 
compared to the 
traditional 
approach of web 
searches and 
lecture material
Chat GPT proved to 
be a valuable tool 
in assisting 
students in 
generating user 
flows and ideas
Han et al. (2023)
Using Chat GPT as 
instructor assisting 
with essay revision
Most students 
reported positive 
experience with 
Chat GPT, however 
students with lower 
technology skills 
faced challenges
Discussion
Exintaris et al. 
(2023)
Workshop to 
critique provided 
Chat GPT-generated 
solutions for 
problems
Enhanced 
metacognitive and 
critical thinking 
skills
Murillo-Ligorred 
et al. (2023)
Classroom 
discussions and 
analysis of 
deepfake images
Develop critical 
thinking about 
deepfakes
Wang, Wang, et al. 
(2024)
Prompt engineering 
applied in flipped 
classrooms for 
information 
retrieval
Observed positive 
influence of 
mastering prompt 
engineering on the 
effectiveness of 
information 
retrieval from 
Chat GPT
Practice
Kuramitsu et al. 
(2023)
AI-based assistance 
for programming 
education
Reduced number of 
basic questions to 
teachers
Widiati et al. 
(2023)
Students used AI 
tools to assist them 
in creative and 
other writing tasks 
in English
Teachers reported 
positive impact on 
student writing, 
such as idea 
generation, 
vocabulary and 
organisation
Bernabei et al. 
(2023)
Students engaged 
with Chat GPT to 
write an essay and 
then Chat GPT used 
to detect if the essay 
AI generated
Students enhanced 
understanding of 
Gen AI benefits and 
limitations and 
emphasized the 
crucial role of 
teachers in the 
educational process
Silitonga et al. 
(2023)
AI chatbot-based 
learning in English 
writing classroom
Increased students’ 
motivation after 
using Chat GPT
Speth et al. (2023)
AI-generated 
exercises 
implemented in 
programming 
courses
Evaluated the use 
of AI teaching 
materials in coding 
education
Qureshi (2023)
Students were 
encouraged to 
Students using 
Chat GPT improved  
Table 3 (continued)
LCF Learning 
type 
Reference 
Learning Activities 
Implemented 
Outcome
engage with 
Chat GPT for help 
with the 
programming 
problems
their scores, but 
teams using 
Chat GPT-generated 
code faced 
difficulties with 
test cases in the 
Programming 
Contest Control 
environment
Khang et al. 
(2023)
Students learning 
English using 
different chatbots
Students may lack 
experience with 
Gen AI
Guo et al. (2023)
Chatbot-assisted 
debates to enhance 
students’ 
argumentation 
skills and 
motivation
Chatbot improves 
the argumentative 
skills and 
motivation in 
students
Uddin et al. 
(2023)
Chat GPT integrated 
into construction 
hazard recognition 
curriculum
Chat GPT 
significantly 
improved students’ 
construction 
hazard recognition 
ability
Lu et al. (2024)
Combination of 
teacher and 
Chat GPT feedback
Evaluated the 
effectiveness of 
Chat GPT and 
teacher feedback in 
assessing student 
writing. Improved 
student’s writing
Collaboration
Belda-Medina and 
Kokoˇskov´a (2023)
Students completed 
assessment report 
with the assistance 
of Chatbots
Found moderate 
level of student 
satisfaction with 
linguistic chatbots
Production
French et al. 
(2023)
Students were 
given a research 
and development 
assignment that 
explicitly required 
them to engage 
with Open AI tools
The integration of 
Open AI tools into 
the curriculum was 
both productive 
and popular
Pitso (2023)
Students using 
Chat GPT to 
complete 
assignment and 
resolve social 
problem
Chat GPT 
significantly 
lessens assignment 
completion time 
and improves 
problem-solving 
abilities
Zhao et al. (2023)
Using Chat GPT to 
design a course; 
students creating 
materials using 
Chat GPT
Explored the 
potentials and 
limitations of AI in 
the classroom, 
learning students’ 
perceptions and 
experiences
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 9 ---

not possible before. This can lead to deeper understanding and 
engagement. Its levels are. 
- Modification: Technology allows for significant task redesign. For 
example, students collaborate on a shared Google Doc to write and 
edit an essay in real-time, providing immediate feedback to each 
other.
- Redefinition: Technology allows for the creation of new tasks that 
were previously inconceivable. For example, students create a 
multimedia presentation or a video essay incorporating various 
digital tools, conduct research online, and collaborate with peers 
from around the world.
To conduct this analysis, we analysed extracted data, such as types of 
learning activities, study outcomes, summaries of Gen AI implementa-
tion, and classified each learning activity mentioned in the selected ar-
ticles through the SAMR Framework. Examples of the technology 
integration extracted from the Gen AI implementation case studies are 
shown in Table 4, along with the justification for the allocation of each 
example to the different SAMR levels.
Most of the selected studies reported multiple teaching activities 
where Gen AI was implemented, and, therefore, each study was allocated 
to all possible SAMR levels of integration that are reflected in the pub-
lication. For example, Exintaris et al. (2023) uses Chat GPT to generate 
solutions to chemical problems, classified as Substitution because this 
task substituted the teacher’s work without causing any significant 
changes to the teaching and learning process. However, the solutions 
created were used by students to analyse and determine errors that 
enhance students’ critical thinking. As this level of integration describes 
a teaching activity where technology is used to redesign learning ac-
tivities with significant functional improvement compared to human 
assistance, it is classified as Modification.
At the Substitution level, Gen AI is used to directly replace traditional 
methods without significantly enhancing or changing the educational 
outcome. As shown in Table 4, examples include using Gen AI for basic 
skills delivery in subjects like math and language, and simulating con-
versations for practice in language learning or customer service.
The Augmentation level, frequently referenced across the studies, 
enhances traditional educational tools by integrating advanced func-
tionalities such as grammar checks and assistance with writing tasks. 
This focus is logical, considering the third of the selected studies are 
from language disciplines.
Moving to the higher tiers of the SAMR model, Modification and 
Redefinition also feature prominently. Modification, as evidenced in 
practices like real-time feedback and dynamic brainstorming sessions, 
significantly alters traditional educational activities. Redefinition goes a 
step further by creating completely new tasks and methods of engage-
ment, such as integration of Chat GPT into the course material to 
enhance student learning (Zhao et al., 2023) or Gen AI integration into 
Computing and Digital Media research and development assignment 
(French et al., 2023). The examples of Modification and Redefinition 
demonstrate the potential for Gen AI tools to profoundly shape and 
enhance the future of education.
For educators, SAMR can be used to assess the impact of Gen AI on 
pedagogy and learning outcomes. For example, the framework allows 
researchers and educators to distinguish between basic uses of Gen AI, 
such as grammar checking (augmentation), and transformative uses, like 
creating entirely new learning tasks (redefinition). This distinction is 
particularly valuable for educators who are just beginning to explore the 
integration of Gen AI into their teaching practices. At the substitution 
and augmentation levels, educators can experiment with simple imple-
mentations, such as using Gen AI for automated feedback on writing 
assignments or generating sample problems for students. These initial 
steps provide a low-risk entry point, enabling educators to become 
familiar with the capabilities of Gen AI without significantly altering 
their existing teaching methods.
Table 4 
An implementation analysis against the SAMR framework.
SAMR 
Classification
Example of 
technology 
integration
Justification
Reference
Substitution
Teach 
fundamental 
skills
Using Gen AI to 
deliver 
fundamental skills, 
such as basic math 
or language rules, 
can directly replace 
traditional teaching 
methods without 
altering the 
educational 
function.
Wang et al. (2023)
Kuramitsu et al. 
(2023)
Silitonga et al. 
(2023)
Elkhodr et al. (2023)
Belda-Medina and 
Kokoˇskov´a (2023)
Han et al. (2023)
​
Simulate 
conversations
Gen AI can simulate 
conversations for 
language learning 
or customer service 
training, 
substituting for 
human interaction 
without adding 
significant 
functionality.
Widiati et al. (2023)
Belda-Medina and 
Kokoˇskov´a (2023)
Khang et al. (2023)
​
Answer student 
enquiries/ 
generate 
solutions
This use of Gen AI 
acts as a direct 
substitute for 
teacher or tutor 
responses, 
providing 
information 
without changing 
the learning 
dynamics.
Kirwan (2023)
Wang and Feng 
(2024) Kuramitsu 
et al. (2023)
Bernabei et al. 
(2023)
Qureshi (2023)
Augmentation
Performs 
grammar 
checks
Gen AI enhances 
traditional spell- 
checkers by 
understanding 
context and 
suggesting more 
accurate 
grammatical 
corrections
Widiati et al. (2023)
Kuramitsu et al. 
(2023) Belda-Medina 
and Kokoˇskov´a 
(2023) Khang et al. 
(2023)
​
Assist with 
writing tasks
Gen AI provides 
enhancements like 
suggestions, 
improvements, or 
structural help that 
goes beyond simple 
text processing
Widiati et al. (2023)
Kirwan (2023)
Bernabei et al. 
(2023) Belda-Medina 
and Kokoˇskov´a 
(2023)
Han et al. (2023)
​
Assist with 
problem solving
Gen AI offers tools 
or methods that 
improve the 
problem-solving 
process, such as 
step-by-step guides 
or interactive aids.
Qureshi (2023)
Modification
Provide 
immediate 
feedback and 
suggestions
Gen AI can analyse 
student responses in 
real-time and offer 
tailored feedback
Wang et al. (2023)
Lu et al. (2024)
Silitonga et al. 
(2023) Elkhodr et al. 
(2023) Belda-Medina 
and Kokoˇskov´a 
(2023) Khang et al. 
(2023)
Guo et al. (2023)
Han et al. (2023)
​
Facilitates 
brainstorming
Gen AI provides 
unique ways to 
enhance or manage 
the brainstorming 
process that 
wouldn’t be 
possible with 
traditional tools.
Elkhodr et al. (2023); 
Zhao et al. (2023)
Pitso (2023)
Guo et al. (2023)
(continued on next page)
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 10 ---

As educators gain confidence, the framework guides them toward 
more advanced applications in the modification and redefinition stages. 
For instance, in modification, educators might redesign a traditional 
brainstorming activity by incorporating Gen AI to provide real-time, 
Gen AI-generated prompts that inspire deeper critical thinking or 
collaborative problem-solving. At the redefinition level, Gen AI could be 
used to create entirely new tasks, such as virtual role-playing scenarios 
or interactive simulations that were previously impossible to achieve 
with traditional tools.
4.5. Technological Pedagogical Content Knowledge (TPACK) framework 
analysis (RQ3) and recommendations to academics (RQ4)
In our final approach to address RQ3 and to answer RQ4, we utilised 
the TPACK (Technological Pedagogical Content Knowledge) framework, 
a model that describes the knowledge and skills needed by teachers to 
effectively integrate technology into their teaching practices (Niess, 
2002). The TPACK framework can provide a scaffold for considering 
what teachers need to know to use any technology effectively (Mishra 
et al., 2023).
In the TPACK framework, there are four principal areas of knowledge 
related to technology: Technological Knowledge (TK) as well as in the 
overlapping spaces that constitute Technological Content Knowledge 
(TCK), Technological Pedagogical Knowledge (TPK), and Technolog-
ical Pedagogical Content Knowledge (TPACK). Additionally, a recent 
and significant shift in the research on TPACK has been an emphasis on 
understanding Contextual Knowledge (XK)—a recognition of the fact 
that context matters and impacts what educators can and cannot do 
(Mishra, 2019).
To provide the description of the TPACK knowledge domains in the 
context of Gen AI integration, we synthesized definitions from the Celik 
(2023) empirical study on the ethical integration of artificial intelligence 
(AI) and Mishra et al. (2023) research exploring TPACK in the age of 
Chat GPT and Gen AI. The descriptions of Gen AI-TPACK factors are as 
follows. 
• Gen AI-TK: Focuses on understanding and proficiency with Gen AI 
tools themselves. It involves knowing how to interact with these 
tools, execute tasks, and utilize them effectively in specific subject 
area or classroom.
• Gen AI-TPK: Addresses the integration of Gen AI tools in teaching 
practices. It includes understanding how these tools can enhance 
teaching methods, such as providing adaptive and personalized 
feedback, real-time assessments, and monitoring student learning. 
Teachers should know how to leverage Gen AI to support diverse 
teaching strategies and scaffold students’ learning experiences.
• Gen AI-TCK: Combines knowledge of Gen AI tools with subject- 
specific content. It encompasses the ability to use Gen AI to search 
for, curate, and create educational material relevant to the teacher’s 
field. Teachers should be familiar with best practices for using Gen AI 
to enhance their understanding and explanation of subject content 
and know how to integrate these tools into their teaching.
• Gen AI-TPACK: Represents the comprehensive understanding of how 
to effectively combine Gen AI tools with pedagogical strategies and 
subject content. It involves creating lessons that integrate Gen AI 
tools to enhance student engagement and learning outcomes.
• Gen AI-XK: Focuses on the broader context within which Gen AI tools 
are used, including policies, ethical considerations, and practical 
constraints. This domain also involves assessing the fairness and 
inclusivity of Gen AI tools and advocating for their responsible use in 
education.
From selected publications, the examples of Gen AI-TK include 
delivering introductory classes demonstrating how to operate Chat GPT 
(Kirwan, 2023) or studying the advantages and limitations of Chat GPT 
(Exintaris et al., 2023; Wang & Feng, 2024). For Gen AI-TPK, the studies 
emphasise enhancing teaching practices, like providing personalized 
feedback on student work (Belda-Medina & Kokoˇskov´a, 2023; Elkhodr 
et al., 2023; Guo et al., 2023; Han et al., 2023; Khang et al., 2023; Lu 
et al., 2024; Silitonga et al., 2023; Wang et al., 2023; Widiati et al., 
2023), supporting flipped-learning classrooms (Wang & Feng, 2024), or 
assisting with writing tasks by offering structural suggestions and im-
provements, thereby augmenting traditional teaching methods and 
enabling more dynamic and interactive learning experiences 
(Belda-Medina & Kokoˇskov´a, 2023; Bernabei et al., 2023; Han et al., 
2023; Kirwan, 2023; Widiati et al., 2023).
In the context of Gen AI-TCK, the majority of selected studies 
implemented Gen AI with subject-specific content, as this is the main 
scope of the systematic literature review. The examples range across 
disciplines, including Chat GPT integration into a construction hazard 
recognition curriculum (Uddin et al., 2023), using Gen AI to assist in 
learning English (Khang et al., 2023; Widiati et al., 2023), or applying 
Gen AI in programming studies (Speth et al., 2023).
The examples of how teachers integrate pedagogical strategies, 
content knowledge, and technology to create transformative learning 
experiences (Gen AI-TPACK) include the integration of Chat GPT into a 
course, where the instructor used the tool to facilitate student learning 
Table 4 (continued)
SAMR 
Classification 
Example of 
technology 
integration 
Justification 
Reference
​
Assist with the 
analysis of 
errors
Gen AI allows for 
deeper analysis or a 
more 
comprehensive 
review than 
traditional 
methods.
Lu et al. (2024)
Kuramitsu et al. 
(2023) Uddin et al. 
(2023)
​
Enhance critical 
thinking
Gen AI challenges 
students or provides 
scenarios that 
require higher- 
order thinking that 
goes beyond 
traditional tasks.
Zhao et al. (2023)
Kirwan (2023)
Murillo-Ligorred 
et al. (2023)
Redefinition
Generate new 
ideas
Gen AI uniquely 
generates ideas that 
would not have 
been possible 
without it, 
potentially through 
AI-driven insights.
Zhao et al. (2023)
Pitso (2023)
​
Generate new 
work samples 
(text, images 
etc.)
Uses Gen AI to 
create unique 
content or samples 
that extend beyond 
simple templates or 
modifications.
Speth et al. (2023)
Zhao et al. (2023)
Murillo-Ligorred 
et al. (2023)
French et al. (2023)
​
Generates new 
method of 
learning
Gen AI introduces 
completely new 
ways of learning or 
interacting with the 
material that 
fundamentally 
transforms the 
educational 
experience.
Belda-Medina and 
Kokoˇskov´a (2023)
Uddin et al. (2023)
​
Generative 
problem- 
solving 
environments
Gen AI creates 
complex, real-world 
problems that 
students must solve, 
offering a platform 
for innovative 
thinking and 
solution 
development that 
wouldn’t be 
possible without AI.
French et al. (2023)
Pitso (2023)
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 11 ---

and develop course materials, demonstrating the comprehensive appli-
cation of TPACK (Zhao et al., 2023), or when students used Chat GPT to 
complete assignments and resolve social problems (Pitso, 2023).
Finally, for Gen AI-XK, we provide examples where studies empha-
sise the importance of understanding broader personal, cultural, politi-
cal, and ethical implications of Gen AI. For instance, one study 
investigates the moral and legal aspects of Gen AI-generated deepfakes 
(Murillo-Ligorred et al., 2023), and another explores the level of trust 
towards Gen AI, the social influence that content generates on students, 
and whether students judge Chat GPT fairly and with moral standards 
(Bernabei et al., 2023).
Summarising the TPACK analysis and to answer RQ4, we developed 
the Gen AI-TPACK diagram (Fig. 4 ) to assist academics in Gen AI 
implementation in teaching practices. The diagram is based on the ca-
nonical TPACK diagram (Mishra, 2019) and expanded with the key 
teacher skills and knowledge recommended for Gen AI implementation 
in the different TPACK technical domains. The lists of recommended 
knowledge is adapted from the Intelligent-TPACK scale developed by 
Celik (2023) and amended to address the characteristics of Gen AI. Each 
overlapping domain in the diagram—such as Gen AI-TPK, Gen AI-TCK, 
and Gen AI-TPACK—is further explained in the accompanying text to 
clarify how Gen AI tools contribute to specific pedagogical, content, and 
technological teaching practices. This model provides a comprehensive 
framework for educators, outlining the necessary technological, 
pedagogical, and content knowledge, as well as contextual under-
standing, required to effectively integrate Gen AI tools into educational 
settings. By following this model, educators can enhance their teaching 
strategies, personalise learning experiences, and ensure ethical and 
effective use of Gen AI technologies in the classroom.
This study does not expand on the TPACK areas of Content Knowl-
edge (CK), Pedagogical Knowledge (PK), and their overlap in Peda-
gogical Content Knowledge (PCK), as these are beyond the scope of this 
study and therefore are not detailed with required teacher skills.
The developed Gen AI-TPACK framework offers a structured 
approach for educators to integrate generative AI tools into their 
teaching practices effectively and ethically. It divides the required 
knowledge into distinct domains - each addressing specific aspects of 
Gen AI integration. Educators start by developing foundational techno-
logical skills, such as understanding how to interact with Gen AI tools 
and creating content like text or images. These basic capabilities allow 
educators to explore Gen AI’s potential in routine tasks, such as auto-
mating feedback or generating lesson materials, while building their 
confidence. As educators progress, they can leverage TPK to incorporate 
Gen AI into teaching strategies, such as creating interactive activities or 
providing personalized learning experiences, which transform tradi-
tional approaches and enhance student engagement. TCK, on the other 
hand, focuses on applying Gen AI within specific subject areas, enabling 
educators to generate discipline-relevant content, address unique 
Fig. 4. Gen AI-TPACK diagram with the key teacher skills and knowledge recommended for Gen AI implementation.
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 12 ---

challenges, and enrich their instructional methods.
At the heart of the framework is Technological Pedagogical Content 
Knowledge, which represents the integration of all domains. Educators 
operating at this level design lessons that seamlessly combine technol-
ogy, pedagogy, and content to maximize learning outcomes. The in-
clusion of Contextual Knowledge (XK) further strengthens the 
framework by addressing the broader environment in which Gen AI is 
used. Educators are guided to consider ethical issues, institutional pol-
icies, and regulatory requirements, ensuring that their use of Gen AI is 
both responsible and aligned with institutional goals.
4.6. Reported limitations and future research opportunities to address 
RQ5
The fifth and final research question was to determine the necessary 
methodological improvements and future research directions needed to better 
understand the impacts of Gen AI in higher education. This is important for 
gaining a deeper and more accurate understanding of the impacts of 
Gen AI in higher education, thereby enhancing its effectiveness and 
integration. The key reported limitations include small sample sizes and 
the inconsistency in students’ ability with prompt engineering. In 
addition, several studies have identified inherent technological limita-
tions within Gen AI systems used in educational research, including 
inconsistent responses, general unreliability, and outright errors in the 
AI’s output (Elkhodr et al., 2023; Kong et al., 2023; Qureshi, 2023; Wang 
& Feng, 2024).
Numerous reports highlight scope limitations in research, particu-
larly citing small sample sizes (Elkhodr et al., 2023; Lu et al., 2024; 
Murillo-Ligorred et al., 2023; Silitonga et al., 2023; Widiati et al., 2023; 
Zhao et al., 2023) and narrow subject focus (Kuramitsu et al., 2023; 
Uddin et al., 2023). Additionally, the short duration of many studies 
further impedes a comprehensive understanding of the long-term im-
plications of Gen AI technologies on higher education and student 
learning.
Wang et al. (2023) reported a limitation in assuming that students 
are already adept at using Gen AI technologies such as prompt engi-
neering. This could affect research results, as not all students may be at 
the same level of proficiency. Further compounding this issue is a lack of 
control over other significant variables like motivation levels and prior 
knowledge (Elkhodr et al., 2023), which can greatly influence the 
outcome of educational interventions.
The generalizability and precision of research findings are noted in 
two studies (Belda-Medina & Kokoˇskov´a, 2023; Pitso, 2023) to be 
limited by the specific conditions under which research is conducted, 
which may not accurately represent broader educational environments. 
This is certainly a limitation of all the papers, even if not explicitly 
acknowledged.
To overcome the limitations of narrow scopes and small sample sizes, 
future research should aim to involve larger and more diverse groups of 
participants as well as an evaluation based on students’ proficiency. 
Extending studies across various educational areas (Belda-Medina & 
Kokoˇskov´a, 2023; Kuramitsu et al., 2023; Zhao et al., 2023) could help 
validate the effectiveness of Gen AI tools in a range of contexts. There is 
also a significant opportunity to investigate newer and broader versions 
of Gen AI (Belda-Medina & Kokoˇskov´a, 2023; Guo et al., 2023; Kur-
amitsu et al., 2023), which could help uncover additional capabilities of 
Gen AI that may be beneficial in educational settings. This will remain an 
ongoing challenge while the powers of Gen AI are evolving so rapidly 
and dynamically diversifying and strengthening.
Understanding the long-term impacts of Gen AI on student learning is 
crucial (Belda-Medina & Kokoˇskov´a, 2023; Widiati et al., 2023). Lon-
gitudinal studies could provide insights into how sustained use of Gen AI 
affects learning outcomes, student engagement, and educational equity. 
The responsible use of Gen AI in unsupervised settings (Elkhodr et al., 
2023) and the ethical implications of Gen AI in education (French et al., 
2023; Kong et al., 2023) are highlighted as critical areas for future 
investigation.
Research focusing on the quantification of time savings for aca-
demics when employing Gen AI in teaching could demonstrate some 
practical benefits (Speth et al., 2023). Likewise, exploring the automa-
tion of routine teaching practices, such as grading (Han et al., 2023), 
could offer insights into how Gen AI can streamline educational pro-
cesses and free up educator time for additional student-focused 
activities.
Specifically in terms of our study, the main limitation is due to the 
dynamic nature of the field of Gen AI, this systematic literature review 
captures papers published from January 2023 to February 2024, 
potentially overlooking more recent developments. Additionally, it in-
cludes only papers written in English, which may exclude relevant 
research published in other languages. Future work should include a 
revised study based on the stated limitations which would gain further 
insights on the dynamic nature of Gen AI through comparison studies 
between timeframes.
5. Conclusions
This systematic review examines the actual impacts, challenges, and 
opportunities of integrating Gen AI into higher education. By analysing 
selected papers through the lenses of the LCF, SAMR, and TPACK 
frameworks, this study demonstrates how these analytical tools enhance 
various learning environments. Our investigation, driven by five 
research questions, uncovered a variety of Gen AI applications, strategies 
for implementation, and outcomes. These findings reveal Gen AI’s po-
tential to elevate educational pedagogy, boost student motivation, and 
enrich the overall learning experience.
The findings from RQ1 highlight the diversity of Gen AI applications 
across regions, participant demographics, and disciplines. However, 
gaps remain, particularly in underexplored fields such as the social 
sciences and interdisciplinary studies, as well as in geographic areas 
with limited representation. For educators, this emphasizes the oppor-
tunity to extend Gen AI research and implementation into underrepre-
sented areas while leveraging existing insights from more well-studied 
contexts.
The study designs and methods reviewed in RQ2 reveal the value of 
mixed-method approaches in capturing both quantitative and qualita-
tive outcomes of Gen AI integration. Educators can use these methods to 
evaluate the impacts of Gen AI tools on student learning, engagement, 
and performance in their own teaching contexts.
Through RQ3, the use of conceptual frameworks such as LCF, SAMR, 
and TPACK provides structured guidance for educators seeking to align 
Gen AI integration with pedagogical theories. These frameworks allow 
educators to start with basic uses, such as grammar checks, and progress 
toward transformative applications like collaborative simulations or 
interdisciplinary problem-solving. By adopting these frameworks, edu-
cators can strategically implement Gen AI in ways that enhance teaching 
practices and improve learning outcomes.
Addressing RQ4, Gen AI-TPACK framework was developed, which 
offers specific recommendations for the knowledge and skills required at 
different levels of Gen AI integration. The framework emphasizes foun-
dational skills, such as understanding Gen AI tools and their capabilities, 
progressing toward more advanced knowledge of integrating these tools 
into pedagogy and subject-specific content. By following the framework, 
educators can develop expertise in areas such as adaptive learning 
design, ethical considerations, and personalized student feedback, 
ensuring a phased and effective implementation of Gen AI in higher 
education.
Finally, RQ5 highlights the critical need for future research to 
address current limitations, such as narrow scopes, small sample sizes, 
and short study durations. Longitudinal studies are particularly impor-
tant to understand the sustained impacts of Gen AI on student learning, 
engagement, and equity. Moreover, research exploring the time-saving 
benefits of Gen AI for educators and its potential to automate routine 
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 13 ---

tasks, such as grading, could provide practical evidence for its value. 
Addressing ethical concerns, such as the reliability of Gen AI in unsu-
pervised settings, remains a key priority as these tools become more 
widely adopted.
Despite encountering issues such as bias and reliability, this research 
argues that critical thinking and structured pedagogical approaches can 
harness Gen AI to tailor and enhance each student’s learning journey. By 
aligning Gen AI integration with pedagogical frameworks and addressing 
gaps in research, this study provides valuable insights for educators, 
academics, and policymakers. This review contributes to bridging gaps 
in current knowledge and lays the groundwork for leveraging Gen AI’s 
transformative potential in higher education.
CRedi T authorship contribution statement
Marina Belkina: Writing – original draft, Visualization, Project 
administration, Methodology, Data curation, Conceptualization. Scott 
Daniel: Writing – review & editing, Methodology, Data curation. Sasha 
Nikolic: Writing – review & editing, Methodology, Data curation. 
Rezwanul Haque: Writing – review & editing, Data curation. Sarah 
Lyden: Writing – review & editing, Data curation. Peter Neal: Writing – 
review & editing, Project administration, Funding acquisition, Data 
curation. Sarah Grundy: Writing – review & editing, Project adminis-
tration, Data curation. Ghulam M. Hassan: Writing – review & editing, 
Data curation.
Declaration of generative AI and AI-assisted technologies in the 
writing process
During the preparation of this work the author(s) used Chat GPT in 
order to optimize the language style in the original draft. After using this 
tool/service, the authors reviewed and edited the content as needed and 
take full responsibility for the content of the publication.
Declaration of competing interest
The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper.
Acknowledgements
This work is an initiative of the Australasian Artificial Intelligence in 
Engineering Education Centre (AAIEEC), a special interest group of the 
Australasian Association of Engineering Education (AAEE). This work 
was supported by the 2023 Australian Council of Engineering Deans 
(ACED) and the Australasian Association for Engineering Education 
(AAEE) Grant.
Appendix 
Table A 
Characteristics of Included Studies Classified by Educational Level (n = 21)
Nº
Reference
Disciplines
Gen AI used
Country
N◦ of 
participants
Aim(s)
First-year students

Exintaris et al. (2023)
Science (chemistry)
Chat GPT 3.5
Australia

To develop problem-solving skills and critical thinking by 
using Chat GPT-generated responses as prompts for 
critiques in a problem-solving workshop

Kirwan (2023)
Humanities and social 
sciences
Chat GPT 3.5
Ireland
Not reported
To provide understanding of how Gen AI technologies 
functions, their strengths and weaknesses, and to provide 
insights on how to best encourage students to think 
critically about their own potential use of Gen AI.

Wang, Wang, et al. 
(2024)
Information Technology
Chat GPT 3.5
China

To evaluate the impact of prompt engineering on college 
students’ information retrieval skills using Chat GPT.

Khang et al. (2023)
English
My virtual Dream 
Friend and John 
English Bot
Indonesia

To determine how AI chatbots can help to learn English as a 
foreign language.
Second and Third-Year Students

Wang and Feng 
(2024)
English
Chat GPT
China

To investigate the effectiveness of Chat GPT in assisting 
with reading comprehension, analysis of narrative 
structure and language style, word explanation, and 
translation of sentences and paragraphs.

Kuramitsu et al. 
(2023)
Computer science
Chat GPT 3.5
Japan

To evaluate the impact of providing AI-based assistance to 
students for addressing unresolved errors, clarifying 
unknown terms, and explaining or modifying code, as an 
alternative to traditional support from teaching staff.

Belda-Medina and 
Kokoˇskov´a (2023)
Teacher Education 
(English as a foreign 
language)
Chatbots: Mondly, 
Andy, John Bot and 
Buddy.ai
Spain, Czech 
Republic

To compare various linguistic and technological aspects of 
four App-Integrated Chatbots (AICs) and to investigate the 
perceptions of English as a Foreign Language teacher 
candidates regarding these chatbots.

Uddin et al. (2023)
Civil, Construction and 
Environmental 
Engineering
Chat GPT
USA

To explore if Chat GPT can aid hazard recognition when 
integrated into the curriculum of students pursuing a career 
in the construction industry.
Postgraduate students

Murillo-Ligorred et al. 
(2023)
Education (Arts)
Technology 
generating ‘deepfake 
images’
Spain

To assess university students’ (training to be teachers) 
ability to recognise deepfakes and their level of knowledge 
about this technology.
(continued on next page)
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 14 ---

Table A (continued)
Nº 
Reference 
Disciplines 
Gen AI used 
Country 
N◦ of 
participants 
Aim(s)

Bernabei et al. (2023)
Mechanical and 
management engineering
Chat GPT 3.5
Italy

To examine the effectiveness of using Chat GPT as a 
learning tool among engineering students. Specifically, it 
involves students using Chat GPT to generate essays, 
assessing the detectability of these essays as AI-generated, 
and exploring student perceptions of large language models 
(LLMs) in the learning process.
Mixed undergraduate and postgraduate

Elkhodr et al. (2023)
Information and 
Communication 
Technologies
Chat GPT 3.5
Australia

To explore the outcomes of using Gen AI as an assistive tool 
in tutorials.
Unspecified undergraduate students

Lu et al. (2024)
Chinese writing
Chat GPT 3.5
China

To compare teacher and Chat GPT feedback on student 
writing, examining the nature of the feedback, student 
perceptions of it, and how students use this feedback to 
revise their work.

Speth et al. (2023)
Computer programming
Chat GPT 3.5
Germany

To evaluate the effectiveness of using Gen AI teaching 
materials in coding education.

French et al. (2023)
Computing and Software 
Engineering
Chat GPT 3.5 or Dall- 
E−2
UK
Not reported
To describe and evaluate students’ experiences using AI 
tools.

Pitso (2023)
Chemical Engineering, 
Accounting and Logistics
Chat GPT 3.5
South Africa

To qualitatively examine the use of Chat GPT in students’ 
assignments and problem-solving processes, focusing on 
the emerging learning dynamics and benefits associated 
with its integration into learning.

Qureshi (2023)
Computer science
Chat GPT 3.5
Saudi Arabia

To investigate the effectiveness of Chat GPT in improving 
students’ learning outcomes in the initial programming 
courses of a Computing degree.

Guo et al. (2023)
English
Argumate chatbot
China

To examine the impact of chatbots on students’ 
argumentation skills and motivation.

Han et al. (2023)
English
RECIPE that uses 
Chat GPT
South Korea

To introduce and evaluate a novel learning platform called 
RECIPE (Revising an Essay with Chat GPT on an Interactive 
Platform for English as a Foreign Language learners).
Unspecified students

Zhao et al. (2023)
Biomedical informatics
Chat GPT 3.5 and 
available AI tools
United 
States

To explore the potential and limitations of AI in the 
classroom; to investigate students’ perceptions of and 
experiences with the application of Chat GPT in teaching 
and learning.

Silitonga et al. (2023)
English
Chat GPT 3.5
Indonesia

To investigate the impact of AI chatbots on students’ 
motivation to learn English.
Academics

Widiati et al. (2023)
English
Jenni AI 
Quillbot 
Word Tune 
Chat GPT 
Copy.ai 
Paperpal 
Essay Writer
Indonesia

To investigate the types of AI writing tools used by English 
as a Foreign Language (EFL) teachers to enhance student 
writing quality, specifically in content and organization, 
and to explore teachers’ perceptions of the impact of these 
tools on students’ writing.
References
Alateyyat, S., & Soltan, M. (2024). Utilizing artificial intelligence in higher education: A 
systematic review. Paper presented at the 2024 ASU International conference in 
emerging technologies for sustainability and intelligent systems (ICETSIS).
Baas, J., Schotten, M., Plume, A., Cˆot´e, G., & Karimi, R. (2020). Scopus as a curated, high- 
quality bibliometric data source for academic research in quantitative science 
studies. Quantitative Science Studies, 1(1), 377–386. https://doi.org/10.1162/qss_a_ 
00019. J Quantitative Science Studies.
Baidoo-Anu, D., & Ansah, L. (2023). Education in the era of generative artificial 
intelligence (AI): Understanding the potential benefits of Chat GPT in promoting 
teaching and learning. Journal of AI, 7. https://doi.org/10.61969/jai.1337500
Belda-Medina, J., & Kokoˇskov´a, V. (2023). Integrating chatbots in education: Insights 
from the chatbot-human interaction satisfaction model (CHISM). Int. J. Educ. 
Technol. High. Educ, 20(1), 62. https://doi.org/10.1186/s41239-023-00432-3
Bernabei, M., Colabianchi, S., Falegnami, A., & Costantino, F. (2023). Students’ use of 
large language models in engineering education: A case study on technology 
acceptance, perceptions, efficacy, and detection chances. Comput Educ.: Artificial 
Intelligence, 5, Article 100172. https://doi.org/10.1016/j.caeai.2023.100172
Blundell, C. N., Mukherjee, M., & Nykvist, S. (2022). A scoping review of the application 
of the SAMR model in research. Comput Educ., 3, Article 100093. https://doi.org/ 
10.1016/j.caeo.2022.100093
Bozkurt, A. (2023). Unleashing the potential of generative AI, conversational agents and 
chatbots in educational praxis: A systematic review and bibliometric analysis of 
Gen AI in education. Open Praxis. https://doi.org/10.55982/openpraxis.15.4.609
Buchner, J., Buntins, K., & Kerres, M. (2021). A systematic map of research 
characteristics in studies on augmented reality and cognitive load. Comput Educ., 2, 
Article 100036. https://doi.org/10.1016/j.caeo.2021.100036
Castillo-Segura, P., Alario-Hoyos, C., Kloos, C. D., & Fern´andez Panadero, C. (2023). 
Leveraging the potential of generative AI to accelerate systematic literature reviews: 
An example in the area of educational technology. Paper presented at the 2023 world 
engineering education forum - global engineering Deans Council (WEEF-GEDC).
Celik, I. (2023). Towards Intelligent-TPACK: An empirical study on teachers’ professional 
knowledge to ethically integrate artificial intelligence (AI)-based tools into 
education. Computers in Human Behavior, 138, Article 107468. https://doi.org/ 
10.1016/j.chb.2022.107468
Chan, C. K. Y., & Lee, K. K. W. (2023). The AI generation gap: Are Gen Z students more 
interested in adopting generative AI such as Chat GPT in teaching and learning than 
their Gen X and millennial generation teachers? Smart Learn. Environ., 10(1). https:// 
doi.org/10.1186/s40561-023-00269-3
Creswell, J. W. (2014). Research design: Qualitative, quantitative, and mixed methods 
approaches. SAGE Publications. 
Currie, G. M. (2023). Academic integrity and artificial intelligence: Is Chat GPT hype, 
hero or heresy? Seminars in Nuclear Medicine, 53(5), 719–730. https://doi.org/ 
10.1053/j.semnuclmed.2023.04.008
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407 

--- Page 15 ---

Das, D., Kumar, N., Longjam, L. A., Sinha, R., Deb Roy, A., Mondal, H., et al. (2023). 
Assessing the capability of Chat GPT in answering first- and second-order knowledge 
questions on microbiology as per competency-based medical education curriculum. 
Cureus, 15(3), Article e36034. https://doi.org/10.7759/cureus.36034
Elkhodr, M., Gide, E., Wu, R., & Darwish, O. (2023). ICT students’ perceptions towards 
Chat GPT: An experimental reflective lab analysis. STEM Edu., 3(2), 70–88. https:// 
doi.org/10.3934/steme.2023006
Exintaris, B., Karunaratne, N., & Yuriev, E. (2023). Metacognition and critical thinking: 
Using Chat GPT-generated responses as prompts for critique in a problem-solving 
workshop (SMARTCHEMPer). J. J. o. C. E.. 100, 2972–2980. https://doi.org/ 
10.1021/acs.jchemed.3c00481
French, F., Levi, D., Maczo, C., Simonaityte, A., Triantafyllidis, S., & Varda, G. (2023). 
Creative use of Open AI in education: Case studies from game development. 7(8), 81.
Geerling, W., Mateer, G. D., Wooten, J., & Damodaran, N. (2023). Chat GPT has aced the 
test of understanding in college economics: Now what? The American Economist, 68 
(2), 233–245. https://doi.org/10.1177/05694345231169654
Gilson, A., Safranek, C. W., Huang, T., Socrates, V., Chi, L., Taylor, R. A., et al. (2023). 
How does Chat GPT perform on the United States medical licensing examination? 
The implications of Large Language Models for medical education and knowledge 
assessment. JMIR Med Educ, 9, Article e45312. https://doi.org/10.2196/45312
Guo, K., Zhong, Y., Li, D., & Chu, S. K. W. (2023). Effects of chatbot-assisted in-class 
debates on students’ argumentation skills and task motivation. Computers & 
Education, 203, Article 104862. https://doi.org/10.1016/j.compedu.2023.104862
Hamilton, E. R., Rosenberg, J. M., & Akcaoglu, M. (2016). The substitution augmentation 
modification redefinition (SAMR) model: A critical review and suggestions for its 
use. Tech Trends, 60(5), 433–441. https://doi.org/10.1007/s11528-016-0091-y
Han, J., Yoo, H., Kim, Y., Myung, J., Kim, M., Lim, H., … Oh, A. (2023). RECIPE: How to 
integrate Chat GPT into EFL writing education. Paper presented at the proceedings of the 
tenth ACM conference on learning @ scale, Copenhagen, Denmark. https://doi.org/ 
10.1145/3573051.3596200
Heinze, A., Procter, C., & Scott, B. (2007). Use of conversation theory to underpin 
blended learning. 1(1–2), 108–120. https://doi.org/10.1504/ijtcs.2007.014213
Hobensack, M., von Gerich, H., Vyas, P., Withall, J., Peltonen, L. M., Block, L. J., … 
Song, J. (2024). A rapid review on current and potential uses of large language 
models in nursing. International Journal of Nursing Studies, 154, Article 104753. 
https://doi.org/10.1016/j.ijnurstu.2024.104753
Kasneci, E., Sessler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., … 
Kasneci, G. (2023). Chat GPT for good? On opportunities and challenges of large 
language models for education. Learning and Individual Differences, 103, Article 
102274. https://doi.org/10.1016/j.lindif.2023.102274
Khang, A., Muthmainnah, M., Seraj, P. M. I., Al Yakin, A., & Obaid, A. J. (2023). AI-aided 
teaching model in education 5.0. In A. Khang, V. Shah, & S. Rani (Eds.), Handbook of 
research on AI-based technologies and applications in the era of the metaverse (pp. 
83–104). Hershey, PA, USA: IGI Global. 
Kirwan, A. (2023). Chat GPT and university teaching, learning and assessment: Some 
initial reflections on teaching academic integrity in the age of Large Language 
Models. Irish Educational Studies, 1–18. https://doi.org/10.1080/ 
03323315.2023.2284901
Kong, Z. Y., Adi, V. S. K., Segovia-Hern´andez, J. G., & Sunarso, J. (2023). Complementary 
role of large language models in educating undergraduate design of distillation 
column: Methodology development. Digit. Chem. Eng., 9, Article 100126. https://doi. 
org/10.1016/j.dche.2023.100126
Kumar, S., Rao, P., Singhania, S., Verma, S., & Kheterpal, M. (2024). Will artificial 
intelligence drive the advancements in higher education? A tri-phased exploration. 
Technological Forecasting and Social Change, 201, Article 123258. https://doi.org/ 
10.1016/j.techfore.2024.123258
Kuramitsu, K., Obara, Y., Sato, M., & Obara, M. (2023). Kogi: A seamless integration of 
Chat GPT into Jupyter environments for programming education. Paper presented at 
the proceedings of the 2023 ACM SIGPLAN International symposium on SPLASH-E, 
Cascais, Portugal. https://doi.org/10.1145/3622780.3623648
Laurillard, D. (2012). Teaching as a design science : Building pedagogical patterns for learning 
and technology. New York, NY: Routledge. 
Lim, W. M., Gunasekara, A., Pallant, J. L., Pallant, J. I., & Pechenkina, E. (2023). 
Generative AI and the future of education: Ragnar¨ok or reformation? A paradoxical 
perspective from management educators. International Journal of Management in 
Education, 21(2), Article 100790. https://doi.org/10.1016/j.ijme.2023.100790
Lu, Q., Yao, Y., Xiao, L., Yuan, M., Wang, J., & Zhu, X. (2024). Can Chat GPT effectively 
complement teacher assessment of undergraduate students’ academic writing? 
Assessment & Evaluation in Higher Education, 1–18. https://doi.org/10.1080/ 
02602938.2024.2301722
Mhlanga, D. (2023). Open AI in education, the responsible and ethical use of Chat GPT 
towards lifelong learning. SSRN Electronic Journal. https://doi.org/10.2139/ 
ssrn.4354422
Michel-Villarreal, R., Vilalta-Perdomo, E., Salinas-Navarro, E. D., Thierry-Aguilera, R., & 
Gerardou, F. S. (2023). Challenges and opportunities of generative AI for higher 
education as explained by Chat GPT. 13(9), 856.
Mishra, P. (2019). Considering contextual knowledge: The TPACK diagram gets an 
upgrade. J. Digit. Learn. Teach. Educ., 35(2), 76–78. https://doi.org/10.1080/ 
21532974.2019.1588611
Mishra, P., Warr, M., & Islam, R. (2023). TPACK in the age of Chat GPT and generative AI. 
J. Digit. Learn. Teach. Educ., 39, 1–17. https://doi.org/10.1080/ 
21532974.2023.2247480
Muddam, A., & Reddy, S. (2023). A guide to conversational AI: Chat GPT for higher 
education and professional development.
Murillo-Ligorred, V., Ramos-Vallecillo, N., Covaleda, I., & Fayos, L. (2023). Knowledge, 
integration and scope of deepfakes in arts education: The development of critical 
thinking in postgraduate students in primary education and master’s degree in 
secondary education. 13(11), 1073.
Niess, M. L. (2002). Preparing teachers to teach science and mathematics with 
technology. In D. Watson, & J. Andersen (Eds.), Networking the learner: Computers in 
education (pp. 689–697). Boston, MA: Springer US. 
Nikolic, S., Daniel, S., Haque, R., Belkina, M., Hassan, G. M., Grundy, S., … Sandison, C. 
(2023). Chat GPT versus engineering education assessment: A multidisciplinary and 
multi-institutional benchmarking and analysis of this generative artificial 
intelligence tool to investigate assessment integrity. European Journal of Engineering 
Education, 48(4), 559–614. https://doi.org/10.1080/03043797.2023.2213169
Nikolic, S., Sandison, C., Haque, R., Daniel, S., Grundy, S., Belkina, M., … Neal, P. 
(2024). Chat GPT, Copilot, Gemini, Sci Space and Wolfram versus higher education 
assessments: An updated multi-institutional study of the academic integrity impacts 
of generative artificial intelligence (Gen AI) on assessment, teaching and learning in 
engineering. Australasian Journal of Engineering Education, 1–28. https://doi.org/ 
10.1080/22054952.2024.2372154
Nikolic, S., Suesse, T. F., Grundy, S., Haque, R., Lyden, S., Hassan, G. M., … Lal, S. 
(2024). Laboratory learning objectives: Ranking objectives across the cognitive, 
psychomotor and affective domains within engineering. European Journal of 
Engineering Education, 49(3), 454–473. https://doi.org/10.1080/ 
03043797.2023.2248042
Page, M. J., Mc Kenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., 
… Moher, D. (2021). The PRISMA 2020 statement: An updated guideline for reporting 
systematic reviews (Vol. 372, p. n71). https://doi.org/10.1136/bmj.n71. J BMJ.
Park, Y., & Doo, M. Y. (2024). Role of AI in blended learning: A systematic literature 
review. The International Review of Research in Open and Distributed Learning, 25, 
164–196. https://doi.org/10.19173/irrodl.v25i1.7566
Pitso, T. (2023). Post-COVID-19 higher learning: Towards Telagogy, A Web-based 
learning experience. IAFOR J. Edu., 11, 39–59. https://doi.org/10.22492/ije.11.2.02
Puentedura, R. R. (2009). As we may teach: Educational technology, from theory into 
practice. In Apple.
Qureshi, B. (2023). Chat GPT in Computer science curriculum assessment: An analysis of 
its Successes and Shortcomings. Paper presented at the Proceedings of the 2023 9th 
International Conference on e-Society, e-Learning and e-Technologies, <conf-loc>, 
Portsmouth, <country>United Kingdom</country>, </conf-loc>. https://doi.org/ 
10.1145/3613944.3613946
Rudolph, J., Tan, S., & Tan, S. (2023). Chat GPT: Bullshit spewer or the end of traditional 
assessments in higher education? J. appl. learn. teach., 6(1), 342–363.
Silitonga, L. M., Hawanti, S., Aziez, F., Furqon, M., Zain, D. S. M., Anjarani, S., et al. 
(2023). The impact of AI chatbot-based learning on students’ motivation in English 
writing classroom, 2023//. Paper presented at the innovative technologies and learning, 
Cham.
Simms, R. C. (2024). Work with Chat GPT, not against: 3 teaching strategies that harness 
the power of artificial intelligence. Nurse Educator, 49(3), 158–161. https://doi.org/ 
10.1097/NNE.0000000000001634
Sohail, S. S., Farhat, F., Himeur, Y., Nadeem, M., Madsen, D.Ø., Singh, Y., … Mansoor, W. 
(2023). Decoding Chat GPT: A taxonomy of existing research, current challenges, and 
possible future directions. Journal of King Saud University - Computer and Information 
Sciences, 35(8), Article 101675. https://doi.org/10.1016/j.jksuci.2023.101675
Speth, S., Meißner, N., & Becker, S. (2023). Investigating the use of AI-generated 
exercises for beginner and intermediate programming courses: A Chat GPT case 
study. Paper presented at the 2023 IEEE 35th international conference on software 
engineering education and training (CSEE&T).
Suryanto, T. L. M., Wibawa, A. P., Hariyono, H., & Nafalski, A. (2023). Evolving 
conversations: A review of chatbots and implications in natural language processing 
for cultural heritage ecosystems. Int. J. Robot. Control Syst., 3(4), 52. https://doi.org/ 
10.31763/ijrcs.v3i4.1195, 2023.
Tlili, A., Shehata, B., Adarkwah, M. A., Bozkurt, A., Hickey, D. T., Huang, R., et al. 
(2023). What if the devil is my guardian angel: Chat GPT as a case study of using 
chatbots in education. Smart Learn. Environ., 10(1), 15. https://doi.org/10.1186/ 
s40561-023-00237-x
Uddin, S. M. J., Albert, A., Ovid, A., & Alsharef, A. (2023). Leveraging Chat GPT to aid 
construction hazard recognition and support safety education and training. 15(9), 
7121.
Wang, & Feng, Y. (2024). An experimental study of Chat GPT-assisted improvement of 
Chinese college students’ English reading skills: A case study of dear life. Paper 
presented at the proceedings of the 15th international conference on education technology 
and computers, <conf-loc>, Barcelona, <country>Spain</country>, </conf-loc>. 
https://doi.org/10.1145/3629296.3629300
Wang, Wang, M., Xu, X., Yang, L., Cai, D., & Yin, M. (2023). Unleashing Chat GPT’s power: 
A case study on optimizing information retrieval in flipped classrooms via prompt 
engineering. IEEE Transactions on Learning Technologies. https://doi.org/10.1109/ 
TLT.2023.3324714
Wang, Wang, M., Xu, X., Yang, L., Cai, D., & Yin, M. (2024). Unleashing Chat GPT’s 
power: A case study on optimizing information retrieval in flipped classrooms via 
prompt engineering. IEEE T Learn Techno L., 17, 629–641. https://doi.org/10.1109/ 
TLT.2023.3324714
Widiati, U., Rusdin, D., Indrawati, I., Marzuki, & Govender, N. (2023). J. C. E. The impact 
of AI writing tools on the content and organization of students’ writing: EFL teachers’ 
perspective (Vol. 10).
Zhai, X. (2023). Chat GPT for next generation science learning. J XRDS, 29(3), 42–46. 
https://doi.org/10.1145/3589649
Zhao, X., Aydeniz, M., & Yuan, F. (2023). Exploring opportunities and challenges of AI- 
incorporated biomedical informatics education: A qualitative study.
M. Belkina et al.                                                                                                                                                                                                                                
Computers and Education: Artiϧcial Intelligence 8 (2025) 100407
