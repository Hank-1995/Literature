# The relationship between media literacy and well-being: A systematic review and meta-analysis

## Metadata
- **Author**: Chloe S. Gordon
- **Subject**: Educational Research Review, 49 (2025) 100731. doi:10.1016/j.edurev.2025.100731
- **Creator**: Elsevier
- **Producer**: Acrobat Distiller 8.1.0 (Windows)
- **Creation Date**: D:20250918012948Z
- **Modification Date**: D:20250918102430Z
- **Source File**: The-relationship-between-media-literacy-and-well-being-_2025_Educational-Res.pdf
- **Converted**: 2025-10-23 22:46:13

---

## Content

--- Page 1 ---

Review
The relationship between media literacy and well-being: A 
systematic review and meta-analysis
Chloe S. Gordon a,*
, Kelly Ferber a, Tanya Notley b, Rachel F. Rodgers c,d, 
Emma Bradshaw a, Geetanjali Basarkod a, Joel Anderson e, Siˆan A. Mc Lean f, 
Simone Mizzi g, Hannah K. Jarman h, Jessica Dickson i, Taren Sanders a, Amy Slater j, 
Erin Pearson k, Theresa Dicke a
a Institute for Positive Psychology and Education, Australian Catholic University, Australia
b School of Humanities and Communication Arts / Institute for Culture and Society, Western Sydney University, Sydney, Australia
c APPEAR, Department of Applied Psychology, Northeastern University, Boston, USA
d Department of Psychiatric Emergency & Acute Care, Lapeyronie Hospital, CHRU Montpellier, Montpellier, France
e Australian Research Centre in Sex, Health and Society, La Trobe University, Melbourne, Australia
f School of Psychology and Public Health, La Trobe University, Melbourne, Australia
g School of Health and Biomedical Sciences, RMIT University, Melbourne, Australia
h School of Psychology, Deakin University, Melbourne, Australia
i Library Services for Research and Learning, Australian Catholic University, Melbourne, Australia
j Centre for Appearance Research, University of West of England, Bristol, UK
k Alannah & Madeline Foundation, Melbourne, Australia
A R T I C L E  I N F O
Keywords:
Digital literacy
Media
Self-esteem
Psychological well-being
Education
A B S T R A C T
Media literacy and well-being are interconnected topics that have garnered increasing attention 
in recent years due to the proliferation of media platforms and the influence they can exert on 
individuals’ mental health and overall well-being. Media literacy is a lifelong educational process, 
defined as the ability to critically access, analyse, evaluate, create, and contribute to media. It is 
especially important for children and adolescents who are more susceptible to negative media 
influences. Well-being encompasses both feeling good and functioning effectively, and is asso-
ciated with numerous benefits including increased productivity and creativity, and better re-
lationships, health and life expectancy. Guided by the 2020 Preferred Reporting Items for 
Systematic Review and Meta-Analysis (PRISMA) statement, this systematic review and meta- 
analysis examined the associations between media literacy and well-being. The search identi-
fied 15 studies involving 47 effect sizes across a variety of dimensions of media literacy. Together, 
the studies had 16,632 participants and 51.8 % comprised school-aged populations. The analysis 
initially revealed a statistically significant, small to medium, positive association between media 
literacy and well-being (r = .19, 95 % CI [.01, .35]); however, this association was no longer 
significant following sensitivity analyses. The ‘Media Literacy Dimension’ significantly moderated 
the pooled effect. A medium-sized positive association between media literacy and well-being was 
observed when the media literacy measure was solely focussed on analysing/evaluating the 
media (r = .24, 95 % CI [.05, .41]). No other significant moderating factors were found. However, 
due to limitations such as small sample size and significant heterogeneity among the studies, 
these findings should be interpreted with caution, especially when considering implications for 
* Corresponding author. 250 Victoria Parade, East Melbourne, Victoria, Australia.
E-mail address: chloe.gordon@acu.edu.au (C.S. Gordon). 
Contents lists available at Science Direct
Educational Research Review
journal homepage: www.elsevier.com/locate/edurev
https://doi.org/10.1016/j.edurev.2025.100731
Received 1 March 2024; Received in revised form 3 August 2025; Accepted 11 September 2025  
Educational Research Review 49 (2025) 100731 
Available online 12 September 2025 
1747-938X/© 2025 The Authors. 
Published by Elsevier Ltd. 
This is an open access article under the CC BY license 
( http://creativecommons.org/licenses/by/4.0/ ). 

--- Page 2 ---

educational policy or curriculum integration. Further research, especially using longitudinal and 
experimental designs, is needed to better understand the nature and direction of this relationship 
and to inform practical applications.
1. Introduction
Access to, and engagement with, media has become ubiquitous and often begins from early childhood (Livingstone, 2017). Media 
types have diversified with the proliferation of new technologies, ranging from traditional platforms such as billboard advertising and 
newspapers, to digital and participatory technologies such as social media and virtual reality (Mills & Brown, 2022; Pfaff-Rüdiger & 
Riesmeyer, 2016). Media literacy is a lifelong educational process, defined as the ability to critically access, analyse, evaluate, create, 
and contribute to, media (Aufderheide & Firestone, 1993; Cho et al., 2024; NAMLE, 2020; Rasi et al., 2019). Media literacy in-
corporates several closely interrelated competencies, including multiliteracy, news literacy, health media literacy, digital literacy, 
coding literacy, data literacy, AI literacy, and platform literacy. These competencies are essential for navigating and critically engaging 
with media in diverse contexts (Rasi et al., 2019).
Media literacy needs and interests evolve over people’s lifespan, with different life experiences, societal contexts, and technological 
advancements shaping individuals’ media literacy skills and understanding (Rasi et al., 2019). For children and adolescents in 
particular, media literacy may be a protective factor from negative media influences on behaviours such as drinking, smoking, sub-
stance use, and consuming an unhealthy diet (Xie et al., 2019). As such, media literacy may reduce ill-being. Young people are 
particularly vulnerable to negative media influences given biological, cognitive and psychosocial factors such as hormonal changes 
that encourage risk-taking behaviours and increased desire for peer approval (Steinberg, 2008). However, fostering a deeper un-
derstanding and critical awareness of media narratives can reduce the persuasive appeal of false and misleading media narratives 
(Hobbs, 2024; Pinkleton et al., 2012).
Researchers increasingly argue that media literacy should be understood as a lifelong learning pursuit that is a pre-requisite for full 
participation in a digitally-mediated society. Supporting lifelong media literacy learning requires interventions that appeal to people at 
different ages and are effective in developing media knowledge, skills, and critical thinking over time (Notley et al., 2024). Support for 
a lifelong approach to media literacy has led governments around the world to introduce national media literacy strategies (Dezuanni 
et al., 2021). In Australia, the Federal Government announced funding a national media literacy strategy in late 2024 (Department of 
the Prime Minister and Cabinet, 2024). Subsequently, the Australian Curriculum, Assessment and Reporting Authority (ACARA, 2025) 
published a new resource to support Australian students’ understanding of media literacy.
Well-being is a multi-dimensional construct that is associated with numerous benefits including increased productivity and 
creativity, and better relationships, health and life expectancy (Huppert, 2017; Ruggeri et al., 2020). Definitions of well-being vary 
widely in the literature, however a commonly accepted definition is well-being as a combination of feeling good (i.e., hedonic 
well-being), and functioning effectively (i.e., eudaimonic well-being (Huppert, 2009). The word ‘flourishing’ has been used synony-
mously with well-being, including features such as positive emotion and self-esteem (Huppert & So, 2013). From Huppert and So’s 
(2013) perspective, ill-being is seen as the opposite of the spectrum of well-being, and may include symptoms connected to depression, 
anxiety and negative affect. International data indicates that many struggle with low emotional well-being and despair, with 12 % of 
men and 15 % of women experiencing more negative than positive feelings in a typical day (OECD, 2020, p. 247).
Media literacy and well-being are interconnected topics that have garnered increasing attention in recent years due to the pro-
liferation of media platforms and the influence they can exert on individuals’ mental health and overall wellbeing (Coyne., 2020; Keles 
et al., 2020; Rasi et al., 2019; Seabrook et al., 2016). Media literacy education is expected to support well-being through empowering 
individuals to make informed decisions about the media content they consume and create, thereby fostering positive media experi-
ences and protecting from negative media experiences (Education and Culture, 2013; Feerrar, 2022; Finnish Ministry of Education and 
Culture, 2013; Livingstone et al., 2005; Xie et al., 2019). In this way, media literacy may both reduce ill-being and promote well-being.
The full potential of media literacy for impacting positive development and well-being is most likely to be realised when all three 
core competency dimensions - accessing, analysing/evaluating and creating - are emphasised. Accessing media encompasses a broad 
range of actions, from using media to stay connected to friends and family, to finding news stories published in different countries 
about the same event. Analysing and evaluating media includes, for example, knowing how to think critically about the media you 
consume and understanding how the media impacts and influences you as a person, as well as the broader society. Creating and 
contributing to media involves, for example, using media to represent your identity and worldview, and developing, sharing and 
disseminating messages in a way that is value-consistent (Chambers et al., 2022; Cho et al., 2024). While all of these core dimensions 
are important, research (e.g., Banerjee & Greene, 2007) suggests that media literacy interventions are most effective when they 
integrate both analysis and production, as this combination enhances the practical application of critical media literacy skills. Building 
on this, we hypothesise that combining all three dimensions—accessing, analysing/evaluating, and creating—will have synergistic 
benefits. This hypothesis will be empirically tested in our study.
1.1. Prior reviews and meta-analyses
To date, systematic reviews on media literacy have generally focussed on specific health-related domains. Gordon et al. (2015)
examined ten alcohol media literacy interventions for school-aged children, including randomised controlled trials and 
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 3 ---

quasi-experimental designs, and reported effects on knowledge, skills, attitudes, and behaviors. Mc Lean et al. (2016b) reviewed 
sixteen studies (eight cross-sectional, seven intervention) across school-aged and adult populations. In cross-sectional studies, higher 
media literacy was associated with lower body dissatisfaction in some, but not all studies, with findings appearing to be related to the 
type of media literacy construct assessed. Both reviews found that media literacy interventions improved media literacy constructs and 
some drinking or body-related outcomes.
Meta-analyses have similarly focussed on targeted domains. Kurtz et al. (2022) analysed seventeen school-based media literacy 
programs to reduce body dissatisfaction in youth (g = .29), with no significant moderators. Xie (2019) reviewed twenty-three qua-
si-experimental interventions addressing deviant behaviors (e.g., drinking, smoking) in predominantly adolescent populations, finding 
a moderate reduction at posttest (d = −.32). Effect sizes varied by measurement times, age, gender, and type of deviant behavior type. 
Jeong et al. (2012) took a broader focus, synthesising fifty-one media literacy interventions on diverse topics delivered in both school 
and community settings. They reported a moderate overall effect (d = .37) on outcomes such as media knowledge and behavioral 
beliefs. Moderator analyses indicated that interventions with more sessions yielded larger effects, whereas those with additional 
components produced smaller effects.
Our study builds upon these earlier reviews. Similar to Jeong et al. (2012), our study uses a broad approach to examine the link 
between media literacy and well-being across diverse populations, regardless of content domain. Except for Mc Lean et al. (2016b), 
previous reviews have not included cross-sectional outcomes and little attention has been given to potential moderators of effects. 
Previous reviews examining intervention effects have primarily focused on school-based settings, with children and adolescents as the 
main target groups. One criticism of this approach is the sometimes didactic nature of the programs. Telling adolescents, in particular, 
to not engage in a specific behaviour can in fact have the opposite effect of creating resistance to change, or making the behaviour more 
appealing (Gordon et al., 2021). Media literacy programs that focus more broadly on well-being may be viewed by young people as 
being more relevant and applicable to their lives. The positive framing of well-being, rather than focussing on negative behaviours such 
as violence, aligns with an asset-based approach to health. This approach recognises individuals’ existing resources and empowers 
them with skills to make informed choices about their health and well-being (Matthews et al., 2015). By incorporating cross-sectional 
studies, our review offers a more comprehensive view of media literacy’s potential impact on well-being across the lifespan.
The association between media use and mental health, particularly depression and anxiety, has been the subject of several reviews 
(Coyne et al., 2020; Keles et al., 2020; Li & Brar, 2022; Seabrook et al., 2016), revealing a complex relationship and mixed findings. An 
indirect, and potentially nonlinear association has emerged with several related elements. For instance, insomnia and sleep-related 
issues often act as mediators between social media use and depressed mood (Keles et al., 2020), while cognitive dispositions such 
as rumination increase the negative association between social media use and depression and anxiety in certain individuals. 
Conversely, social media and other digital technologies can offer benefits such as social support, connectedness and avenues for 
help-seeking, which are associated with lower levels of depression and anxiety (Seabrook et al., 2016; Li & Brar).
Several gaps exist in the current evidence base. First, there have been no reviews that examine how the ability to critically engage 
with the media in an educated way impacts well-being more generally. Given the integral part that the media plays in society and its 
enduring nature, it is valuable to understand the relation between being able to critically access, analyse, evaluate, create, and 
contribute to media, and mental well-being. Second, less is known about how the association between media literacy and well-being 
occurs naturally in a setting without intervention, and whether having high levels of media literacy is indeed protective. Third, it is not 
known how the association between media literacy and well-being differs across population groups, from school-aged children to older 
adults. This gap is particularly important in light of the lifelong relevance of media literacy (Notley et al., 2024). Media literacy skills 
are taught in varied contexts, not only to young people by educators and researchers in school settings, but also to older adults by 
Fig. 1. Hypothesised relationships between media literacy and well-being. 
Note. Media experiences are included as a potential conceptual mechanism in the pathway from media literacy to well-being, but we were not able 
to formally test it as a mediator because most studies were cross-sectional and longitudinal studies would be needed to formally test mediation.
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 4 ---

graduate students, professionals at senior centers, ICT instructors, or librarians (Rasi et al., 2021). Understanding different experiences 
and contexts is essential for tailoring interventions to the needs of each group.
This review aims to provide insights into the relation between media literacy and mental health and well-being. If a positive as-
sociation is found, it may lead to more targeted media literacy resources and programs tailored to individuals experiencing lower levels 
of well-being. It may also provide greater impetus for focussing on media literacy in school and online learning environments and 
provide an additional avenue for teaching media literacy within a well-being curriculum, or with a well-being lens.
1.2. The present study
The overarching aims of this study are to understand a) the extent to which media literacy and well-being are linked, and b) how 
media literacy and well-being are measured in the extant literature, given the complex and multi-dimensional nature of both con-
structs. The following hypotheses were made and are visualised in Fig. 1. 
a) Greater media literacy will be associated with higher well-being (Hypothesis 1) given the dual ability of media literacy to foster 
positive media experiences and protect from negative media experiences (Education and Culture, 2013; Feerrar, 2022; Finnish 
Ministry of Education and Culture, 2013; Livingstone et al., 2005; Xie et al., 2019)
b) The effect of media literacy on both positive markers of well-being (e.g., positive affect) and measures of ill-being (e.g., negative 
affect) will be equivalent. That is, we do not expect the well-being outcome type to moderate the main effect of media literacy on 
outcomes (Hypothesis 2). This expectation is based on both the protective and empowering nature of media literacy to reduce 
negative or harmful forms of media engagement and increase beneficial uses of media (Feerrar, 2022; Livingstone et al., 2005; Xie 
et al., 2019).
c) We expect that more holistic measures of media literacy (i.e., measures that capture the core dimension of analysing/evaluating 
media plus an additional dimension of accessing and/or creating/contributing to media), will yield greater benefits compared to 
measures solely focussed on the dimension of analysing/evaluating media (Hypothesis 3). This expectation is based on the un-
derstanding that actively creating or contributing to media facilitates the practical application of critical media literacy skills 
(Banerjee & Greene, 2007; Gordon et al., 2018), while accessing media allows users to interact with media tailored to their specific 
needs, such as self-expression, escapism, or educational purposes (Dindar & Yaman, 2018; Sendurur et al., 2015).
d) We expect to see no moderation effects related to demographic variables (Hypothesis 4). Prior reviews of media literacy in-
terventions have found no moderation effects related to gender, age or country, suggesting that media literacy interventions can be 
generalised to various types of individuals (Xie et al., 2019).
In the preregistration we had included an additional research question aimed at understanding the association between media 
literacy and mental health. However, following the data extraction phase, it became evident that there was not enough available data 
to answer this question and hence it was removed from our study. Consequently, studies were reorganised into two categories, 
measures of well-being (e.g., positive affect) and measures of ill-being (e.g., negative affect).
2. Method
This systematic review protocol was registered on the Open Science Framework (OSF) on August 30, 2023 (https://doi.org/10. 
17605/OSF.IO/DZW87) and has been conducted in accordance with the Preferred Reporting Items for Systematic Review and Meta- 
Analysis statement (PRISMA; Page et al., 2021). The R code and data underlying the meta-analysis has also been made publicly 
available via the above OSF link.
2.1. Search strategy
Key terms were identified from the research hypotheses (media literacy, well-being), previous reviews and the academic literature. 
To ensure a comprehensive and holistic search strategy, the search terms extended beyond simply using the terms ‘media literacy’ and 
‘well-being’. Instead, a search strategy encompassing terms closely connected to understandings of media literacy and well-being were 
used. Search terms underwent numerous refinement processes as a result of scoping searches, consultation with co-authors, and 
consultation with a senior librarian. Search terms were also tested to ensure they retrieved pre-identified papers that met the inclusion 
criteria. The preliminary searches were collaboratively piloted by the lead researcher and the senior librarian to reach consensus on the 
strategy. Final database searches were then executed by the senior librarian who has advanced training in systematic searching. For the 
purpose of this review, media encompassed all forms of media including “old media” such as TV and “new media” such as social 
networking sites (Erstad & Amdam, 2013; Potter, 2013). Media literacy was defined as the ability to critically access, analyse, evaluate, 
create, and contribute to, media (Aufderheide & Firestone, 1993; NAMLE, 2020). Well-being was defined as a multi-dimensional 
construct including both subjective and psychological measures of well-being (Diener et al., 1999; Huppert, 2009; Ryff, 1989) and 
the PERMA model (positive emotions, engagement, relationships, meaning and achievement; Seligman, 2018). Mental health was also 
included as a distinct and related concept to capture ill-being and was operationalised with a focus on depression, anxiety, stress and 
distress, given they are among the most common and pervasive mental health concerns (Cusack et al., 2019; Mc Guire et al., 2022). See 
Table 1 for the final search terms used.
The search was completed in the following databases: Medline Complete, ERIC, APA Psyc INFO, Soc INDEX and CINAHL (Ebsco), 
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 5 ---

Web of Science and Scopus from inception to September 7, 2023. These databases were selected as they provided comprehensive 
subject specific coverage as well as a broader multi-disciplinary perspective of the literature. Databases were searched using com-
parable search strategies, with adapted index terms for each database. A sample search strategy used in Medline Complete is provided 
in Table S1. Reference lists of the studies included in the review were explored, and forward citation searches were conducted, to check 
for any other relevant studies not previously identified.
A comprehensive grey literature search was also conducted. An advanced Google Search was performed across six sites or domains 
(.org, org.au, org.uk, gov.au, gov.uk, .gov) using a simple keyword search in the ‘exact words’ box and the file type set to PDF. The first 
20 entries for each domain were screened for potential relevance at the title/abstract level. A targeted web-based search was also 
performed across twelve organisational websites identified by the research team, with 668 reports screened for potential relevance at 
the title level.
2.2. Eligibility criteria
To be included in the review, studies had to fulfil the following criteria. 
1. Be quantitative and include original data, e.g., survey data and standardised observations.
2. Assess media literacy. Given that critical thinking is the focal skill of media literacy (Potter, 2014), the ability to analyse and/or 
evaluate media had to be captured in the measure used.
3. Assess well-being/ill-being.
4. Examine the association between media literacy and well-being/ill-being (i.e., correlation, regression, or other effect size).
No publication date, status or language restrictions were imposed.
2.3. Identification of records
All results from the database searches were imported into Covidence Systematic Review software (Veritas Health Innovation; 
Melbourne, VIC, Australia) which was used to manage records throughout the review. Results from the advanced Google Search, 
targeted web-based searches and reference lists of included studies were imported into Microsoft Excel spreadsheets. Forward and 
backward citation searches of included studies were performed using Scopus. Potentially relevant documents from the grey literature 
searches and forward/backward citation searches were uploaded to Covidence for title/abstract and full-text screening.
2.4. Record screening
A PRISMA flow chart summarising the article selection process is presented in Fig. 2. At the first-round of screening, titles and 
Table 1 
Search terms.
Media literacy
Media
Mental health
Well-being
“media literac*” 
“media educat*” 
“media analysis” 
“media 
competenc*” 
“critical think*” 
“critical analysis” 
“critical evaluat*” 
“digital literac*” 
“advertising 
literacy” 
media 
“social network*” 
advertis*
“mental health” 
“mental status” 
“mental illness” 
“mental distress” 
“mental disorder” 
“psychological distress” 
psychopathology 
affect 
anxiety 
depress* 
stress 
mood 
K10 
“Kessler psychological distress scale” 
CESD 
“center for epidemiologic studies 
depression scale” 
PHQ 
“patient health questionnaire” 
DASS 
“depression anxiety stress scales”
well-being 
wellbeing 
WHO-5 
“well-being index” 
WEMWBS 
“warwick edinburgh 
mental well-being 
scale” 
resilience* 
coping 
“personal growth” 
“growth mindset” 
self-esteem 
self-efficacy 
SWB 
“subjective well-being” 
QOL 
“quality of life” satisfaction 
PWB 
“psychological well-being” 
“psychological functioning” flourish* 
PERMA 
“Positive Emotions Engagement Relationships Meaning 
Accomplishment” emotion* 
engagement 
meaning*
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 6 ---

abstracts of articles were screened in duplicate against the eligibility criteria. The screening was shared amongst the authorship team 
(all articles were screened by the first author and then one of the remaining authorship team independently). Interrater reliability was 
assessed using Cohen’s Kappa (κ), which accounts for chance agreement. At the first round, the agreement between reviewers was 95.7 
% (κ = .45), which suggests a moderate level of interrater agreement (Landis & Koch, 1977). At the second-round of screening (i.e., 
full-text), the 104 articles that met the criteria based on title and abstract had their full-texts screened in duplicate according to the 
eligibility criteria. The screening was shared between the authorship team in the same way as the first-round of screening. At this 
round, the observed agreement was 91.2 % (κ = .62), which suggests a substantial level of interrater agreement between reviewers.
Conflicts at each stage were resolved through discussion or by a third reviewer. Any full-text articles unavailable to the research 
team were requested through inter-library loans or the corresponding author of that article. Papers written in a language other than 
English had their data extracted and translated into English by a member of the research team. The most common exclusion reasons 
were only one variable of interest having been assessed (n = 42) or the association between variables not having been examined 
statistically (n = 21). Fifteen studies satisfied the inclusion criteria and were retained in the study. Seventy-one entries were deemed as 
potentially relevant from the grey literature searches and forward/backward citations searches, however no additional studies were 
retained in the study. Thus, a total of fifteen studies were included for the review and meta-analysis.
2.5. Data extraction
Data were extracted into a custom-made systematic review form in Microsoft Excel. Two reviewers piloted the form using four 
studies and then refined it following feedback from the research team. The following data was double extracted: Publication details 
(first author, year of publication & paper title), peer-reviewed status, type of report, study characteristics (country, study setting, 
participants, age [M, SD, range], gender, study design), media literacy measure(s) used (name, subdomain, reference, dimension of 
media literacy, example item and scale reliability), well-being/ill-being measure(s) used (domain, subdomain, well-being/ill-being, 
name, reference, scale reliability), correlation and regression coefficients as well as any effect size that indicates an association be-
tween the media literacy and well-being/ill-being variables and calculation of effect size. Information about whether data were 
collected in single or multiple sessions was rarely reported clearly or consistently across studies. Therefore, this variable was not 
included in the data extraction process. Where necessary, the corresponding author of included studies was contacted by email to 
obtain any required data not presented in the published paper.
2.6. Quality assessment
The quality of studies was assessed using the Joanna Briggs Institute’s (JBI) critical appraisal checklist for analytical cross sectional 
studies (Moola et al., 2020). This tool has eight items with a rating system of ‘yes’, ‘no’, ‘unclear’, and ‘not applicable’. Cut-off val-
ues/scores for determining whether a study is low, moderate or high quality are advised against and therefore were not used, given that 
the appraisal questions are not all “equal” (Moola et al., 2020). The JBI tool was selected because it includes a critical appraisal 
checklist specifically designed for analytical cross-sectional studies and is widely used in systematic reviews (Barker et al., 2023). 
Fig. 2. Prisma diagram of the review process.
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 7 ---

Furthermore, the tool’s validity has been strengthened through recent work by the JBI Evidence Synthesis Methodology Group, which 
mapped questions from the checklist to established risk-of-bias frameworks (Barker et al., 2023). In this mapping exercise, the JBI 
checklist for analytical cross-sectional studies demonstrated strong alignment with domains from the ROBINS-I and ROBINS-E tools 
(Barker et al., 2023; Appendix IV).
2.7. Analysis
A multilevel meta-analysis with meta-regression was conducted using meta SEM (Version 1.2.5.1; Cheung, 2015) in R (Version 
4.2.1; R Core Team, 2022), to examine the link between media literacy and well-being and the effects of potential moderators. 
Meta SEM offers a transparent approach to estimating a three-level random effects model with effect sizes nested within studies to 
account for dependency of multiple effects extracted from the same report, and to explore the heterogeneity both within and between 
studies. We report separate I2 estimates for within-study (level 2) and between-study (level 3) heterogeneity, reflecting the proportion 
of total variance not due to sampling error at each level. Level 3 estimates can be unstable with a small number of studies so we 
interpreted them with caution. We used restricted maximum likelihood estimation (REML) and specified a full random-effects 
structure to model dependencies robustly (Cheung, 2015).
Pooled effect sizes for predictor-outcome pairs were calculated where there were at least two studies. Effect sizes were extracted in 
the form of Pearson’s r and standardized regression coefficients. Effect sizes in the form of standardised regression coefficients were 
converted into a correlation coefficient using the formula by Peterson and Brown (2005). All effect sizes were extracted and trans-
formed into Fisher’s z and variance (v) and standard errors (SE) were calculated. After analysis, effect sizes were transformed back into 
Pearson’s r for ease of interpretation. The inclusion of diverse study designs is not problematic in this case because we only analysed 
correlations that reflect the same conceptual association—between media literacy and well-being—at a single time point, prior to any 
later interventions or treatments. For the five studies that used an intervention, longitudinal or experimental design, only baseline 
correlational data was inputted. As such, we have not aggregated intervention effects of causal estimates, and our effect size estimates 
can be interpreted consistently as zero-order associations. This approach is common in meta-analyses across literatures with het-
erogeneous methods (see Borenstein et al., 2021).
Moderation analyses were conducted when there was evidence of at least moderate heterogeneity (I2 > .25). Potential moderators 
included age, proportion of gender, media literacy dimension, and well-being/ill-being to determine if they improved the baseline 
model between media literacy and well-being. Age was measured as a continuous variable. Proportion of gender was also measured as 
a continuous variable indicating an increasing proportion of females in the study sample. Well-being effects were categorised as either 
well-being (e.g., self-esteem) or ill-being (e.g., distress). Publication bias was also examined using funnel plots and multilevel meta- 
analytic Egger’s regression test (Egger MLMA; Rodgers & Pustejovsky, 2021).
2.8. Effect size magnitudes
We interpret effect sizes consistent with the contemporary benchmarks proposed by Funder and Ozer (2019) and Gignac and 
Szodorai (2016). Drawing from a systematic review and a meta-analytic synthesis, respectively, both studies converged on equivalent 
guidelines for evaluating the practical and empirical significance of correlational effects. Funder and Ozer (2019) suggested that 
correlations near .05 reflect very small effects, .10 corresponds to small effects, .20 indicates medium effects, and .30 denotes large 
effects. Gignac and Szodorai’s (2016) meta-analysis of 708 effect sizes found comparable thresholds, with correlations of .10 deemed 
small, .20 viewed as typical, and .30 considered relatively large. Rather than serving as rigid thresholds, these guidelines are intended 
to help contextualise findings within the broader landscape of psychological research and inform judgments about their likely 
real-world implications. We, therefore, adopted these conventions in interpreting and reporting our results.
3. Systematic review results
3.1. Study characteristics
All 15 studies were published between 2013 and 2023 and the majority (n = 13) were peer-reviewed and published in the last five 
years (n = 10). Six of the studies were conducted in the USA (Bennett, 2020; Lepore et al., 2019; Parcell et al., 2023; Stamps, 2023; 
Volpe et al., 2021; Wright et al., 2022). The remaining studies were each conducted in a different country across the continents of Asia 
(Hung et al., 2021; Tran-Duong & Vo-Thi, 2023), Europe (Picton et al., 2020; Rojo et al., 2023; Scandurra et al., 2022; Schreurs & 
Vandenbosch, 2022; Spielvogel & Terlutter, 2013; Yavuzalp et al., 2021) and North America (S´anchez-Reina & Gonz´alez-Lara, 2022; 
See Table S2 for study characteristics).
3.2. Research design and participants
Ten studies were cross-sectional, one study was longitudinal (Schreurs & Vandenbosch, 2022), three were intervention studies 
(Bennett, 2020; Lepore et al., 2019; Wright et al., 2022), and one was an experimental study (Parcell et al., 2023). The 15 studies 
comprised a total of 16,632 participants (sample ranged in each study from 94 to 7494). Three of the studies had exclusively female 
samples (Bennett, 2020; Lepore et al., 2019; Parcell et al., 2023) and the remaining studies had between 40 and 65 % females in their 
sample. Three studies focussed on school-aged children and comprised 51.8 % of the overall sample (Picton et al., 2023; Rojo et al., 
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 8 ---

2023; Spielvogel & Terlutter, 2013), while one study focussed on both school-aged and young adults under 30 years (Schreurs & 
Vandenbosch, 2022). The remaining eleven studies focussed on adults, with six of them specifically focussed on university stu-
dents/young adults (typically 19–26 years; Bennett, 2020; Parcell et al., 2023; Tran-Duong & Vo-Thi, 2023; Volpe et al., 2021; Wright 
et al., 2022; Yavuzalp et al., 2021). Considerable diversity emerged amongst the populations represented in the studies, including a 
study focussed on breast cancer survivors (Lepore et al., 2019), Black participants in the US (Stamps, 2023), as well as general 
populations (e.g., a convenience sample of university students; Tran-Duong & Vo-Thi, 2023). Several studies were conducted during 
the COVID-19 pandemic, with five studies specifically focussed on the COVID-19 context (Hung et al., 2021; Parcell et al., 2023; 
S´anchez-Reina & Gonz´alez-Lara, 2022; Scandurra et al., 2022; Yavuzalp et al., 2021; See Table S3 for study design and participants).
3.3. Quality assessment
The studies were evaluated for eight potential sources of bias using the JBI Critical Appraisal Checklist for Analytical Cross- 
Sectional Studies (Moola et al., 2020). The first and second author independently evaluated studies on each of the areas of poten-
tial bias. The highest level of risk for any given study was two out of the eight areas rated as having a risk of bias, with the majority of 
studies having low risk of bias (see Table S4). The most common source of bias, identified in eight studies (Hung et al., 2021; Lepore 
et al., 2019; Parcell et al., 2023; Picton et al., 2020; S´anchez-Reina & Gonz´alez-Lara, 2022; Tran-Duong & Vo-Thi, 2023; Wright et al., 
2022; Yavuzalp et al., 2021), was the lack of a strategy utilised to deal with potential confounds. Overall, all studies were found to be 
predominantly low in risk across all areas.
3.4. Media literacy measures
All fifteen studies used self-report measures of media literacy. However, no common measures of media literacy were used (see 
Fig. 3. Moderation analysis of the effects of the media literacy and well-being meta-analytic model. 
Note. Moderation matrix showing the effects of covariates across the model, based on the 15 quantitative studies included in the analysis. White cells 
indicate statistically significant moderators; grey cells indicate non-significant moderators. Age was mean-centered, so the intercept reflects the 
estimated effect size at the average sample age. The slope (labeled “Yearly”) represents the change in effect size for each one-year increase in mean 
age. Female Prop is a continuous variable representing the proportion of females in the sample; the intercept reflects the estimated effect size when 
the female proportion is 0, and the slope reflects the change in effect size for each unit increase. Baseline refers to the model without any adjustment 
for moderating covariates.
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 9 ---

Table S5). Four studies utilised more than one media literacy measure (Bennett, 2020; Schreurs & Vandenbosch, 2022; Stamps, 2023; 
Wright et al., 2022) and six studies utilised measures with multiple domains (Bennett, 2020; Hung et al., 2021; Schreurs & Van-
denbosch, 2022; Tran-Duong & Vo-Thi, 2023; Wright et al., 2022). The majority of the studies used established measures of media 
literacy, while Yavuzalp et al. (2021), Hung et al. (2021), and S´anchez-Reina and Gonz´alez-Lara (2022) included measures that were 
purpose-built for their specific studies. Spielvogel and Terlutter (2013) did not report scale reliability. All of the other studies reported 
scale reliability with acceptable Cronbach Alpha’s ranging from .71 to .95.
The first and second authors independently coded each measure across three dimensions of media literacy: access, analyse/ 
evaluate, and create (Chambers et al., 2022; Cho et al., 2024). Interrater agreement was high for the create dimension (κ = .94) and 
moderate for access (κ = .50). For the analyse/evaluate dimension, the two raters who independently coded the data, did not fully 
agree on the presence of the analyse/evaluate dimension in the measurement scales. One rater interpreted all scales as containing 
evaluative elements and therefore coded analyse/evaluate as present for all measurement scales. The other rater coded this dimension 
as present for only some scales. As a result, Cohen’s Kappa could not be calculated; instead, a simple agreement score of 79 % was 
reported. All discrepancies were resolved through discussion until full consensus was reached. All of the measures and subdomains of 
the measures focussed on ability to analyse and evaluate media. For example, “I think about what the people who made the media 
message want me to believe” (Mc Lean et al., 2016a; Rojo et al., 2023; Scull et al., 2010). Only three of the studies included measures or 
subdomains of measures that assessed all three abilities of accessing, analysing/evaluating and creating media (Hung et al., 2021; 
Volpe et al., 2021; Yavuzalp et al., 2021). A further three assessed ability to access media (Lepore et al., 2019; Stamps, 2023; 
Tran-Duong & Vo-Thi, 2023). For example, “I use technology to help me reach my full potential” (Tynes et al., 2020; Volpe et al., 
2021). Picton et al. (2022) assessed ability to create. For example, “I feel confident about posting my own writing online.” Three of the 
studies included measures that were appearance related (Bennett, 2020; Schreurs & Vandenbosch, 2022; Volpe et al., 2021). For 
example, “Normally women (in real life) look like models in ads” (Bennett, 2020).
Fig. 4. Forest plot for the effect sizes of the correlation between media literacy and well-being.
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 10 ---

3.5. Well-being measures
All fifteen studies used self-report measures of well-being. The majority of the studies used established measures of well-being, 
while Hung et al. (2021), Lepore et al. (2019), and S´anchez-Reina and Gonz´alez-Lara (2022) included measures that were 
purpose-built for their specific studies. Measures were classified as either measuring well-being (e.g., positive affect, or ill-being, e.g., 
negative affect [see Table S6]). The Rosenberg Self-Esteem measure was the only measure used in more than one study (Rojo et al., 
2023; Spielvogel & Terlutter, 2013; Wright et al., 2022). Spielvogeal and Terlutter (2013) did not report on scale reliability. All of the 
other studies reported scale reliability with acceptable Cronbach Alpha’s or Mc Donald’s Omega’s ranging from .70 to .95.
3.6. Visual evidence gap map
Fig. 3 provides an at-a-glance summary of the results of the systematic review. Specific effect sizes and the effects of moderators are 
outlined in the meta-analysis reporting in Section 4, but Fig. 3 serves as a visual evidence gap map. Each box summarizes the moderator 
results, with rows in each box representing the level/s of that moderator. The boxes with white backgrounds indicate moderators that 
were statistically significant, and grey boxes indicate moderators that were not statistically significant. Effects were estimated across a 
diverse set of study characteristics, including gender, age, educational setting, wellness outcome type, and media literacy dimension. 
Most moderators did not show statistically significant variation, however, the evaluation-focussed dimension of media literacy 
emerged as a significant moderator.
4. Meta-analysis findings: media literacy associated with higher well-being
Fifteen independent studies involving 47 effect sizes measured media literacy and well-being (see Fig. 4). Results (see Table 2) 
indicate a statistically significant, small to medium, positive association between media literacy and well-being (r = .19, p = .04, 95 % 
CI [.01, .35], level 2 I2 = 10 %, level 3 I2 = 89.2 %), indicating that higher levels of media literacy are linked with higher levels of well- 
being. Although statistically significant, the confidence interval was relatively wide, indicating some imprecision in the estimated 
effect size. Significant heterogeneity was found Q(46) = 8418.02, p < .001. ‘Media Literacy Dimension’ was a statistically significant 
moderator of the pooled effect (see Table 2). The association between media literacy and well-being was medium-sized and positive 
when the media literacy measure only focussed on the dimension of analysing/evaluating the media (r = .24, p = .01, 95 % CI [.05, 
.41]). The association was not significant when the media literacy measure focussed on analysing/evaluating media plus accessing 
and/or creating media. The baseline model was not improved by any of the other moderators. We additionally explored whether 
results were moderated by educational context, however this result was not statistically significant (see Table S7). No publication bias 
was detected using the MLMA Egger’s test, χ2(1) = 3.03, p = .08. However, the distribution of effect sizes in the funnel plot revealed 
some level of asymmetry. Rather than suggesting publication bias, the funnel plot suggests that smaller, positive studies were un-
derrepresented, potentially suggesting small study effects are present, or that the findings are driven by the larger, more precise 
studies. Our findings should be interpreted with this in mind (see Fig. S1).
Table 2 
Meta-regressions for the pooled link between media literacy and well-being.
Moderation
k
n
r [95 % CI]
zʹ
SE
p
τ2
(2)
τ2
(3)
R2
(2)
R2
(3)
Likelihood Ratio Test
Baseline


.19 [.01, .35]
.19
.09
.041
.01
.12
​
​
​
Age


​
​
​
​
.00
.13
.00
11.76
χ2 (1) = 1.46, p = .23
Intercept
​
​
.17 [-.04, .36]
.17
.11
.12
​
​
​
​
​
Yearly
​
​
.02 [-.01, .05]
.02
.01
.21
​
​
​
​
​
Gender


​
​
​
​
.01
.12
.00
.00
χ2 (1) = .00, p = 1.00
Intercept
​
​
.19 [-.40, 67]
.19
.31
.55
​
​
​
​
​
Female prop
​
​
.00 [-.01, .01]
.00
.00
1.00
​
​
​
​
​
Well-Being Type


​
​
​
​
.01
.12
.43
.00
χ2 (1) = .20, p = .66
Ill-being


.17 [-.04, .36]
.17
.10
.11
​
​
​
​
​
Well-being


.20 [.01, .38]
.20
.10
.038
​
​
​
​
​
Media Literacy Dimension


​
​
​
​
.01
.13
26.75
.00
χ2 (1) = 5.20, p = .023
Evaluate and additional


.10 [-.11, .29]
.10
.10
.35
​
​
​
​
​
Evaluate only


.24 [.05, .41]
.24
.10
.014
​
​
​
​
​
Note. k = number of studies, n = number of effects. r = Pearson’s correlation, zʹ = Fisher’s z transformed correlation, SE = standard error of Fisher’s z 
transformed correlation, p = p-value of each slope. R2
(2) = % of within study heterogeneity explained by the model, R2
(3) = % of between study 
heterogeneity explained by the model, Likelihood Ratio Test = tests if the model that includes the moderator is an improvement over the baseline 
model, Age = the variable was mean-centered so that the intercept reflects the estimated effect size at the average age of the samples. The slope 
(labeled “Yearly”) represents the change in effect size for each one-year increase in mean age. Female prop = a continuous variable representing the 
proportion of females in the sample. The slope reflects the change in effect size for each unit increase in female proportion, the intercept reflects the 
estimated effect size when Female prop is equal to zero.
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 11 ---

4.1. Sensitivity analyses
A sensitivity analysis using standardised residuals and Cook’s distance identified six influential effect sizes. All six standardised 
residuals exceeded ±1.96 in the positive direction and originated from two studies (Study 11 and Study 15; see Table S8). The residuals 
from Study 15 were particularly elevated (ranging from 2.22 to 2.58), indicating that this study contributed disproportionately high 
effect sizes relative to the model’s predictions.
Excluding these data points reduced the pooled effect size to r = .11, which was no longer statistically significant (p = .10; see 
Table S9). However, the direction of the effects remained consistently positive, suggesting a small but potentially meaningful asso-
ciation. The true effect size likely lies within the range of r = .11 to r = .19.
5. Discussion
This is the first systematic review and meta-analysis investigating the association between media literacy and well-being. Given the 
dynamic nature of today’s media landscape and the nuanced relationship between media use and mental health, understanding the 
interplay between media literacy and well-being holds significant value. This study demonstrated a positive association between media 
literacy and well-being, extending previous research that focussed on media literacy in relation to specific health attitudes and be-
haviours (Gordon et al., 2015; Jeong et al., 2012; Kurz et al., 2022; Mc Lean et al., 2016b; Xie et al., 2019).
5.1. Meta-analysis findings and theoretical implications
Supporting Hypothesis 1, we found a statistically significant, positive association between media literacy and well-being (r = .19, p 
= .04, 95 % CI [.01, .35]). According to Funder & Ozer (2019), and Gignac and Szodorai (2016), this correlation represents a small to 
medium connection between individuals’ media literacy levels and their overall sense of well-being.
However, the estimate was relatively imprecise and should be interpreted cautiously. A sensitivity analysis that excluded six 
influential cases attenuated the estimate such that it was no longer statistically significant. While the direction of effect remained 
consistently positive, there is insufficient evidence to be able to conclude a relationship between media literacy and wellbeing at this 
point. This finding contrasts with previous meta-analyses that reported more definitive positive effects of media literacy in specific 
domains. For example, Kurtz et al. (2022) found a moderate positive association between media literacy and reduced body dissatis-
faction (g = .29). Similarly, Xie et al. (2019) reported that media literacy was linked to lower engagement in behaviours such as 
drinking and smoking among adolescents (d = −.32).
In line with Hypothesis 2, the effect of media literacy on both positive markers of well-being (e.g., positive affect) and measures of 
ill-being (e.g., negative affect) was equivalent, as well-being outcome type did not exert a moderation effect. The domain of media 
literacy had a significant moderating effect on the association between media literacy and well-being, but in a different direction to 
what was expected. Contrary to expectations (Hypothesis 3), media literacy measures focussed solely on the dimension of analysing/ 
evaluating media resulted in a medium-sized, positive association between media literacy and well-being. In contrast, media literacy 
measures that included the skill of analysis/evaluating, plus additional components had no significant moderating effect. One 
explanation for this could be that the ability to analyse/evaluate media is the crucial link between media literacy and well-being. The 
inclusion of additional components such as accessing and/or creating media may potentially dilute this central focus. The skill of 
accessing media may be particularly critical for reducing social inequality given our reliance on technology for economic and social 
participation (Bach et al., 2018), whereas the skill of creating or contributing to media may be particularly important for the 
participatory nature of digital media (Cho et al., 2024; Park et al., 2023). However, these interpretations remain speculative, and 
empirical studies or interventions are needed to test these hypotheses. It is also worth noting that differences in how the components of 
media literacy relate to well-being may be influenced by how they are measured. For example, skills such as creating or contributing to 
media content may be more challenging to measure reliably compared to accessing or consuming media. This difficulty arises because 
creating and contributing involves context-dependent behaviours that are harder to capture through self-report or observational tools. 
However, incorporating more objective measures, such as tracking actual user contributions through data donation or digital foot-
prints, could improve the reliability and validity of assessing these media literacy components. Further discussion of measurement 
challenges in media literacy and implications for future research can be found in Section 5.2.
No significant moderating effects emerged when examining demographic characteristics as moderators of the association between 
media literacy and well-being (Hypothesis 4). Thus it appears that this association transcends age groups and gender ratios and 
suggests that media literacy interventions are equally applicable across these demographics. Nevertheless, the absence of significant 
moderators could also be attributed to the limited number of effect sizes included in the meta-analysis, necessitating caution in 
drawing definitive conclusions. Additional research in the field is needed to facilitate more robust meta-analyses and clarify the as-
sociation between media literacy and well-being. Moreover, further studies would provide greater insight into potential heterogeneity 
and whether stronger effects are exhibited in certain demographic groups.
5.2. Measurement of media literacy
Considerable diversity emerged in how media literacy was measured across the included studies, mirroring the broad spectrum of 
approaches within the field regarding its definition, application, and contextual nuances (Hobbs, 2017; Wuyckens et al., 2022). 
Notably, none of the studies incorporated performance-based assessments of media literacy, which typically involve tasks akin to 
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 12 ---

real-world media analysis and creation practices (Hobbs, 2017). While this omission may be explained by pragmatic considerations of 
large-scale survey research, it is worth noting that some scholars advocate for the adoption of performance-based measures as the “gold 
standard” (Hobbs, 2017), citing potential discrepancies between self-assessment and actual proficiency (Somerville et al., 2008). Given 
the absence of performance-based measures, it is possible that the tools used did not accurately assess media literacy. This may have 
contributed to the non-significant association between media literacy and well-being found in the sensitivity analyses. Further psy-
chometric work is needed to develop reliable and valid performance-based measures of media literacy, which should then be tested in 
future experimental studies.
Within the pool of media literacy measures included in this meta-analysis, varying degrees of alignment with the conventional 
definition of media literacy were observed. For instance, Lepore et al. (2019)’s assessment of ’digital literacy’ primarily focused on the 
skill of media access, with only one item incorporating an analytical dimension. This research highlighted that the link between media 
literacy and well-being was stronger when media literacy measures only focussed on the skill of analysing/evaluating media. It would 
be helpful for future research studies to explore why this may be the case.
Another important point is the wide variation in both the structure and quality of media literacy measures used across studies, as 
shown in the results and in Table S5. Notably, no common measures of media literacy were used across the fifteen studies. To enable 
moderation analysis, we categorised the measures into three dimensions, analyse/evaluate, access, and create, based on a widely 
accepted definition of media literacy (Livingstone, 2004). However, in the original studies, the measures were often categorised 
differently, with some focussing on a single domain, and others incorporating multiple dimensions. It has been argued by a number of 
authors that media literacy is multifaceted (e.g. Mc Lean et al., 2016b), suggesting that the multidimensional scales may be better 
suited to capture this complex dimension. Additionally, whether media literacy is measured as trait-like knowledge or as the capacity 
to apply skills in the moment may influence the relationships that can be detected. Future work should aim to refine the measurement 
of media literacy to improve the quality of assessment tools.
5.3. Practical implications
While prior research suggests the benefits of media literacy in enhancing civic engagement (Mihailidis, 2018; Park et al., 2023) and 
mitigating negative media influences (Gordon et al., 2015; Jeong et al., 2012; Kurz et al., 2022; Mc Lean et al., 2016b; Xie et al., 2019), 
our study represents the first attempt to provide meta-analytical evidence on the association between media literacy and well-being. 
However, the evidence for a link between media literacy and well-being remains inconclusive.
Media literacy continues to be an important skill for navigating the complexities of the 21st century with potential benefits for 
diverse demographic groups. Schools, with their wide reach in shaping future generations, offer a promising avenue for fostering these 
skills. Yet, implementation may be constrained by an already overcrowded curriculum. At the same time, there is a growing emphasis 
on addressing well-being within educational settings, with many schools integrating well-being curricula, programs and initiatives 
(Pulimeno et al., 2020).
At this stage, media literacy efforts may be most impactful when focused on specific health-related areas where positive effects have 
been demonstrated, for example, reducing harmful behaviours such as drinking and smoking among adolescents (Xie, 2019). Further 
research is required to establish whether media literacy contributes to broader well-being outcomes. This should be examined through 
both experimental and longitudinal designs.
To enhance impact, school-based and adult educators should consider emphasising the importance of analysing and evaluating 
media within their media literacy programs. Furthermore, there is potential advantage in imparting media literacy skills to adult 
learners, through contexts such as tertiary education institutions and online environments given the importance of critical thinking 
(Karaca-Atik et al., 2023). However, more research is needed to clarify the relationship between media literacy and well-being to 
provide a stronger foundation for practical recommendations.
5.4. Strengths and limitations
This study has several strengths. A notable strength is the comprehensiveness of the search strategy employed. A wide array of 
search terms, closely aligned with accepted definitions of media literacy and well-being were utilised, ensuring a thorough exploration 
of relevant literature. Additionally, a comprehensive search of the grey literature was conducted, further enhancing the breadth of 
information considered. The included studies spanned various age groups, ethnicities, and contextual settings, exploring the link 
between media literacy and well-being across different demographic groups. Moreover, the included studies were deemed to have a 
low risk of bias, enhancing the robustness and reliability of the findings. However, the multifaceted nature of both media literacy and 
well-being present challenges in fully capturing all relevant literature. Consequently, while efforts were made to encompass all 
relevant literature, it is possible that certain relevant papers may have been missed by the search strategy.
Several limitations in terms of the included studies should be considered when interpreting the findings and conclusions of this 
meta-analysis. First, some intervention studies were not included in the review and meta-analysis due to not measuring media literacy 
or absence of baseline data, potentially limiting the comprehensiveness of the analyses. Second, the predominantly cross-sectional 
correlational designs of the included studies preclude the identification of cause-effect relationships. The presence or direction be-
tween media literacy and well-being therefore cannot be determined. Furthermore, a key limitation is that most analyses were based 
on data collected at a single point in time. This is an important consideration for future research, as the small observed correlation may 
be inflated due to shared method variance. Specifically, the use of self-reported measures for all variables within the same data 
collection session may have introduced correlations due to common method bias. Third, the majority of studies included in the meta- 
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 13 ---

analysis relied on online surveys, assuming a baseline level of digital literacy skills among the population which may introduce bias. 
Fourth, the small number of included studies limited both the scope of the analyses that could be conducted and the strength of the 
conclusions that could be drawn. Relatedly, the limited sample size reduced the statistical power to detect moderator effects. 
Therefore, non-significant findings should not be interpreted as definitive evidence of null effects. Several moderators showed asso-
ciations that, while not statistically significant, may still be of practical interest. Last, all data were self-reported, with no performance- 
based measures of media literacy utilised, potentially introducing biases such as social desirability. These limitations underscore the 
need for cautious interpretation of the results and highlight areas for future research to address these gaps in understanding.
5.5. Future directions
The systematic search only found 15 studies that explored the association between media literacy and well-being, indicating that 
further research in the area is needed to more fully understand this dynamic. The majority of the studies were published within the last 
five years indicating a potentially burgeoning interest in exploring the connection between media literacy and well-being. The body of 
research would also benefit from an increased focus on longitudinal and experimental studies to clarify causal associations. To reduce 
limitations caused by common method bias, more objective methods for measuring media literacy should be included where possible, 
including performance-based assessments (Hobbs, 2017). Studies could also benefit from using multiple data sources, such as 
combining self-reports with teacher or parent reports of well-being, particularly for younger cohorts.
Of the 15 studies, only one was longitudinal, highlighting a gap in understanding how the link between media literacy and well- 
being may change over time. A directional association between media literacy and well-being was not proposed in our review. A bi- 
directional association is conceivable, where higher levels of media literacy contribute to enhanced well-being and individuals with 
greater well-being are receptive to thinking critically about their media engagement. However, longitudinal data is needed to explore 
this further.
The studies included in the review were not limited to one region and covered North America, Europe and Asia. It would be useful 
to explore these effects in other regions to track the generalisability of the results to inform intervention research. In regions such as 
Australia and New Zealand, there is emerging policy and growing interest in media literacy (Australian Government, 2023). The 
existing ‘place’ of media literacy in the Australian national curriculum has been recently revised and extended with the last national 
Australian Curriculum and Reporting Authority curriculum review (ACARA, 2021). It would therefore be particularly valuable to 
understand the link between media literacy and well-being to inform school-based resources and interventions.
There remains a notable gap in the literature concerning the association between media literacy and mental health. Despite the 
growing interest in understanding the impact of media use on mental health, studies specifically examining the role of media literacy in 
this context are limited. Given that media use can have both positive and negative impacts on mental health, as well as indirect and 
potentially nonlinear associations (Coyne et al., 2020; Keles et al., 2020; Li & Brar, 2022; Seabrook et al., 2016), further understanding 
of the role media literacy can play is needed. Specifically, future research should explore whether possessing strong media literacy 
skills acts as a protective factor against the potential negative effects of media use on mental health. Additionally, it would be valuable 
to investigate whether media literacy proficiency contributes to improved mental health outcomes by capitalising on the positive 
aspects of media, such as facilitating social connections. Addressing these research gaps will not only enhance our understanding of the 
dynamic between media literacy and mental health but also inform the development of effective interventions aimed at promoting 
positive media engagement and safeguarding mental well-being in the digital age.
Author contributions
Chloe S. Gordon: Conceptualization, Methodology, Writing – Original Draft, Writing – Review & Editing, Project administration, 
Data Curation. Kelly Ferber: Methodology, Data Curation, Visualisation, Formal analysis, Writing – Original Draft, Writing – Review & 
Editing. Tanya Notley: Conceptualization, Methodology, Writing – Review & Editing. Rachel F. Rodgers: Conceptualization, Meth-
odology, Writing – Review & Editing. Emma Bradshaw: Conceptualization, Methodology, Writing – Review & Editing. Geetanjali 
Basarkod: Conceptualization, Methodology, Writing – Review & Editing. Joel Anderson: Conceptualization, Methodology, Writing – 
Review & Editing. Siˆan A. Mc Lean: Conceptualization, Methodology, Writing – Review & Editing. Simone Mizzi: Conceptualization, 
Methodology, Writing – Review & Editing. Hannah K. Jarman: Conceptualization, Methodology, Writing – Review & Editing. Jessica 
Dickson: Methodology, Writing – Review & Editing. Taren Sanders: Conceptualization, Methodology. Amy Slater: Conceptualization, 
Methodology, Writing – Review & Editing. Erin Pearson: Writing – Review & Editing. Theresa Dicke: Conceptualization, Methodology, 
Writing – Review & Editing.
Declaration of generative AI and AI-assisted technologies in the writing process
During the editing phase of this work the authors used Chat GPT in some sections to help make writing more concise. After using this 
tool/service, the authors reviewed and edited the content as needed and take full responsibility for the content of the publication.
Funding
This research received funding from an Australian Catholic University internal grant award. The funder had no involvement in the 
conduct of the research or preparation of the article.
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 14 ---

Appendix A. Supplementary data
Supplementary data to this article can be found online at https://doi.org/10.1016/j.edurev.2025.100731.
Data availability
The data is available via the link to the OSF depository provided in the manuscript
References
ACARA. (2021). What has changed and why? Proposed revisions to the foundation – Year 10 (F–10) Australian curriculum: The arts. http:// 
efaidnbmnnnibpcajpcglclefindmkaj/https://www.australiancurriculum.edu.au/media/7127/ac_review_2021_the_arts_whats_changed_and_why.pdf.
Aufderheide, P., & Firestone, C. M. (1993). Media literacy: A report of the national leadership conference on media literacy. National leadership conference on media literacy.
Australian Curriculum, Assessment and Reporting Authority. (2025). New resource for teachers to support Australian students in understanding media literacy. 
ACARA https://www.acara.edu.au/docs/default-source/media-releases/media-release-new-resource-for-teachers-to-support-australian-students-in- 
understanding-media-literacy-19-05-25.pdf.
Australian Government. (2023). New media assistance program consultation paper. https://www.infrastructure.gov.au/sites/default/files/documents/news-media- 
assistance-program-consultation-paper-december2023.pdf.
Bach, A. J., Wolfson, T., & Crowell, J. K. (2018). Poverty, literacy, and social transformation: An interdisciplinary exploration of the digital divide. The Journal of 
Media Literacy Education, 10(1), 22–41. https://doi.org/10.23860/JMLE-2018-10-1-2
Banerjee, S. C., & Greene, K. (2007). Antismoking initiatives: Effects of analysis versus production media literacy interventions on smoking-related attitude, norm, and 
behavioral intention. Health Communication, 22(1), 37–48. https://doi.org/10.1080/10410230701310281
Barker, T. H., Stone, J. C., Sears, K., Klugar, M., Leonardi-Bee, J., Tufanaru, C., Aromataris, E., & Munn, Z. (2023). Revising the JBI quantitative critical appraisal tools 
to improve their applicability: An overview of methods and the development process. JBI Evidence Synthesis, 21(3), 478–493. https://doi.org/10.11124/JBIES-22- 

Bennett, B. L. (2020). Alleviating the harm: A media literacy intervention for body dissatisfaction using ecological momentary intervention. https://scholarspace. 
manoa.hawaii.edu/items/503be8a5-3fd1-4794-8b53-3e7709f65d7b.
Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2021). Introduction to meta-analysis. John Wiley & Sons. 
Chambers, S., Notley, T., Dezuanni, M., & Park, S. (2022). Values and media literacy: Exploring the relationship between the values people prioritize in their life and 
their attitudes toward media literacy. International Journal of Communication Systems, 16(25), 2596–2620.
Cheung, M. W.-L. (2015). meta SEM: An R package for meta-analysis using structural equation modeling. Frontiers in Psychology, 5, 1521. https://doi.org/10.3389/ 
fpsyg.2014.01521
Cho, H., Cannon, J., Lopez, R., & Li, W. (2024). Social media literacy: A conceptual framework. New Media & Society, 26(2), 941–960. https://doi.org/10.1177/ 

Coyne, S. M., Rogers, A. A., Zurcher, J. D., Stockdale, L., & Booth, M. (2020). Does time spent using social media impact mental health?: An eight year longitudinal 
study. Computers in Human Behavior, 104, Article 106160. https://doi.org/10.1016/j.chb.2019.106160
Cusack, S. E., Hicks, T. A., Bourdon, J., Sheerin, C. M., Overstreet, C. M., Kendler, K. S., Dick, D. M., & Amstadter, A. B. (2019). Prevalence and predictors of PTSD 
among a college sample. Journal of American College Health: J of ACH, 67(2), 123–131. https://doi.org/10.1080/07448481.2018.1462824
Department of the Prime Minister and Cabinet. (2024). Charting the course for a diverse and sustainable news sector. December 16 https://ministers.pmc.gov.au/ 
mccarthy/2024/charting-course-diverse-and-sustainable-news-sector.
Dezuanni, M., Notley, T., & Di Martino, L. (2021). Towards a national strategy for media literacy: National consultation report. Australian media literacy alliance. https:// 
medialiteracy.org.au/wp-content/uploads/2022/03/AMLA-Consultation-Workshop-Report_UPDATE-25-10-2021-1.pdf.
Diener, E., Suh, E., Lucas, R. E., & Smith, H. L. (1999). Subjective Weil-being: Three decades of progress. Psychological Bulletin, 125(2), 276–302.
Dindar, M., & Yaman, N. D. (2018). #IUse Twitter Because: Content analytic study of a trending topic in Twitter. Information Technology & People, 31(1), 256–277. 
https://doi.org/10.1108/ITP-02-2017-0029
Erstad, O., & Amdam, S. (2013). From protection to public participation. Javnost-The Public, 20(2), 83–98. https://doi.org/10.1080/13183222.2013.11009115
Feerrar, J. (2022). Bringing digital well-being into the heart of digital media literacies. The Journal of Media Literacy Education, 14(2), 72–77. https://doi.org/ 
10.23860/JMLE-2022-14-2-6
Finnish Ministry of Education and Culture. (2013). Good media literacy national policy guidelines 2013-2016. Publications of the ministry of education. https://julkaisut. 
valtioneuvosto.fi/bitstream/handle/10024/75280/OKM13.pdf?sequence=1&is Allowed=y.
Funder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2 
(2), 156–168. https://doi.org/10.1177/2515245919847202
Gignac, G. E., & Szodorai, E. T. (2016). Effect size guidelines for individual differences researchers. Personality and Individual Differences, 102, 74–78. https://doi.org/ 
10.1016/j.paid.2016.06.069
Gordon, C. S., Jarman, H. K., Rodgers, R. F., Mc Lean, S. A., Slater, A., Fuller-Tyszkiewicz, M., & Paxton, S. J. (2021). Outcomes of a cluster randomized controlled trial 
of the So Me social media literacy program for improving body image-related outcomes in adolescent boys and girls. Nutrients, 13(11). https://doi.org/10.3390/ 
nu13113825
Gordon, C. S., Jones, S. C., & Kervin, L. (2015). Effectiveness of alcohol media literacy programmes: A systematic literature review. Health Education Research, 30(3), 
449–465. https://doi.org/10.1093/her/cyv015
Hobbs, R. (2017). Measuring the digital and media literacy competencies of children and teens. In F. C. Blumberg, & P. J. Brooks (Eds.), Cognitive development in digital 
contexts (pp. 253–274). Academic Press. https://doi.org/10.1016/B978-0-12-809481-5.00013-4. 
Hobbs, R. (2024). Media literacy in action: Questioning the media (2nd ed.). Rowman & Littlefield https://rowman.com/ISBN/9781538180136/Media-Literacy-in- 
Action-Questioning-the-Media-Second-Edition. 
Hung, S.-C., Yang, S.-C., & Luo, Y.-F. (2021). New media literacy, health status, anxiety, and preventative behaviors related to COVID-19: A cross-sectional study in 
Taiwan. International Journal of Environmental Research and Public Health, 18(21). https://doi.org/10.3390/ijerph182111247
Huppert, F. A. (2009). Psychological well-being: Evidence regarding its causes and consequences. Applied Psychology. Health and Well-Being, 1(2), 137–164. https:// 
doi.org/10.1111/j.1758-0854.2009.01008.x
Huppert, F. A. (2017). Challenges in defining and measuring well-being and their implications for policy. In M. A. White, G. R. Slemp, & A. S. Murray (Eds.), Future 
directions in well-being: Education, organizations and policy (pp. 163–167). Springer International Publishing. https://doi.org/10.1007/978-3-319-56889-8_28. 
Huppert, F. A., & So, T. T. C. (2013). Flourishing across Europe: Application of a new conceptual framework for defining well-being. Social Indicators Research, 110(3), 
837–861. https://doi.org/10.1007/s11205-011-9966-7
Jeong, S.-H., Cho, H., & Hwang, Y. (2012). Media literacy interventions: A meta-analytic review. Journal of Communication, 62(3), 454–472. https://doi.org/10.1111/ 
j.1460-2466.2012.01643.x
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 15 ---

Karaca-Atik, A., Meeuwisse, M., Gorgievski, M., & Smeets, G. (2023). Uncovering important 21st-century skills for sustainable career development of social sciences 
graduates: A systematic review. Educational Research Review, 39, Article 100528. https://doi.org/10.1016/j.edurev.2023.100528
Keles, B., Mc Crae, N., & Grealish, A. (2020). A systematic review: The influence of social media on depression, anxiety and psychological distress in adolescents. 
International Journal of Adolescence and Youth, 25(1), 79–93. https://doi.org/10.1080/02673843.2019.1590851
Kurz, M., Rosendahl, J., Rodeck, J., Muehleck, J., & Berger, U. (2022). School-based interventions improve body image and media literacy in youth: A systematic 
review and meta-analysis. Journal of Prevention, 43(1), 5–23. https://doi.org/10.1007/s10935-021-00660-1
Landis, J. R., & Koch, G. G. (1977). An application of hierarchical kappa-type statistics in the assessment of majority agreement among multiple observers. Biometrics, 
33(2), 363–374. https://doi.org/10.2307/2529786
Lepore, S. J., Rincon, M. A., Buzaglo, J. S., Golant, M., Lieberman, M. A., Bauerle Bass, S., & Chambers, S. (2019). Digital literacy linked to engagement and 
psychological benefits among breast cancer survivors in internet-based peer support groups. European Journal of Cancer Care, 28(4), Article e13134. https://doi. 
org/10.1111/ecc.13134
Li, J., & Brar, A. (2022). The use and impact of digital technologies for and on the mental health and wellbeing of Indigenous people: A systematic review of empirical 
studies. Computers in Human Behavior, 126, Article 106988. https://doi.org/10.1016/j.chb.2021.106988
Livingstone, S. (2004). What is media literacy? Inter Media, 32(3), 18–20. http://eprints.lse.ac.uk/1027/.
Livingstone, S. (2017). Children’s and young people’s lives online. In J. Brown (Ed.), Online risk to children: Impact, protection and prevention (pp. 23–36). Hoboken, N. 
J.: Wiley The NSPCC/Wiley Series in Protecting Children: The Multi-Professional Approach. 
Livingstone, S., Van Couvering, E., & Thumim, N. (2005). Adult media literacy. A review of the research literature: Department of media and communications. London 
school of economics and political science.. https://dera.ioe.ac.uk/id/eprint/5283/1/aml.pdf.
Matthews, N., Kilgour, L., Christian, P., Mori, K., & Hill, D. M. (2015). Understanding, evidencing, and promoting adolescent well-being: An emerging agenda for 
schools. Youth & Society, 47(5), 659–683. https://doi.org/10.1177/0044118X13513590
Mc Guire, J., Kaiser, C., & Bach-Mortensen, A. M. (2022). A systematic review and meta-analysis of the impact of cash transfers on subjective well-being and mental 
health in low- and middle-income countries. Nature Human Behaviour, 6(3), 359–370. https://doi.org/10.1038/s41562-021-01252-z
Mc Lean, S. A., Paxton, S. J., & Wertheim, E. H. (2016a). The measurement of media literacy in eating disorder risk factor research: Psychometric properties of six 
measures. Journal of Eating Disorders, 4, 30. https://doi.org/10.1186/s40337-016-0116-0
Mc Lean, S. A., Paxton, S. J., & Wertheim, E. H. (2016b). The role of media literacy in body dissatisfaction and disordered eating: A systematic review. Body Image, 19, 
9–23. https://doi.org/10.1016/j.bodyim.2016.08.002
Mihailidis, P. (2018). Civic media literacies: Re-imagining human connection in an age of digital abundance. Routledge. 
Mills, K. A., & Brown, A. (2022). Immersive virtual reality (VR) for digital media making: Transmediation is key. Learning, Media and Technology, 47(2), 179–200. 
https://doi.org/10.1080/17439884.2021.1952428
Moola, S., Munn, Z., Tufanaru, C., Aromataris, E., Sears, K., Sfetcu, R., Currie, M., Qureshi, R., Mattis, P., Lisy, K., & Mu, P.-F. (2020). Chapter 7: Systematic reviews of 
etiology and risk. In E. Aromataris (Ed.), JBI manual for evidence synthesis. JBI. 
NAMLE. (2020). NAMLE; national association for media literacy education. September 18 https://namle.org/resources/media-literacy-defined/.
Notley, T., Chambers, S., Park, S., & Dezuanni, M. (2024). Adult media literacy in 2024: Australian attitudes, experiences, and needs. Western Sydney University; 
Queensland University of Technology; University of Canberra. 
OECD. (2020). How’s life? 2020: Measuring well-being. OECD Publishing. https://doi.org/10.1787/9870c393-en
Page, M. J., Mc Kenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., Shamseer, L., Tetzlaff, J. M., Akl, E. A., Brennan, S. E., Chou, R., Glanville, J., 
Grimshaw, J. M., Hr´objartsson, A., Lalu, M. M., Li, T., Loder, E. W., Mayo-Wilson, E., Mc Donald, S., … Moher, D. (2021). The PRISMA 2020 statement: An 
updated guideline for reporting systematic reviews. BMJ, 372, n71. https://doi.org/10.1136/bmj.n71
Park, S., Lee, J. Y., Notley, T., & Dezuanni, M. (2023). Exploring the relationship between media literacy, online interaction, and civic engagement. The Information 
Society, 39(4), 250–261. https://doi.org/10.1080/01972243.2023.2211055
Pfaff-Rüdiger, S., & Riesmeyer, C. (2016). Moved into action. Media literacy as social process. Journal of Children and Media, 10(2), 164–172. https://doi.org/ 
10.1080/17482798.2015.1127838
Picton, I., Clark, C., Riad, L., & Cole, A. (2022). Insights into young people’s literacy, critical digital literacy, online communication and wellbeing. The national literacy 
trust. https://literacytrust.org.uk/research-services/research-reports/young-peoples-literacy-critical-digital-literacy-online-communication-and-wellbeing/.
Pinkleton, B. E., Austin, E. W., Chen, Y.-C. Y., & Cohen, M. (2012). The role of media literacy in shaping adolescents’ understanding of and responses to sexual 
portrayals in mass media. Journal of Health Communication, 17(4), 460–476. https://doi.org/10.1080/10810730.2011.635770
Potter, W. J. (2013). Review of literature on media literacy. Sociology Compass, 7(6), 417–435. https://doi.org/10.1111/soc4.12041
Potter, W. (2014). Guidelines for media literacy interventions in the digital age. Medijska Istrazivanja: Znanstveno-Struˇcni ˇcasopis Za Novinarstvo I Medije, 20(2), 5–31. 
https://hrcak.srce.hr/file/197508.
Pulimeno, M., Piscitelli, P., Colazzo, S., Colao, A., & Miani, A. (2020). School as ideal setting to promote health and wellbeing among young people. Health Promotion 
Perspectives, 10(4), 316–324. https://doi.org/10.34172/hpp.2020.50
R Core Team. (2022). R: A language and environment for statistical computing. R foundation for statistical computing Version 4.2.1. http://www.r-project.org.
Rasi, P., Vuoj¨arvi, H., & Rivinen, S. (2021). Promoting media literacy among older people: A systematic review. Adult Education Quarterly, 71(1), 37–54. https://doi. 
org/10.1177/0741713620923755
Rasi, P., Vuoj¨arvi, H., & Ruokamo, H. (2019). Media literacy education for all ages. Journal of Media Literacy Education, 11(2), 1–19. https://doi.org/10.23860/JMLE- 
2019-11
Rodgers, M. A., & Pustejovsky, J. E. (2021). Evaluating meta-analytic methods to detect selective reporting in the presence of dependent effect sizes. Psychological 
Methods. https://doi.org/10.1037/met0000300
Rojo, M., Beltr´an-Garrayo, L., Del Blanco-Barredo, M. D. C., & Sepúlveda, A. R. (2023). Spanish validation of two social media appearance-related constructs 
associated with disordered eating in adolescents: The Appearance-related social media consciousness scale (ASMC) and the critical thinking about media 
messages scale (CTMM). Body Image, 45, 401–413. https://doi.org/10.1016/j.bodyim.2023.04.004
Ruggeri, K., Garcia-Garzon, E., Maguire, ´A., Matz, S., & Huppert, F. A. (2020). Well-being is more than happiness and life satisfaction: A multidimensional analysis of 
21 countries. Health and Quality of Life Outcomes, 18(1), 192. https://doi.org/10.1186/s12955-020-01423-y
Ryff, C. D. (1989). Happiness is everything, or is it? Explorations on the meaning of psychological well-being. Journal of Personality and Social Psychology, 57(6), 
1069–1081. https://doi.org/10.1037/0022-3514.57.6.1069
S´anchez-Reina, J.-R., & Gonz´alez-Lara, E.-F. (2022). The COVID-19 infodemic among young people and adults: The support of critical media literacy. Comunicar, 30 
(73), 71–81. https://doi.org/10.3916/c73-2022-06
Schreurs, L., & Vandenbosch, L. (2022). Should I post my very best self? The within-person reciprocal associations between social media literacy, positivity-biased 
behaviors and adolescents’ self-esteem. Telematics and Informatics, 73, Article 101865. https://doi.org/10.1016/j.tele.2022.101865
Scull, T. M., Kupersmidt, J. B., Parker, A. E., Elmore, K. C., & Benson, J. W. (2010). Adolescents’ media-related cognitions and substance use in the context of parental 
and peer influences. Journal of Youth and Adolescence, 39(9), 981–998. https://doi.org/10.1007/s10964-009-9455-3
Seabrook, E. M., Kern, M. L., & Rickard, N. S. (2016). Social networking sites, depression, and anxiety: A systematic review. JMIR Mental Health, 3(4), e50. https://doi. 
org/10.2196/mental.5842
Sendurur, P., Sendurur, E., & Yilmaz, R. (2015). Examination of the social network sites usage patterns of pre-service teachers. Computers in Human Behavior, 51, 
188–194. https://doi.org/10.1016/j.chb.2015.04.052
Somerville, M. M., Smith, G. W., & Macklin, A. S. (2008). The ETS i Skills TM assessment: A digital age tool. The Electronic Library, 26(2), 158–171. https://doi.org/ 
10.1108/02640470810864064
Spielvogel, J., & Terlutter, R. (2013). Development of TV advertising literacy in children. International Journal of Advertising, 32(3), 343–368. https://doi.org/ 
10.2501/IJA-32-3-343-368
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731 

--- Page 16 ---

Stamps, D. L. (2023). The nexus between black media consumers’ racial identity, critical and digital media literacy skills, and psychological well-being. Information, 
Communication & Society, 1–17. https://doi.org/10.1080/1369118X.2023.2174789
Steinberg, L. (2008). A social neuroscience perspective on adolescent risk-taking. Developmental Review: Developmental Review, 28(1), 78–106. https://doi.org/ 
10.1016/j.dr.2007.08.002
Tran-Duong, Q. H., & Vo-Thi, N.-T. (2023). The influence of social media literacy on student engagement in online learning. Journal of Computer Assisted Learning, 39 
(6), 1888–1901. https://doi.org/10.1111/jcal.12849
Tynes, B. M., Volpe, V., Willis, H. A., Stewart, A., & Hamilton, M. (2020). The liberatory media literacy inventory for emerging adults. Manuscript Submitted for 
Publication https://onlinelibrary.wiley.com/doi/10.1002/jts.2640.
Volpe, V. V., Willis, H. A., Joseph, P., & Tynes, B. M. (2021). Liberatory media literacy as protective against posttraumatic stress for emerging adults of color. Journal 
of Traumatic Stress, 34(5), 1045–1055. https://doi.org/10.1002/jts.22640
Wright, C. L., Branch, R., Ey, L.-A., Megan Hopper, K., & Warburton, W. (2022). Popular music media literacy: A pilot study. The Journal of Media Literacy Education, 
14(3), 29–38. https://doi.org/10.23860/JMLE-2022-14-3-3
Wuyckens, G., Landry, N., & Fastrez, P. (2022). Untangling media literacy, information literacy, and digital literacy: A systematic meta-review of core concepts in 
media education. The Journal of Media Literacy Education, 14(1), 168–182. https://doi.org/10.23860/JMLE-2022-14-1-12
Xie, X., Gai, X., & Zhou, Y. (2019). A meta-analysis of media literacy interventions for deviant behaviors. Computers & Education, 139, 146–156. https://doi.org/ 
10.1016/j.compedu.2019.05.008
Yavuzalp, N., Demirbag, M., & Bahcivan, E. (2021). A structural equation modeling on pandemic session dataset: Turkish university students’ new media literacy. 
Journal of Educational Technology and Online Learning. https://doi.org/10.31681/jetol.973845
C.S. Gordon et al.                                                                                                                                                                                                      
Educational Research Review 49 (2025) 100731
