# AI imaginaries shape technological identity and digital futures

## Metadata
- **Author**: Bu Zhong
- **Subject**: Computers in Human Behavior, 169 (2025) 108682. doi:10.1016/j.chb.2025.108682
- **Creator**: Elsevier
- **Producer**: Acrobat Distiller 8.1.0 (Windows)
- **Creation Date**: D:20250507034423Z
- **Modification Date**: D:20250507034812Z
- **Source File**: AI-imaginaries-shape-technological-identity-and-d_2025_Computers-in-Human-Be.pdf
- **Converted**: 2025-10-23 22:46:12

---

## Content

--- Page 1 ---

AI imaginaries shape technological identity and digital futures
Bu Zhong a,*
, Yunya Song b
, Guangchao Charles Feng a
, Jingyuan Shi a
, Yuner Zhu a
,  
Lola Xie a
, Wanhui April Zhou a
, Sinan Yu a
, Yajing Lu a
, Ying Qin a
, Zuquan Xiong a
a Department of Interactive Media, AI Media Centre, School of Communication, Hong Kong Baptist University, Hong Kong
b Division of Emerging Interdisciplinary Areas, Hong Kong University of Sciences and Technology, Hong Kong
A R T I C L E  I N F O
Handling editor: Matthieu Guitton
Keywords:
Artificial intelligence
AI imaginary
AI imaginary model
Digital future
Technological identity
A B S T R A C T
Artificial intelligence (AI) has evolved to become a transformative driver across various societal sectors, influ-
encing our perception of shared digital futures. Central to this transformation are AI imaginaries – collective 
visions, beliefs, symbols, and expectations that individuals and communities hold about AI and its potential 
outcomes. AI imaginaries not only reflect societal hopes and concerns, but also actively shape the trajectory of AI 
development, integration, and governance. Drawing insights from theories of social identity, identity infusion 
and sociotechnical imaginaries, we propose the AI Imaginary Model as a conceptual framework examining their 
influence on user technological identity and shared digital futures. By exploring the interplay between AI 
imaginaries and sociotechnical systems, we highlight the role of these imaginaries in molding public attitudes, 
driving policy decisions, and fostering innovation. Recognizing the spectrum of AI imaginaries, from utopian to 
dystopian, we emphasize the need for a critical and balanced discourse to navigate the complex landscape of AI 
imaginaries. Our analysis should contribute to a deeper understanding of how AI imaginaries may empower or 
hinder users, shaping their technological identities and broader visions of digital futures. Finally, we call for 
increased scholarly focus on AI imaginaries to guide responsible technology stewardship and ensure that AI’s 
development aligns with our shared values and collective well-being.
1. Introduction
When we imagine the future these days, whether it is 10 or 100 years 
from now, artificial intelligence (AI) consistently emerges as a central 
theme. The genesis of disruptive technological inventions, epitomized 
by recent AI advances, is deeply rooted in the fertile ground of human 
imagination research (Finn & Wylie, 2021; Gosetti-Ferencei, 2023). 
Scientists have made a series of predictions about AI development and 
its far-reaching impact since the 1960s (Law, 2023) and some expect an 
upcoming AI revolution (Makridakis, 2017). As AI dawns, our collective 
imagination expands to embrace the vision of a world progressively 
shaped by AI technology. The ability to imagine is deeply rooted in our 
neurological development, particularly within the brain’s default mode 
network (Carroll, 2020). Mental imagery has been demonstrated to be 
intricately linked to various brain functions associated with memory and 
perception (Sereno et al., 1995). As imagination has consistently driven 
us to envision, innovate, and plan for the future, AI imaginaries can be 
categorized as a “higher cognitive function” akin to other mental 
imaginations (Kosslyn et al., 2001, p. 635).
AI imaginaries significantly influence how individuals integrate AI 
technologies into their personal, professional, and social identities (Finn 
& Wylie, 2021). Earlier research on technological identity has primarily 
focused on how individuals adopt and integrate innovative technologies 
into their lives. Studies have shown that technological identity is 
influenced by factors such as personal interests, social norms, and 
perceived utility, as well as social identity variables including funda-
mental values, cultural backgrounds, and group memberships (Kanzola 
et al., 2024). Through the lens of Social Identity Theory (Tajfel, 1978), 
individuals derive their self-concept from membership in social groups, 
adopting group characteristics, norms, and behaviors, which in turn 
inform their perception of AI technology (Mc Leod, 2023). Yet the spe-
cific role of AI imaginaries in shaping technological identity and visions 
of digital futures, remains underexplored. While there is a growing body 
of literature on sociotechnical imaginaries and technological identity, a 
* Corresponding author.
E-mail addresses: zhongbu@hkbu.edu.hk (B. Zhong), yunyasong@ust.hk (Y. Song), charlesfeng@hkbu.edu.hk (G.C. Feng), jolieshi@hkbu.edu.hk (J. Shi), 
yunerzhu@hkbu.edu.hk (Y. Zhu), lolawxie@hkbu.edu.hk (L. Xie), aprilchow2022@life.hkbu.edu.hk (W.A. Zhou), 23483644@life.hkbu.edu.hk (S. Yu), yajinglu@ 
life.hkbu.edu.hk (Y. Lu), 23482281@life.hkbu.edu.hk (Y. Qin), 22481966@life.hkbu.edu.hk (Z. Xiong). 
Contents lists available at Science Direct
Computers in Human Behavior
journal homepage: www.elsevier.com/locate/comphumbeh
https://doi.org/10.1016/j.chb.2025.108682
Received 16 September 2024; Received in revised form 18 April 2025; Accepted 22 April 2025  
Computers in Human Behavior 169 (2025) 108682 
Available online 23 April 2025 
0747-5632/© 2025 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ). 

--- Page 2 ---

significant gap persists in examining how AI imaginaries facilitate or 
hinder social integration and cohesion in different social contexts. This 
paper addresses this gap by proposing the concept of AI imaginaries and 
exploring the impact of AI imaginaries on users’ technological identity 
and perception of digital futures.
This article is structured into four sections. The first section begins by 
introducing the conceptual framework of AI imaginaries based on the 
existing literature. It reviews prior studies that address AI and other 
technological developments as social actors, laying the groundwork for 
a critical analysis of AI imaginaries. The second section explores the four 
primary roots of AI imaginaries: science fiction, media coverage, aca-
demic discourse, and public discussion. The third section analyzes AI 
imaginaries as a conceptual framework that shapes digital futures, 
including forstering technological identities in the era of AI. Finally, the 
fourth section summarrizes the key elements in the concept of AI 
imaginaries, emphasizing the need for growing scholarly attention to 
such imaginaries that influence our society, individual lives, and digital 
futures. Proposed shortened and long scales for measuring AI imagi-
naries are included in Appendices I and II, consisting of 12 or 24 items 
respectively.
2. A conceptual framework of AI imaginaries
Human imagery has held a principal place in theories of mental 
function since the time of Plato (Kosslyn et al., 2001). Research has 
found that people’s visual areas emphasize on the center of gaze 
compared to those in nonhuman primates, suggesting a uniquely human 
aspect of visual processing in the human brain that prioritizes the 
interpretation of visual stimuli (Sereno et al., 1995). Studies employing 
PEP and f MRI methods discover that mental imagery activates over-
lapping neural pathways associated with visual, auditory, and motor 
functions (Kosslyn et al., 2001), though it does not rely entirely on the 
same mechanisms as perception. In parallel to mental imagery, re-
searchers coined the term “social imaginary” – referring to the ways 
people envision their social existence, their integration with others, and 
the interactions within society. This concept unified path to modernity 
that transcends cultural differences, suggesting a universal approach 
rather than distinct trajectories for each culture (Taylor, 2004). In this 
context, AI imaginary is fundamentally a cognitive ability with sub-
stantial social implications for fostering collective beliefs, values, and 
perceptions, while providing insights into how the brain supports these 
functions.
In this study, we propose a conceptual framework investigating the 
links between AI imaginaries, technological identity, and digital futures. 
It offers a foundational representation of how AI imaginaries take shape 
in users after receiving various inputs and stimuli. The framework in-
troduces individual factors – such as AI literacy (Long & Magerko, 2020, 
pp. 1–16), AI experiences, technological knowledge and beliefs – as in-
ternal variables. They moderate how users process auditory, visual and 
textual inputs to form AI imaginaries, which are then moderated by 
collective factors or external variables like social norms, cultural values 
(Hohendanner et al., 2023, pp. 351–362), technology policies and media 
systems (see Fig. 1).
Users with more technological knowledge or AI experiences are 
likely to interpret these external narratives differently (Bliuc & Chidley, 
2022; Dahlstrom, 2014). By positioning individual factors as moderators 
rather than mere predictors, the conceptual framework captures the 
dynamic interplay between personal experiences and the formation of AI 
imaginaries. At the societal level, contextual and cultural influences are 
incorporated as external moderators, including social norms, cultural 
values, tech policies, and media systems, that shape the interpretation of 
AI imaginaries fostered. Recognizing these influences aligns the model 
with the understanding that AI imaginaries are not only internally 
formed in isolation but also shaped by broader societal contexts. The 
framework, therefore, highlights its applicability across various cultural 
settings and recognizes social norms in how users foster and interpret AI 
imaginaries.
2.1. The concept of AI imaginary
Artificial intelligence has evolved beyond a mere collection of al-
gorithms, emerging as a transformative social catalyst across various 
societal sectors (Zhong, 2022). Paralleled to technological leaps, human 
communication has undergone a profound transformation (Zhong, 
2020). Each groundbreaking media technology – from the printing press 
to the internet – has redefined how we process information and interact 
with one another. AI represents the latest milestone in this evolutionary 
journey, introducing transformative modes of communication through 
tools like natural language processing, chatbots, and virtual assistants. 
These advancements promise more personalized and efficient in-
teractions, breaking down barriers and nurturing connectivity. This 
paper introduces the concept of AI imaginaries and suggests that it 
warrants more academic attention, particularly in understanding how AI 
imaginaries influence communication, drive behavior change, foster 
identity formation, and shape the shared digital future.
The potential of AI to either accomplish remarkable feats or cause 
harm has led us to consider it not just as a tool, but as a new reality, in 
which our dreams and aspirations are tied to the impact of AI systems or 
algorithms we create (Zhong, 2023). In this era of innovation, many 
people are putting hopes into AI as a trusted ally or co-pilot in navigating 
the uncertainties of the future. This perspective propels the profound 
influence of AI to the forefront of our collective consciousness, shaping 
public discourse, policy responses, ethical considerations, economic 
dynamics, and social equity (Guitton et al., 2024). AI imaginaries 
Fig. 1. AI imaginaries help construct users’ technology identity and shared digital futures.
B. Zhong et al.                                                                                                                                                                                                                                   
Computers in Human Behavior 169 (2025) 108682 

--- Page 3 ---

encourage creative thinking and innovation by pushing the boundaries 
of what is considered possible. This exposure to speculative technologies 
through science fiction literature and media helps users become more 
comfortable with and accepting of radical technological concepts like 
mind upload (Laakasuo et al., 2018). Recognizing and addressing these 
social influences is crucial to fostering responsible AI development and 
ensuring that AI technologies serve the social good.
Group cognition has long be found to serve as a foundation for 
transforming individual beliefs into collective perceptions (Bliuc & 
Chidley, 2022). Collective narratives play a crucial role in shaping group 
behavior and shared understanding (Chubb et al., 2022). Users’ collec-
tive visions of AI, manifested as AI imaginaries, could serve as “meta--
stories” that integrate moral principles and societal norms, during which 
the narratives function as blueprints for group norms, guiding group 
members’ behavior through identity formation and development (Bliuc 
& Chidley, 2022). At the societal level, AI has sparked a broader societal 
movement characterized by discussions, debates, and activism sur-
rounding its impact on society, ethics, and governance (Zhong, 2022). 
This social movement encompasses various stakeholders, including re-
searchers, policymakers, industry leaders, ethicists, advocacy groups, 
and the public. They engage in dialogue and advocacy to steer the di-
rection of AI development and deployment, focusing on key topics such 
as AI ethics, fairness, transparency, accountability, and the societal 
implications of AI technologies. This growing movement advocates for 
responsible AI development and the use of AI for social good, striving to 
ensure that AI can benefit all members of society and promotes equity, 
diversity, and inclusion (Bengio et al., 2024). Understanding the social 
influence of AI requires examining AI imaginaries that shape our col-
lective visions and expectations for this technology. These imaginaries 
influence not only how we perceive AI but also how it evolves and in-
tegrates into our lives and society.
Guided by sociotechnical studies (Jasanoff, 2015; Jasanoff & Kim, 
2009; Zacher, 2015), we define AI imaginaries as the collective ideas, 
beliefs, values, symbols, expectations, and narratives that individuals and 
communities hold about artificial intelligence and its potential impact on our 
shared digital futures. AI imaginaries are not limited to the technology itself 
but also encompass the societal transformations. Each type of AI imaginary 
is linked to a specific vision of the digital future powered by AI. Different 
stakeholders promote their preferred visions of AI future, based on their 
diverse and often competing understanding of how AI will impact eco-
nomic, scientific, and political agendas (Law, 2023).
A wide range of AI imaginaries have emerged, from optimistic vi-
sions of AI-driven progress to dystopian fears of job displacement, so-
cietal control, or existential risks posed by superintelligent AI. These 
imaginaries are underpinned by a confluence of cultural, social, and 
technological factors and shape how users perceive and interact with AI 
systems (Hautala & Heino, 2023). This influence occurs through a blend 
of direct interactions, including the use of AI applications, and indirect 
interactions, such as exposure to media portrayals and social discourses. 
Users with AI background demonstrate different patterns of under-
standing and interacting with AI systems compared to those without 
such background (Ehsan et al., 2024). Ehsan et al. (2024) also found that 
those with more AI exposure tend to have more sophisticated (though 
not always better) interpretations of AI systems, showing a higher pro-
pensity to engage with numerical representations. A notable gap was 
identified 
in 
comparative 
studies 
examining 
heavy 
versus 
light/non-users of AI technologies (Pinski & Benlian, 2024). Active 
engagement with AI technologies appears to foster more intricate and 
informed imaginaries among heavy users compared to light users or 
non-users. It’s possible that heavy and light users of AI might exhibit 
distinct technological identities and varying perceptions of digital fu-
tures largely due to the different AI imaginaries they form.
In this study, we define digital futures as the envisioned scenarios or 
forecasts of how digital technologies bring out transformative impacts 
on the way we envision and interact with the world, which is driven by 
continuous innovation and connectivity. The concept underscores the 
significant role that digital information and communication technolo-
gies will play in the forthcoming era. Digital futures mark a forthcoming 
period that will be predominantly influenced by these technologies, 
ushering in a novel era characterized by unprecedented digital trans-
formation and innovation (Macgilchrist et al., 2024). Shared digital 
futures highlight the pivotal role of digital technologies in shaping the 
upcoming era, influencing diverse aspects of life and work, as well as 
other social factors.
2.2. Sources of AI imaginaries
The concept of AI imaginaries is rooted in the broader field of soci-
otechnical imaginaries (Jasanoff, 2009), reflecting how visions of 
technological futures are co-constructed by social factors and human 
interaction with technology (Zhong, 2022). Sociotechnical imaginaries 
represent the collective visions and expectations that societies hold 
regarding how science and technology will shape their futures. These 
imaginaries encompass not only the technologies themselves but also 
the social structures and ways of life that these technologies can support 
or restrict (Jasanoff, 2015).
Informed by the concept of sociotechnical imaginaries (Jasanoff, 
2009), AI imaginaries specifically focus on the futuristic visions of AI 
and its potential. These imaginaries include optimistic ideas of AI 
transforming sectors such as healthcare, education, and transportation, 
alongside concerns about potential risks like job displacement and pri-
vacy violations. AI imaginaries are formed through a combination of 
individual and social experiences, particularly exposure to key sources 
like science fiction, media coverage, academic debates, and public 
discourse. 
• Science fiction: Fictional portrayals of AI, both utopian and dysto-
pian, shape public perceptions and expectations (Appio et al., 2025; 
Nader et al., 2022; Satchell, 2008, pp. 1593–1602). Science fiction 
has been a powerful force in shaping public perceptions of AI tech-
nology (Bliuc & Chidley, 2022; Dahlstrom, 2014). During the Cold 
War in the 1960s, for example, computer scientists Marvin Minsky 
and Fernando J. Corbato had shaped narratives across film, televi-
sion, and the media to promote desirable futures centering on their 
own technical approaches, in which AI imaginaries served as tools 
scientists used to promote their visions of digital futures (Law, 2023). 
Science fiction provides a narrative framework that helps people 
conceptualize and understand potential future technologies. This 
familiarity with speculative technological concepts through science 
fiction can lead to greater acceptance when similar technologies 
emerge in reality (Laakasuo et al., 2018). Many technologies that 
were once purely fictional have become reality, demonstrating how 
science fiction can influence both technological advancements and 
public acceptance. In the realm of science fiction, AI continues to be a 
subject of profound ambiguity, and the precise boundaries and 
agency of AI remain elusive, leading to challenges in defining 
governance structures and establishing effective interactions with 
these systems (Hudson et al., 2023). Utopian narratives can inspire 
optimism about AI’s potential to solve complex problems, while 
dystopian tales can amplify fears about loss of control and ethical 
dilemmas. Jones and Paris (2018) found that contrary to conven-
tional wisdom, dystopian narratives do not necessarily diminish 
political trust and efficacy, underscoring the importance of consid-
ering science fiction’s role in shaping attitudes and actions.
• Media coverage: Media coverage, such as news articles, documen-
taries, and popular culture representations, plays a crucial role in 
informing the public about AI’s capabilities and potential impacts 
(Hautala & Heino, 2023). Positive stories about AI advancements in 
healthcare, finance, and other sectors can foster excitement and 
anticipation. Conversely, reports on job displacement, privacy con-
cerns, and biases in AI algorithms can lead to apprehension and 
distrust. Non-experts primarily obtain their scientific information 
B. Zhong et al.                                                                                                                                                                                                                                   
Computers in Human Behavior 169 (2025) 108682 

--- Page 4 ---

from mass media due to its widespread availability and frequent 
dissemination. News coverage inherently adopts narrative formats 
that inherently possess persuasive qualities and such narratives may 
enhance comprehension, captivate audiences, and foster engage-
ment (Dahlstrom, 2014). The media’s portrayal of AI often oscillates 
between these extremes, contributing to a dynamic and sometimes 
conflicting understanding of AI.
• Academic debates: Academic works play a crucial role in shaping AI 
imaginaries by setting research agendas and fostering debates on 
ethical considerations, technical challenges, and potential applica-
tions (Bearman et al., 2023). This scholarly dialogue influences 
funding priorities and regulatory frameworks, guiding the trajectory 
of AI research. Conferences, journals, and collaborations among in-
stitutions provide a platform for exploring both theoretical and 
practical aspects of AI. The contributions of academia are essential in 
addressing the complexities and ensuring the responsible develop-
ment of AI technologies. However, AI narratives may exacerbate 
certain negative aspects of academic culture, while the expansion of 
AI in research should potentially enhance and not replace human 
creativity (Chubb et al., 2022). Meanwhile, interdisciplinary ap-
proaches in AI research help highlight the role of academia in 
advancing AI imaginaries as scholarly research is crucial in identi-
fying opportunities, and challenges, and guiding research efforts 
across various domains such as business, management, and public 
policy (Dwivedi et al., 2021).
• Public discourse: Public discourse on AI imaginaries, encompassing 
social media conversations, public opinion polls, reflects both soci-
etal anxieties and hopes. While AI has the potential to enhance 
communication and transform interpersonal dynamics, there is also a 
prominent fear or skepticism regarding the technology’s role in 
altering 
communication 
patterns 
and 
social 
relationships 
(Hohenstein et al., 2023). Social media platforms facilitate the rapid 
and extensive discussion of AI-related topics, enabling the sharing of 
diverse opinions and experiences. Public opinion polls provide in-
sights into general sentiments about AI, indicating levels of trust, 
acceptance, and concern. Meanwhile, ethical debates in public fo-
rums address issues, such as AI’s impact on employment, privacy, 
and human rights. These discussions help shape societal expectations 
and influence policy decisions as they help identify AI-related op-
portunities and challenges in the public agenda. Ongoing public 
discourse is essential for navigating ethical and legal implications of 
AI advancement (Sartori & Bocca, 2022).
These diverse influences create a complex web of imaginaries that 
influence both AI beliefs and technological development. AI imaginaries 
are formed through a complex interplay of individual experiences, 
media representations, and social discourse. Heavy AI users tend to have 
more detailed and optimistic imaginaries, while light users and non- 
users often hold more cautious or skeptical views. Heavy users often 
see AI as an extension of themselves, leading to a more profound and 
nuanced understanding of these systems. In contrast, light users and 
non-users may struggle to integrate AI into their identities, resulting in a 
more superficial engagement with the technology (Zhong, 2013). 
Frequent users of AI often weave these technologies into both their 
personal and professional lives. This integration shapes their behaviors, 
attitudes, and expectations toward technology (Pauketat & Anthis, 
2022). The development of AI imaginaries sets heavy users apart from 
light users and non-users. Heavy users are more inclined to imagine 
advanced and transformative digital futures, while light users and 
non-users might hold more limited or skeptical perspectives on AI’s 
potential. This pattern mirrors the adoption process of other 
internet-based technologies such as social media or mobile technology 
(Zhong, 2013, 2020). Overall, AI imaginaries are not static in their two 
initial stages, i.e., the states of sensory imaginary or short-term imagi-
nary but could be more stable in the stage of long-term imaginaries 
(Fig. 2); they evolve as new technologies emerge and societal contexts 
change (Fazlioglu, 2023). More importantly, they play a crucial role in 
shaping technological trajectories and policy decisions (Deˇzman, 2024), 
reflecting shared understandings of what AI can and should be.
3. Sociotechnical imaginaries
Examining AI imaginaries can be a valuable approach to analyzing 
the social meaning of AI technology. By integrating multiple levels of 
analysis, such as collective visions, beliefs, values, and expectations, we 
can gain a deeper understanding of the significance of AI in shaping our 
society. The concept of AI imaginaries builds in part on sociotechnical 
imaginaries, which was developed by Sheila Jasanoff, referring to 
“collectively held, institutionally stabilized, and publicly performed vi-
sions of desirable futures, animated by shared understandings of forms 
of social life and social order” (Jasanoff, 2015, p. 6).
Collective visions emerge from two fundamental factors: updating 
phenomena at the individual level and the social network structures 
created during conversational recall (Coman et al., 2016). Coman and 
colleagues (2016) found that large-scale social phenomena (collective 
memory) can emerge from microlevel local dynamics. Similarly, the 
development of AI imaginaries encompasses both individual and col-
lective visions of AI technology and its potential outcomes. Thus, AI 
imaginaries can be significantly influenced by both individual cognitive 
processes and the broader social network dynamics. There exists a gap in 
understanding the mechanisms through which individual cognitive 
processes transform into collaborative ones (Finn & Wylie, 2021). Our 
present study aims to address this gap by investigating the formation of 
AI imaginaries, which was known as sociotechnical imaginaries before 
the AI era (Jasanoff & Kim, 2009).
Sociotechnical imaginaries are constructed by the interaction 
Fig. 2. The AI Imaginary Model (AIM). 
Note: The estimated time in each of three AI imaginary stages is based on the memory studies (Atkinson, 2001; Atkinson & Shiffrin, 1968).
B. Zhong et al.                                                                                                                                                                                                                                   
Computers in Human Behavior 169 (2025) 108682 

--- Page 5 ---

between social and technological factors (Jasanoff & Kim, 2009), which 
help explain why certain envisioning of scientific and social order gain 
support and become co-produced, while others do not (Jasanoff, 2015). 
Like the concept of co-production in science and technology studies, 
sociotechnical imaginaries reveal how certain visions of the future, 
sustained by infrastructures, practices, and shared meanings, inform and 
shape social life (Jasanoff, 2015). Sociotechnical imaginaries can be 
seen as guiding how we collectively perceive and organize the world, 
influencing systems of meaning and shared senses of belonging 
(Sismondo, 2020).
Jasanoff’s work on sociotechnical imaginaries has been applied to 
various contexts, such as understanding digital touch communication, 
exploring the concept of Smart Cities, and analyzing public perceptions 
of AI and socio-technical systems (Jasanoff, 2015). The concept has also 
been used to examine the role of imaginaries in the fabrication of power 
and the governance of science and technology (Jasanoff, 2019). Thus, 
sociotechnical imaginaries provide a framework for understanding how 
visions of the future, shaped by the interplay of social and technological 
factors, influence the development and implementation of scientific and 
technological projects, as well as the societal implications of these 
projects (Jasanoff, 2016).
Sociotechnical Imaginaries Theory (Jasanoff, 2015) posits that col-
lective visions of technological futures shape the development and 
governance of technologies. These imaginaries are co-constructed by 
social and technical actors, influencing how societies envision and 
implement technological advancements. Sociotechnical imaginaries are 
shared visions that combine social and technical elements to create a 
coherent narrative about the future of technology. These imaginaries 
help to frame the potential benefits and risks associated with AI, thereby 
influencing public acceptance and policymaking. Narratives constructed 
around AI technologies significantly impact how the public perceives 
and understands these technologies in their daily lives. These narratives 
often reflect underlying social relations and production practices, which 
can either align with or diverge from the actual technical possibilities of 
AI. For example, media representations and public debates about AI 
often shape the public’s understanding and expectations of AI’s capa-
bilities and limitations.
Sociotechnical imaginaries are not only shaped by public perceptions 
but also actively constructed by various stakeholders, including re-
searchers, policymakers, and industry leaders. For instance, computer 
scientists at institutions like MIT have historically constructed visions of 
the future to direct AI research agendas and influence public and 
governmental attitudes towards AI (Bearman et al., 2023). These 
imaginaries can lead to the allocation of resources and the establishment 
of policies that support the development and integration of AI technol-
ogies. Governments and corporations also contribute to the construction 
of sociotechnical imaginaries by promoting certain visions of AI’s future. 
These visions often emphasize the potential benefits of AI in areas such 
as healthcare, security, and economic growth, while downplaying po-
tential risks and ethical concerns. This selective framing can lead to a 
more favorable public perception and acceptance of AI technologies 
(Zacher, 2015).
4. The AI Imaginary Model
The AI Imaginary Model (AIM) conceptualizes how collective vi-
sions, beliefs, symbols, and expectations about AI contribute to rela-
tively stabilized AI imaginaries. The model suggests that people rely on 
these imaginaries as a source of information, with different imaginaries 
providing various types of insights. Mental imageries, like other stimuli 
such as symbols, emotions, and cultural cues (Schwarz, 2012), can be a 
source of information. Inferences drawn from such imaginaries are 
sensitive to the surrounding environment and the cultural context in 
which they are formed. Hence, AI imaginaries can inform us about the 
nature of AI usage and expectations. By integrating the literature in the 
areas of sociotechnological imaginaries (Jasanoff, 2015), social identity 
(Tajfel & Turner, 2001), and identity infusion (Swann et al., 2001), we 
propose the AIM to provide a comprehensive framework for under-
standing the impact of AI imaginaries on technological identity and 
digital futures.
As shown in Fig. 2, the AIM is designed to theorize how people 
process AI imaginaries by treating them as information, which is 
informed by theories of information processing (Atkinson & Shiffrin, 
1968), feelings-as-information (Schwarz, 1990, 2012), and socio-
technical imaginaries (Jasanoff, 2015). The following conceptual model 
illustrates the process, consists of three consequential stages, plus an 
initial input stage (Fig. 2). 
1. Imaginary input. This input stage involves imaginary perception and 
recognition. 1) Perception: Individuals perceive AI-related imagi-
naries from various sources, such as news articles, movies, and social 
media. This stage involves the sensory reception of AI-related con-
tent. 2) Recognition: The brain recognizes and categorizes these 
imaginaries based on prior knowledge and experiences with AI 
technologies (see Atkinson & Shiffrin, 1968).
2. Sensory imaginary. This is the initial processing stage where the input 
is interpreted and integrated. 1) Interpretation: The perceived 
imaginaries are interpreted in the context of existing AI experiences 
and sociotechnical imaginaries. This involves understanding the 
narratives and implications of AI that are presented in the input 
content (Shartori & Bocca, 2023). 2) Integration: The interpreted 
imaginaries are integrated with existing knowledge and beliefs about 
AI, forming a more comprehensive understanding of AI’s role and 
potential in society (Richter et al., 2023).
3. Short-term imaginary. This is the storage stage where certain pro-
cessed imaginaries are stored from one day to a lifetime. The inte-
grated information is encoded into memory, influencing future 
perceptions and decisions regarding AI. This stage is crucial for the 
long-term retention of AI imaginaries.
4. Long-term imaginary. This stage involves the formation and expres-
sion of enduring imaginaries. 1) Formation: The stored information 
contributes to the formation of personal and collective AI imagi-
naries, shaping how individuals and societies envision digital futures 
(Hoff, 2023). 2) Expression: These imaginaries are expressed through 
discussions, policy-making, and creative works, influencing public 
discourse and technological development.
The model includes a feedback loop dedicated to reflection and 
adaptation. 1) Reflection: Individuals reflect on their new and existing 
AI imaginaries, considering new information and experiences. 2) 
Adaptation: Imaginaries are adapted based on feedback from real-world 
AI developments and societal changes, leading to a dynamic and 
evolving understanding of AI. Overall, this model illustrates how AI 
imaginaries are processed as information, highlighting the cognitive and 
social processes that shape our understanding and expectations of AI 
technologies.
4.1. Fostering technological identity
The pervasive use of artificial intelligence has generated a wide array 
of narratives and imaginaries about its potential societal impact. Our AI 
Imaginary Model suggests that these imaginaries are collective visions 
that help define how individuals and communities perceive and antici-
pate AI’s role in our shared digital futures. To understand the social 
dynamics underpinning these imaginaries and their influence on form-
ing and redefining technological identity, we apply Social Identity 
Theory (SIT) (Tajfel & Turner, 2001) to analyze how technological 
identities can be formed and influenced by collective beliefs and ex-
pectations about AI.
Social Identity Theory posits that individuals derive a portion of their 
identity from their membership in social groups. This theory explains 
the cognitive processes and social conditions that influence intergroup 
B. Zhong et al.                                                                                                                                                                                                                                   
Computers in Human Behavior 169 (2025) 108682 

--- Page 6 ---

behaviors, such as prejudice and discrimination. According to SIT, social 
identity is a person’s sense of who they are based on their group mem-
berships, which can include social class, family, or even technological 
affiliations. Now we use SIT to emphasize the impact of AI imaginaries 
on group identity, categorization, and social context in shaping both 
individual and collective behaviors in the areas of technology use and 
perceptions of digital futures.
Informed by Social Identity Theory, we have identified three primary 
areas concerning the impact of AI imaginaries on users’ technological 
identification. 1) Social categorization: This cognitive process involves 
classifying people, including oneself, into groups. In the era of AI, AI 
imaginaries help users simplify and organize their tech world by 
creating in-groups, where they feel a sense of belonging due to shared AI 
imaginaries. Meanwhile, they could create out-groups, where they do 
not belong to. For instance, users of i OS or Android appliances some-
times call themselves fans of Apple or Android products. They may avoid 
products they do not identify with or are unfamiliar with. More 
importantly, they tend to view those who use the same operating system 
as belonging to their in-groups, while viewing others using a different 
operating system as part of out-groups. 2) Technological identification: 
Once categorized, users adopt the tech identity of the group they belong 
to, influencing their perceptions of the technology and digital futures. 
This identification may lead to behavior change and a sense of belonging 
and unity within the group. For instance, scientific fiction fan identity 
and positive emotions are among the most robust and consistent pre-
dictors of moral consideration for Ais, which significantly influence how 
those fans perceive and morally include AIs within their moral frame-
work (Pauketat & Anthis, 2022). 3) Social comparison: AI users compare 
their in-groups with out-groups, often favoring their own group to 
enhance self-esteem, which can lead to in-group favoritism and 
out-group discrimination.
4.2. Identity infusion
AI imaginaries are deeply embedded in social, economic, and polit-
ical contexts and reflect shared understandings of desirable futures. As 
organizing visions, they play a significant role in shaping technological 
identity, influencing how communities form collective identities around 
technology. Social Identity Theory suggests that individuals align with 
groups that share similar beliefs and visions. AI imaginaries can influ-
ence how communities form collective identities around technology, 
thus shaping individual technological identities. For example, groups 
may form based on shared optimism or skepticism about AI’s potential, 
affecting how they perceive and interact with AI technologies. As AI 
becomes more integrated into society, it may be perceived as an out- 
group, intensifying the strength of human identity through between- 
group comparison. This dynamic can lead to increased identification 
with humanity as people navigate AI’s implications on their social and 
technological identities.
When users are so deeply identified with certain sets of AI imagi-
naries, identity fusion happens. Identity Infusion Theory, as proposed by 
William B. Swann, suggests that individuals integrate certain aspects of 
their identity with external entities, leading to a stronger sense of self 
(Swann et al., 2001). This theory can be applied to understand how users 
integrate AI technologies into their personal and professional identities, 
which in turn affects their engagement with these technologies. Swann’s 
concept of self-verification, where individuals seek feedback that con-
firms their self-views, can be applied to AI imaginaries. Users who 
integrate AI into their identity seek out AI applications and systems that 
reinforce their self-concept, leading to a deeper engagement with these 
technologies. Swann’s findings on identity fusion and pro-group be-
haviors suggest that users who strongly identify with AI technologies 
may become advocates for these systems. This can influence how they 
envision digital futures, often seeing AI as a central and beneficial 
component of society.
Swann’s research indicates that identity fusion affects both personal 
and social self-views. Users who integrate AI into their identity may not 
only change their self-perception but also influence their social in-
teractions and expectations of technological advancements. The prin-
ciples of identity fusion can be extended to understand the diverse ways 
in which AI users might envision and interact with digital futures. This 
helps identify how different user groups, based on their levels of 
engagement with AI, form distinct AI imaginaries.
4.3. Shared digital futures
Imagination plays a crucial role in AI development, guiding re-
searchers and developers to explore novel ideas and applications. The 
ability to imagine new AI capabilities and their potential impacts drives 
innovation and experimentation. This aligns with the broader evolu-
tionary role of imagination, which has historically enabled humans to 
envision and create new realities (Gosetti-Ferencei, 2023). To scientists, 
imagination is no longer seen as mere fantasy or illusion (Sarewitz, 
1996). It becomes an important cultural resource that enables new forms 
of life by projecting positive goals and seeking to attain them (Jasanoff & 
Kim, 2009). AI development benefits from interdisciplinary collabora-
tion, combining insights from computer science, psychology, ethics, and 
the arts. This collaborative approach enriches the imaginaries of AI, 
ensuring that diverse perspectives are considered in shaping the future 
of AI technologies.
Imagination serves as a unique creative faculty that fills the gap 
between what is seen and unseen, operating in a “possibility space” that 
perception alone cannot address (Mozhdehfarahbakhsh et al., 2024). 
Mozhdehfarahbakhsh et al. (2024) found that imagination actively 
constructs and fills these spaces with potential realities and possibilities, 
allowing us to experience multiple possible worlds simultaneously 
through our meta-cognitive ability, even while knowing that only one 
physical reality exists. These findings are particularly significant 
because they challenge traditional views of imagination as merely a 
supplementary cognitive function, instead positioning it as a funda-
mental component in how we construct and experience reality. Thus, 
imagination is integral to perception and helps in interpreting sensory 
information (O’Connor & Aardema, 2005).
Imagination is fundamentally linked to future thinking as it repre-
sents the cognitive ability to envision potential future events (Szpunar 
et al., 2014). In general, imagination encompasses a variety of 
future-oriented cognitions, including simulation, prediction, intention, 
and planning and they serve different functions in the context of adap-
tive behavior and are essential for effective future thinking (O’Connor & 
Aardema, 2005). Understanding how individuals engage in future 
thinking can enhance decision-making and goal-setting behavior. The 
link between imaginative processes and future thinking illustrates how 
individuals mentally simulate potential futures and equip themselves for 
these scenarios using various cognitive strategies (Szpunar et al., 2014).
4.4. Collective visions and beliefs
As we step into a new era where AI becomes an integral part of our 
lives, human communication is undergoing a transformative change. 
Digital threads are intertwining our destinies with the algorithmic 
threads of AI, creating a new tapestry of communication. The digital 
futures envisioned by users are shaped by their AI imaginaries. Heavy 
users, with their integrated AI identities, often foresee a future where AI 
plays a central role in various aspects of life, from work to personal 
relationships (Zhong, 2013). In contrast, light users and non-users may 
envision a more cautious or minimalistic integration of AI technologies. 
The diverse AI imaginaries and envisioned digital futures have signifi-
cant sociotechnical implications. Policymakers and technologists must 
consider these varied perspectives to ensure inclusive and equitable 
development and implementation of AI technologies. Understanding the 
diverse AI imaginaries and their impact on technological identity can 
inform the development and implementation of AI technologies to 
B. Zhong et al.                                                                                                                                                                                                                                   
Computers in Human Behavior 169 (2025) 108682 

--- Page 7 ---

ensure they are inclusive and equitable. Historically, AI imaginaries 
have evolved from utopian visions of intelligent machines to more 
nuanced and diverse narratives influenced by cultural, economic, and 
political factors (see Satchell, 2008, pp. 1593–1602). The imaginaries 
surrounding AI often emphasize its ability to revolutionize communi-
cation. For instance, AI applications can understand and respond to 
human emotions (affective computing), suggesting a future where ma-
chines can provide empathetic support and nuanced conversation 
(Sartori & Bocca, 2022). This vision influences how we integrate AI into 
our communication systems, driving the development of more sophis-
ticated and emotionally intelligent AI.
AI technologies have significant potential to influence human 
behavior. AI-driven applications can promote positive behavior change 
in areas such as health, education, and environmental conservation. AI 
imaginaries as a tool for behavior modification can evoke both excite-
ment and concern. On one hand, there is optimism about AI’s ability to 
support healthier and more productive lifestyles. On the other, there are 
fears about loss of autonomy and privacy, with AI potentially manipu-
lating behavior in ways that may not align with individual or societal 
values. These imaginaries shape public attitudes towards AI adoption 
and regulation. The collective imagination about AI’s future impact on 
society oscillates between utopian and dystopian visions (Satchell, 2008, 
pp. 1593–1602). Utopian narratives often envision a world where AI 
enhances human capabilities, solves complex problems, and creates a 
more equitable society. In contrast, dystopian narratives warn of AI 
surpassing human control, leading to mass unemployment, privacy in-
vasion, and even existential threats. These futuristic visions influence 
policymaking and innovation. Policymakers may implement regulations 
to safeguard against potential AI risks, while also fostering innovation 
that aligns with positive imaginaries. For instance, ethical AI frame-
works are developed to ensure that AI technologies are designed and 
deployed in ways that benefit society (Pauketat & Anthis, 2022).
Susan T. Fiske’s Stereotype Content Model (SCM) provides a 
framework to understand how people categorize AI based on dimensions 
such as warmth and competence (Fiske & Taylor, 1984). Positive or 
negative stereotypes about AI influence individuals’ attitudes, in-
teractions, and trust in these systems. Warm and competent AI may be 
perceived positively and trusted, while perceptions of cold but compe-
tent AI could lead to cautious or limited interaction (Fiske & Taylor, 
2013). This categorization affects the acceptance and use of AI in various 
contexts, shaping how society integrates these technologies into 
everyday life (Mc Kee et al., 2023). People generally exhibit similar 
emotional and behavioral reactions to robots as they do to humans, with 
perceptions being primarily shaped by warmth (associated with 
friendliness and sincerity) and competence (related to efficacy and 
capability). These dimensions predict specific emotional responses such 
as admiration, envy, contempt, and pity, which in turn influence distinct 
behavioral tendencies including active facilitation and passive harm 
(Mieczkowski et al., 2019).
Thus, user perception of AI is often found to influence interpersonal 
dynamics. Individuals may prefer human interaction over AI for 
emotionally significant tasks if they perceive AI as highly competent but 
lacking warmth. This preference shapes social interactions and poten-
tially alters the nature of interpersonal relationships, affecting how trust 
and emotional support are perceived and exchanged in human-AI in-
teractions. As AI becomes more integrated into social environments, 
understanding these dynamics is crucial for designing systems that 
complement rather than disrupt human relationships (Mc Kee et al., 
2023). In this vein, AI may exacerbate certain negative aspects of aca-
demic debates, while its growing role in research should potentially 
enhance and not replace human creativity (Chubb et al., 2022).
5. Future research directions
Exploring AI imaginaries calls for interdisciplinary research bridging 
social psychology, AI ethics, and technology development. Future 
studies should investigate how AI imaginaries evolve and their impact 
on societal norms, practices, and policies. The research of AI imaginaries 
is crucial for informed decision-making, ethical AI development, and 
cultivating a harmonious relationship between humans and AI tech-
nologies. Future research should examine the impact of AI imaginaries 
on various demographic groups, including age, gender, and cultural 
backgrounds. The integration of theoretical frameworks, such as 
Swann’s Identity Infusion Theory (Swann et al., 2001) and Jasanoff’s 
Sociotechnical Imaginaries Theory (Jasanoff, 2015), offers a robust basis 
for understanding how AI imaginaries influence the digital futures and 
technological identity. These imaginaries, shaped by cultural and soci-
etal contexts, allow us to examine the collective beliefs, values, and 
expectations about AI across different regions and communities. Overall, 
the novel findings related to AI imaginaries opens up important avenues 
for future research directions, for instance, in understanding how 
emotional intelligence in robots, multimodal interaction capabilities, 
and ethical implications of human-robot emotional engagement might 
influence these behavioral tendencies (Mieczkowski et al., 2019). The 
approaches suggest a need to further investigate how the traditional 
SCM might need to be modified when applied to artificial agents.
AI imaginaries vary significantly across cultures due to differing 
norms, values, and historical experiences. Cultural factors shape per-
ceptions of AI, influencing societal attitudes and adoption rates. For 
instance, technologically advanced societies may embrace AI more 
readily, while those valuing human interaction and tradition may 
exhibit reservations. Understanding these cultural nuances is essential 
for developing culturally sensitive AI systems that are widely accepted 
(Fiske, 2022). Future research could further explore how AI imaginaries 
and technological identities evolve in various cultural settings, 
comparing these trajectories across global contexts to gain a more 
comprehensive understanding of AI’s role in shaping digital futures. 
Through such interdisciplinary efforts, we can ensure that the evolution 
of AI aligns with societal values and fosters equitable, inclusive digital 
futures.
6. Conclusion
AI imaginary is an important concept in the long and arduous 
journey towards understanding how users comprehend and interpret the 
various layers of the social significance of AI technology. AI’s trans-
formative power has generated multitude of diverse and often conflict-
ing visions of digital futures. Understanding how users perceive and 
interpret AI imaginaries is crucial for navigating this complex landscape, 
fostering open dialogue to reach a shared vision for AI’s future. During 
the process, humans bear the responsibility for deciding which tech-
nologies deserve investment, ensuring that these choices align with our 
ethical and societal values. As AI continues to evolve, it is crucial to 
approach these challenges thoughtfully to maximize the benefits of AI 
while minimizing potential risks. In this crucible of innovation, 
humanity’s hopes are fervently cast, forging a vision of technology as 
our ultimate ally in navigating the labyrinth of tomorrow’s un-
certainties. As we ponder the fate of our society in the next 10 or 100 
years, the conversations invariably gravitate towards the nexus of pos-
sibilities and risks that AI holds.
Our digital futures, intricately woven with algorithms, spark a cos-
mic dialogue on AI’s benevolent gifts and ominous shadows. In this era 
of technological advancement, our collective imagination could uplift or 
challenge our existence. In this article, we emphasize the importance of 
AI imaginaries in shaping shared digital futures, including user tech-
nological identity. The AI Imaginary Model provides insights into how 
users perceive and interact with AI technologies. AI imaginaries influ-
ence AI development, adoption, and regulation. Understanding and 
engaging with these imaginaries shape AI perception and guides 
responsible AI integration. Balanced imagination provides a roadmap 
for navigating AI opportunities and challenges, ensuring alignment with 
collective values. AI imaginaries, as higher cognition capabilities 
B. Zhong et al.                                                                                                                                                                                                                                   
Computers in Human Behavior 169 (2025) 108682 

--- Page 8 ---

forming visions, perceptions, and expectations about AI, profoundly 
influence social cognition and behaviors. By addressing these com-
plexities, we can harness the potential of AI to positively impact social 
dynamics while mitigating potential risks.
CRedi T authorship contribution statement
Bu Zhong: Writing – review & editing, Writing – original draft, 
Validation, Supervision, Resources, Project administration, Methodol-
ogy, Conceptualization. Yunya Song: Writing – review & editing, 
Project administration, Conceptualization. Guangchao Charles Feng: 
Writing – review & editing, Methodology, Conceptualization. Jingyuan 
Shi: Writing – review & editing, Resources, Conceptualization. Yuner 
Zhu: Writing – review & editing, Methodology, Conceptualization. Lola 
Xie: Writing – review & editing, Investigation, Conceptualization. 
Wanhui April Zhou: Writing – review & editing, Conceptualization. 
Sinan Yu: Writing – review & editing, Conceptualization. Yajing Lu: 
Writing – review & editing, Conceptualization. Ying Qin: Writing – 
review & editing, Conceptualization. Zuquan Xiong: Writing – review 
& editing, Conceptualization.
CRedi T authorship statement
B. Zhong, Conceptualization, project administration, resources, su-
pervision and writing - original draft. Y. Song, C. Feng, J. Shi, Y. Zhu 
and L. Xie, Conceptualization, validation, writing - review & editing; W. 
Zhou, S. Yu, Y. Lu, Y. Qin, and Z. Xiong, Writing - review, conceptu-
alization, and resources.
Declaration of competing interest
The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper.
Appendix I. The short scale of AI imaginaries (12 items)
Introduction: AI imaginaries, which encompass the collective vi-
sions and narratives surrounding the future of artificial intelligence, play 
a crucial role in shaping public perception, influencing policymaking, 
and guiding technological development. To systematically study and 
quantify these imaginaries, we have developed a scale informed by 
research across the humanities, social sciences, computing, and infor-
mation science. While AI imaginaries are assessed at the individual user 
level, they ultimately reflect broader collective visions and narratives. 
The literature identifies six key dimensions of this concept. Based on our 
conceptual framework, we have created two items for each dimension in 
this condensed version. Pilot testing and statistical analyses will ensure 
the scale’s validity and reliability. This approach not only deepens our 
understanding of the social aspects of AI but also highlights the impor-
tance of integrating diverse perspectives in the ongoing discourse about 
artificial intelligence and its implications for society.
Perceived Benefits and Risks:
1. AI will significantly enhance healthcare by transforming medical 
systems and improving patient outcomes.
2. AI poses a threat to job security in many industries.
Emotional Responses:
3. I am excited about advancements in AI technology.
4. I worry about the potential misuse of AI.
Ethical and Social Considerations:
5. AI development should prioritize ethical guidelines.
6. AI could exacerbate existing social inequalities.
Impact on Human Behavior and Cognition:
7. AI imaginaries influence my daily decision-making processes.
8. AI developments have changed the way I interact with others and the 
world.
Technological Understanding:
9. I have a good understanding of how AI algorithms work and what 
they can do.
10. I understand the limitations of current AI technologies and do not 
overestimate their benefits.
Future Expectations:
11. In the next decade, AI will be integrated into most aspects of daily 
life.
12. AI developments make me feel optimistic about the future, and I 
trust in its positive impact.
Note: Rationale for Item Selection. 
• Perceived Benefits and Risks: Items selected reflect both positive and 
negative perceptions, capturing the dual nature of AI’s impact.
• Emotional Responses: These items address both excitement and 
concern, which are common emotional reactions to AI.
• Ethical and Social Considerations: The chosen items highlight the 
importance of ethics and potential social impacts, which are critical 
in AI discussions.
• Technological Understanding: These items assess the respondent’s 
self-reported knowledge, which is crucial for understanding AI 
imaginaries.
• Impact on Human Behavior and Cognition: Items focus on personal 
influence and media portrayal, both significant in shaping AI 
imaginaries.
• Future Expectations: These items capture the anticipated integration 
and overall impact of AI, reflecting forward-looking imaginaries.
Appendix II. The full scale of AI imaginaries (24 items)
Note: This is the long version of the scale of AI imaginaries. Each 
dimension is measured by four items.
Perceived benefits and risks:
1. AI will significantly improve healthcare outcomes.
2. AI poses a threat to job security in many industries.
3. AI can enhance educational experiences.
4. The development of AI can lead to increased inequality.
Emotional responses:
5. I feel excited about advancements in AI technology.
6. I am worried about the potential misuse of AI.
7. AI developments make me feel hopeful about the future.
8. I feel anxious about AI’s impact on privacy.
Ethical and social considerations:
9. AI development should prioritize ethical guidelines.
10. AI could exacerbate existing social inequalities.
B. Zhong et al.                                                                                                                                                                                                                                   
Computers in Human Behavior 169 (2025) 108682 

--- Page 9 ---

11. The ethical implications of AI are well managed.
12. AI can be developed in ways that respect human rights.
Technological understanding:
13. I have a good understanding of how AI algorithms work.
14. I am aware of the different applications of AI in various fields.
15. I understand the limitations of current AI technologies.
16. The technical aspects of AI are often overestimated.
Impact on behavior and cognition:
17. AI imaginaries influence my daily decision-making processes.
18. The portrayal of AI in media affects my understanding and ex-
pectations of technology.
19. AI developments have changed the way I interact with others and 
the world.
20. My behavior has been influenced by AI-powered applications.
Future expectations:
21. In the future, AI will be integrated into most aspects of daily life.
22. AI will lead to significant societal changes in the next decade.
23. AI will replace many current jobs.
24. The benefits of AI will outweigh the potential risks.
Data availability
No data was used for the research described in the article.
References
Appio, F. P., Hernandez, C. T., Platania, F., & Schiavone, F. (2025). AI narratives in 
fiction and media: Exploring thematic parallels in public discourse. Technovation, 
142, Article 103201. https://doi.org/10.1016/j.technovation.2025.103201
Atkinson, P. (2001). Handbook of ethnography. SAGE. 
Atkinson, R. C., & Shiffrin, R. M. (1968). Human memory: A proposed system and its 
control processes. Psychology of Learning and Motivation, 2, 89–195. https://doi.org/ 
10.1016/S0079-7421(08)60422-3
Bearman, M., Ryan, J., & Rola, A. (2023). Discourses of artificial intelligence in higher 
education: A critical literature review. Higher Education, 86, 369–385. https://doi. 
org/10.1007/s10734-022-00937-2
Bengio, Y., Hinton, G., Yao, A., Song, D., Abbeel, P., Darrell, T., Harari, Y. N., Zhang, Y.- 
Q., Xue, L., Shalev-Shwartz, S., Hadfield, G., Clune, J., Maharaj, T., Hutter, F., 
Baydin, A. G., Mc Ilraith, S., Gao, Q., Acharya, A., Krueger, D., & Mindermann, S. 
(2024). Managing extreme AI risks amid rapid progress: Preparation requires 
technical research and development, as well as adaptive, proactive governance. 
Science, 384(6698), 842–845. https://doi.org/10.1126/science.adn0117
Bliuc, A.-M., & Chidley, A. (2022). From cooperation to conflict: The role of collective 
narratives in shaping group behaviour. Social and Personality Psychology Compass, 16, 
1–15. https://doi.org/10.1111/spc3.12670. Article e12670.
Carroll, J. (2020). Imagination, the brain’s default mode network, and imaginative 
verbal artifacts. In J. Carroll, M. Clasen, & E. Jonsson (Eds.), Evolutionary perspectives 
on imaginative culture (pp. 31–52). Cham: Springer. https://doi.org/10.1007/978-3- 
030-46190-4_2. 
Chubb, J., Cowling, P., & Reed, D. (2022). Speeding up to keep up: Exploring the use of 
AI in the research process. AI & Society, 37, 1439–1457. https://doi.org/10.1007/ 
s00146-021-01259-0
Coman, A., Momennejad, I., Drach, R. D., & Geana, A. (2016). Mnemonic convergence in 
social networks: The emergent properties of cognition at a collective level. PNAS, 
113(29), 8171–8176. https://doi.org/10.1073/pnas.1525569113
Dahlstrom, M. F. (2014). Using narratives and storytelling to communicate science with 
nonexpert audiences. Pest Articles and News Summaries, 111(Suppl. 4), 13614–13620. 
https://doi.org/10.1073/pnas.1320645111
Deˇzman, D. V. (2024). Promising the future, encoding the past: AI hype and public media 
imagery. AI and Ethics, 4, 743–756. https://doi.org/10.1007/s43681-024-00474-x
Dwivedi, Y. K., Hughes, L., smagilova, E. I., Aarts, G., Coombs, C., Crick, T., Duan, Y., 
Dwivedi, R., Edwards, J., Eirug, A., Galanos, Ilavarasan, P. V., anssen, M. J., 
Jones, P., Kar, A. K., Kizgin, H., Kronemann, B., Lal, B., Lucini, B., & Williams, M. D. 
(2021). Artificial Intelligence (AI): Multidisciplinary perspectives on emerging 
challenges, opportunities, and agenda for research, practice and policy [Opinion 
paper]. International Journal of Information Management, 57, 1–47. https://doi.org/ 
10.1016/j.ijinfomgt.2019.08.002, 101994.
Ehsan, U., Passi, S., Liao, Q. V., Chan, L., Lee, I.-H., Muller, M., & Riedl, M. O. (2024). The 
who in XAI: How AI background shapes perceptions of AI explanations. ACM CHI 
2024, 2. https://doi.org/10.48550/ar Xiv.2107.13509. ar Xiv:2107.13509.
Fazlioglu, M. (2023). US federal AI governance: Laws, policies and strategies. 
https://iapp.org/resources/article/us-federal-ai-governance/#:~:text=And%2C% 
20on%2011%20April%2C,by%20generative%20AI%20is.
Finn, E., & Wylie, R. (2021). Collaborative imagination: A methodological approach. 
Futures, 132, 1–11. https://doi.org/10.1016/j.futures.2021.102788. Article 102788.
Fiske, S. T., & Taylor, S. E. (1984). Social cognition. Addison-Wesley Pub. Co. 
Fiske, S. T., & Taylor, S. E. (2013). Social cognition: From brains to culture (2nd ed.). Sage. 
Gosetti-Ferencei, J. (2023). Imagination: A very short introduction. Oxford Academic. 
https://doi.org/10.1093/actrade/9780198830023.001.0001
Guitton, M., Zhong, B., & Song, C. Y. (2024). Revisiting scholarly and public perceptions 
of artificial intelligence: Current state and future trajectories. Communications 
Society, 68, 1–44.
Hautala, J., & Heino, H. (2023). Spectrum of AI futures imaginaries by AI practitioners in 
Finland and Singapore: the unimagined speed of AI progress. Futures, 153, 1–11. 
https://doi.org/10.1016/j.futures.2023.103247
Hoff, J.-L. (2023). Unavoidable futures? How governments articulate sociotechnical 
imaginaries of AI and healthcare services. Futures, 148, 1–13. https://doi.org/ 
10.1016/j.futures.2023.103131. Article 103131.
Hohendanner, M., Ullstein, C., Buchmeier, Y., & Grossklags, J. (2023). Exploring the 
reflective space of AI narratives through speculative design in Japan and Germany. 
Good IT ’23: Proceedings of the 2023 ACM conference on information technology for 
social good. https://doi.org/10.1145/3582515.3609554
Hohenstein, J., Kizilcec, R. F., Di Franzo, D., Aghajari, Z., Mieczkowski, H., Levy, K., 
Naaman, M., Hancock, J., & Jung, M. F. (2023). Artificial intelligence in 
communication impacts language and social relationships. Scientific Reports, 13, 1–9. 
https://doi.org/10.1038/s41598-023-30938-9. Article 5487.
Hudson, A. D., Finn, E., & Wylie, R. (2023). What can science fiction tell us about the 
future of artificial intelligence policy? AI & Society, 38, 197–211. https://doi.org/ 
10.1007/s00146-021-01273-2
Jasanoff, S. (2015). Future imperfect: Science, technology, and the imaginations of 
modernity. In S. Jasanoff, & a.-H. Kim (Eds.), Dreamscapes of modernity: 
Sociotechnical imaginaries and the fabrication of power (pp. 1–31). The University of 
Chicago Press. https://doi.org/10.7208/chicago/9780226276663.003.0001. 
Jasanoff, S. (2016). The ethics of invention: Technology and the human future (1st ed.). 
Norton. 
Jasanoff, S. (2019). Can science make sense of life? Polity. 
Jasanoff, S., & Kim, S.-H. (2009). Containing the atom: Sociotechnical imaginaries and 
nuclear power in the United States and South Korea. Minerva, 47(2), 119–146. 
https://doi.org/10.1007/s11024-009-9124-4
Jones, C. W., & Paris, C. (2018). It’s the end of the world and they know it: How 
dystopian fiction shapes political attitudes. Perspectives on Politics, 16(4), 968–989. 
https://doi.org/10.1017/S1537592718002153
Kanzola, A.-М., Papaioannou, K., & Petrakis, P. (2024). Unlocking society’s standings in 
artificial intelligence. Technological Forecasting and Social Change, 200, 1–26. https:// 
doi.org/10.1016/j.techfore.2023.123106. Article 123106.
Kosslyn, S. M., Ganis, G., & Thompson, W. L. (2001). Neural foundations of imagery. 
Nature Reviews Neuroscience, 2, 635–642. https://doi.org/10.1038/35090055
Laakasuo, M., Drosinou, M., Koverola, M., Kunnari, A., Halonen, J., Lehtonen, N., & 
Palom¨aki, J. (2018). What makes people approve or condemn mind upload 
technology? Untangling the effects of sexual disgust, purity and science fiction 
familiarity. Palgrave Communications, 4, 1–14. https://doi.org/10.1057/s41599-018- 
0124-6. Article 84 (2018.
Law, H. (2023). Computer vision: AI imaginaries and the (Vol. 4, pp. 657–663). 
Massachusetts Institute of Technology. AI and Ethics. https://doi.org/10.1007/ 
s43681-023-00389-z
Long, D., & Magerko, B. (2020). What is AI literacy? Competencies and design 
considerations. CHI ’20: Proceedings of the 2020 CHI conference on human factors in 
computing systems. https://doi.org/10.1145/3313831.337672
Macgilchrist, F., Allert, H., Pargman, T. C., & Jarke, J. (2024). Designing postdigital 
futures: Which designs? Whose futures? Postdigital Science and Education, 6, 13–24. 
https://doi.org/10.1007/s42438-022-00389-y
Makridakis, S. (2017). The forthcoming Artificial Intelligence (AI) revolution: Its impact 
on society and firms. Futures, 90, 46–60. https://doi.org/10.1016/j. 
futures.2017.03.006
Mc Kee, K. R., Bai, X., & Fiske, S. T. (2023). Humans perceive warmth and competence in 
artificial intelligence. i Science, 26(8), 1–26. https://doi.org/10.1016/j. 
isci.2023.107256
Mc Leod, S. (2023). Social identity theory in psychology. Simply Psychology. https://www. 
simplypsychology.org/social-identity-theory.html#:~:text=Once%20individuals% 
20categorize%20themselves,terms%20of%20group%20characteristics.
Mieczkowski, H., Liu, S. X., Hancock, J., & Reeves, B. (2019). Mieczkowski et al. 14th 
ACM/IEEE International Conference on Human-Robot Interaction (HRI). https://doi. 
org/10.1109/HRI.2019.8673307, 2019.
Mozhdehfarahbakhsh, A., Hecker, L., Joos, E., & Kornmeier, J. (2024). Visual 
imagination can influence visual perception – towards an experimental paradigm to 
measure imagination. Scientific Reports, 14, 1–12. https://doi.org/10.1038/s41598- 
024-74693-x, 24486 (2024).
Nader, K., Toprac, P., Scott, S., & Baker, S. (2022). Public understanding of artificial 
intelligence through entertainment media. AI & Society, 2, 1–14. https://doi.org/ 
10.1007/s00146-022-01427-w. April.
O’Connor, K. P., & Aardema, F. (2005). The imagination: Cognitive, pre-cognitive, and 
meta-cognitive aspects. Consciousness and Cognition, 14(2), 233–256. https://doi. 
org/10.1016/j.concog.2004.07.005
Pauketat, J. V. T., & Anthis, J. R. (2022). Predicting the moral consideration of artificial 
intelligences. Computers in Human Behavior, 136, 1–18. https://doi.org/10.1016/j. 
chb.2022.107372, 107372.
B. Zhong et al.                                                                                                                                                                                                                                   
Computers in Human Behavior 169 (2025) 108682 

--- Page 10 ---

Pinski, M., & Benlian, A. (2024). AI literacy for users – a comprehensive review and 
future research directions of learning methods, components, and effects. Computers 
in Human Behavior: Artificial Humans, 2(1). https://doi.org/10.1016/j. 
chbah.2024.100062. Article 100062.
Richter, V., Katzenbach, C., & Sch¨afer, M. S. (2023). Imaginaries of artificial intelligence. 
In S. Lindgren (Ed.), Handbook of critical studies of artificial intelligence (pp. 209–223). 
Edward Elgar. https://doi.org/10.4337/9781803928562.00024. 
Sarewitz, D. R. (1996). Frontiers of illusion : Science, technology, and the politics of progress. 
Temple University Press. 
Sartori, L., & Bocca, G. (2022). Minding the gap(s): Public perceptions of AI and socio- 
technical imaginaries (Vol. 38, pp. 443–458). AI & Society. https://doi.org/10.1007/ 
s00146-022-01422-1
Satchell, C. (2008). Cultural theory and real world design: Dystopian and utopian 
outcomes. SIGCHI: Conference on human factors in computing systems. https://doi.org/ 
10.1145/1357054.135730
Schwarz, N. (1990). Feelings as information: Informational and motivational functions of 
affective states. In E. T. Higgins, & R. M. Sorrentino (Eds.), Handbook of motivation 
and cognition: Foundations of social behavior (Vol. 2, pp. 527–561). Guilford. 
Schwarz, N. (2012). Feelings-as-information theory. In P. A. M.v. Lange, 
A. W. Kruglanski, & E. T. Higgins (Eds.), Handbook of theories of social psychology 
(Vol. II, pp. 289–308). Sage. https://doi.org/10.4135/9781446249215.n15. 
Sereno, M. I., Dale, A. M., Reppas, J. B., & Kwong, K. K. (1995). Borders of multiple visual 
areas in humans revealed by functional magnetic resonance imaging. Science, 268, 
889–893.
Shartori, L., & Bocca, G. (2023). Minding the gap(s): Public perceptions of AI and socio- 
technical imaginaries (Vol. 38, pp. 443–458). AI & Society. https://doi.org/10.1007/ 
s00146-022-01422-1
Sismondo, S. (2020). Sociotechnical imaginaries: An accidental themed issue. Social 
Studies of Science, 50(4), 505–507. https://doi.org/10.1177/0306312720944753
Swann, W. B., Angel, G., Seyle, D. C., Morales, J. F., & Huici, C. (2001). Identity fusion: 
The interplay of personal and social identities in extreme group behavior. Journal of 
Personality and Social Psychology, 96(5), 995–1011. https://doi.org/10.1037/ 
a0013668
Szpunar, K. K., Spreng, R. N., & Schacter, D. L. (2014). A taxonomy of prospection: 
Introducing an organizational framework for future-oriented cognition. PNAS, 111 
(52). https://doi.org/10.1073/pnas.1417144111
Tajfel, H. (1978). Differentiation between social groups: Studies in the social psychology 
of intergroup relations. Published in cooperation with European association of 
experimental social psychology by. Academic Press. 
Tajfel, H., & Turner, J. (2001). An integrative theory of intergroup conflict. In 
M. A. Hogg, & D. Abrams (Eds.), Intergroup relations: Essential readings (pp. 94–109). 
Psychology Press. 
Taylor, C. (2004). Modern social imaginaries. Duke University Press. Table of contents http 
://www.loc.gov/catdir/toc/ecip046/2003014769.html.
Zacher, L. W. (2015). Digital future(s). In L. W. Zacher (Ed.), Endycolopedia of information 
sciences and technology (p. 10). IGI Global. https://doi.org/10.4018/978-1-4666- 
5888-2.ch367. 
Zhong, B. (2013). From smartphones to i Pad: Power users’ disposition toward mobile 
media devices. Computers in Human Behavior, 29(4), 1742–1748. https://doi.org/ 
10.1016/j.chb.2013.02.016
Zhong, B. (2020). Social consequences of internet civilization. Computers in Human 
Behavior, Article 106308.
Zhong, B. (2022). Social media communication: Trends and theories. Wiley-Blackwell. 
Zhong, B. (2023). Going beyond fact-checking to fight health misinformation: A multi- 
level analysis of the twitter response to health news stories. International Journal of 
Information Management, 70, 1–11. https://doi.org/10.1016/j. 
ijinfomgt.2023.102626. Article 102626.
B. Zhong et al.                                                                                                                                                                                                                                   
Computers in Human Behavior 169 (2025) 108682
