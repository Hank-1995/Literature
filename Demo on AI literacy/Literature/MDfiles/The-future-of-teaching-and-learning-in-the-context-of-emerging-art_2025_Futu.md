# The future of teaching and learning in the context of emerging artificial intelligence technologies

## Metadata
- **Author**: Elochukwu Ukwandu
- **Subject**: Futures, 171 (2025) 103616. doi:10.1016/j.futures.2025.103616
- **Creator**: Elsevier
- **Producer**: Acrobat Distiller 8.1.0 (Windows)
- **Creation Date**: D:20250606155938Z
- **Modification Date**: D:20250607101941Z
- **Source File**: The-future-of-teaching-and-learning-in-the-context-of-emerging-art_2025_Futu.pdf
- **Converted**: 2025-10-23 22:46:11

---

## Content

--- Page 1 ---

The future of teaching and learning in the context of emerging 
artificial intelligence technologies
Elochukwu Ukwandu a,*,1, Omobolanle Omisade a, Karl Jones b, Simon Thorne b, 
Mike Castle c
a Department of Applied Computing, Cardiff School of Technologies, Cardiff Metropolitan University, 200 Western Avenue, Cardiff, Wales CF5 2YB, 
UK
b Department of Computer Science, Cardiff School of Technologies, Cardiff Metropolitan University, 200 Western Avenue, Cardiff, Wales CF5 2YB, 
UK
c Quality Enhancement Directorate, Cardiff Metropolitan University, 200 Western Avenue, Cardiff, Wales CF5 2YB, UK
A R T I C L E  I N F O
Keywords:
Generative artificial intelligence
Prompt technologies
Artificial intelligence
Chat GPT
AI-Agents
Future of teaching and learning
Emerging AI disruptive technologies
A B S T R A C T
In the context of emerging artificial intelligence technologies (AI) such as AI-Bots (Chat GPT) and 
AI-Agents, it is imperative that adequate adjustment be made, and also seen to be made. However, 
this has to be done from an informed positions. There is no doubt that these disruptive tech-
nologies are changing the way we live, conduct our day-to-day businesses, teach, learn and 
conduct research. There are also emerging concerns that these dynamics may result in a paradigm 
shift from student-teacher relationship to student-AI-Tutor-based relationship within the aca-
demic circle. Besides, there are foreseeable dangers of compromising academic integrity through 
high-technology plagiarism and the potentials of students avoiding learning through AI deploy-
ment and utilisation in their academic pursuits. But something worth considering is how applying 
these tools in education will potentially change the entire classroom experience of students, their 
knowledge and skills outcomes that are relevant in this AI era. This position paper is an effort to 
put into context what the authors of this paper forecast as the future of teaching and learning in 
the context of these inevitable disruptions to education activities and its subsectors as we 
currently know it. The authors found it necessary to take these positions to help bring to fore some 
practical use cases of AI in education; recent developments and theoretical frameworks in liter-
ature, technical reports, as well as experts opinions that can help assuage stakeholder’s concerns 
despite some obvious existing challenges. It is our view that this paper will be found useful by 
educators, stakeholders and administrators in the areas of curriculum design, classroom admin-
istration and entire academic planning and reviews.
1. Introduction
It is no longer up for debate that an emerging AI-centric society will be a deviation from norms - how we live, move, do business, 
and conduct our day-to-day life activities. In line with this, there are strong indications that AI will completely transform our 
* Corresponding author.
E-mail addresses: eaukwandu@cardiffmet.ac.uk (E. Ukwandu), bomisade@cardiffmet.ac.uk (O. Omisade), krjones@cardiffmet.ac.uk (K. Jones), 
sthorne@cardiffmet.ac.uk (S. Thorne), mcastle@cardiffmet.ac.uk (M. Castle). 
1 0000-0003-1350-4438
Contents lists available at Science Direct
Futures
journal homepage: www.elsevier.com/locate/futures
https://doi.org/10.1016/j.futures.2025.103616
Received 17 May 2024; Received in revised form 18 March 2025; Accepted 1 May 2025  
Futures 171 (2025) 103616 
Available online 15 May 2025 
0016-3287/© 2025 The Author(s). 
Published by Elsevier Ltd. 
This is an open access article under the CC BY license 
( http://creativecommons.org/licenses/by/4.0/ ). 

--- Page 2 ---

workplace, skill demands, and businesses Robert and Meenakshi (2024). These anticipated changes are also expected to affect the 
existing teaching and learning environment Popenici (2023). Much more is the consideration that in no distant time, these dynamics 
will lead to a shift from student-teacher relationship to student-AI-enabled Personal Assistant relationship, that is the anticipated era of 
artificial general intelligence (AGI). Some of the evolving technologies that can lead to these shifts are AI-enabled chatbots (for 
example, Chat GPT, a Generative AI (Gen AI) technology based on a large language model), personal agents, or personal digital-service 
provider (Gates, 2023c). These agents are a type of software tool that can respond and act on user instructions through everyday 
natural language and based on its knowledge of the user, can help to carry out virtually any activity in any area of life (Gates, 2023b). 
In education, there are fears about the dangers of compromising academic integrity (Cotton et al., 2023) through high-technology 
plagiarism and the potentials of students avoiding learning (Chomsky, 2023) through AI deployment and utilisation in their aca-
demic pursuits. More worrying are the potentials of changing the entire classroom experience for students; their knowledge and skills 
outcomes. Furthermore, Rosenblatt (2023) believes that having existing tools to detect text generated by AI is not enough to protect 
against the threats of academic integrity posed by AI.
In light of the above, there are some arguments on whether to ban the use of AI in the classroom or not, while the case where it was 
banned (Yang, 2023) has been lifted. Singer (2023) posits that its use and integration in classroom administration has been vocal 
(Roose, 2023; Rim, 2023; Brown, 2023; Duckworth & Ungar, 2023; Heaven, 2023) and overwhelming. Dowling and Lucey (2023); 
Thorp (2023) and Shields (2023) while arguing that AI tools have strong impacts on classroom administration, encouraged the use 
rather than the prohibition. Their reason is that the use of AI tools has been very helpful to students, ranging from getting started with 
an essay, writing an outline, and providing feedback on their work. Else (2023) in addition, said that AI tools have been helpful to 
students in generating ideas, organising their thoughts, writing an entire essay, as well as writing or debugging codes. One of the 
compelling voices in support of AI deployment in teaching and learning is that of the UK government (Edwards et al., 2025). The 
government has recently identified teachers as one of the groups that will start using AI for faster planning and record keeping in their 
recent plan to boost growth and deliver public services more efficiently using AI tools. This will in no small measure help in support of 
the deployment of existing government-developed AI teaching assistant that had been used by about 30,000 teachers in England at the 
moment.
In support of the above, Shields (2023) is of the opinion that, rather than banning AI tools in the classroom, teachers should design 
lessons around how the use of Gen AIs can help with academic exercises such as essay writing. In addition, teachers should 
acknowledge the realities of the powers of Gen AIs and focus on helping students through their use, which in turn will help revolu-
tionise how they teach Agarwal and Vij (2024); Shamsuddinova et al. (2024). Dwivedi et al. (2023) added that due to the potentials 
offered by AIs, higher education teachers should focus on engaging deeply with these disruptive technologies, using them in creating 
state-of-the-art classroom experiences and research experimentation rather than avoiding or banning them. Gates (2023c) in 
furtherance of his support for the use of AI in education advised that the use of AI should be encouraged in classroom administration, as 
the tools can help students’ writing and critical thinking alongside generating articles that the teacher and student can fact check. In 
addition, AIs can help students develop a study plan, point them to good resources, and test their knowledge. Heaven (2023) differs 
with Gates (2023c) by positing that although these AI tools may be helpful in providing students with quick answers to questions, they 
are devoid of the capacity to impact on them some essential academic and lifelong skillsets such as critical thinking and problem 
solving skills. Moreover, AI tools are deficient in being able to draw a student into a subject he/she is not already interested in.
In light of these points, the question is as follows: Should educators be gripped with fears or face the future by leaning on history 
and learning from previous disruptive technologies before AIs? Gates (2023c) argues that many of the issues that are raised in AI today 
have a historic precedent and there is no doubt that AIs will have big impacts on education (Dwivedi et al., 2023). He further opined 
that we could learn from history starting from the introduction of handheld electronic calculators, computers, etc. Furthermore, Gates 
(2023c) agrees that many teachers are concerned about the ways in which artificial intelligence will undermine their work with 
students, especially with the introduction of Chat GPT and other related prompt technologies. However, society has come to see how 
these technologies have changed how we query computers, write computer codes, write essays, assignments, and even academic 
articles.
The extent to which these disruptions by AIs will unfold remains very much unclear. Thus, exploring and holding a position based 
on perceived unfolding dynamics, especially as it affects teaching and learning, is the focus of this paper. The overall aim of this 
opinion paper is to situate the future of teaching and learning with regards to the rapid proliferation and roll-out of Gen AIs and other AI 
related tools in education. The authors intend to do this by synthesising the existing literature, technical reports, practical use cases, 
recent developments, experts, and stakeholders’ opinions.
The contributions of this paper include: 
• Identify from the existing literature the level of Gen AI applications in education.
• Providing some practical use case examples and safety measures on Gen AIs in Higher Education.
• Providing information on precedence, the present, and the pedagogical adaptation to teaching and learning in the context of 
systemic changes.
• Deep dive into Gen AIs in education: shortcomings, opportunities, threats, and recent developments.
• Providing through existing knowledge and opinions the present and future implications of use and non-use of these tools in 
education.
• Finally, we present the views and opinions of the authors in the context of this important ongoing academic discourse.
It is the authors’ understanding and preliminary position that Gen AIs have shown strong applications in education, as the 
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 3 ---

algorithms can be used by teachers and students as learning and communication support tools, research, and administrative assistance. 
They can also be used to create new and original content, such as images, computer codes, videos, and texts that cannot be easily 
differentiated from human-created content. But as a word of caution, the authors will advise against using Gen AI tools outside one’s 
domain of knowledge, as outputs need to be fact-checked for accuracy using expert knowledge. However, the coming era of AGIs is 
hypothetically believed to be a time when machines will have the ability to learn, think, and act in a way that is very close to that of 
humans. Thus, blurring the line between machine and human intelligence has very strong implications in education. For clarity, Gen AI 
tools/Large Language Models (LLMs), AI/AI tools may be used interchangeably in this paper.
The rest of the paper is organised as follows: Section 2 provides some existing literature in the public domain that focused on the 
subject matter under discussion, their outcomes, and areas of further studies. Section 3 was used by the authors to provide some 
practical use case examples of Gen AIs in HE. Section 4 showed how learning theories and contemporary pedagogical approaches can 
help inform the deployment of educational AIs, while section 5 was used to provide information on the evolution of teaching and 
learning practices in the face of systemic changes to help lean on the precedence in the navigation of emerging disruptive technologies 
in education. Section 6 provided a detailed look at Gen AI tools and their applications in education, as well as their limitations, op-
portunities, threats, recent developments, and varying opinions on their application and future of education. The paper summarised 
and made recommendations in section 7 and concluded in section 8.
2. Review of related works
Reading through section 1, it is clear that the authors of this paper are advocates of Gen AI tools in teaching, learning, and research. 
It is also the authors’ view that Gen AI systems operate a shared responsibility model. Whereas it is the duty of the user to carefully 
guide Gen AI tools with the right prompts for the expected outputs, it also lies on the user to fact check the outputs for accuracy before 
usage. So, the authors reiterate that it is not advisable to use Gen AI tools outside one’s domain of knowledge, as the issue of accuracy of 
results remains a challenge. On the basis of the above, this Section will be used to review existing knowledge, opinions, and advice in 
the literature on the use or otherwise of Gen AI tools in teaching and learning.
Artificial intelligence systems are human-created computer models that can help solve a specific problem or provide a particular 
service. Gates (2023a) opined that AI-driven software in the next few years will help revolutionise teaching and learning practices. 
Dwivedi et al. (2023) in their recent opinion paper stated that the practice of teaching, learning and academic research will be 
transformed by these emerging dynamics Shodieva (2024). In line with these, O’Connor (2022), Ifenthaler et al. (2024) discussed the 
possibilities of having increased human-AI collaborations in higher education in the near future. Their opinions focus on advocating for 
change in existing academic policies to provide legal and policy frameworks for the development, testing, and application of these 
disruptive computational tools that have shown potential to improve student learning and experience Deguara (2024). The authors 
also noted that, although the use of AI technologies has shown numerous benefits, there are concerns with issues of biases (Chen et al., 
2023; Hartmann et al., 2023; Popenici, 2023; Tariq, 2025); out-of-date training data; lack of transparency and credibility. Gates 
(2023c) shared some of these views and added hallucinations as part of the concerns. In AI systems, particularly Gen AIs, hallucinations 
refer to the models’ inability to understand the specifics of a user request, thereby resulting in an incorrect answer. Bias, on the other 
hand, happens because AI models have the chances of inheriting whatever prejudice baked into the datasets they were trained on. 
Some other concerns raised by Dwivedi et al. (2023) with regard to education (teaching and learning) in higher education (HE) 
include: the chances that its use could lead to superficial learning, lean abilities for critical thinking and creativity (O’Connor, 2022; 
Popenici, 2023), trust and transparency (Dowling & Lucey, 2023), privacy and security (Okonkwo & Ade-Ibijola, 2021a). Felten et al. 
(2023) listed teachers in schools and higher education as one of the most exposed to AI disruptions, which can lead to their profession 
being lost or degraded. This view was shared by the work of Popenici (2023). Popenici Popenici (2023) further argued that Gen AI 
outputs are just texts with good grammar and syntax, but lacking in creativity, critical thinking, depth, and wisdom.
The need to provide a more personalised learning experience and engagement has been the major driving force in the use and 
application of AI technologies in education according to (Cunningham-Nelson et al. 2019; Mohammed et al. 2024; Francis et al. 2025
and Okonkwo & Ade-Ibijola 2021a). According to the authors, chatbots appear to be the main AI technologies that are used to achieve 
this personalised and engaging learning experience for students (Benotti et al., 2017). The reasons for this wider use and applications 
range from being able to provide a quick and instance response to users (Okonkwo & Ade-Ibijola, 2021a; Smutny & Schreiberova, 
2020); respond to queries about course details and contents (Cunningham-Nelson et al., 2019); help students practice on their tests 
through questions and answers (Sinha et al., 2020). Gates (2023c) advised to use AI tools with caution as they are subject to biases and 
hallucinations, more cautiously when relying on them for routine frequently asked questions (FAQs) (Ranoliya et al., 2017) and so on. 
An example of a Chatbot widely used in Okonkwo and Ade-Ibijola (2021a) is Chat GPT (a Gen AI tool). The use of this has shown from 
Okonkwo and Ade-Ibijola (2021a); Khanna et al. (2024) to be able to enhance student learning outcomes and experiences when 
deployed to answer their questions, navigate e-learning resources, curriculum participation, and instant feedback. Gates (2023a)
agrees to the above, but added that AI technologies can only enhance learning and will never replace the classroom students-teacher 
relationship that fosters learning. However, it can help teachers with their routine administrative tasks, allowing them to engage more 
deeply on their classroom work (Hien et al., 2018; R¨ohrig and Heß, 2019). Some of these views were shared by the work of Mulaudzi 
(2024), who added that Gen AIs for teaching and learning in higher education can lead to innovative teaching methods, personalised 
learning experiences, and improved student engagement. Beyond these, they have the ability to bring about improved administrative 
efficiency, and by addressing education inequalities, they can promote equity and inclusion Tariq (2025), Limba et al. (2024), but this 
can vary between institutions and disciplines.
The works of Shamsuddinova et al. (2024) explored the views and perceptions of educators about the impact of AI on teaching and 
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 4 ---

learning within the case study area. Their findings showed that although educators are open to the use and optimistic about the 
potential benefits for education, the lack of understanding and training Ojha (2024) in the use of these tools in classroom instruction 
and assessment remains a barrier to its utilisation. There are also fears about the impacts of what they identified as inhibiting factors 
such as sociocultural reservations, systematic resistance to change Dube and Setlalentoa (2024), lack of structured policies Agarwal 
and Vij (2024) and available resources within the study region. Hence, the study concluded that the need for structured policy 
frameworks and guidelines on the use of AI in education cannot be overemphasised as this will help in the integration and better 
understanding of how to mitigate against associated risks.
This study by Okonkwo and Ade-Ibijola (2021b) evaluated the ethical implications of Chatbots use and application in higher 
education. Based on their findings, the use of chatbots in higher education creates a digital gap, impacts user privacy, is not trans-
parent, and has trust issues Rudolph et al. (2024). Furthermore, (O’Connor et al., 2023) said that Gen AI tools cannot replace human 
interactions in learning, which they identified as part of their downside. The use of these tools in teaching and learning according to the 
authors has the potential to reduce learners’ emotional intelligence; demeaning the necessary human social interaction that deepens 
learning and threatens the use of conventional classroom environment in teaching and learning. However, the authors agree that 
Gen AI tools can help assess critical thinking ability of learners; help in language acquisition, and support digital literacy.
The literature above showed nearly the same views from various authors on the potentials, threats, opportunities, and challenges of 
using Gen AI tools in teaching and learning. Although there are existing challenges and pitfalls regarding the use of these tools in HEIs, 
there are overwhelming views that these technologies are disruptive, have great impacts in education, and are coming to stay. One 
thing to note is that applications, user experiences, and usefulness vary between institutions and disciplines Mulaudzi (2024). The 
technologies are also a work in progress, and some Gen AI tools are better than others. For example, a celebrated case of hallucination 
using Microsoft Co-Pilot Thorne (2024) has now been fixed. In addition, there are improvements in the newer versions of these tools 
that are being released, such as Chat GPTo1 Strawberry, which have been found to be better than previous versions with more 
functionalities such as self-prompting around the input prompt given, thus forcing GPT to explore more options related to the initial 
query and, in principle, reduces hallucinations.
In addition to the issue of hallucination, Michael Calvin Wood Wood (2024) as quoted in Stakelum (2024) has claimed to 
demonstrate the ability to achieve 100 % accuracy in certain types of AI tasks, particularly in question-answer scenarios through his 
work, Acurai. Acurai Wood and Forbes (2024) according to Michael Calvin Wood is the world’s first AI that provides 100 % accurate, 
hallucination-free responses as made available to the public on July 23, 2024.
This study focuses on using the current available information and use cases, related theories, precedence, experiences, and recent 
developments to forecast the future of these powerful AI tools in teaching and learning.
3. Some practical uses of Gen AI in HE: authors’ use case examples
Gen AI systems like Chat GPT, Copilot, Gemini, Claude, Grok, etc. are large language models (LLMs), which are deep learning neural 
networks. What LLMs offer to HE is really the same benefits they offer to everyone. In teaching and learning, we categorised the 
offerings into: 
• Learning Support: Personalised tutoring, language learning, summarisation, and breaking down complex topics. Practical ex-
amples: LLMs were used in generating Python programming code for Data Science in a undergraduate class. The work involved 
giving plain English descriptions of complex programming code, which were used to analyse datasets in Data Science.
• The benefit of this is that even if the student does not know Python programming, LLMs can be used by the student to solve complex 
coding problems. This has been found to be an excellent way to learn the structures and form of the language by beginners.
• Another use case is where LLMs were used in breaking down complex papers in an MSc class. The application was found very useful 
by international students who struggled with the use of the English language. They used it to break down the content of a paper by 
asking a series of simple questions about the paper. Thus, making it easier for them to understand and build knowledge slowly.
• Communication Support: written communication, comprehension of communication, and simplification of language. Practical 
Use Cases: International students who struggle with the use of the English language have found the use of LLMs useful in trans-
lating between languages to clarify the meaning of written assignments/notes. They also used them in simplifying some concepts 
they found complex and confusing. Helping them to explain concepts step-by-step to improve comprehension, especially those 
switching programmes between their undergraduate and post-graduate studies.
• Another good use case is where a student with autism spectrum disorder (ASD) condition found the use of LLMs very useful in email 
communication: reading, understanding, composing, and replying to email communications. The student said that the use of LLMs 
in email communications has been a game changer.
• Research Assistance: Literature reviews, hypothesis generation, data synthesis, data analysis, rewriting of the manuscript, 
improved readability, transforming style and formatting. Practical examples: LLMs were used in data analysis, large-scale data 
handling, summarising large chunks of written data and performing analytics on datasets by undergraduate and post-graduate data 
science students.
• Some went further to using LLMs to generate potential research questions and hypotheses around a particular topic of their interest 
in research.
• Administrative Use: Streamlining student queries, automation of certain processes within schools. Practical examples: LLMs 
were used by some of the authors to automate repetitive tasks, such as questions frequently asked by students. This helped free up 
time for higher-value activities.
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 5 ---

• Another use case is where students in Postgraduate Computer Science programme were asked to use it in analysing anonymised 
Personal Statements provided by prospective students. These were used to build profiles of the kind of students applying to our 
programmes, and helped in gaining insight into how well our course provisions matched their interests.
3.1. Some suggested safety measures on using LLMs in HE
UK Cabinet Minister, Pat Mc Fadden in (Edwards et al., 2025) while acknowledging the significant strides of AI applications in 
teaching and health in the UK, added that AI is a developing technology with faults such as the recent call on Apple to withdraw a 
feature on its latest i Phone that generated inaccurate news alert using AI (Kleinman et al., 2025). Mc Fadden advised that the use of AI 
tools has become a necessity but requires a mix of safety while maximising their opportunities. With some of these significant pitfalls 
evident on LLMs, one needs to worry about using the output from LLMs safely. Below are some of the safety measures recommended 
while using LLMs. 
• One of the measures is to adopt a process that allows us to make use of the technology, but also to be totally sure of the output. For 
instance, avoid using LLMs to generate content outside of your own domain knowledge, as you may not be able to validate the 
outputs, and this is very risky.
• Planning the prompt in terms of input and output for the problem you are trying to solve will make better prompts with fewer 
hallucinations - using Case Diagrams or Data Flow Diagrams can provide enough detail to reduce likelihood of hallucinations.
• When interacting with LLMs, tell the LLM that it will be acting as a copyeditor/programmer/marketeer or whatever the task is at 
hand.
• When using LLMs for your domain work, consider that your role changes from being the primary source of knowledge to one of a 
supervisor checking and verifying the outputs.
• It is very important that users avoid providing Personally Identifiable Information (PII) in any LLM, as this could be used to train 
future versions of LLMs and may end up being publicly disclosed. Where possible, use a “no memory mode” in the LLM, this will 
mean that any prompts you write will not be remembered or used for future training.
• Furthermore, it is important for users to get acquainted with prompt engineering, plan input ahead before prompting LLMs.
• Whenever prompting LLMs, ask for the response to be explained step-by-step, as this can fundamentally change how the LLM 
responds to you and improves the detail of the response.
• Ask for levels of confidence in the answer expressed as a percentage, which will generally highlight any areas where the LLM is 
unsure of the answer and may indicate potential hallucinations.
• Also, ask LLM the following: to tell you how effective your prompt was in generating the output and to seek any areas of 
improvement from your input; to provide worked examples with the content produced; and for sources of knowledge used to 
generate the output.
• Finally, we advise that users avoid trying to get LLMs to “do the thinking” for you in the prompt. You need to tell LLM what you 
want, not ask it to solve a problem for you.
4. Learning theories and pedagogical strategies to inform the deployment of educational AI
Pedagogy as a concept, according to Loughran (2013), rather than being similar to teaching, is enmeshed in the relationship be-
tween teaching and learning. Loughran (2013), underscores the importance of understanding the relationship between teaching and 
learning, their recognition, and development in the educational enterprise. There is therefore a need to consider contemporary 
pedagogical approaches and strategies in order to appropriately underpin the pedagogical applications of educational AI. As Tang et al. 
(2023) highlights, there are concerns about the capabilities of educational theories, pedagogical approaches, and models in an 
AI-enabled learning environment. However, our understanding of AI in education is still in its infancy, and thus we are faced with 
several challenges of application and ethics Tahiru (2021).
Crucially, the world has witnessed the rapid development and deployment of Gen AIs in day-to-day activities, so it is necessary to 
accelerate the development of modern pedagogical approaches, models, and methodologies that support a more intentional and 
considered application within teaching and learning. This is a direction already argued for in teaching and learning, particularly to 
close emerging human resource gaps (e.g., Gates, 2023c; Shields, 2023; Heaven, 2023; Zhang & Aslan, 2021). Although some (e.g., 
Kabudi et al., (2021) have begun collaborative work on AI-enabled adaptive systems, a knowledge gap exists regarding how to manage 
and implement these in educational settings, particularly in more authentic learning contexts (Bates et al., 2020 and Kabudi et al. 
2021).
In the absence of this understanding, we argue that understanding of learning theories and pedagogical approaches can help ed-
ucators design suitable learning environments that incorporate AI technologies. We believe that more considered applications of AI 
within educational contexts can facilitate more effective implementations, whilst also accounting for some of the present concerns and 
ethical challenges highlighted within the area. Thus, what follows is an introduction to several learning theories and their relevance (or 
not) to AI technologies in teaching and learning contexts. Some specific pedagogical strategies are also provided, with the aim of 
presenting example conceptualisations of how AI and pedagogy may be suitably put to use together by an educator.
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 6 ---

4.1. Learning theories and their relevance to educational AI
Theories of learning have developed significantly in the last century, with understandings of how learning happens moving 
relatively frequently. Beginning with earlier conceptualisations of behaviourism, the following passage introduces and discusses 
theories of cognitivism, constructionism, constructivism, and social constructivism in relation to educational AI. 
• Behaviourism: Behaviourism (Pavlov, 2010; Skinner, 1988; Thorndike, 2017) centres on the idea that environmental interaction 
of learners impact on their behaviours (Anastasie & Cyprien, 2021). This implies that learning occurs as action changes. For 
instance, the use of repetition and training can turn certain behaviours into habit (Bloomfield, 1976), thus making evaluation or 
assessment focused on observed behaviour (Ibrahimu, 2022). It is associated with both rewards and negative sanctions for learning 
or lack of learning (Nath, 2013a,b). Whilst the theory of behaviourism has not recently been more widely advocated as a suitable 
lens with which to view learning, it can be considered in relation to the development of educational AI systems that provide 
immediate feedback for students. This is particularly relevant with AI triggers and progress tracking on student learning activities. 
It can also be effective in the development of digital rewards systems to encourage learning for students.
• Cognitivism: Cognitivism focuses on how the human mind receives, processes, and organises information as well as stores, and 
retrieves it. Changes in understanding over time is the main stay of cognitivism according to (Hanfstingl et al., 2019). Principally 
associated with the work of (Piaget, 1976), cognitivism highlights that life-long constructive processing leads to knowledge 
development through the organisation, structuring, and restructuring of experiences in the light of existing schemes of thought. 
Cognitivist theory has the potential of being effectively applied to educational AI systems, particularly in the design of information 
processing models, such as mirroring how humans process, store and retrieve information. Cognitivism also advocates the breaking 
down complex topics into more manageable chunks, a task that educational AI can perform through task-setting and triggers. 
However, cognitivism has been criticised for presenting a somewhat incomplete view of learning, particularly in relation to the 
social, cultural, and historical underpinnings of learning (see Vygotsky & Cole 1978). As such, we present cognitivism with a note of 
caution, that educators must consider how they are implicated within the learning process, above and beyond the content of a 
curriculum alone.
• Constructionism: Constructionism (e.g., Papert (1991) builds on Piaget (1976) notions of cognitivism. The emphasis of the theory 
is on the efficacy of learning through the creation and actively constructing knowledge rather than just passively receiving in-
formation. Central to the idea that learners have the ability to make or construct their own knowledge based on experience. It 
makes a case for the toleration of technology in learning by pioneering the use of computers as learning tools. Thus, digital tools 
have the potential to enable students to test ideas in more concrete ways. Beyond mere imagination, digital tools and educational AI 
can allow students to construct and make things of personal value, thereby testing their concrete capabilities. Such a process lends 
itself to (Papert, 1991) theory of constructionism, where learners produce learning artefacts, externalisations of their knowledge.
• Constructivism: Constructivism focuses on the idea that learners have the capability of making or constructing their own 
knowledge based on experience (Alismaiel et al., 2022). The theory implies that for learning to take place, new learning experiences 
must take into consideration human factors that can influence how learners assimilate new knowledge to their existing knowledge 
constructs. For instance, notions of cultural-historical theory (see Vygotsky & Cole 1978), highlight the need for an educator to take 
account of the prior knowledge and lived experience of a learner, in order to facilitate appropriate connections between current and 
new knowledge. It is important to note here that, whilst a more complete view than cognitivism, later conceptualisations of 
constructivism (i.e., social constructivism) are more widely advocated for in educational research.
• Social Constructivism: This differs from constructivism as conceived by (Piaget, 1976) as it adds that learning is a collaborative 
effort. Vygotsky and Cole (1978) and Vygotsky (1986) views centred on the role of teachers in facilitating learning rather than 
learning as a seamless and environmental phenomenon. These arguments implicate the role of a More Knowledgeable Other 
(Vygotsky & Cole, 1978), and therefore advocate that learning must take place within social contexts. It is therefore, incumbent on 
an educator to make effective use of technology within teaching. Thus, it is critical for educators to understand their intentional use 
of digital tools and Gen AI. Recent understandings of digital learning and alike often advocate social constructivist learning (e.g., 
Fawns, 2022).
• Liberationism: Arguing that learning should be democratic in nature, Freire (1972) proposed that student voice in teaching and 
learning should be incorporated as a matter of essence. The theory proposes that learners are able to make choices about their 
education, in terms of how they engage with their learning, but also in terms of what they engage with. Freire’s work developed 
educationalists’ ideas of transparency, ethics, and educational virtues within their curricula. As such, he has promoted human 
values of openness, humility, tolerance, attentiveness, rigour, and commitment. With respect to educational AI, we argue that 
educators must take great care with how they suggest (or even permit) students engage with it. For instance, educational AI that is 
embedded within a Virtual Learning Environment (VLE) to unlock learning opportunities as a student progresses may seem 
liberating to an individual at first, particularly if perceived as a reward for their engagement. However, this liberation is illusionary, 
as the AI actually limits a student’s choice of what they can engage with. Some Gen AI tools, on the other hand, may allow students 
to discover concepts outside of the defined curriculum, offering a level of empowerment. Great care must be taken here, however, 
as pure liberation may also lead to engagement with irrelevant or contradictory concepts. Thus, Vygotsky and Cole (1978) notion of 
a more knowledgeable other rears its head. Educators must first, therefore, understand the inherent boundaries placed on learners 
as a result of their predefined curriculum. Consequently, they must secondly consider their role in the development of critical 
thinking and critical consciousness in relation to the educational AI use of their students.
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 7 ---

In thinking of the above theories, we recommend that educators adopt a knowledge-based attitude. That is, we argue that each of 
these theories has relevance to the teaching and learning realities of the readers, and also to their implementation of educational AI. 
This is not to say that one-size-fits-all, however, hence the provision of a more detailed chronology of learning theory for the reader.
4.2. Pedagogical strategies and educational AI
• Scaffolding: Derived originally in the work of Wood, Bruner, and Ross Wood et al. (1976), the word scaffolding is offered as a 
metaphor for learning. Wood et al. (1976) described a process in which a teacher, or more knowledgeable other Vygotsky and Cole 
(1978), provides temporary support to help a learner learn new skills and develop new concepts. In light of this, it should be noted 
that the links between scaffolding and social constructivism are particularly explicit, so we reiterate the need for educators to 
understand how their knowledge supports a learner. The metaphor suggests the provision of support through instruction, moti-
vation, appropriate selection of learning activities, and feedback, which are then gradually removed as the learner becomes more 
competent and autonomous. Scaffolds can be put in place by a teacher in order to bring a learner into their Zone of Proximal 
Development (ZPD) (Vygotsky and Cole, 1978). This process involves the role of assessment, where a teacher must assess what a 
learner can or cannot do independently before providing an appropriate level of challenge or support. Useful scaffolding techniques 
may involve breaking down complex tasks into step-by-step processes; separating bigger concepts into manageable chunks; using 
hints, prompts, and templates; or modelling desired results for a learner to imitate.
• Adaptive Learning: Adaptive learning theory, as introduced by Rachmad (2022), uses technology, methodologies, and data to 
create personalised learning experiences that are dynamic in relation to each student’s performance, needs, pace, learning patterns, 
and preferences. The theory provides guidelines for creating a flexible, dynamic, and responsive learning environment tailored to 
individual needs. It can be used to personalise learning in which the instructor continuously collects student data on performance, 
behaviours, and analyses these data to understand where the student needs support, and applies appropriate measures to help 
improve the student’s learning experience. Theoretically speaking, it is understandable that one may consider this as cognitivist 
practice, particularly if these actions are automated or driven by educational AI. However, any integration of human intervention 
should be considered as a social-constructivist approach. Here, the integration (or interplay) of human and educational AI becomes 
particularly apparent. In practice, adaptive learning can be applied by the instructor using different types of assessment, and then 
from the data make informed decisions on appropriate learning pathways for a student. Such a learning pathway be to break down 
the indicative learning contents into more manageable chunks or using different methods in representing information such as text, 
video, audio, graphs, interactive elements, etc.
Although Gen AI is still in the early stages of adoption, its accessibility is undeniably poised to shape pedagogical discussions in 
these areas in the future. Table 1 outlines how Gen AI can contribute and influence these educational approaches.
5. Teaching and learning in the context of systemic changes
This section is a summary of how teaching and learning approaches have been transformed in the context of systemic changes. 
Examples of such a pandemic are the recent COVID-19 pandemic, during and after the pandemic era. The section will provide in-
formation on the lessons learned and potentials of leveraging these in dealing with the issue of AI (Gen AIs and anticipated AGIs) in 
teaching and learning. 
• Virtual Learning and Teaching: Virtual learning and teaching (VLT) refers to a learning environment where teacher and student 
interact through a technological mediated space. It involves the deployment of course contents through application software; while 
teaching instruction and discussion take place using multimedia resources, the Internet, videoconferencing, and so on (Dung, 2020; 
Bri et al., 2009; Mueller & Strohmeier, 2011). Though popularised during the COVID-19 pandemic, a major benefit of this approach 
is that is has shown to be adaptable and personalised, which can enhance academic performance (Mai, 2023; Reginald, 2023). 
However, VLT may unintentionally lead to a heightened sense of isolation among learners, a condition that is potentially intensified 
by the physical separation and the lack of immediate, tangible visual and verbal feedback. The isolation might result in increased 
Table 1 
Contemporary pedagogical approaches and suitability in educational AI.
Pedagogical Model
Discussion
Behaviourism
Generative AI can provide immediate feedback, triggers, and progress tracking for students. It could also facilitate digital reward systems to 
encourage learning through reinforcement.
Constructivism
Technology-driven learning aligns with constructivist theories, making educational AI useful for personalized and adaptive learning 
experiences that build on prior knowledge.
Social 
Constructivism
Educational AI can facilitate collaborative learning by incorporating social elements, supporting peer interactions, and enabling role-based 
knowledge sharing through intelligent tutoring systems, as well as acting as an artificial more knowledgeable other.
Cognitivism
AI can model cognitive processes, helping students by breaking down complex topics into manageable chunks, supporting schema 
development, and enhancing metacognition.
Liberationism
AI can empower students by giving them control over their learning path, supporting democratic and inclusive education, and fostering 
critical consciousness through ethical AI applications.
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 8 ---

anxiety and apathy about engaging in online classes, negatively impacting higher education sustainability (Tennakoon et al., 
2023). It is therefore critical to identify the VLT communication barriers that may cause some students to become disengaged when 
deploying VLT technologies, especially the international students (Crawford-Ferre & Wiest, 2012). While existing studies have 
confirmed that online discussions facilitate knowledge construction and learning engagement (Liu et al., 2023), it also appears that 
there may be some face-to-face interactions that might influence students’ online interactions. Crawford-Ferre and Wiest (2012)
discovered that the lack of visual cues in asynchronous and synchronous discussions caused problems for international students 
participating in an online Master of Business Administration programme.
• Although VLT approaches have shown promise in improving the performance of learners, there is a clear research gap about how 
well they work in promoting student interactive behaviour and engagement. The components that make VLT platforms interesting 
are not adequately stated in the literature. A comprehensive understanding of these properties is paramount for creating and 
preserving the strong sense of community in virtual learning spaces. This knowledge is essential for fostering a learning envi-
ronment that is not only intellectually stimulating but also emotionally supportive. Furthermore, research needs to examine into 
how virtual environments can emulate the shared experiences and relationships of a traditional classroom in order to preserve the 
feeling of community within VLT. This includes the development of shared goals, the fostering of mutual support networks, and the 
encouragement of a culture of collaboration.
• Blended Teaching and Learning: The approach as defined by Garrison and Kanuka (2004) is the combination of online (virtual) 
with face-to-face (in-person) learning. Their position pre-COVID was that the use of this approach in teaching and learning will be 
an effective low-risk strategy that will aid universities in meeting the demand of teaching and learning in the context of techno-
logical advancements or what the authors of this paper refer to as systemic change driven by advanced level technologies and tools.
• Furthermore, Barber (2022) defined Blended learning as the combination of in-person delivery and that of delivery in a digital 
environment. The authors posit that Blended learning should be carried out through a well thought out plan. It is important that any 
such plan focuses on determining the level of online activity requisite for students’ learning and supplementing that with 
face-to-face activity. In some instances, it uses the online materials to support students’ learning, while that of traditional for a 
follow-up of the online activities.
• Though the position of Garrison and Kanuka (2004) did not foresee the implications of teaching and learning in a post-COVID era, it 
became a much-adopted approach. The approach became necessary in closing the transitory gap between COVID era where virtual 
learning was predominant as a result of difficulties of in-person classroom setting and pre-COVID, a return to normal in-person 
traditional classroom setting.
• Flipped Teaching and Learning: While Bishop and Verleger (2013) described flipped classrooms as an approach that combines 
asynchronous video-based lectures with problem-based learning (PBL), this definition does not fully capture the broader scope of 
flipped teaching. The flipped model extends beyond video-based instruction and PBL, incorporating various pedagogical methods 
to enhance student engagement. As stated in the article, “the method encourages the use of multiple teaching and learning ap-
proaches” meaning that flipped learning is adaptable and not limited to a single instructional format. It fosters active learning 
environments that prioritise student engagement and skill development over traditional teacher-centered instruction (Rahman 
et al., 2019). Additionally, flipped learning aligns well with the technological advancements of the 21st century, making it a 
relevant and effective strategy in modern education Rahman et al. (2020), Rahman et al. (2019), Bredow et al. (2021).
5.1. Adapting existing methods in AI era
Zhao and Watterston (2021) identified potential three changes to teaching and learning in a post-COVID era (otherwise known as 
era of AI), such as having a developmental, personalised and evolving curriculum and student-centred pedagogy, that is enquiry-based, 
authentic and purposeful. They also identified education delivery that focuses on the use of synchronous and asynchronous teaching 
and learning environments. The latter has been supported by the works of Imran et al. (2023), Singh et al. (2021), Saboowala and 
Manghirmalani-Mishra (2020), Pellegrini et al. (2020), and Guppy et al. (2022), where it was considered a blended/hybrid learning 
system.
Although researchers have shown concerns about the capabilities of contemporary education theories, pedagogical approaches and 
models in an AI-enabled learning environments (Tang et al., 2023). Gates (2023c) argues on leaning on historical precedent, insights 
from the works of Zhao and Watterston (2021) and that of many experts can be leveraged in overcoming the emerging challenges 
posed by disruptive Gen AIs in teaching and learning.
Section 3 has practical use cases from the authors’ experiences on how Gen AIs can be used effectively in teaching and learning in 
the areas of providing students with communication and learning supports, as well as research and administrative assistance for both 
staff and students. In addition to these use case examples, 4 provides information on how learning theories and contemporary 
pedagogical frameworks can be adapted in educational AI systems. For instance, Cognitivism theory can be effectively used in the 
design of AI-based information processing model that can mirror how human process; store and retrieve information, as well as 
breaking down complex topics into manageable chunks. It can also be used to design AI systems that can track students’ cognitive load 
and adjust content delivery accordingly. Cognitive theory can also be leveraged in building pattern recognition algorithms that are 
capable of identifying students’ learning strategies and adapting instruction given to the student in line with the pattern as identified.
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 9 ---

6. Generative artificial intelligence technologies in the context of teaching and learning
This section will focus on emerging AI technologies applied in teaching and learning, their limitations, opportunities, and threats, 
some recent developments, and the opinions of experts and authors on their application and future of education.
6.1. Emerging AI technologies in teaching and learning)
• Chat GPT: The Centre for Teaching and Learning at the University of Oxford (CTL, 2023) opined that Chat GPT is one of the many 
tools expected to change the landscape of teaching and learning in the coming years. It is not just a chatbot, but also a useful tool 
that will have a strong impact on teaching and learning in the coming years. There are many known and yet to be known potentials 
of Chat GPT in education, which have been widely discussed in 1 and 2 above.
• Intelligent AI-Agents: These agents or tutors, as suggested by Zhang and Aslan (2021) have the capacity of providing customised, 
timely, and appropriate materials, as well as guidance and feedback to learners. Can also act as personal-digital-service providers 
(Gates, 2023c); and will be the next software system platform like today’s Windows, Linux, Android and i OS (Gates, 2023b). 
According to Mc Carthy et al. (2018) have been shown to promote independent learning, but have failed to improve student ac-
ademic performance. Other AI tools that educators can look out for in the coming years as Zhang and Aslan (2021) posit include, 
Expert Systems, Machine Learning-powered tools, Personalised learning systems or environments, and Visualisations and virtual 
learning environments.
6.2. Limitations of Gen AIs and prompt technologies in education
This section highlights the limitations of Gen AIs in education and the importance of critical evaluation and validation processes to 
mitigate risks and ensure the accuracy and reliability of AI-generated content. The authors believe that trust in AI systems should be 
balanced with a commitment to thorough validation and verification practices. These, in no doubt, will help to uphold educational 
standards, as well as promote effective learning outcomes. The following are some of the existing shortcomings in AI tools in education.
1. Risks arising from Gen AIs: Gen AI tools while in their nascent stages pose numerous risks that warrant careful consideration, such 
as the ability to promote independent learning but fail to improve student academic performance. This domain is rapidly evolving 
with technological advances that continue to shape the landscape of Gen AI providers, capabilities, and accuracy levels Stakelum 
(2024). Inaccuracies stemming from Gen AIs collectively termed as hallucinations result in outputs that are often nonsensical; 
inaccurate, or entirely unrelated to the user’s prompt.
2. Hallucinations: These refer to instances where the output deviates significantly from the intended prompt, resulting in inaccurate 
answers or reasoning (IBM, 2024). For example, research on the limitations of Chat GPT for code production revealed instances 
where the model provided incorrect answers (Thorne, 2023), particularly in scenarios involving uncertainty. Although subsequent 
updates may improve model performance, other Gen AIs may still exhibit hallucinations, especially in tasks involving logic and 
mathematics (Plevris et al., 2023; Davis, 2024; Frieder et al., 2024; Shakarian et al., 2023).
3. Prompt Engineering, Validation, and Verification: Prompt engineering plays a crucial role in ensuring accurate output from 
Gen AIs. Incomplete or ambiguous prompts increase the likelihood of hallucinations (Plevris et al., 2023; Thorne, 2023; Wan et al., 
2024), leading to errors in the generated artefacts. Validation and verification are essential processes to confirm that the output 
aligns with the prompt and accurately reflects real-world scenarios. However, users may overlook these steps due to misplaced trust 
in the AI system’s capabilities, contributing to the persistence of inaccuracies.
4. Magical Thinking and Reification in AI: Magical thinking (Morris, 2023; Shakarian et al., 2023) and reification Croll (2018)) 
pose significant risks in the context of Gen AIs for education. Students may attribute unwarranted properties to AI systems, such as 
infallibility or wisdom, leading to misplaced trust and lack of validation and verification. Reification further exacerbates these 
issues by transforming abstract AI systems into unquestionable truths, regardless of their actual performance. Such tendencies 
contribute to inflated expectations and perceptions of AI capabilities, increasing the risk of reliance on inaccurate outputs. One such 
approach to reduce the impact of these factors is to instill critical thinking skills in students (Sternberg & Halpern, 2020) when 
using Gen AIs and provide them with mechanisms such as triangulation (Greyson, 2018) to validate and verify the result of Gen AIs.
6.3. AI technologies in teaching and learning: opportunities and threats
Every system that improves on the existing method (innovation) will inevitably lead to skill gaps, system and technical obsoles-
cence, as well as human and skill redundancies (Anyanwu, 2024). One of such inevitable changes has been brought about by Gen AI 
technologies. Whether these technologies will shape our era is no longer up for debate, the question is how best humanity can fully 
utilise the revolutionary power of AI by making it human-centric. Doing these requires a deliberate retooling of our contemporary 
teaching and learning practices, research and knowledge development, ethics, policies, and regulatory frameworks.
Dwivedi et al. (2023) are of the view that the concept of mindfulness in information technology is key to how critical it is for 
instructors and teachers to focus their mindset on experience and experimentation during systemic change. IT Mindfulness according 
to Thatcher et al. (2018) has four aspects namely: 1) awareness of distinction, 2) awareness of multiple perspectives, 3) openness to 
novelty, and 4) orientation in the present. Imbibing these constructs will help teachers engage with students on how best to explore and 
experiment with new technology tools. In line with the above, Dwivedi et al. (2023) posit that inviting students to apply IT mindfulness 
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 10 ---

will be necessary as it relates to Gen AIs in their work and practices.
On the basis of these, the authors of this paper present herein what they think will be the changes that Gen AI technologies will bring 
in teaching and learning practices as presently practiced in the next Section - Summary and Recommendations.
6.4. Some recent developments underscoring the potentials of Gen AIs in education
In addition to the new development as reported in 2 on the claim by Michael Calvin Wood (Wood, 2024) as quoted in (Stakelum, 
2024) that Acurai has demonstrated the ability to achieve 100 % accuracy in certain types of AI tasks, particularly in question-answer 
scenarios. This subsection brings to fore some other similar development that have potentials of putting to rest most of the concerns 
raised by stakeholders on the application of Gen AIs in education - covering ethics and bias in AI, assistive technologies, adaptive and 
personalised learning, document analysis for researchers, and critical thinking AI support systems.
Ethics and bias In AIs: The work of (Team et al., 2024b) claimed to have developed a model known as Gemma models that can be 
used in dealing with ethics and bias issues in AIs. These models, as claimed, can be used in creating AI applications that provide 
transparent insights into decision-making processes, as well as detecting and mitigating biases during model inference.
Assistive technologies: In Qwen 2 Model Series, (Yang et al., 2024) claimed to have developed models that can be used in the 
creation of AI tools in assistive technologies. For instance, a tool for the visually impaired that can interprete and describe images in 
real time. Other tech-assistance that can be developed using the nodel include: advanced language translation paired with visual 
context, as well as visual assistants with features that can understand and respond to multimodal queries.
Adaptive and personalised learning: Mix R A7B as developed by (Jiang et al., 2024) has shown to possess the ability to be used in 
the creation of AI systems that can adapt to individual user preferences in real time. They can also be used to build educational tools 
that can be tailored to student needs.
Document analysis and research: Gemini 1.5 by Google Deep Mind (Team et al., 2024a) is an AI tool suitable for analysing large 
documents, such as books, articles or legal texts. This tool can be used to summarize large and voluminous documents by providing 
specific information (text extraction) and insights, which makes it very useful for researchers and legal professionals.
Critical thinking AI tutors: Orca LLM as developed by (Mitra et al., 2023) focuses on improving the reasoning capabilities of 
learners as claimed. The LLM can be used in the development of AI systems that teach critical thinking to students by walking them 
step-by-step through logical problems. They can also be used in creating AI tools that can assist students in decision making by logically 
evaluating trade-offs as well as games or apps that solve riddles or logical challenges.
6.5. Expert opinions on Gen AIs in teaching and learning
In view of emerging changes and the need for adaptation in teaching and learning, United States Department of Education in 
(Department of Education, U., 2023) provided areas that need urgent attention and policy change. Changes that focus on using 
automation to advance the achievement of expected learning outcomes while protecting human decision making and judgement. 
Furthermore, there is a need to understand the quality of data used in AI models by interrogating them. Doing this, they argued, will 
help ensure a fair and unbiased decision-making process for AI models. In addition, educators should take appropriate steps in 
examining how AI technologies provide for equity and take steps in safeguarding this by limiting AI systems that undermine equity, as 
well as providing for human checks and balance on these emerging systems.
However, experts from UNESCO (Sabzalieva & Valentini, 2023) support the use and integration of Gen AIs in higher education 
institutions (HEI), but advised that it be used with care and creativity. The advice focused on how HEIs could connect the use of these 
tools with the expected learning outcomes of programme Modules; conduct a review of all forms of assessments and evaluations in line 
with this inevitable change, as well as review and update policies relating to academic integrity and honesty in relation to Gen AIs and 
other AI tools (Torres, 2023).
In support of this, UNESCO suggested that HEIs build the capacity and competencies of their staff members to understand and 
manage Gen AIs. This new knowledge could lead to the introduction of new programmes and indicative course content focusing on 
Gen AIs and other emerging AGI tools. That there is also need to revamp existing programmes and modules in a way to proactively 
articulate and incorporate the teaching of core AI competencies, skills, literacy,and ethics besides providing peer support and men-
toring among staff and faculty members.
In contrast, the Center for Teaching and Learning at the University of Oxford CTL (2023) provided four lessons on the opportunities 
and challenges of Gen AIs, which are: the challenge of academic integrity is real with the emergence of Gen AIs, but neither new nor 
unique from precedence. That the tools are useful for educators, though at an early stage of exploration in terms of teaching and 
learning. Finally, Gen AIs are just one of the many tools expected to change the landscape of teaching and learning in the coming years.
Below are a summary of some existing expert opinions on the impacts of Gen AI tools in teaching and learning practices. 
• Assessments need to be diverse, where some are classed as Human - describing a situation where the assignment is carried out 
without any AI input except for grammar and spellchecking; AI-Acknowledged, where the student is allowed to use AI tools as part 
of the study and in preparing initial guidance on the assignment; and AI-embedded, where the student is permitted to use AI tool as 
an integral and expected part of the assessment. These have become necessary because these tools are likely to be used in the future 
workplace, which could enhance students’ employability prospects (CTL, 2023).
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 11 ---

• With regard to pedagogical research, human creativity is now more than ever needed to explore how teaching, learning, and 
assessment can be enhanced using Gen AIs. Also, on how best to employ AI tools in all aspects of the process (Sabzalieva & Valentini, 
2023; Department of Education, U., 2023).
• A human-AI collaboration in higher education is now in the foreseeable future. Hence, more funding, along with policy changes, is 
needed to ensure that we can develop, test, and apply these sophisticated computational tools to further student learning 
(Sabzalieva & Valentini, 2023; Department of Education, U., 2023).
6.6. Authors’ opinions on Gen AIs in teaching and learning
Gleaning from the existing literature, technical reports, recent developments, expert advise and opinions on the impacts of Gen AIs 
in education, the authors will want to state as thus: 
• Fully human-centred classroom administration will be gradually integrated with that of AI assistance leading to some levels of 
automation, but the extent of integration/automation will vary across nations, institutions, disciplines, and programmes. That is to 
say, there will be a gradual increment on the percentage of human-AI classroom integration based on improvements, understanding 
and adaptations.
• Generative AI has the capacity to support pedagogy in a way that can may develop concept of an ’AI integrated classroom’. The 
level and type of adoption however will vary greatly by level of study, as well as the subjects being studied. These emerging dy-
namics and considerations of use could result in a paradigm shift from student-teacher relationship to student-AI-Tutor-based 
relationship within academic circles, especially to help support students with scaffolding their own development. This will be 
likely driven largely by AI-Agents and the increasing accessibility of generative AI through large language models.
• These Agents will have the capacities of offering personalised learning and communication supports; self-paced teaching and 
learning - tutoring, assessment, and feedback; research and administrative assistance. In the nearest future, the right to formal 
education will increase the existing requirements associated with digital competence to have a greater focus on AI literacy, as 
knowledge related to AI will become that of international importance and of high-skill demand.
• When we begin to see the development of systems that are close to general artificial intelligence, machines will have a greater 
capacity to mimic the ability to learn, think, and act in a way that is very close to that of humans. Thus blurring the line between 
machine and human intelligence, and likely once again calling into question the role this technology will play in formal education.
• There is a capacity for improved generative AI to support a rise in of asynchronous learning. As with other areas, the capacity for 
this development will largely be factored around the level of the technology, as well as the level and subject of learning taking 
place. In the light of the above, the concept of asynchronous learning through opencourseware and social media may begin to be 
popular. What these imply is that formal educational institutions may have to resort to the use of opencoursewares, social media 
platforms in advertising their programmes, drive for formal education and learning Mc Namara (2023).
• Gates (2023b) posits that AI-based personal assistants (Agents) will be the next software system platform like today’s Windows, 
Linux, Android and i OS. The authors share in this opinion and believe that the potentials of having AI-based personal tutors are not 
far fetched. An AI-powered personal tutor that can tailor individual learning needs, provide curriculum, instruct and measure 
learning based on the knowledge of the user. A view also shared by (Javaid et al., 2023), and include the ability to create individual 
educational resources and contents in line with the student’s interests, learning pace and goals. There is no doubt that this trends 
may change the traditional learning environment, but with appropriate laws and regulations, adequate measures will be put in 
place to mitigate risks that may accrue as a result of this disruption. The precedence to this exist in the way digital currency is being 
developed by different national banks in the light of the disruptive non-regulated cryptocurrencies.
• Emerging disruptive Gen AI technologies will lead to the development of agents in the nearer future (Gates, 2023c). These agents 
will act as personal-digital-service providers and will in no doubt revolutionise learning. Take for instance, if someone could have 
AI-agent to write computer codes and deploy it, prepare presentations, write articles, help the individual pass examinations (Else, 
2023), the quest for teacher-student traditional learning system may be affected. It is therefore necessary for educators and relevant 
stakeholders to start rethinking the concept of teaching and learning, the curriculum design and deployment in the context of these 
emerging realities.
• In the coming years, emerging skill gaps in AI industries will lead to the need for dynamic (yearly changing) curriculum in teaching 
and learning. Thus, making the concept of virtual University a needed alternative to provide the urgent training and skill demands 
and this will be driven by the big technology industries. The traditional HEIs will be made to adopt two main modes of learning 
environments - Virtual and Hybrid. While the virtual learning environment will be run on a dynamic curriculum, the hybrid will be 
an intermediary between dynamic and non-dynamically tailored curriculum in teaching and learning.
7. Summary and recommendations
This section provides what the authors can glean from the provisions of this paper alongside reasonable recommendations for all 
education stakeholder as derived from the relevant literature, recent developments, theoretical frameworks and opinions.
7.1. Summary
The transformative effects of Gen AIs in education cannot be overemphasised and are here to stay. Therefore, acquiring the 
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 12 ---

necessary knowledge and upskilling in this domain has become a necessity for teachers and learners. Although there are some obvious 
challenges and concerns about Gen AIs’ adoption in education, but going by recent developments, better understanding, emerging AI 
policy frameworks, and expected regulations, the adoption in education will surge over the years. As adoption increases leading to 
mixed mode classroom administration, teachers, educators, and stakeholders would have to grapple with the issues of ethics, privacy, 
student assessments, academic integrity, and true measurement of learning. Although the use of research would lead to a reduction in 
some of these challenges and concerns, some emerging issues may require reasonable and thoughtful adaptations but not compromise. 
We can take a cue from the emergence of virtual Viva Voce after the COVID-19 pandemic as an alternative to face-to-face Viva Voce 
before COVID-19 as a result of social distancing and total lockdown of movements around the world.
7.2. Recommendations
The following are the authors’ recommendations as derived from the contents of this manuscript. 
• Educators are encouraged to review existing teaching and learning curricula in line with the contemporary issues posed by AI and 
its constituent technologies. Developing AI-infused programmes is a necessary step in curriculum development.
• There is an emerging need for AI technologies (e.g., Chat GPT) to be discussed in relation to learning and teaching activities. These 
discussions should focus on how it works, principles, ethics, capabilities, applications, and weaknesses. In doing so, we suggest that 
learning can be enhanced in the modern era, leading to the development of new skillsets by learners. Conversations on how AI 
technologies can be abused or reduced should also be discussed. Such conversations may facilitate the development of employ-
ability skills of learners (O’Connor, 2022).
• As some of the concerns of emerging educational AI systems are - what are the best ways of measuring learning as the current 
assessment systems have been found inadequate in the face of current realities and the risk that though the systems have shown to 
promote independent learning, but failed to improve student academic performance. Therefore, it is necessary to focus the 
emerging education curriculum on understanding how AI systems work, their developments, and their management in different 
HEI programmes. Adding to knowledge should therefore be seen as the ability to use the tools in creating novel or modifying 
existing knowledge.
• It is obvious that in the coming years, AI technologies will take up many available routine and lower level technical jobs. Doing this 
will redefine the expected learning outcomes, skillset demands in the labour market by employers. Therefore, knowing how to 
interpret AI results; deciphering AI bias from the outputs; understanding of AI hallucinations; defining manageable organisational 
risk appetite; de-risking AI agents and bots prior to deployment; AI risk level management in different workspaces will be required 
in many sector of human endeavours. So, we urge employers of labour in education to consider training and retraining of their 
employees in AI for efficient service deliveries.
• Critical thinking has always been a measure of students’ progress and independence in learning. It is necessary as it equips students 
with the ability to manage their own learning by being able to independently analyse, synthesise, evaluate, and form logical 
conclusions from their vast array of available information. It also provides them with sense of creativity and curiosity, self-assertion 
and reflection, problem solving, innovation, and ’I can do spirit.’ Thus, strengthening the prospects of their career. In the context of 
generative AI-Bots and Agents, teaching critical thinking using AI-Bots and Agents may be challenging, as abuse is seemingly 
inevitable. So serious tinkering, field experience, and experimentation using diverse methods and adaptive pedagogy may be 
needed.
8. Conclusion and future works
Humanity over the years has been fraught with dynamics leading to systemic changes in day-to-day life activities, including how 
businesses and education are conducted. In recent time, the COVID-19 pandemic is a perfect example of such systemic change. The 
pandemic threw the world into some level of chaos, but in a short period of time, the concept of remote work and virtual learning was 
introduced to adapt to the realities on the ground. The present post-COVID-19 era has seen the introduction of hybrid work pattern and 
blended learning, a combination of work from home, virtual learning, and traditional face-to-face learning environment. Since 
November 2022, the world has been witnessing another systemic change led by the emergence of Gen AI tools, for instance, Chat GPT as 
introduced by Open AI. There is no doubt that this is fast leading to an inevitable systemic change in all facets of human endeavours 
including education. As the focus of this paper is to take position on foreseeable impacts of these emerging disruptive technologies in 
relation to teaching and learning, this study has been able to x-ray deeply into the available literature, technical reports, authors’ 
practice examples, expert opinions and guidelines in the use and utilisation of generative AI tools in education.
The material provided above includes information on the present level of applications of Gen AI tools in education. Understanding 
how issues of systemic change affect teaching and learning has been handled in the past through pedagogical adaptation, giving 
credence that the emergent Gen AIs will not be different. Furthermore, the knowledge on the existing shortcoming of Gen AIs in ed-
ucation is a pointer that AIs will not completely replace humans in teaching and learning, as there will always be a place for human 
supervision of AI tools and the need for social interactions that deepen learning. In general, there is strong advocacy for the use of 
Gen AIs in education by experts and stakeholders with thoughtful application, caution about adaptation, and implementations.
Despite this information, there is no doubt that quite a good number of educational institutions, especially HEIs, will remain very 
cautious, aloof, and hesitant about the use and integration of these tools in teaching and learning. Some of these instances may arise 
from the lack of policy directions, attendant costs, capacities, manpower, and technical know-how on how to integrate these tools and 
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 13 ---

still provide education that meets the expected learning outcomes as stipulated in existing programmes. However, with existing and 
compelling arguments on the integration of these tools in teaching and learning, there will be a balance, as these opinions are 
overwhelming.
Returning to the aim of the paper, the authors have attempted to provide valuable information on some practical uses of Gen AIs in 
HE. To achieve this, we have provided case examples alongside theoretical frameworks for educational AI. In doing so, we note how 
contemporary pedagogical approaches can inform the use of educational AI, particularly leaning on how our understanding of teaching 
and learning has evolved over time (e.g., from behaviourist to more constructivist lenses).
This paper, to our knowledge, has provided the necessary information and opinions from experts and educators on Gen AIs in 
education. It is our firm belief that the information and recommendations made herein will be useful to education stakeholders, 
administrators, and government agencies in making informed decisions, policies, and regulations on the way forward in the context of 
emerging disruptive artificial intelligence technologies in education.
8.1. Future works
In the near future, some of the authors aim to start incorporating Gen AI tools on a large scale into their learning materials in line 
with Adaptive Learning Theory. This will be used in conducting internal action research with the informed consent of their students. 
The results will determine appropriate funding needed to take the research forward within the wider University community. The 
authors have become a team of researchers working on the use of generative AIs in education by starting with a survey on staff usage of 
the tools in teaching and learning, research, and development. This will be followed by that of the students. The authors understand 
that these ongoing efforts will help provide empirical evidence that will lead to responsible and safe use of Gen AIs in education.
Authors and abbreviations
Elochukwu Ukwandu (E.U.), Bola Omisade (B.O.), Karl Jones (K.J.) and Simon Thorne (S.T.)
CRedi T authorship contribution statement
Elochukwu Ukwandu: Writing – review & editing, Writing – original draft, Validation, Supervision, Project administration, 
Methodology, Investigation, Formal analysis, Conceptualization. Bola Omisade: Writing – original draft, Formal analysis, Concep-
tualization. Karl Jones: Writing – review & editing, Methodology, Investigation, Data curation, Conceptualization. Simon Thorne: 
Writing – review & editing, Writing – original draft, Supervision, Investigation, Formal analysis. Mike Castle: Writing – review & 
editing, Writing – original draft, Supervision, Investigation, Conceptualization.
Contributions
Conceptualisation and formal analysis: E.U.; investigation: E.U. and K.J.; methodology: E.U., and K.J.; validation, E.U., B.O., K.J., 
and S.T.; writing—original draft preparation, E.U., B.O., and S.T.; and writing—review and editing, E.U., K.J. and S.T. All authors have 
read and agreed to the published version of the manuscript.
Funding
This work did not receive any funding.
Declaration of Competing Interest
The authors have read and approved for this paper to be submitted for publication and hence declare that they have no competing 
interests.
References
Agarwal, P., & Vij, A. (2024). Assessing the challenges and opportunities of artificial intelligence in indian education. International Journal for Global Academic 
Scientific Research, 3, 36–44.
Alismaiel, O. A., Cifuentes-Faura, J., & Al-Rahmi, W. M. (2022). Online learning, mobile learning, and social media technologies: An empirical study on constructivism 
theory during the covid-19 pandemic. Sustainability, 14, 11134.
Anastasie, U., & Cyprien, T. (2021). Theories underpinning language acquisition/learning: Behaviourism, mentalist and cognitivism. International Journal of 
Contemporary Applied Researches, 8, 1–15.
Anyanwu, P., 2024.Prompts et al: The new creativity.〈https://studio52seven.com/2024/02/10/prompts-et-al-the-new-creativity/〉.accessed 11 February 2024.
Barber, S. (2022). Blended synchronous learning case study. Pacific Journal of Technology Enhanced Learning, 4, 1–8.
Bates, T., Cobo, C., Mari˜no, O., & Wheeler, S. (2020). Can artificial intelligence transform higher education? International Journal of Educational Technology in Higher 
Education, 17, 1–12.
Benotti, L., Martnez, M. C., & Schapachnik, F. (2017). A tool for introducing computer science with automatic formative assessment. IEEE Transactions on Learning 
Technologies, 11, 179–192.
Bishop, J., Verleger, M.A., 2013.The flipped classroom: A survey of the research, In: 2013 ASEE Annual Conference & Exposition, 23-1200.
Bloomfield, T. (1976). About skinner: Notes on the theory and practice of ‘radical behaviourism. Philosophy of the Social Sciences, 6, 75–82.
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 14 ---

Bredow, C. A., Roehling, P. V., Knorp, A. J., & Sweet, A. M. (2021). To flip or not to flip? a meta-analysis of the efficacy of flipped learning in higher education. Review 
of Educational Research, 91, 878–918.
Bri, D., García, M., Coll, H., & Lloret, J. (2009). A study of virtual learning environments. Wseas Transactions on Advances in Engineering Education, 6, 33–43.
Brown, C., 2023.Why teachers don’t need to ban chatgpt or ai tools in the classroom (and what to do instead).〈https://truthforteachers.com/dont-ban-chatgpt-ai- 
tools-in-school-teachers-do-this-instead/〉.Last accessed 18 January 2024.
Chen, F., Wang, L., Hong, J., Jiang, J., Zhou, L., 2023.Unmasking bias and inequities: A systematic review of bias detection and mitigation in healthcare artificial 
intelligence using electronic health records.ar Xiv preprint ar Xiv:2310.19917 20, 2023.
Chomsky, N., 2023.Noam chomsky on chatgpt: Itas “basically high-tech plagiarism” and “a way of avoiding learning”. 〈https://www.openculture.com/2023/02/ 
noam-chomsky-on-chatgpt.html〉 Last accessed 20 January 2024.
Cotton, D. R., Cotton, P. A., & Shipway, J. R. (2023). Chatting and cheating: Ensuring academic integrity in the era of chatgpt. Innovations in Education and Teaching 
International, 21, 1–12.
Crawford-Ferre, H. G., & Wiest, L. R. (2012). Effective online instruction in higher education. Quarterly Review of Distance Education, 13, 11.
Croll, G.J., 2018.The reification of an incorrect and inappropriate spreadsheet model.ar Xiv preprint ar Xiv:1801.10249.
CTL, 2023.Four lessons from chatgpt: Challenges and opportunities for educators.〈https://www.ctl.ox.ac.uk/article/four-lessons-from-chatgpt-challenges-and- 
opportunities-for-educators〉 Last accessed 26 March 2024.
Cunningham-Nelson, S., Boles, W., Trouton, L., Margerison, E., 2019.A review of chatbots in education: practical steps forward, in: 30th annual conference for the 
australasian association for engineering education (AAEE 2019): educators becoming agents of change: innovate, integrate, motivate, 299-306.
Davis, E., 2024.Mathematics, word problems, common sense, and artificial intelligence.Bulletin of the American Mathematical Society.
Deguara, D. (2024). Embracing the academic change caused by the proliferation of generative artificial intelligence chatbots in higher education. MCAST Journal of 
Applied Research Practice, 8, 150–178.
Department of Education, U., 2023.Artificial intelligence and future of teaching and learning: Insights and recommendations.〈https://tech.ed.gov〉 accessed 13 March 
2024.
Dowling, M., & Lucey, B. (2023). Chatgpt for (finance) research: The bananarama conjecture. Finance Research Letters, 53, Article 103662.
Dube, B., & Setlalentoa, W. (2024). Artificial intelligence in education: Embracing change, addressing challenges, and shaping tomorrow’s curriculum. Interdisciplinary 
Journal of Education Research, 6, 1–2.
Duckworth, A., Ungar, L., 2023.Op-ed: Don’t ban chatbots in classrooms — use them to change how we teach.〈https://www.latimes.com/opinion/story/2023-01-19/ 
chatgpt-ai-education-testing-teaching-changes〉.Last accessed 18 January 2024.
Dung, D. T. H. (2020). The advantages and disadvantages of virtual learning. IOSR Journal of Research Method in Education, 10, 45–48.
Dwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., Baabdullah, A. M., Koohang, A., Raghavan, V., Ahuja, M., et al. (2023). So what if chatgpt 
wrote it?” multidisciplinary perspectives on opportunities, challenges and implications of generative conversational ai for research, practice and policy. 
International Journal of Information Management, 71, Article 102642.
Edwards, C.; Kleinman, Z., Mc Mahon, L., 2025.Pm plans to ’unleash ai’ across uk to boost growth.〈https://www.bbc.co.uk/news/articles/crr05jykzkxo〉.Last accessed 
13 January 2025.
Else, H. (2023). Abstracts written by chatgpt fool scientists. Nature, 613, 423.
Fawns, T. (2022). An entangled pedagogy: Looking beyond the pedagogy–technology dichotomy. Postdigital Science and Education, 4, 711–728.
Felten, E., Raj, M., Seamans, R., 2023.How will language modelers like chatgpt affect occupations and industries? ar Xiv preprint ar Xiv:2303.01157.
Francis, N. J., Jones, S., & Smith, D. P. (2025). Generative ai in higher education: Balancing innovation and integrity. British Journal of Biomedical Science, 81, 14048.
Freire, P. (1972). Pedagogy of the oppressed harmondsworth, 19721 p. 20). UK: Penguin.
Frieder, S., Pinchetti, L., Griffiths, R. R., Salvatori, T., Lukasiewicz, T., Petersen, P., & Berner, J. (2024). Mathematical capabilities of chatgpt. Advances in Neural 
Information Processing Systems, 36.
Garrison, D. R., & Kanuka, H. (2004). Blended learning: Uncovering its transformative potential in higher education. The Internet and Higher Education, 7, 95–105.
Gates, B., 2023a.The age of ai has begun.〈https://www.gatesnotes.com/The-Age-of-AI-Has-Begun〉.Last accessed 21 January 2024.
Gates, B., 2023b.Ai is about to completely change how you use computers.〈https://www.gatesnotes.com/AI-agents?WT.mc_id= 20230907090000_AI-Agents_BG-EM_ 
&WT.tsrc=BGEM〉.Last accessed 22 January 2024.
Gates, B., 2023c.The risks of ai are real but manageable.〈https://www.gatesnotes.com/The-risks-of-AI-are-real-but-manageable〉.accessed 18 January 2024.
Greyson, D. (2018). Information triangulation: A complex and agentic everyday information practice. Journal of the Association for Information Science and Technology, 
69, 869–878.
Guppy, N., Verpoorten, D., Boud, D., Lin, L., Tai, J., & Bartolic, S. (2022). The post-covid-19 future of digital learning in higher education: Views from educators, 
students, and other professionals in six countries. British Journal of Educational Technology, 53, 1750–1765.
Hanfstingl, B., Benke, G., & Zhang, Y. (2019). Comparing variation theory with piaget’s theory of cognitive development: More similarities than differences? 
Educational Action Research, 27, 511–526.
Hartmann, J., Schwenzow, J., Witte, M., 2023.The political ideology of conversational ai: Converging evidence on chatgpt’s pro-environmental, left-libertarian 
orientation.ar Xiv preprint ar Xiv:2301.01768 25, 2023.
Heaven, W., 2023.Chatgpt is going to change education, not destroy it.〈https://www.technologyreview.com/2023/04/06/1071059/chatgpt-change-not-destroy- 
education-openai/〉.Last accessed 18 January 2024.
Hien, H.T., Cuong, P.N., Nam, L.N.H., Nhung, H.L.T.K., Thang, L.D., 2018.Intelligent assistants in higher-education environments: the fit-ebot, a chatbot for 
administrative and learning support, In: Proceedings of the 9th International Symposium on Information and Communication Technology, 69-76.
Ibrahimu, K. (2022). Behaviourism theory in teaching and learning english as a second language in primary schools. International Journal of English and Literature, 13, 
33–38.
Ifenthaler, D., Majumdar, R., Gorissen, P., Judge, M., Mishra, S., Raffaghelli, J., & Shimada, A. (2024). Artificial intelligence in education: Implications for 
policymakers, researchers, and practitioners. Technology, Knowledge and Learning, 1–18.
Imran, R., Fatima, A., Salem, I. E., & Allil, K. (2023). Teaching and learning delivery modes in higher education: Looking back to move forward post-covid-19 era. The 
International Journal of Management Education, 21, Article 100805.
Javaid, M., Haleem, A., Singh, R. P., Khan, S., & Khan, I. H. (2023). Unlocking the opportunities through chatgpt tool towards ameliorating the education system. 
Bench Council Transactions on Benchmarks, Standards and Evaluations, 3, Article 100115.
Jiang, A.Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C., Chaplot, D.S., Casas, D.d.l., Hanna, E.B., Bressand, F., et al., 2024.Mixtral of experts.ar Xiv 
preprint ar Xiv:2401.04088.
Kabudi, T., Pappas, I., & Olsen, D. H. (2021). Ai-enabled adaptive learning systems: A systematic mapping of the literature. Computers and Education: Artificial 
Intelligence, 2, Article 100017.
Khanna, S., Ghosh, F.N., Kumar, S., 2024.Successful footprints of chatgpt deployments in the education sector: Pros outweigh cons by embracing ethics and etiquette, 
in: Revolutionizing the Service Industry Wth Open AI Models. IGI Global, 219-242.
Kleinman, Z., Mc Mahon, L., Sherman, N., 2025.Apple urged to withdraw ’out of control’ ai news alerts.〈https://www.bbc.co.uk/news/articles/cge93de21n0o〉.Last 
accessed 13 January 2025.
Limba, T., Leleˇsien˙e, L., Novogreckas, S., Kowalewska, A., 2024.Exploring the impact of artificial intelligence on educational paradigms: Unleashing the potential, in: 
EDULEARN24 Proceedings, organization, IATED.4349-4357.
Liu, Z., Zhang, N., Peng, X., Liu, S., & Yang, Z. (2023). Students’ social-cognitive engagement in online discussions. Educational Technology Society, 26, 1–15.
Loughran, J. (2013). Pedagogy: Making sense of the complex relationship between teaching and learning. Curriculum Inquiry, 43, 118–141.
Mai, V. L. T. (2023). Autonomy-based listening: Vietnamese university students’ perceptions of self-access web-based listening practices. Studies in Self-Access Learning 
Journal, 14.
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 15 ---

Mc Carthy, K. S., Likens, A. D., Johnson, A. M., Guerrero, T. A., & Mc Namara, D. S. (2018). Metacognitive overload!: Positive and negative effects of metacognitive 
prompts in an intelligent tutoring system.  International Journal of Artificial Intelligence in Education, 28, 420–438.
Mc Namara, J., 2023.Social media analysis of the uk’s prospective international students.〈https://opportunities-insight.britishcouncil.org/features/social-media- 
analysis-of-uks-prospective-international-students〉.Last accessed 06 January 2025.
Mitra, A., Del Corro, L., Mahajan, S., Codas, A., Simoes, C., Agarwal, S., Chen, X., Razdaibiedina, A., Jones, E., Aggarwal, K., et al., 2023.Orca 2: Teaching small 
language models how to reason.ar Xiv preprint ar Xiv:2311.11045.
Mohammed, A. T., Velander, J., & Milrad, M. (2024). A retrospective analysis of artificial intelligence in education (aied) studies: perspectives, learning theories, 
challenges, and emerging opportunities. In Radical Solutions for Artificial Intelligence and Digital Transformation in Education: Utilising Disruptive Technology for a 
Better Society (pp. 127–141). Springer. 
Morris, D. (2023). Magical thinking and the test of humanity: We have seen the danger of ai and it is us. AI Society, 1–3.
Mueller, D., & Strohmeier, S. (2011). Design characteristics of virtual learning environments: State of research. Computers Education, 57, 2505–2516.
Mulaudzi, L. (2024). Opportunities presented by artificial intelligence to teaching and learning in higher education: A review of literature. Kagisano, 64.
Nath, S. (2013b). Is functionalism an alternative to behaviourism? International Journal of Humanities and Social Science Innovation, 2(13), 58–63.
Nath, S. (2013a). Behaviourism as a precursor of identity theory of mind. International Journal of Scientific and Research Publications, 3, 510.
O’Connor, S. (2022). Open artificial intelligence platforms in nursing education: Tools for academic progress or abuse? Nurse Education in Practice, 66, Article 103537.
O’Connor, S., Permana, A. F., Neville, S., & Denis-Lalonde, D. (2023). Artificial intelligence in nursing education 2: Opportunities and threats. Nursing Times, 2, 2.
Ojha, D. R. (2024). Opportunities and challenges of adopting artificial intelligence in learning and teaching in higher education. AMC Journal (Dhangadhi), 5, 65–76.
Okonkwo, C. W., & Ade-Ibijola, A. (2021a). Chatbots applications in education: A systematic review. Computers and Education: Artificial Intelligence, 2, Article 100033.
Okonkwo, C. W., & Ade-Ibijola, A. (2021b). Evaluating the ethical implications of using chatbot systems in higher education. digi TAL, 2021(3), 68.
Papert, S., 1991.Situating constructionism.Constructionism/Ablex.
Pavlov, P. I. (2010). Conditioned reflexes: An investigation of the physiological activity of the cerebral cortex. Annals of neurosciences, 17, 136.
Pellegrini, M., Uskov, V., Casalino, N., 2020.Reimagining and re-designing the post-covid-19 higher education organizations to address new challenges and responses 
for safe and effective teaching activities. Law and Economics Yearly Review Journal-LEYR, Queen Mary University, London, UK 9, 219-248.
Piaget, J., 1976.Biology and cognition, in: Piaget and his school: A reader in developmental psychology, 45-62.
Plevris, V., Papazafeiropoulos, G., & Jim´enez Rios, A. (2023). Chatbots put to the test in math and logic problems: A comparison and assessment of chatgpt-3.5, 
chatgpt-4, and google bard. AI, 4, 949–969.
Popenici, S. (2023). The critique of ai as a foundation for judicious use in higher education. Journal of Applied Learning and Teaching, 6.
Rachmad, Y.E., 2022.Adaptive learning theory.
Rahman, S. F. A., Yunus, M. M., & Hashim, H. (2019). An overview of flipped learning studies in malaysia. Arab World English Journal, 10, 194–203.
Rahman, S. F. A., Yunus, M. M., & Hashim, H. (2020). The uniqueness of flipped learning approach. International Journal of Education and Practice, 8, 394–404.
Ranoliya, B.R., Raghuwanshi, N., Singh, S., 2017.Chatbot for university related faqs, in: 2017 International Conference on Advances in Computing Communications 
and Informatics (ICACCI), 1525-1530.
Reginald, G. (2023). Teaching and learning using virtual labs: Investigating the effects on students’ self-regulation. Cogent Education, 10, Article 2172308.
Rim, C., 2023.Don’t ban chatgpt–teach students how to use it.〈https://www.forbes.com/sites/christopherrim/2023/05/03/dont-ban-chatgpt-teach-students-how-to- 
use-it/〉.Last accessed 18 January 2024.
Robert, R., & Meenakshi, S. (2024). The future of artificial intelligence (ai) in education: Threats and prospects for long-term growth. Multidisciplinary, 181.
R¨ohrig, C., & Heß, D. (2019). Omniman: A mobile assistive robot for intralogistics applications. Engineering Letters, 27, 2019.
Roose, K., 2023.Don’t ban chatgpt in schools. teach with it.〈https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html〉.Last accessed 18 
January 2024.
Rosenblatt, K. (2023). Chatgpt passes mba exam given by a wharton professor. Retrieved Jan, 25, 2023.
Rudolph, J., Ismail, M. F. B. M., & Popenici, S. (2024). Higher education’s generative artificial intelligence paradox: The meaning of chatbot mania. Journal of 
University Teaching and Learning Practice, 21, 1–35.
Saboowala, R., Manghirmalani-Mishra, P., 2020.Perception of in-service teachers towards blended learning as the new normal in teaching-learning process post covid- 
19 pandemic pandemic. Europe PMC.
Sabzalieva, E., Valentini, A., 2023.Chatgpt and artificial intelligence in higher education.〈https://www.iesalc.unesco.org/en/〉.Last accessed 26 March 2024.
Shakarian, P., Koyyalamudi, A., Ngu, N., Mareedu, L., 2023.An independent evaluation of chatgpt on mathematical word problems (mwp).ar Xiv preprint ar Xiv: 
2302.13814.
Shamsuddinova, S., Heryani, P., & Naval, M. A. (2024). Evolution to revolution: Critical exploration of educators’ perceptions of the impact of artificial intelligence 
(ai) on the teaching and learning process in the gcc region. International Journal of Educational Research, 125, Article 102326.
Shields, C., 2023.Don’t ban chatgpt. use it as a teaching tool.〈https://www.edweek.org/technology/opinion-dont-ban-chatgpt-use-it-as-a-teaching-tool/2023/01〉. 
Last accessed 18 January 2024.
Shodieva, M. (2024). The influence of artificial intelligence on education. Modern Science and Research, 3, 394–401.
Singer, N., 2023.Despite cheating fears, schools repeal chatgpt bans.〈https://www.nytimes.com/2023/08/24/business/schools-chatgpt-chatbot-bans.html〉.Last 
accessed 18 January 2024.
Singh, J., Steele, K., & Singh, L. (2021). Combining the best of online and face-to-face learning: Hybrid and blended learning approach for covid-19, post vaccine, & 
post-pandemic world. Journal of Educational Technology Systems, 50, 140–171.
Sinha, S., Basak, S., Dey, Y., Mondal, A., 2020.An educational chatbot for answering queries, in: Emerging Technology in Modelling and Graphics: Proceedings of IEM 
Graph 2018, 55-60.
Skinner, B. F. (1988). Preface to the behavior of organisms. Journal of the Experimental Analysis of Behavior, 50, 355.
Smutny, P., & Schreiberova, P. (2020). Chatbots for learning: A review of educational chatbots for the facebook messenger. Computers Education, 151, Article 103862.
Stakelum, J.L., 2024.The end of ai hallucinations: A big breakthrough in accuracy for ai application developers.〈https://medium.com/@James Stakelum/the-end-of- 
ai-hallucinations-a-breakthrough-in-accuracy-for-data-engineers-e67be5cc742a〉.Last accessed 05 January 2025.
Sternberg, R. J., & Halpern, D. F. (2020). Critical thinking in psychology. Cambridge University Press. 
Tahiru, F. (2021). Ai in education: A systematic literature review. Journal of Cases on Information Technology (JCIT), 23, 1–20.
Tang, K. Y., Chang, C. Y., & Hwang, G. J. (2023). Trends in artificial intelligence-supported e-learning: A systematic review and co-citation network analysis 
(1998–2019). Interactive Learning Environments, 31, 2134–2152.
Tariq, M.U., 2025.Artificial intelligence challenges in higher education. IGI Global - 10.4018/979-8.3693-4074-5.ch004.
Team, G., Georgiev, P., Lei, V.I., Burnell, R., Bai, L., Gulati, A., Tanzer, G., Vincent, D., Pan, Z., Wang, S., et al., 2024a.Gemini 1.5: Unlocking multimodal 
understanding across millions of tokens of context.ar Xiv preprint ar Xiv:2403.05530.
Team, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, L., Rivi`ere, M., Kale, M.S., Love, J., et al., 2024b.Gemma: Open models based on 
gemini research and technology.ar Xiv preprint ar Xiv:2403.08295.
Tennakoon, H., Hansen, J. M., Saridakis, G., Samaratunga, M., & Hansen, J. W. (2023). Drivers and barriers of social sustainable development and growth of online 
higher education: The roles of perceived ease of use and perceived usefulness. Sustainability, 15, 8319.
Thatcher, J. B., Wright, R. T., Sun, H., Zagenczyk, T. J., & Klein, R. (2018). Mindfulness in information technology use. MIS Quarterly, 42, 831–A14.
Thorndike, E. (2017). Animal intelligence: experimental studies. Routledge. 
Thorne, S., 2023.Experimenting with chatgpt for spreadsheet formula generation: Evidence of risk in ai generated spreadsheets.ar Xiv preprint ar Xiv:2309.00095.
Thorne, S., 2024.Why microsoft’s copilot ai falsely accused court reporter of crimes he covered.〈https://theconversation.com/why-microsofts-copilot-ai-falsely- 
accused-court-reporter-of-crimes-he-covered-237685〉.Last accessed 04 January 2025.
Thorp, H. H. (2023). Chatgpt is fun, but not an author. Science, 379, 313.
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616 

--- Page 16 ---

Torres, J.L., 2023.Tec de monterrey recommends its community to use chatgpt intelligently.〈https://conecta.tec.mx/es/noticias/nacional/institucion/tec-de- 
monterrey-recomienda-su-comunidad-uso-inteligente-de-chatgpt〉.Last accessed 26 March 2024.
Vygotsky, L.S., 1986.Thought and language (a. kozulin, trans.).
Vygotsky, L. S., & Cole, M. (1978). Mind in society: development of higher psychological processes. USA: Harvard University Press. 
Wan, Y., Wang, W., Yang, Y., Yuan, Y., Huang, J.t., He, P., Jiao, W., Lyu, M.R., 2024.A & b= = b & a: Triggering logical reasoning failures in large language models. 
ar Xiv preprint ar Xiv:2401.00757.
What are ai hallucinations?, 2024.What are ai hallucinations? 〈https://www.ibm.com/topics/ai-hallucinations〉.Last accessed 18 March 2024.
Wood, M.C., 2024.Ragfix—x.〈https://www.ragfix.ai/〉.Last accessed 05 January 2025.
Wood, D., Bruner, J. S., & Ross, G. (1976). The role of tutoring in problem solving. Journal of Child Psychology and Psychiatry, 17, 89–100.
Wood, M.C., Forbes, A.A., 2024.100% hallucination elimination using acurai.ar Xiv preprint ar Xiv:2412.05223.
Yang, M., 2023.New york city schools ban ai chatbot that writes essays and answers prompts.〈https://www.theguardian.com/us-news/2023/jan/06/new-york-city- 
schools-ban-ai-chatbot-chatgpt〉.Last accessed 18 January 2024.
Yang, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Li, C., Liu, D., Huang, F., Wei, H., et al., 2024.Qwen2. 5 technical report.ar Xiv preprint ar Xiv:2412.15115.
Zhang, K., & Aslan, A. B. (2021). AI technologies for education: Recent research & future directions. Computers and Education: Artificial Intelligence, 2, Article 100025.
Zhao, Y., & Watterston, J. (2021). The changes we need: Education post covid-19. Journal of Educational Change, 22, 3–12.
E. Ukwandu et al.                                                                                                                                                                                                      
Futures 171 (2025) 103616
