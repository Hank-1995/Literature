# Factors influencing educators' AI adoption: A grounded meta-analysis review

## Metadata
- **Author**: Rana Taheri
- **Subject**: Computers and Education: Artificial Intelligence, 9 (2025) 100464. doi:10.1016/j.caeai.2025.100464
- **Creator**: Elsevier
- **Producer**: Acrobat Distiller 8.1.0 (Windows)
- **Creation Date**: D:20250916043300Z
- **Modification Date**: D:20250916051603Z
- **Source File**: Factors-influencing-educators--AI-adoption-_2025_Computers-and-Education--Ar.pdf
- **Converted**: 2025-10-23 22:46:13

---

## Content

--- Page 1 ---

Factors influencing educators’ AI adoption: A grounded 
meta-analysis review
Rana Taheri a,*
, Neda Nazemi b
, Sarah E. Pennington c
, Jason A. Clark d
,  
Faraz Dadgostari e
a Department of Education, Montana State University, Bozeman, USA
b Department of Computer Science, Montana State University, USA
c Department of Education, Montana State University, USA
d Montana State University Library, USA
e Mechanical and Industrial Engineering, Montana State University, USA
A R T I C L E  I N F O
Keywords:
Artificial intelligence in education (AIEd)
Educators’ AI adoption
AI literacy
Grounded meta-analysis
A B S T R A C T
Artificial Intelligence (AI) is rapidly reshaping educational practices, yet educators’ adoption of AI varies. This 
paper utilized a grounded meta-analysis framework of 45 peer-reviewed articles published between 2020 and 
2024, including qualitative, quantitative, mixed-method, and social media (X) studies, to examine factors 
influencing educators’ AI adoption. Four primary categories emerged from coding the papers: Individual Factors 
(demographics, AI literacy, beliefs, and self-efficacy), Infrastructure (institutional support, resource availability, 
social influence, and media narratives), Tools (perceived usefulness, ease of use, compatibility, transparency, 
bias, and reliability), and Impacts (concerns about overdependence, job security, and potential misuse). X-data 
paper findings also indicated that educators generally view AI positively but express notable concerns regarding 
trust, transparency, and ethical implications, highlighting the necessity for improved AI literacy. This study 
moreover revealed that although common technology adoption frameworks (e.g., TAM, UTAUT) frequently 
informed the analyses, these models inadequately address the unique ethical, pedagogical, institutional, and 
technical complexities specific to AI. The findings offer valuable insights for educators, educational institutions, 
and AI developers by pinpointing these critical factors. Key recommendations include providing robust insti-
tutional support, establishing transparent AI usage policies, and offering targeted professional development 
opportunities. Implementing these strategies will enhance educators’ confidence and ensure the responsible and 
ethical integration of AI into educational settings, ultimately maximizing AI’s potential to positively transform 
education.
1. Introduction
As Artificial Intelligence (AI) continues to transform various sectors 
of society, it has also reshaped education, with growing pedagogical 
impact across disciplines—from STEM fields such as chemistry and 
biology (Chiu, 2021; Nasution, 2023; Xu & Ouyang, 2022), and 
healthcare and medical education (Dave & Patel, 2023; Mir et al., 2023; 
Nagi et al., 2023), to business (Sollosy & Mc Inerney, 2022; Xu & 
Babaian, 2021), and language education (Huang et al., 2023; Woo & 
Choi, 2021). Artificial Intelligence in Education (AIEd) refers to the use 
of AI technologies to enhance learning experiences (Harry & Sayudin, 
2023). In recent years, AIEd has gained widespread attention for its 
numerous advantages for educators, ranging from classroom applica-
tions to supporting professional growth. However, despite these bene-
fits, research indicates that educators often exhibit resistance to AI 
adoption, resulting in hesitation or delays in its integration (e.g., 
Cukurova et al., 2023; Istenic et al., 2021; Woodruff et al., 2023). This 
resistance can stem from its drawbacks, such as concerns about aca-
demic integrity, trustworthiness, overreliance on AI, teacher readiness, 
and job displacement (e.g., Flores-Viva & García-Pe˜nalvo, 2023; Holmes 
et al., 2022; Whalen & Mouza, 2023). In this study, AI adoption refers to 
incorporating AI technologies into educational systems —such as K–12 
schools, higher education (HE) institutions, and teacher education 
programs— to enhance teaching and learning.
* Corresponding author. 107 Branegan Courts, apt F, Bozeman, MT, 59715, USA.
E-mail address: rana.taheri@studnet.montana.edu (R. Taheri). 
Contents lists available at Science Direct
Computers and Education: Artificial Intelligence
journal homepage: www.sciencedirect.com/journal/computers-and-education-artificial-intelligence
https://doi.org/10.1016/j.caeai.2025.100464
Received 18 April 2025; Received in revised form 14 August 2025; Accepted 18 August 2025  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 
Available online 12 September 2025 
2666-920X/© 2025 Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ). 

--- Page 2 ---

Several studies have examined factors influencing AI adoption 
among educators, including Al-Mughairi & Bhaskar, 2024, Al-Momani 
and Ramayah (2024), and Cukurova et al. (2023). While these studies 
consistently emphasize the need for further research in this area, no 
comprehensive review has synthesized and coded factors across 
educator groups or integrated findings from diverse research method-
s—quantitative, qualitative, and social media data analyses—as of 
December 2024. In this paper, "educators" refers broadly to K-12 
teachers, pre-service teachers (PSTs), lecturers at the college and uni-
versity level, and HE faculty members. This study does not restrict its 
scope to specific educator groups or geographic regions and aims to 
synthesize existing research on AI adoption among educators, by 
extracting grounded themes from articles under study. The grounded 
meta-analysis framework developed by Stall-Meadows and Hyle (2010)
and recently used by Rˆego et al. (2023) was applied in this study. This 
approach synthesizes findings from diverse studies, facilitating hy-
pothesis development and identifying key factors influencing AI adop-
tion in education.
The contribution of this study is threefold. First, identifying obstacles 
to AI adoption allows for more targeted interventions to bridge the gap 
between innovation and practice. So, Stakeholders and policymakers 
can provide educators with essential support and resources, enabling 
them to develop confidence in using AI tools and seamlessly integrate 
them into their teaching practices. Second, this study offers valuable 
insights for educational tool developers, helping them enhance acces-
sibility and ensure seamless integration into classroom settings while 
aligning with educators’ needs. Third, with the rapid pace of techno-
logical advancement, delayed AI adoption could lead to missed oppor-
tunities for enhancing student learning, potentially widening the 
teacher-student gap. This study further informs educators about their 
crucial role in adopting AI tools and highlights how their knowledge and 
collaboration with companies and stakeholders can help mitigate the 
potential negative impacts of AIEd.
2. Definitions
2.1. AI
While many definitions have been proposed for AI, no single defi-
nition has gained universal acceptance. For example: 
“Computing systems that are able to engage in human-like processes 
such as learning, adapting, synthesizing, self-correction and the use 
of data for complex processing tasks” (Popenici & Kerr, 2017, p. 2).
“AI is about emulating the human intelligence process by machines.” 
(Ng & Leung, 2020, p.1).
“It is the tangible real-world capability of non-human machines or 
artificial entities to perform, task solve, communicate, interact, and 
act logically as it occurs with biological humans” (Gil de Zú˜niga, 
Goyanes, & Durotoye, 2024, p.4)
AI is commonly defined as machines trained by humans to perform 
tasks using algorithms and data, assisting with processes such as data 
collection, analysis, assessment, and decision-making. However, AI 
differs fundamentally from human intelligence, lacking comprehension, 
self-awareness, emotions, ethics, and cultural understanding (Cao & 
Dede, 2023).
2.2. Generative AI (GAI)
It refers to AI systems that create content—text, images, audio, and 
code—using trained models like GPT-based Large Language Models 
(Bender et al., 2021; Cao & Dede, 2023). Chat GPT is an example of GAI 
tool.
2.3. AIEd
An academic field for over 30 years since the 1980s (O’shea & Self, 
1986; Williamson & Eynon, 2020), which applies AI technologies like 
tutoring systems, chatbots, robots, and adaptive learning to enhance 
education and decision-making (Chen et al., 2020; Harry & Sayudin, 
2023). By bridging human instruction and technology, it creates dy-
namic learning environments while integrating social, cultural, eco-
nomic, and pedagogical aspects (Selwyn, 2016; Vashishth et al., 2024). 
AI tools benefit educators and students but also present challenges. The 
next section highlights key considerations for educators.
3. AIEd opportunities for educators
AI adoption has enhanced learning activities and advanced 
technology-driven environments (Limna et al., 2022), offering new op-
portunities for educators. While its full impact remains uncertain 
(Holmes et al., 2022), its benefits can be categorized into two key areas.
3.1. Classroom purposes
Educators can use AI for various purposes, including personalized 
curriculum delivery, classroom management, lesson planning, content 
creation, syllabus development, assessment design, automated grading, 
and providing instant, personalized feedback (eg. Asadi & Taheri, 2024; 
Celik et al., 2022; Chen et al., 2020; Haque et al., 2022; Harry & 
Sayudin, 2023; Mohammadi et al., 2024; Pesek et al., 2022; Swiecki 
et al., 2022). AI tools enable educators to monitor and predict students’ 
performance, progress, learning abilities, and needs by analyzing stu-
dent data and presenting actionable insights (Akmese et al., 2021; Chiu 
et al., 2023). These tools can also predict academic success, support 
at-risk students and those with special needs, measure engagement, 
track attendance, and facilitate language learning (Pesek et al., 2022; 
UNESCO, 2019).
3.2. Professional growth
AI tools can support the delivery of more efficient, customized, and 
effective learning experiences (Chen et al., 2020; Kasneci et al., 2023) 
and provide models for planning, assessment, and recommendations to 
enhance their instructional strategies (Celik et al., 2022; Hu, 2021). It 
enhances teaching skills by providing evaluation models, suggesting 
improvement strategies, and fostering self-reflection and inspiration 
(Aldeman et al., 2021; Hu, 2021). AI can elevate the teaching experience 
by introducing engaging features into the classroom and breaking up 
routine (Mc Carthy et al., 2016). It also enables educators to refine their 
methods, thereby fostering better interaction between instructors and 
students (Zhang & Zhang, 2024). Additionally, AI supports the creation 
of dynamic learning materials and encourages a re-evaluation of tradi-
tional assessments (Chen et al., 2020; Chounta et al., 2022; Zhai, 2022). 
By automating routine tasks, it frees up time for essential responsibilities 
such 
as 
student 
evaluations, 
personalized 
support, 
and 
relationship-building, while also increasing focus on student well-being 
(Alwaqdani, 2024; Chan & Zary, 2019; Huong, 2024; Vij et al., 2020).
4. AIEd challenges for educators
While AI offers valuable opportunities to enhance teaching and 
learning, it also introduces ethical concerns and potential risks. The 
following highlights key challenges educators encounter and their con-
cerns regarding AI’s impact on students.
4.1. Privacy concerns
Data privacy is a widely discussed issue in AI-driven education (e.g., 
Flores-Viva & García-Pe˜nalvo, 2023; Kiryakova & Angelova, 2023; 
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 3 ---

Whalen & Mouza, 2023). AI tools collect vast amounts of user data, 
including confidential information (Elmore, 2023; Whalen & Mouza, 
2023; Zawacki-Richter et al., 2019) which are often stored and may be 
shared with third parties (Al-Mughairi & Bhaskar, 2024; Limna et al., 
2023; Whalen & Mouza, 2023). There are also concerns about collecting 
sensitive data without consent and its inability to verify user age, which 
may expose young learners to inappropriate content (Sabzalieva & 
Valentini, 2023; Su & Yang, 2023). Without proper safeguards, privacy 
risks can lead to data breaches, misuse, and identity theft (Hill-Yardin 
et al., 2023; Rahman & Watanobe, 2023).
4.2. Academic integrity
Plagiarism, copyright infringement, scholarly misconduct, and 
cheating are major challenges in AI-assisted education (Baek & Kim, 
2023; Holmes et al., 2022; Mao et al., 2024; Vargas-Murillo et al., 2023). 
Some students submit AI-generated assignments as their own, bypassing 
critical analysis and proper citation which highlight concerns over the 
misuse of AI in academia (Cotton et al., 2024; Halaweh, 2023; Qadir, 
2023). 
Moreover, 
distinguishing 
between 
AI-generated 
and 
student-authored work remains a challenge, as AI tools can paraphrase 
text in ways that evade plagiarism and detection software (Al Afnan 
et al., 2023; Cotton et al., 2024). With ineffective detection programs, a 
punitive approach alone fails to uphold education’s core objectives and 
may undermine trust between students and educators (Kramm & 
Mc Kenna, 2023).
4.3. Trustworthiness
GAI tools can generate text that appears credible but often contains 
inaccuracies or fabricated information, a phenomenon known as 
"hallucination" (Mamo et al., 2024; Whalen & Mouza, 2023). AI algo-
rithms can reinforce stereotypes, perpetuate inequities, generate harm-
ful content, and even introduce new forms of bias if trained on 
inadequate or biased data (Farrokhnia et al., 2024; Flores-Viva & Gar-
cía-Pe˜nalvo, 2023; Ismail et al., 2024; Whalen & Mouza, 2023). This 
issue is particularly concerning in education, where biased AI models 
can affect data-driven decisions in areas like classroom instruction and 
college admissions, potentially creating inequities in students’ academic 
trajectories (Mao et al., 2024). Educators worry that students may 
accept AI-generated responses as objective truth and rely on that 
without verifying their accuracy (Kiryakova & Angelova, 2023; Limna 
et al., 2023; Warschauer et al., 2023).
4.4. Overreliance on AI
A major concern is that overreliance on AI may hinder educators’ 
professional growth by limiting problem-solving, critical thinking, and 
interpersonal skills, while also weakening educator collaboration, and 
mentorship, ultimately affecting education quality (Adiguzel et al., 
2023; Arif et al., 2023; Ismail et al., 2024; Kiryakova & Angelova, 2023; 
Qadir, 2023). Additionally, AI dependence may introduce biases, reduce 
empathy and the educator-student relationship, and impair educators’ 
ability to understand student emotions, backgrounds, and learning 
needs (Mao et al., 2024). AI’s role in assessments raises concerns about 
its impact on personal development, decision-making, and creativity, as 
it may limit originality and critical thinking (Ahmad et al., 2023; Smo-
lansky et al., 2023). It also risks promoting superficial engagement over 
deep understanding (Firat, 2023a; Ismail et al., 2024). Additionally, 
AI-generated evaluations may misrepresent students’ abilities, reducing 
their sense of learner agency (Berendt et al., 2020; Swiecki et al., 2022).
4.5. Educator readiness and job displacement concern
AI tools are still in their early stages, and many educators lack the 
knowledge and readiness to use them effectively or trust its role in 
education (Antonenko & Abramowitz, 2023; Celik et al., 2022; Chiu & 
Chai, 2020; Chounta et al., 2022; Jafari & Keykha, 2024; Kaplan-Ra-
kowski et al., 2023; Nazaretsky et al., 2022). Limited institutional ac-
cess, along with the time and training required for effective AI 
implementation, can hinder educators from integrating AI into their 
curriculum (Alwaqdani, 2024; Whalen & Mouza, 2023). Moreover, AI’s 
ability to automate various teaching tasks raises concerns about teacher 
job displacement (Farrokhnia et al., 2024; Flores-Viva & García-Pe-
˜nalvo, 2023; Zawacki-Ritcher et al., 2019). While some question AI’s 
ability to replace human educators, many researchers emphasize the 
irreplaceable role of educators in providing interaction, emotional 
support, and personalized guidance (Firat, 2023a; Ismail et al., 2024; 
Mamo et al., 2024).
5. Conceptual framework
This study applied a cyclical grounded meta-analysis process to 
examine the factors influencing educators’ AI adoption. It was intro-
duced by Hossler and Scalese-Love (1989) and then developed by 
Stall-Meadows and Hyle (2010). This inductive process constructs the-
ory through systematic and iterative data analysis (Hossler & 
Scalese-Love, 1989). Unlike quantitative meta-analyses, which struggle 
with study heterogeneity, and the challenge of synthesizing qualitative 
findings quantitatively, grounded meta-analysis embraces this diversity 
to uncover contextual nuances and deepen the understanding of the 
studied phenomena (Lorenc et al., 2016). Furthermore, this approach 
embraces the principle that "all is data," meaning that all relevant in-
formation, including research papers with multiple data collection 
methods, are valid for analysis, facilitating a comprehensive examina-
tion of relationships between concepts (Savin-Baden & Major, 2023). By 
integrating various research methods, extracting comparable categories, 
and comparing studies based on their purposes, methodologies, and 
outcomes, this approach synthesizes themes to reveal commonalities 
and underlying causes. The coding procedure, adapted from Strauss and 
Corbin (1990), Hossler and Scalese-Love (1989), and Stall-Meadows and 
Hyle (2010), is detailed in the methodology section.
6. Methodology
6.1. Data collection
The data collection strategy was designed to identify the most rele-
vant topics in AI adoption among educators, including professors, K-12 
teachers, university lecturers, instructors, etc. The following search 
strings "(AI OR Artificial Intelligence OR generative AI) AND (adoption 
OR adaptation OR acceptance OR perceptions) AND (Education) AND 
(Educators OR teachers OR professors OR pre-service teachers OR lec-
turers OR student teachers OR faculty OR instructors OR tutors)" were 
applied in Google Scholar, Web of Science, and ERIC. These databases 
were selected for their reliability, high research quality, and extensive 
domain coverage, resulting in approximately 800 articles. After 
removing duplicates, non-empirical studies, and those not situated 
within educational contexts, titles and abstracts were screened for 
relevance, with a focus on research examining educators’ perceptions 
and adoption of AI. Studies published in semi high-quality journal-
s—defined as peer-reviewed publications with moderate to strong aca-
demic reputations, acceptable editorial standards, and reasonable 
impact factors in the fields of education and technology—were priori-
tized. Articles with poor methodological quality or weak research design 
were excluded from the review. Snowballing techniques were applied to 
the study as a systematic method of identifying relevant literature by 
chaining references and citations from selected papers to find related 
articles (Wohlin, 2014). Finally, a total of 45 peer-reviewed English--
language articles focusing on AI adoption in education contexts that 
published between 2020 and 2024 were included in the review. Fig. 1
depicts the search process, including all inclusion and exclusion criteria. 
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 4 ---

The distribution of studies by research method, publication year, and 
country is presented in Figs. 2–4, respectively.
Particular attention was given to papers that utilized X platform 
(formerly Twitter) data to explore educators’ perceptions of AI and 
public attitudes toward AIEd. As part of a broader project, this initiative 
will further expand into a text mining study to uncover deeper patterns, 
trends, and sentiments in educators’ discussions on AI. Due to recent X 
application programming interface (API) restrictions limiting access to 
personal data, including occupations, only four papers were found to be 
relevant to the study’s scope. The next section explains the rationale for 
selecting papers that analyzed Tweets.
6.2. Social media data analysis
With 4.8 billion active users worldwide (Kemp, 2023), social media 
has become a key research data source. Among these platforms, X pro-
vides real-time insights into public perceptions and emerging technol-
ogies like Chat GPT (Lampropoulos et al., 2023; Stracqualursi & Agati, 
2024). Researchers increasingly use X’s data, often regarded as scalable 
and unbiased, to analyze sentiments, providing faster insights than 
traditional methods like surveys and interviews (Fütterer et al., 2023; 
Fischer et al., 2020; Zou et al., 2023). Many educators use X for pro-
fessional and educational purposes, leveraging hashtags to connect and 
collaborate with peers (Carpenter et al., 2022; Greenhalgh et al., 2020; 
Nochumson, 2020). Analyzing their tweets offers valuable insights into 
their perceptions and sentiments. Sentiment analysis, a common tech-
nique in text mining, interprets opinions, attitudes, and emotions, 
effectively categorizing the content as positive, negative, or neutral 
(Astya, 2017; Liu, 2022). This study examines research utilizing X data, 
Studies that use data 
sourced from the X platform
(n = 4)
(AI OR Artificial Intelligence OR generative AI) AND (adoption OR 
adaptation OR acceptance OR perceptions) AND (Education) AND 
(Educators OR teachers OR professors OR pre-service teachers OR lecturers 
OR student teachers OR faculty OR instructors OR tutors)
(n = 800)
Supplementary sources:
Exclusion criteria:
•
Non-English
•
Duplicates
•
Non empirical research 
•
Not in education context
(n = 650)
First Screening
Title & Abstract Screening
Exclusion criteria:
•
Studies without educator participants
•
Those not addressing AI adoption 
•
Poor methodological quality and 
design
(n = 117)
Database search (Google Scholar, Web of Science, ERIC) using the query:
Snowball sampling from 
reference lists
 (n = 8)
N = 12
Final full-text included
N = 45
Second Screening
Full-Text Eligibility 
Inclusion criteria:
•
Publication years 2020–2024
•
Peer-reviewed, high-impact journals
•
English language
•
Focus on education contexts
•
Relevant titles/abstracts to AI adoption
(n = 150)
Inclusion criteria:
•
Direct relevance to our research questions
•
Focus on factors influencing AI adoption
•
Participants are educators at any teaching 
level 
(n = 33)
Fig. 1. Overview of the search process, exclusion and inclusion criteria.
Fig. 2. Distribution of studies by methodology.
Fig. 3. Distribution of studies by year.
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 5 ---

including public tweets and those authored by educators.
6.3. Data analysis
6.3.1. General approach
The grounded theory approach to research synthesis involves sys-
tematically documenting and categorizing detailed information from 
each study (Hossler & Scalese-Love, 1989). All selected articles were 
reviewed and documented in a Google Sheets database (Appendix 1), 
capturing each study’s target population, methodology, theoretical 
framework, purpose, results, and emerging codes. Then, the initial 
analysis of X-related research aimed to identify polarities (positive, 
negative, neutral) and sentiments were applied, and other studies were 
examined for their theoretical frameworks. Grounded coding was then 
applied across all papers, categorizing factors as "Themes" in the table. 
Extracted data were then organized into another table with key findings, 
example quotes, emergent themes, and sources (Appendix 2). This 
database was analyzed to identify common patterns, overarching 
themes, and cross-study comparisons, followed by a final comparative 
analysis to synthesize the findings, which will be explained in the 
following section. Fig. 5 illustrates the data analysis process for all 
articles.
6.3.2. Grounded coding cycle
The grounded theory method systematically grouped similar phe-
nomena into categories to build a conceptual framework through cod-
ing, memoing, and sorting. All processes were carried out manually with 
careful attention by a group of five experts from diverse fields, including 
education, computer science, systems engineering, and library science. 
• Open Coding: Data was broken down, categorized, and labeled to 
identify initial concepts (Strauss & Corbin, 1990). Appendix 2 pre-
sents sentences and their corresponding codes.
• Axial Coding: Categories were refined into subcategories, clarifying 
relationships within a structured framework. For consistency, color 
coding was applied (e.g., teacher knowledge, teaching strategy, and 
background were grouped and marked in pink) (Appendix 3).
• Selective Coding: Core categories were consolidated into theoretical 
concepts, 
emphasizing 
relationships 
among 
key 
themes 
(Stall-Meadows & Hyle, 2010). For example, reliability, ethics, and 
Fig. 4. Distribution of studies by country.
Fig. 5. General data analysis.
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 6 ---

data privacy collectively represented AI’s opaque and uncertain 
aspects.
• Memoing: Memos facilitated category refinement and theory 
development through constant comparison (Hossler & Scalese-Love, 
1989). Analyzing and sorting memos helped define the study’s cen-
tral phenomenon, ensuring methodological rigor (Strauss & Corbin, 
1990).
This iterative process continued until theoretical saturation was 
reached, leading to the development of a data-driven theory (see Ap-
pendix 3).
6.4. Validity and reliability
Grounded meta-analysis involves a thorough review of individual 
studies. In this research, over 180 studies were examined, with an in- 
depth analysis conducted on 45. Each paper was individually analyzed 
to identify factors influencing AI adoption, utilizing a grounded coding 
cycle to categorize and organize themes. Cross-case comparisons were 
performed at each coding stage to ensure consistency and accuracy, 
strengthening the study’s internal validity. This process required careful 
consideration of potential biases in coding and interpretation (Hossler & 
Scalese-Love, 1989). To mitigate these biases, a multidisciplinary 
research team of five experts—spanning education, computer science, 
systems engineering, and library science—met weekly over six months 
to analyze the data, discuss findings, and refine emerging themes, 
ensuring the study’s validity was reinforced by diverse perspectives. 
Moreover, ensuring consistency across analyses and enabling the repli-
cation of conclusions when reviewing the same data is essential for 
achieving reliability (Morgan, 1991; Yin & Heald, 1975). To ensure this, 
a thorough and transparent audit trail was created, documenting each 
stage of the analysis in detail for clarity and reproducibility (see 
Appendices 1, 2, and 3).
7. Findings
7.1. Framework analysis
One approach to evaluating educators’ technology adoption is 
through established models such as the Technology Acceptance Model 
(TAM), the Unified Theory of Acceptance and Use of Technology 
(UTAUT), Technological, Pedagogical, and Content Knowledge 
(TPACK), etc., or a combination of these frameworks. Of the 45 articles 
reviewed, 34 cited a framework, with TAM and UTAUT being the most 
common. Fig. 6 presents the frameworks and their frequencies, while 
Table 1 outlines the themes that emerged from each framework and 
study (see Fig. 7).
TAM: It was introduced by Davis (1986), is widely used in education 
to study technology adoption, emphasizing perceived ease of use (PEU) 
and perceived usefulness (PU). TAM2 (Venkatesh & Davis, 2000) 
expanded the model by incorporating factors such as voluntariness and 
job relevance, while TAM3 (Venkatesh & Bala, 2008) further refined it 
by categorizing influences like self-efficacy and anxiety under individual 
differences and social influence. This framework has been extensively 
applied in recent studies to examine AI adoption among various 
educator groups (PSTs, lecturers, etc.) and across different contexts 
(Appendix 1). For example, Zhang et al. (2024) explored AI adoption in 
rural-urban settings, while Güneyli et al. (2024) investigated its use 
across different school types and educational levels. Table 1 highlights 
the key themes emerging from these studies. Additionally, some 
research has integrated TAM with other frameworks to address specific 
contexts. For instance, Ofosu-Ampong (2024) combined TAM, TOE, and 
PPA (explained later in this section) to examine AI adoption factors in 
greater depth within their study.
UTAUT: This framework was developed by Venkatesh et al. (2003), 
expanded TAM by integrating eight acceptance theories and introducing 
key determinants: Performance Expectancy (PE), Effort Expectancy 
(EE), Social Influence, and Facilitating Conditions, which predict 
Behavioral Intention (BI) and actual usage behavior. UTAUT has been 
widely applied in recent research on AI acceptance in education, 
including HE (Chatterjee & Bhattacharjee, 2020) and schools (Molefi 
et al., 2024). UTAUT2 (Venkatesh et al., 2012) further expanded the 
model by adding Hedonic Motivation and Price Value. Two studies 
specifically utilized UTAUT2 to examine AI adoption in education: 
Cabero-Almenara et al. (2024) explored AI acceptance among 452 ed-
ucators in Ecuador, while Wijaya et al. (2024) investigated AI chatbot 
use among 322 PSTs.
TPACK: Developed by Mishra and Koehler (2006), it emphasizes the 
integration of Technology, Pedagogy, and Content Knowledge, essential 
for effective technology-enhanced teaching (Schmidt et al., 2009). It 
highlights the foundational knowledge educators need to transition from 
traditional methods to technology-driven education systems (Henderson 
& Corry, 2021). TPACK was applied by Sun, Tian, Sun, Fan, & Yang, 
2024 to 239 PSTs in China and by Celik (2023) to 700 educators in 
Turkey.
AI-e3: The AI-enabled Educational Ecosystem (AI-e3) framework, 
introduced by Wu et al. (2024), focuses on three core dimensions: 
technologies, pedagogies, and cultures. It emphasizes the importance of 
examining how AI technologies can contribute to sustainable develop-
ment goals. Wu et al. (2024) applied this framework to 4349 educators 
in China.
VAM: The Value-Based Adoption Model (VAM), developed by Kim 
et al. (2007), examines technology acceptance from a value maximiza-
tion perspective, considering users as service consumers who weigh 
costs and benefits in voluntary adoption. The model identifies four key 
factors influencing adoption: benefits (usefulness and enjoyment) and 
costs (technicality and perceived fees). Du and Gao (2022) applied this 
model in a study of 342 Greek teachers.
APT: The Academically Productive Talk (APT) framework, applied 
in Wang and Cheng (2021) during a study of Chinese PSTs, is rooted in 
theories emphasizing the role of social interaction in cognitive devel-
opment 
and 
has 
evolved 
alongside 
concepts 
from 
the 
computer-supported collaborative learning community (Dyke et al., 
2013).
DOI: Unlike TAM and UTAUT, which focus on individual adoption, 
Fig. 6. Frequency of frameworks used in articles.
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 7 ---

the Diffusion of Innovation (DOI) theory examines how new technolo-
gies spread within a social system, considering the broader context of 
adoption decisions (Almaiah et al., 2022). DOI identifies key fac-
tors—relative advantages, compatibility, observability, trialability, and 
perceived complexity—that influence an organization’s willingness to 
adopt emerging technologies (Rogers et al., 2014). It provides valuable 
insights into organizational dynamics influencing technology adoption 
and was applied in three studies listed in Table 1.
KCT: Knowledge Construction Theory (KCT) is based on the belief 
that AI aligns with constructivist learning theory, which highlights the 
importance of learners actively engaging in knowledge construction 
rather than passively absorbing information (Blikstein & Worsley, 
2016). Chou et al. (2024) applied this theory to examine educators’ 
adoption of AI-supported teaching.
The findings indicate that educators’ AI adoption is shaped by mul-
tiple factors. TAM remains the most widely used model, emphasizing 
PU, PEU, self-efficacy, Trust, BI, and Attitude, suggesting that AI adop-
tion largely depends on how accessible and beneficial educators 
perceive AI tools to be. However, UTAUT and UTAUT2 extend this 
perspective by incorporating social and institutional influences, such as 
data ethics, legal standards, and school policies, demonstrating that AI 
adoption is not solely an individual decision but is shaped by broader 
systemic factors. Studies applying TPACK underscore the role of peda-
gogical knowledge, PU, and self-efficacy, indicating that successful AI 
integration requires both technological accessibility and pedagogical 
confidence. Meanwhile, DOI, TOE + TAM + PPA, and AI-e3 highlight 
the importance of institutional policies, leadership, and resource avail-
ability, reinforcing that AI adoption is an organizational initiative rather 
than an isolated personal choice.
Across frameworks, ethical concerns, data security, transparency, 
and AI-driven decision-making consistently emerge as barriers, partic-
ularly in UTAUT and APT-based studies, affecting educators’ confidence 
in AI. While some models focus on individual perceptions (e.g., TAM, 
TPACK, KCT), others emphasize external and institutional factors (e.g., 
UTAUT, TOE, DOI, AI-e3, APT). Studies combining multiple frameworks 
suggest that AI adoption is a multi-dimensional process requiring a 
holistic approach that integrates personal, social, organizational, and 
ethical considerations.
Overall, the results suggest that AI adoption in education is a peda-
gogical and institutional transformation rather than merely a techno-
logical shift. While TAM remains dominant, models like UTAUT, DOI, 
and AI-e3 provide broader perspectives, incorporating social, institu-
tional, and ethical dimensions. No single framework fully explains AI 
adoption, highlighting the need for a comprehensive AI-related 
framework that encompasses all key adoption factors.
7.2. X-data paper findings
Four studies under review have utilized X data analysis to explore 
educators’ perceptions of AI through their tweets. For instance, Miya-
zaki et al. (2024), analyzed 3 million posts focusing on users’ occupa-
tions and AI usage, and found that educators, particularly professors, 
show significant interest in GAI. Also, Haque et al. (2022) analyzed 10, 
732 tweets and found that 52 % of users expressed positive views, 32 % 
negative, and 16 % neutral regarding the use of Chat GPT in education. 
Another study by Mamo et al. (2024), analyzing 3559 tweets, revealed 
that 40 % of the expressed sentiments were positive, 51 % were neutral, 
and 9 % were negative. The study revealed a spectrum of emotions 
among HE faculty toward Chat GPT, with trust and joy as the most 
common positive sentiments and fear and anger as the dominant nega-
tive emotions. Similarly, Lampropoulos et al. (2023) analyzed 2,282, 
289 tweets to explore early adopters’ perspectives on Chat GPT’s general 
and educational use, finding that education-related tweets exhibited 
stronger positive (trust, anticipation, and joy) and negative (fear and 
anger) sentiments compared to general tweets. This suggests that edu-
cators may be prone to impulsive decisions regarding new technologies, 
such as AI, potentially leading to irrational bans or mass acceptance 
without fully considering the risks.
The results of these studies show that educators generally express 
positive sentiments and perceptions toward AI tools and are increasingly 
using them for both professional tasks and casual interactions. This 
growing integration of AI into their work suggests that educators may 
help bridge the gap between AI and public understanding, particularly 
in the educational field. However, the presence of neutral and negative 
perceptions is noteworthy. The authors suggest that these sentiments 
stem from educators’ familiarity with AI, which can lead to either a 
better understanding (trust) and appreciation of its benefits and prac-
tical value (joy) or, conversely, feelings of fear, anger, resistance, or even 
outright neglect of its potential. Additionally, increasing their knowl-
edge and exposure to AI could help prevent ill-informed, irrational and 
impractical decision-making.
In examining these sentiments, social media data serves as a valu-
able, real-time source for capturing users’ perceptions and concerns 
across large populations, with many researchers suggesting it yields 
faster and potentially less biased insights than traditional methods such 
as interviews and surveys (Fischer et al., 2020; Fütterer et al., 2023; 
Stracqualursi & Agati, 2024; Zou et al., 2023). However, due to API 
access limitations introduced in 2023, there has been a decline in studies 
Adoption Factors
Tools
Trustworthiness
Compatibility
Usefulness/ Easiness
Impacts
Job Displacement
Misuse
Overreliance
Infrastructures
Social - Media
Institutional 
Support
Individual 
Aspects
Demographic
AI literacy
Stress/ Self-efficacy
Knowledge/ Beliefs
Fig. 7. Factors and sub-themes.
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 8 ---

focusing on specific professional groups, such as educators. Conse-
quently, the data itself may have limited generalizability to broader 
populations. In our study, findings from papers analyzing X-data were 
treated as supplementary evidence and triangulated with empirical 
studies to verify their consistency and reliability. They offered an 
additional perspective on educators’ perceptions rather than being given 
equal weight to peer-reviewed research. This approach enriched the 
evidence base, added valuable contextual depth, and strengthened the 
credibility of our conclusions while limiting the influence of 
platform-specific biases. Accordingly, we regarded these papers as 
enhanced evidence, selected for their potential to inform future 
research.
7.3. Grounded coding findings
The findings suggest that the adoption process is complex and shaped 
by multiple interconnected factors. After extracting the factors 
mentioned in the reviewed papers and applying a grounded coding 
cycle, the following themes emerged: Individual Aspects (Encompasses 
educator demographics, knowledge, attitudes, and beliefs about AI), 
Infrastructures (Highlights the influence and support of the social 
environment, media, and institutions), Tools (Addresses the AI tools’ 
usefulness, ease of use, and compatibility with other tools and envi-
ronments, as well as the opaque side of AIEd), and Impacts (Focuses on 
the effects of these technologies on educators’ job security, as well as the 
overreliance and potential misuse by both educators and students). The 
themes, subthemes and coding process are shown in appendix 3.
7.3.1. Individual aspects
Educators themselves play a critical role in AI adoption. Based on the 
reviewed studies, factors such as educators’ knowledge, AI literacy, 
beliefs and attitudes, openness to experience, background, emotions, 
and teaching strategies were identified and categorized into the 
following four themes.
Demographics: Recent research (e.g., Alshorman, 2024; Caber-
o-Almenara et al., 2024; Zhang et al., 2023) highlights that factors such 
as educators’ age, gender, and background experiences influence AI 
adoption. Woodruff et al. (2023) studied 4528 K-12 educators in the U.S. 
and found that despite overall positive attitudes toward AI, comfort with 
technology varied by gender and age. Female and younger educators 
generally felt more comfortable with technology than their male and 
older counterparts, even with similar training levels. Additionally, 
Zhang et al. (2024) found urban-rural differences significantly influence 
AI acceptance, with rural PSTs showing greater sensitivity to privacy 
and safety risks. However, Nja et al. (2023), in a study of 170 science 
teachers in Nigeria, reported that gender, age, and residence location did 
not influence AI adoption behavior or intent. Furthermore, Ofo-
su-Ampong (2024) found that 84 % of the 94 lecturers surveyed were 
open to AI adoption for their students, with teaching experience and AI 
attitude serving as key influencing factors. Yao and Abd Halim (2023)
also supported this, showing that a higher educational background en-
hances educators’ willingness to adopt AI by increasing both their ex-
pectations of AI performance and sensitivity to social influence 
regarding AI technology.
AI Literacy: A significant barrier to AI adoption is a lack of under-
standing and expertise. Many educators and administrators lack deep 
knowledge of AI technologies and their applications in HE, hindering 
effective implementation (Hazaimeh & Al-Ansi, 2024). Limited knowl-
edge, insufficient preparation, and unclear explanations contribute to 
distrust and underuse of AI tools (Alshorman, 2024; Cukurova et al., 
2023; Nazaretsky et al., 2022; Wang & Cheng, 2021). Ma and Lei (2024)
study of 359 PSTs in China highlights the pivotal role of AI literacy in 
educators’ acceptance of AI technologies. Educators must grasp the 
pedagogical benefits of AI-based tools to optimize their use in education. 
Additionally, Güneyli et al. (2024) identified practical knowledge as the 
most critical factor influencing AI adoption in teaching (importance 
Table 1 
Themes that emerged from each framework.
Framework
Themes
Studies
TAM
Usefulness, Perceived Ease of 
Use, Trust, AI- specific 
misconceptions, Myths, Fear, 
Self- efficacy, Attitudes, 
Behavioral Intentions, Stress 
and Anxiety, Years of Teaching 
Experience, Institutional 
Support, Perceived pedagogical 
affordances, Organizational 
Policies and Incentives, 
Perceived Complexity, 
Usability, Socio-Cultural 
Context, Perceived Privacy, 
Safety Risks, Functionally 
robust, User-friendly, 
Transparency, Teacher’s urban- 
rural differences, Age, Sex, 
Residence type, Expected 
Benefits, Practical Knowledge, 
Beliefs and Attitudes, 
Relatability, Theoretical 
Knowledge, AI Literacy, 
Creativity and Teacher Agency 
Concern
Al Darayseh, 2023; Alshorman, 
2024; Chocarro et al., 2023; 
Choi et al., 2023; Dehghani & 
Mashhadi, 2024; Güneyli et al., 
2024; Ma & Lei, 2024; 
Nazaretsky et al., 2022; Nja 
et al., 2023; Ofosu-Ampong, 
2024; Wang & Cheng, 2021; 
Yang & Appleget, 2024; Zhang 
et al., 2024
TAM3
Perceived Usefulness and 
Perceived Ease of Use
Zhang et al. (2023)
UTAUT
Data Ethics and Legal 
Standards, Perceived Risk, 
Effort Expectancy, Behavioral 
Intention, Performance 
Expectancy, Social Influence, 
Educational Background, 
School Support and Resources, 
Personal Innovativeness
Brandhofer & Tengler, 2024; 
Chatterjee & Bhattacharjee, 
2020; Helmiatin et al., 2024; 
Molefi et al., 2024; Shahid et al., 
2024; Yao & Abd Halim, 2023
UTAUT2
Age, Gender, Teaching 
Modality, Constructivist 
Pedagogical Beliefs, 
Performance Expectancy, Effort 
Expectancy, Technology 
Performance, Habit
Alhwaiti, 2023; 
Cabero-Almenara et al., 2024; 
Strzelecki et al., 2024; Wijaya 
et al., 2024
TPACK
Perceived Usefulness, 
Perceived Ease of Use, Self- 
Efficacy, AI-specific 
technological and pedagogical 
knowledge
Celik, 2023; Sun, Tian, Sun, Fan, 
& Yang, 2024
VAM
Effectiveness, Efficiency and 
Complexity
Du and Gao (2022)
AI-e3
School-level dimensional 
elements (dimensions of 
Technologies, Pedagogies, and 
Cultures)
Wu et al. (2024)
APT
Explanation and Trust
Wang and Cheng (2021)
DOI
Complexity, Compatibility, 
Trialability, Observability, 
Educator’s leadership 
behaviors and interpersonal 
skills, Anxiety
Almaiah et al., 2022; Bae et al., 
2024; Tyson & Sauers, 2021
KCT
Innovative intentions, 
Organizational innovation 
identification, AI-supported 
teaching behavior
Chou et al. (2024)
TOE + TAM 
+ PPA
Years of teaching experience, 
Institutional support, Attitude 
toward AI, Perceived 
pedagogy, Organizational 
Policies, Perceived Complexity 
and Usability, Socio-cultural 
context and Incentives
Ofosu-Ampong (2024)
TAM +
UTAUT
Perceived usefulness, social 
Influence, Personal 
innovativeness, Trust
Velli and Zafiropoulos (2024)
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 9 ---

weight of 0.450), followed by beliefs and attitudes.
Knowledge and Beliefs: Another major challenge is bridging the 
gap between theoretical and pedagogical perspectives and the practical 
application of AI-based tools in classrooms (Choi et al., 2023). According 
to the TPACK framework used in Celik (2023) study, greater familiarity 
with AI-based tools enhances educators’ understanding of their peda-
gogical benefits. Effective AI integration in education requires strong 
AI-specific technological pedagogical knowledge, which helps educators 
critically evaluate AI-driven decisions (Seufert et al., 2021). For 
instance, educators with constructivist pedagogical beliefs are more 
likely to adopt AI tools than those with transmissive orientations, 
demonstrating a positive correlation with AI integration in education 
(Cabero-Almenara et al., 2024; Choi et al., 2023). Additionally, educa-
tors’ leadership behavior and interpersonal skills are considered as key 
factors influencing AI adoption (Tyson & Sauers, 2021).
Stress and Self-efficacy: Educators’ self-efficacy positively in-
fluences their attitudes toward AI adoption (Al Darayseh, 2023; Nja 
et al., 2023; Wang & Cheng, 2021). Conversely, educators’ anxiety is a 
significant barrier to successful technology integration at all levels of 
teaching (Henderson & Corry, 2021). Among 452 PSTs studied, females 
were more likely than males to experience anxiety and be externally 
influenced in their intention to use AI tools in education (Zhang et al., 
2023). However, Wang and Cheng (2021) found a negative correlation 
between educators’ self-efficacy and anxiety, suggesting that enhancing 
self-efficacy could reduce AI-related anxiety in teaching.
7.3.2. Infrastructures
Several external factors shape educators’ adoption of AI. These fac-
tors form the broader category of Infrastructure, referring to founda-
tional resources such as technology access, institutional support, school 
culture and policies, and social media influence (e.g., fears and mis-
conceptions). They are further divided into two sub-categories:
Institutional Support: School-level dimensions, including technol-
ogy, pedagogy, culture, support, and resources, play a critical role in 
facilitating AI adoption (Al-Mughairi & Bhaskar, 2024; Alshorman, 
2024; Chou et al., 2024; Molefi et al., 2024; Ofosu-Ampong, 2024; Wu 
et al., 2024), while institutional barriers and inadequate training are 
primary obstacles (Gupta & Bhaskar, 2020). Factors such as perceived 
pedagogical benefits, organizational policies, and the broader 
socio-cultural context also shape AI adoption (Ofosu-Ampong, 2024). 
Brandhofer 
and 
Tengler 
(2024)
highlight 
the 
need 
for 
school-type-specific professional development opportunities. Addition-
ally, integrating AI in HE requires significant funding and technical 
expertise. Many institutions struggle to allocate the necessary funds and 
skilled personnel for successful AI integration (Hazaimeh & Al-Ansi, 
2024).
Social Environment and Media: Media coverage significantly 
shapes educators’ perceptions of AI, often amplifying fears of job 
displacement due to a limited understanding of AI’s potential to enhance 
teaching and learning (Luckin & Holmes, 2016). Additionally, social 
influence plays a crucial role, as Velli and Zafiropoulos (2024) found it 
significantly impacted the perceptions of 342 Greek educators. 
AI-specific misconceptions and a general lack of understanding of AIEd 
further exacerbate these concerns (Cukurova et al., 2023). Wang and 
Cheng (2021) emphasized that providing clear explanations can build 
trust and encourage technology acceptance among educators.
7.3.3. Tools
Based on the reviewed papers, the opaque aspects of AI—such as 
bias, hallucinations, data ethics, privacy concerns, legal standards, and 
potential misuse—impact educators’ trust. The more an AI tool is 
perceived as reliable, user-friendly, accessible, and helpful, the more 
likely educators are to adopt it. These factors are elaborated in the 
following sub-themes:
Easiness and Usefulness: When selecting AI tools for classroom use, 
educators and researchers often consider various factors, with PU, PEU, 
and PE being among the most critical (Chocarro et al., 2023; Helmiatin 
et al., 2024; Ma & Lei, 2024; Molefi et al., 2024; Sun, Tian, Sun, Fan, & 
Yang, 2024; Yao & Abd Halim, 2023).These factors are mostly based on 
TPACK, UTAUT and TAM frameworks that were discussed in previous 
sections. In Zhang et al. (2023), PU and EU factors significantly influ-
enced intentions to adopt AI technologies, with PU having a more sub-
stantial impact than EU. However, Choi et al. (2023) found that the EU 
was the most influential factor in predicting acceptance. Wijaya et al. 
(2024) studied 322 PSTs in China, revealing that PE had influence on 
their behavior intention to use AI chatbots. Wang and Cheng (2021)
highlighted that educators’ self-efficacy positively influenced PU 
through EU. The adoption process is hindered when users encounter 
challenges in understanding and navigating complex systems (Almaiah 
et al., 2022).
Compatibility: Existing educational platforms may face difficulties 
in adopting AI tools. Issues such as compatibility and the need for 
seamless integration with legacy systems often pose significant hurdles 
(Hazaimeh & Al-Ansi, 2024). Adopters are more inclined to embrace 
innovation when it aligns with their daily lives and routines (Almaiah 
et al., 2022). For example, how well AI tools are adapted to support local 
languages and cultural contexts also affects AI acceptance among edu-
cators (Ofosu-Ampong, 2024). Also, trialability significantly influences 
AI adoption by allowing hands-on experience, while observability 
further encourages adoption as users can clearly see its benefits in 
practice (Almaiah et al., 2022).
Trustworthiness: Trust and reliability are key factors influencing 
educators’ use of AI in teaching across various studies (e.g., Choi et al., 
2023; Güneyli et al., 2024). Conversely, privacy concerns and uncer-
tainty surrounding AI ethics and data collection are consistently cited as 
major challenges to AI adoption (Alshorman, 2024; Hazaimeh & 
Al-Ansi, 2024; Nazaretsky et al., 2022; Ofosu-Ampong, 2024). A survey 
of 468 educators in Brandhofer and Tengler (2024) study revealed that 
while educators are generally optimistic about AI’s potential, concerns 
about data ethics and legal standards persist. The study revealed a strong 
link between trust in AI and its adoption, as educators who view AI tools 
as trustworthy are more likely to integrate them into their teaching. 
Similar concerns were evident in K-12 education in Nazaretsky et al. 
(2022) and among 483 PSTs in China (Zhang et al., 2024), where lack of 
trust, negative attitudes, and safety risks significantly impacted educa-
tors’ confidence in AI. Furthermore, AI systems are prone to bias, 
potentially leading to significant challenges in education. Ensuring that 
AI algorithms used in HE are fair and do not perpetuate inequalities is 
critical (Hazaimeh & Al-Ansi, 2024). AI bias and fairness play a key role 
in shaping educators’ attitudes toward AI (Mamo et al., 2024; Ofo-
su-Ampong, 2024).
7.3.4. Impacts
AI, alongside its many opportunities, also brings several negative 
impacts. The reviewed papers highlight key concerns, including reduced 
human interaction, overreliance on technology, unemployment, 
plagiarism, threats to writing and assessment practices, disruption, and 
the spread of disinformation—factors categorized under the most dis-
cussed sub-themes below. These negative impacts can discourage edu-
cators from adopting AI and may amplify negative perceptions, such as 
AI anxiety and related apprehensions.
Job Displacement: The introduction of AIEd raises concerns about 
its potential impact on employment, particularly in roles that could be 
automated by AI systems (Hazaimeh & Al-Ansi, 2024). Job displacement 
and unemployment has been identified as key factors influencing AI 
adoption (Mamo et al., 2024; Ofosu-Ampong, 2024). Educators may also 
hesitate to adopt AI technologies, viewing its advanced capabilities as a 
potential threat to traditional teaching roles (Al-Mughairi & Bhaskar, 
2024; Hazaimeh & Al-Ansi, 2024).
Over-reliance: The use of GAI in teaching has reduced collaboration 
and opportunities for educator engagement with peers, as educators 
may now turn to AI for assistance instead of colleagues (Al-Mughairi & 
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 10 ---

Bhaskar, 2024). Additionally, concerns persist regarding AI’s impact on 
critical thinking, writing skills, assessment challenges, and the risk of 
overreliance on AI platforms (Al-Mughairi & Bhaskar, 2024; Mamo 
et al., 2024). There is also growing apprehension that students’ reliance 
on AI for tasks like assignments may hinder their learning process by 
discouraging independent idea generation.
Misuse: The report by Haque et al. (2022) found some users were 
worried about AI tools being misused, especially in the education sector. 
These apprehensions stem from GAI’s ability to generate diverse texts 
quickly and efficiently from minimal prompts, raising fears that students 
may rely on AI instead of developing their own writing and critical 
thinking skills (Mamo et al., 2024). Additional concerns include diffi-
culties in detecting AI-generated plagiarism in student assignments and 
the shallow, surface-level responses these tools may produce for com-
plex research questions (Haque et al., 2022). Mamo et al. (2024) further 
highlight claims that GAI tools could undermine traditional writing 
practices, while Al-Mughairi & Bhaskar, 2024 and Ghimire et al. (2024)
note that educators sometimes fail to verify AI-generated content, 
leading to a lack of confidence in detecting GAI. Recognizing these 
challenges, educators emphasize shifting their roles from sole knowl-
edge providers to facilitators and mentors, guiding students to engage 
critically with AI tools rather than relying on them passively 
(Al-Mughairi & Bhaskar, 2024).
8. Discussion
8.1. Summary of key findings
The objective of this study was to identify the factors influencing AI 
adoption among educators. A total of 45 articles examining educators’ 
adoption, perceptions, and acceptance of AI across different global 
contexts were analyzed, with the majority being quantitative (n = 32). 
Publications on educators’ AI adoption increased notably from 2 in 2020 
to 25 in 2024, with China (n = 10) and the USA (n = 5) leading among 
23 countries. Given the diverse methodologies employed in these 
studies, a grounded meta-analysis framework was chosen to identify 
underlying factors as “grounded codes” present in each study. Addi-
tionally, we analyzed the sentiments expressed in four X-data papers and 
examined the technological and theoretical frameworks used in other 
studies. The analysis of X-data papers revealed a generally positive 
sentiment of AI use; however, some held neutral or negative perceptions. 
The potential reason for these sentiments can be explained by educators’ 
familiarity level of AI tools, which can foster trust or lead to fear and 
resistance as mentioned in Lampropoulos et al. (2023) and Miyazaki 
et al. (2024). These findings highlight the value of developing AI literacy 
among educators. Greater AI knowledge, literacy and exposure can help 
educators make informed decisions, engage with AI tools more critically, 
and use them with confidence and responsibility (Hollands & Breazeal, 
2024; Walter, 2024).
The result of grounded coding of studies’ abstract, finding, and result 
sections revealed four factors including Individual aspects, Infrastruc-
ture, Tools, and Impacts. The Individual aspects refer to the influence of 
educators’ demographics, AI literacy, beliefs, and self-efficacy on their 
AI adoption. Infrastructure refers to external factors that influence ed-
ucators, such as institutional support, resources, or social and media 
influences. The Tools themselves were also identified as a factor. Their 
usefulness, ease of use, compatibility, and black-box side of that like 
potential bias, trust and reliability all impact whether educators choose 
to adopt them. Lastly, the Impacts of AI tools on both students and ed-
ucators were highlighted. Issues such as overreliance, job security, and 
potential misuse, like plagiarism, were among the concerns revealed in 
these studies.
Among these four factors, three—Individual Aspects, Tools, and 
Infrastructure—were also identified through framework analysis. 
Among 41 studies, 34 referenced specific frameworks, with TAM and 
UTAUT being the most common, highlighting aspects like PU, PEU, self- 
efficacy, Trust, and BI. Other frameworks also added more aspects to 
consider. For example, utilizing the TPACK (Celik, 2023; Sun, Tian, Sun, 
Fan, & Yang, 2024) along with KTC framework (Chou et al., 2024) 
highlighted the importance of educator’s technological and pedagogical 
knowledge, constructivist attitude as well as self-efficacy (aligning with 
Individual aspects). The AI-e3 framework (Wu et al., 2024) along with 
APT framework emphasized the role of explanation and SI in educators’ 
AI adoption and emphasized school-level elements (aligning with 
Infrastructure). VAM theory (Du & Gao, 2022) and DOI framework 
(Almaiah et al., 2022) revealed efficiency, trialability, observability, and 
compatibility (aligning with Tools). Some papers (Ofosu-Ampong, 
2024) also attempted to combine multiple frameworks—TAM, TOE, and 
PPA— and get the combination aspects like teaching experience, insti-
tutional support, attitudes, pedagogical affordances, organizational 
policies, incentives, usability, complexity, and socio-cultural context.
8.2. Comparison with Ed Tech
8.2.1. Alignment with prior research
Prior meta-analyses on general educational technology (Ed Tech) 
adoption—such as Grani´c (2022) and Feng et al. (2025)—have identi-
fied foundational predictors, including user aspects, self-efficacy, sub-
jective norms, enjoyment, and system complexity (Grani´c, 2022). They 
also highlight constructs such as PE, EE, Social Influence, and Facili-
tating Conditions (Feng et al., 2025). In contrast, our findings point to a 
set of factors that are uniquely salient in the context of AI adoption. 
Specifically, our four themes—Individual Aspects, Infrastructure, Tools, 
and Impacts—extend beyond the traditional constructs by addressing 
the emerging complexities of generative and algorithmic AIEd. For 
example, while user aspects and PE overlap conceptually with our In-
dividual Aspects, our study highlights deeper concerns tied to educators’ 
beliefs, ethical uncertainties, and professional identity in response to 
AI’s disruptive capabilities. Moreover, our Tools theme addresses not 
only usability and compatibility, as noted in past frameworks, but also 
uniquely AI-related concerns such as opacity, trustworthiness, and the 
“black box” effect—dimensions absent from conventional Ed Tech. 
Finally, the Impacts category introduces concerns around job displace-
ment, overreliance, and student misuse, which are rarely discussed in 
earlier technology adoption studies. This comparison underscores the 
novelty of our findings and the need for AI-specific frameworks to fully 
capture the social, ethical, and pedagogical implications of AIEd.
8.2.2. Ethical and operational complexities
AI-based tools in education pose more intricate ethical and opera-
tional challenges than traditional Ed Tech such as learning management 
systems (LMS) —software that delivers, organizes, and tracks online 
learning (Firat, 2023b). Privacy concerns are heightened due to AI’s 
dependence on extensive user data, including behavioral indicators and 
potentially sensitive or confidential inputs, whereas conventional tools 
like LMSs typically handle more limited datasets (e.g., course enroll-
ment, grades) and operate within predefined data boundaries (e.g., 
Al-Mughairi & Bhaskar, 2024; Firat, 2023b; Whalen & Mouza, 2023). 
The integrity of academic work is particularly vulnerable with AI, as 
generative tools can produce original-seeming yet untraceable content, 
complicating authorship attribution and enabling sophisticated forms of 
plagiarism—issues less prevalent in standard Ed Tech systems (e.g., 
Cotton et al., 2024; Mao et al., 2024). Trust in AI outputs is further 
undermined by hallucinations and the reproduction of biased content, 
risks largely absent in traditional, non-generative digital tools (e.g., 
Mamo et al., 2024; Warschauer et al., 2023). Moreover, student over-
reliance on GAI may inhibit critical thinking and self-directed learning, 
especially when used without appropriate pedagogical scaffolding (e.g., 
Ismail et al., 2024; Qadir, 2023). In contrast, traditional technologies 
tend to offer greater transparency, predictability, and lower ethical 
complexity. On the other hand, AI tools can support educators in ways 
that traditional technologies cannot, assisting with tasks ranging from 
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 11 ---

lesson planning and content creation to grading, feedback, and even 
professional growth (e.g., Celik et al., 2022; Chen et al., 2020).
8.2.3. Educator readiness and capacity
However, educator readiness remains uneven, with many instructors 
lacking the training and institutional support necessary for ethical and 
effective AI integration (e.g., Celik et al., 2022; Kaplan-Rakowski et al., 
2023). As AI rapidly evolves, introducing new ethical challenges and 
opportunities, it becomes essential for educators to develop the knowl-
edge and skills needed to critically assess AIEd. Educators will continue 
to shape the future of teaching by deciding how to integrate AI-powered 
tools (Pedro et al., 2019). Those who are well-informed and proficient in 
AI can mitigate its drawbacks and negative impacts—such as over-
reliance and misuse—by guiding students to use these technologies 
effectively and responsibly. Educators who possess leadership qualities, 
adopt a more constructivist approach, and demonstrate higher 
self-efficacy, tend to have more positive perceptions of AI and adopt it 
more easily, as evidenced in several studies (e.g., Choi et al., 2023; 
Tyson & Sauers, 2021; Wang & Cheng, 2021). Achieving this necessi-
tates a robust infrastructure, encompassing institutional support, 
adequate resources, comprehensive training programs, constructive 
social media influences, and well-defined policies to facilitate AI adop-
tion. The more AI-literate teachers are, the more trust they exhibit—and 
the less anxiety they experience—toward these tools (e.g., Cukurova 
et al., 2023; Nazaretsky et al., 2022; Wang & Cheng, 2021).
8.3. Considerations for AI researchers and developers
In addition, the findings underline the need for AI companies to be 
transparent about the limitations and potential dark sides of AI tools. 
When educators are concerned about what happens to their or their 
students’ data, whether AI responses are biased or accurate, or when 
they perceive AI as a black box of uncertainty, they cannot fully trust 
these tools. To maintain trust in education, educational AI tools must 
give users control over their data, ensuring secure collection, storage, 
and sharing (Huang, 2023; Nguyen et al., 2023). Additionally, AI tools 
should be customized to fit educators’ specific needs and teaching en-
vironments. Each educational AI tool should be purposefully designed 
for distinct educational settings, as educators often remain skeptical of 
companies that promote technology as a universal solution to educa-
tional challenges (Stockman & Nottingham, 2022). Developers should 
also prioritize the tool’s ease of use, usefulness, compatibility, and 
trustworthiness.
The study also pinpoints the fact that although the mentioned 
frameworks were employed, most studies relied heavily on the most 
common frameworks originally designed for general technology adop-
tion rather than AI-specific contexts. This raises a critical question: What 
about factors unique to AI technologies? While these frameworks pro-
vide valuable insights, they may lack the precision needed to address the 
distinctive ethical, pedagogical, institutional, and technical challenges 
and opportunities AI presents in education, such as algorithmic trans-
parency, ethical complexities, dynamic learning capabilities, and AI tool 
evaluation. Also, there are still questions: Can educators understand AI 
decisions? How well does AI fit into existing teaching practices? How do 
educators interact with AI? Moreover, educators’ responses may be 
shaped by these frameworks; in other words, each study analyzed and 
identified factors based on the framework’s predefined elements. This 
raises another question: If these frameworks are based on general 
technology adoption, would the findings differ if AI-specific education 
frameworks were used instead?
Moreover, the results of the X data paper analysis were consistent 
with the other findings, as they also reflected users’ perceptions of uti-
lizing AI in education and highlighted the most frequently discussed 
topics on the platform. Studies such as Mamo et al. (2024) and Haque 
et al. (2022) identified concerns like job displacement, trustworthiness 
—including hallucinations and bias—and the misuse of AI as dominant 
themes in user discussions, which align closely with the findings of other 
papers used in this study. This suggests that social media data can serve 
as a valuable source for understanding users’ perceptions, concerns, and 
attitudes at scale and in real time (Fütterer et al., 2023; Stracqualursi & 
Agati, 2024; Zou et al., 2023). However, it is worth noting some limi-
tations. Most users on platforms like X tend to be younger and more 
tech-savvy— about 93 % of X users worldwide are under the age of 50 
(Statista, 2025), and studies by Malik et al. (2015) and Yildiz et al. 
(2017) confirm this trend—which may result in perspectives that are not 
representative of the general population or typical educators. In addi-
tion, due to recent API limitations, access to detailed demographic in-
formation (e.g., occupation, location) is no longer available, and there 
are still a limited number of X-related studies in this area. Therefore, the 
generalizability of such data is debatable. Nonetheless, emerging 
decentralized platforms like Bluesky may offer opportunities to explore 
these topics using less biased data sources (Quelle & Bovet, 2025). While 
the insights from social media are preliminary, they remain valuable, 
and future text-mining research can serve as a supplementary and 
complementary data source.
8.4. Strengths of study
Grounded meta-analysis offers a rigorous approach to identifying 
key factors influencing educators’ AI adoption, regardless of the 
frameworks or research methods used in original studies. Additionally, 
social media data provides large-scale insights, reducing interviewer 
bias and capturing organic, unbiased responses (Fütterer et al., 2023; 
Fischer et al., 2020; Zou et al., 2023). Integrating it with traditional 
methods enhances data diversity and strengthens the overall under-
standing of AI adoption in education.
8.5. Implications
This study has the potential to guide researchers exploring AI 
adoption topics in selecting more effective approaches and frameworks. 
By understanding the key factors that influence educators’ decisions, 
researchers can design interviews or questionnaires that are more tar-
geted and specific. Additionally, the findings can assist AI tool de-
velopers in addressing educators’ concerns and designing tools that 
align more closely with their needs and expectations, fostering greater 
trust and adoption in educational settings. Furthermore, this study can 
help institutions identify the barriers preventing educators from 
adopting AI technologies by highlighting the key psychological, peda-
gogical, and infrastructural factors that influence adoption. These in-
sights can guide institutions in designing more targeted interventions. 
Rather than relying solely on one-time workshops, institutions should 
build comprehensive support systems that include ongoing professional 
development, clear policies, and access to appropriate tools. Findings 
from this study also underscore the need to prepare educators for the 
evolving AI–teacher relationship. Teachers must adopt a constructivist 
mindset, manage AI-related anxiety, and strengthen their AI literacy and 
self-efficacy. This study provides evidence to inform PST education, 
encouraging programs to equip future educators with the skills to crit-
ically evaluate AI tools, teach students how to use them responsibly as 
learning assistants, and design assignments that promote innovation 
over misuse. Ultimately, by addressing these areas, institutions can 
foster a pedagogically sound, supportive environment that empowers 
educators to confidently and effectively integrate AI into their teaching 
practices.
8.6. Limitations
Analyzing studies using X data, we found few focused on educators’ 
perspectives, likely due to strict API regulations limiting access to user 
information and tweet volume. Additionally, social media analysis lacks 
depth, excludes non-social media users, and is susceptible to 
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 12 ---

misinformation, fake accounts, and polarized views. Given these limi-
tations, it may need to be combined with interviews and surveys to 
ensure a more balanced and comprehensive analysis of educators’ AI 
adoption. This study also primarily relied on Web of Science, Google 
Scholar, and ERIC, trusted academic sources; however, excluding other 
databases and journals may have narrowed the scope of included 
studies. Furthermore, the use of narrow search terms may have over-
looked relevant studies that used alternative terminology or phrasing.
8.7. Recommendations
Future research should develop AI-specific adoption frameworks 
beyond general technology models, addressing individual aspects (e.g., 
educators’ competencies), infrastructure (e.g., institutional and social 
support), tools (e.g., transparency, complexity), and broader impacts on 
education. Longitudinal studies are needed to track shifts in AI adoption, 
examining institutional support, evolving AI capabilities, and profes-
sional development. Moreover, integrating social media sentiment 
analysis with traditional methods can offer a comprehensive view while 
mitigating bias and misinformation. Expanding data collection across 
platforms may broaden educator perspectives, while future studies 
should go beyond perceptions to explore educators’ needs and expec-
tations for AI adoption. By diversifying methodologies and AI-specific 
frameworks, research can provide actionable insights for policy-
makers, educators, and developers, ensuring responsible and effective AI 
adoption.
9. Conclusion
Although numerous studies have examined educator’s AI adoption, 
most have been grounded in general technology-focused frameworks. 
While these models provide valuable insights, they often fail to fully 
capture the complexities of AI adoption in education. A broader syn-
thesis of these findings underscores that AI adoption is not solely an 
individual decision but a systemic transformation, requiring a collective 
effort from institutions, policymakers, social media platforms, and AI 
companies. By offering adequate resources, professional support, and 
transparent policies, these stakeholders can play a crucial role in 
enhancing educators’ AI literacy, mitigating risks, and fostering greater 
trust in AI technologies. Institutions must provide structured training, 
clear ethical guidelines, and open discussions on AI’s role in education, 
while AI developers must prioritize explainability, user control, and 
adaptability to different educational contexts. Ultimately, AI adoption in 
education is more than a technological shift; it represents a broader 
pedagogical and institutional transformation. To ensure responsible and 
sustainable integration, future research must prioritize the development 
of AI-specific adoption frameworks that accurately reflect the realities of 
teaching, learning, and ethical responsibility in AI-driven environments.
CRedi T authorship contribution statement
Rana Taheri: Writing – original draft, Resources, Methodology, 
Investigation, Formal analysis, Data curation, Conceptualization. Neda 
Nazemi: Writing – review & editing, Validation, Methodology, Formal 
analysis, Data curation, Conceptualization. Sarah E. Pennington: 
Writing – review & editing, Validation, Methodology, Data curation. 
Jason A. Clark: Writing – review & editing, Validation, Data curation. 
Faraz Dadgostari: Writing – review & editing, Visualization, Supervi-
sion, Resources, Methodology, Data curation.
Statements and declarations
The authors have no relevant financial interests to disclose.
Statements and declarations
There is no potential conflict of interest in this study.
Declaration of generative AI and AI-assisted technologies in the 
writing process
During the preparation of this work the authors used Chat GPT for 
copy editing. After using this tool, the authors reviewed and edited the 
content as needed and take full responsibility for the content of the 
publication.
Declaration of competing interest
The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper.
List of Abbreviations and Acronyms
AI
Artificial Intelligence
AIEd
Artificial Intelligence in Education
API
Application Programming Interface
APT
Academically Productive Talk
BI
Behavioral Intention
DOI
Diffusion of Innovation
Ed Tech
Educational Technology
EE
Effort Expectancy
GAI
Generative Artificial Intelligence
HE
Higher Education
KCT
Knowledge Construction Theory
LMS
Learning Management System
PE
Performance Expectancy
PEU
Perceived Ease of Use
PSTs
Pre-Service Teachers
PU
Perceived Usefulness
TAM
Technology Acceptance Model
TPACK
Technological, Pedagogical, and Content Knowledge
UTAUT
Unified Theory of Acceptance and Use of Technology
X
X platform (formerly Twitter)
Appendix A. Supplementary data
Supplementary data to this article can be found online at https://doi. 
org/10.1016/j.caeai.2025.100464.
Data availability
The authors confirm that all data generated or analyzed during this 
study are included in this published article, specifically in appendices 1 
to 3.
References
Adiguzel, T., Kaya, M. H., & Cansu, F. K. (2023). Revolutionizing education with AI: 
Exploring the transformative potential of Chat GPT. Contemporary Educational 
Technology, 15(3).
Ahmad, S. F., Han, H., Alam, M. M., Rehmat, M., Irshad, M., Arra˜no-Mu˜noz, M., & Ariza- 
Montes, A. (2023). Impact of artificial intelligence on human loss in decision 
making, laziness and safety in education. Humanities and Social Sciences 
Communications, 10(1), 1–14.
Akmese, O. F., Kor, H., & Erbay, H. (2021). Use of machine learning techniques for the 
forecast of student achievement in higher education. Information Technologies and 
Learning Tools, 82(2), 297–311. https://doi.org/10.33407/itlt.v82i2.4178
Al Darayseh, A. (2023). Acceptance of artificial intelligence in teaching science: Science 
teachers’ perspective. Computers and Education: Artificial Intelligence, 4, Article 
100132. https://doi.org/10.1016/j.caeai.2023.100132
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 13 ---

Al-Momani, A. A. M., & Ramayah, T. (2024). Adoption of artificial intelligence in 
education: A systematic literature review. Current and Future Trends on Intelligent 
Technology Adoption, 2, 117–135.
Al Afnan, M. A., Dishari, S., Jovic, M., & Lomidze, K. (2023). Chatgpt as an educational 
tool: Opportunities, challenges, and recommendations for communication, business 
writing, and composition courses. Journal of Artificial Intelligence and Technology, 3 
(2), 60–68.
Aldeman, N. L. S., Aita, K., Machado, V. P., da Mata Sousa, L. C. D., Coelho, A. G. B., da 
Silva, A. S., Mendes, A. P. D., Neres, F. J. D., & do Monte, S. J. H. (2021). Smartpath 
(k): A platform for teaching glomerulopathies using machine learning. BMC Medical 
Education, 21(1), 248. https://doi.org/10.1186/s12909-021-02680-1
Alhwaiti, M. (2023). Acceptance of artificial intelligence application in the post-covid 
ERA and its impact on faculty members’ occupational well-being and teaching self 
efficacy: A path analysis using the utaut 2 model. Applied Artificial Intelligence, 37(1), 
Article 2175110.
Almaiah, M. A., Alfaisal, R., Salloum, S. A., Hajjej, F., Shishakly, R., Lutfi, A., … Al- 
Maroof, R. S. (2022). Measuring institutions’ adoption of artificial intelligence 
applications in online learning environments: Integrating the innovation diffusion 
theory with technology adoption rate. Electronics, 11(20), 3291.
Al-Mughairi, H., & Bhaskar, P. (2024). Exploring the factors affecting the adoption AI 
techniques in higher education: Insights from teachers’ perspectives on Chat GPT. 
Journal of Research in Innovative Teaching & Learning. https://doi.org/10.1108/JRIT- 
09-2023-0129
Alshorman, S. M. (2024). The readiness to use AI in teaching science: Science teacher’s 
perspective. Journal of Baltic Science Education, 23(3), 432–448.
Alwaqdani, M. (2024). Investigating teachers’ perceptions of artificial intelligence tools 
in education: Potential and difficulties. Education and Information Technologies, 1–19.
Antonenko, P., & Abramowitz, B. (2023). In-service teachers’(mis) conceptions of 
artificial intelligence in K-12 science education. Journal of Research on Technology in 
Education, 55(1), 64–78.
Arif, T. B., Munaf, U., & Ul-Haque, I. (2023). The future of medical education and 
research: Is Chat GPT a blessing or blight in disguise? Medical Education Online, 28(1), 
Article 2181052.
Asadi, M., & Taheri, R. (2024). Enhancing peer assessment and engagement in online 
IELTS writing course through a teacher’s multifaceted approach and AI integration. 
Technology Assisted Language Education, 2(2), 94–117.
Astya, P. (2017). Sentiment analysis: Approaches and open issues. In 2017 international 
conference on computing, communication and automation (ICCCA) (pp. 154–158). 
IEEE. 
Bae, H., Hur, J., Park, J., Choi, G. W., & Moon, J. (2024). Pre-service teachers’ dual 
perspectives on generative AI: Benefits, challenges, and integration into their 
teaching and learning. Online Learning, 28(3), 131–156.
Baek, T. H., & Kim, M. (2023). Is Chat GPT scary good? How user motivations affect 
creepiness and trust in generative artificial intelligence. Telematics and Informatics, 
83, Article 102030.
Bender, E. M., Gebru, T., Mc Millan-Major, A., & Shmitchell, S. (2021). On the dangers of 
stochastic parrots: Can language models be too big?. In Proceedings of the 2021 ACM 
conference on fairness, accountability, and transparency (pp. 610–623).
Berendt, B., Littlejohn, A., & Blakemore, M. (2020). AI in education: Learner choice and 
fundamental rights. Learning, Media and Technology, 45(3), 312–324.
Blikstein, P., & Worsley, M. (2016). Multimodal learning analytics and education data 
mining: Using computational technologies to measure complex learning tasks. 
Journal of Learning Analytics, 3(2), 220–238.
Brandhofer, G., & Tengler, K. (2024). Acceptance of artificial intelligence in education: 
Opportunities, concerns and need for action. Advances in Mobile Learning Educational 
Research, 4(2), 1105–1113.
Cabero-Almenara, J., Palacios-Rodríguez, A., Loaiza-Aguirre, M. I., & Rivas- 
Manzano, M. D. R. D. (2024). Acceptance of educational artificial intelligence by 
teachers and its relationship with some variables and pedagogical beliefs. Education 
Sciences, 14(7), 740.
Cao, L., & Dede, C. (2023). Navigating a world of generative AI: Suggestions for 
educators. The Next Level Lab at Harvard Graduate School of Education, 5(2).
Carpenter, J., Tani, T., Morrison, S., & Keane, J. (2022). Exploring the landscape of 
educator professional activity on Twitter: An analysis of 16 education-related 
Twitter hashtags. Professional Development in Education, 48(5), 784–805.
Celik, I. (2023). Towards Intelligent-TPACK: An empirical study on teachers’ professional 
knowledge to ethically integrate artificial intelligence (AI)-based tools into 
education. Computers in Human Behavior, 138, Article 107468.
Celik, I., Dindar, M., Muukkonen, H., & J¨arvel¨a, S. (2022). The promises and challenges 
of artificial intelligence for teachers: A systematic review of research. Tech Trends, 66 
(4), 616–630.
Chan, K. S., & Zary, N. (2019). Applications and challenges of implementing artificial 
intelligence in medical education: Integrative review. JMIR medical education, 5(1), 
Article e13930. https://doi.org/10.2196/13930
Chatterjee, S., & Bhattacharjee, K. K. (2020). Adoption of artificial intelligence in higher 
education: A quantitative analysis using structural equation modelling. Education 
and Information Technologies, 25, 3443–3463.
Chen, L., Chen, P., & Lin, Z. (2020). Artificial intelligence in education: A review. LEEE 
Access, 8, 75264–75278.
Chiu, W. K. (2021). Pedagogy of emerging technologies in chemical education during the 
era of digitalization and artificial intelligence: A systematic review. Education 
Sciences, 11(11), 709.
Chiu, T. K., & Chai, C. S. (2020). Sustainable curriculum planning for artificial 
intelligence education: A self-determination theory perspective. Sustainability, 12 
(14), 5568.
Chiu, T. K., Xia, Q., Zhou, X., Chai, C. S., & Cheng, M. (2023). Systematic literature 
review on opportunities, challenges, and future research recommendations of 
artificial intelligence in education. Computers and Education: Artificial Intelligence, 4, 
Article 100118.
Chocarro, R., Corti˜nas, M., & Marcos-Mat´as, G. (2023). Teachers’ attitudes towards 
chatbots in education: A technology acceptance model approach considering the 
effect of social language, bot proactiveness, and users’ characteristics. Educational 
Studies, 49(2), 295–313.
Choi, S., Jang, Y., & Kim, H. (2023). Influence of pedagogical beliefs and perceived trust 
on teachers’ acceptance of educational artificial intelligence tools. International 
Journal of Human-Computer Interaction, 39(4), 910–922.
Chou, C. M., Shen, T. C., Shen, T. C., & Shen, C. H. (2024). Teachers’ adoption of AI- 
supported teaching behavior and its influencing factors: Using structural equation 
modeling. Journal of Computers in Education, 1–44.
Chounta, I. A., Bardone, E., Raudsep, A., & Pedaste, M. (2022). Exploring teachers’ 
perceptions of artificial intelligence as a tool to support their practice in Estonian K- 
12 education. International Journal of Artificial Intelligence in Education, 32(3), 
725–755.
Cotton, D. R., Cotton, P. A., & Shipway, J. R. (2024). Chatting and cheating: Ensuring 
academic integrity in the era of Chat GPT. Innovations in Education & Teaching 
International, 61(2), 228–239.
Cukurova, M., Miao, X., & Brooker, R. (2023). Adoption of artificial intelligence in 
schools: Unveiling factors influencing teachers’ engagement. In International 
Conference on artificial intelligence in education (pp. 151–163). Cham: Springer Nature 
Switzerland. 
Dave, M., & Patel, N. (2023). Artificial intelligence in healthcare and education. British 
Dental Journal, 234(10), 761–764.
Davis, F. D. (1986). A technology acceptance model for empirically testing new end-user 
information systems. Theory and results. Massachusetts Institute of Technology. 
Dehghani, H., & Mashhadi, A. (2024). Exploring Iranian English as a foreign language 
teachers’ acceptance of Chat GPT in English language teaching: Extending the 
technology acceptance model. Education and Information Technologies, 29(15), 
19813–19834.
Du, Y., & Gao, H. (2022). Determinants affecting teachers’ adoption of AI-based 
applications in EFL context: An analysis of analytic hierarchy process. Education and 
Information Technologies, 27(7), 9357–9384.
Dyke, G., Howley, I., Adamson, D., Kumar, R., & Ros´e, C. P. (2013). Towards 
academically productive talk supported by conversational agents. In Productive 
multivocality in the analysis of group interactions (pp. 459–476). Springer. 
Elmore, M. (2023). The hidden costs of Chat GPT: A call for greater transparency. The 
American Journal of Bioethics, 23(10), 47–49.
Farrokhnia, M., Banihashem, S. K., Noroozi, O., & Wals, A. (2024). A SWOT analysis of 
Chat GPT: Implications for educational practice and research. Innovations in Education 
& Teaching International, 61(3), 460–474.
Feng, J., Yu, B., Tan, W. H., Dai, Z., & Li, Z. (2025). Key factors influencing educational 
technology adoption in higher education: A systematic review. PLOS Digital Health, 4 
(4), Article e0000764.
Firat, M. (2023a). How Chat GPT can transform autodidactic experiences and open 
education? Education and Information Technologies, 28(4), 4221–4241.
Fırat, M. (2023b). Integrating AI applications into learning management systems to 
enhance e-learning. Instructional Technology and Lifelong Learning, 4(1), 1–14.
Fischer, C., Pardos, Z. A., Baker, R. S., Williams, J. J., Smyth, P., Yu, R., … 
Warschauer, M. (2020). Mining big data in education: Affordances and challenges. 
Review of Research in Education, 44(1), 130–160.
Flores-Viva, J. M., & García-Pe˜nalvo, F. J. (2023). Reflections on the ethics, potential, 
and challenges of artificial intelligence in the framework of quality education 
(SDG4). Comunicar: Media Education Research Journal, 31(74), 35–44.
Fütterer, T., Fischer, C., Alekseeva, A., Chen, X., Tate, T., Warschauer, M., & Gerjets, P. 
(2023). Chat GPT in education: Global reactions to AI innovations. Scientific Reports, 
13(1), Article 15310.
Ghimire, A., Pather, J., & Edwards, J. (2024). Generative AI in education: A study of 
educators’ awareness, sentiments, and influencing factors. In 2024 IEEE frontiers in 
education conference (FIE) (pp. 1–9). IEEE. 
Gil de Zú˜niga, H., Goyanes, M., & Durotoye, T. (2024). A scholarly definition of artificial 
intelligence (AI): Advancing AI as a conceptual framework in communication 
research. Political Communication, 41(2), 317–334.
Grani´c, A. (2022). Educational technology adoption: A systematic review. Education and 
Information Technologies, 27(7), 9725–9744.
Greenhalgh, S. P., Rosenberg, J. M., Willet, K. B. S., Koehler, M. J., & Akcaoglu, M. 
(2020). Identifying multiple learning spaces within a single teacher-focused Twitter 
hashtag. Computers & education, 148, Article 103809.
Güneyli, A., Burgul, N. S., Dericio˘glu, S., Cenkova, N., Becan, S., S¸ims¸ek, S¸. E., & 
Güneralp, H. (2024). Exploring teacher awareness of artificial intelligence in 
education: A case study from northern Cyprus. European Journal of Investigation in 
Health Psychology and Education, 14(8), 2358.
Gupta, K. P., & Bhaskar, P. (2020). Inhibiting and motivating factors influencing 
teachers’ adoption of AI-based teaching and learning solutions: Prioritization using 
analytic hierarchy process. Journal of Information Technology Education, 19, 693–713.
Halaweh, M. (2023). Chat GPT in education: Strategies for responsible implementation. 
Contemporary Educational Technology, 15(2).
Haque, M. U., Dharmadasa, I., Sworna, Z. T., Rajapakse, R. N., & Ahmad, H. (2022). "I 
think this is the most disruptive technology": Exploring sentiments of Chat GPT early 
adopters using Twitter data. https://doi.org/10.48550/ar Xiv.2212.05856.
Harry, A., & Sayudin, S. (2023). The role of AI in education. Interdisciplinary Journal and 
Humanity (INJURITY), 2(3), 260–268.
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 14 ---

Hazaimeh, M., & Al-Ansi, A. M. (2024). Model of AI acceptance in higher education: 
Arguing teaching staff and students’ perspectives. The International Journal of 
Information and Learning Technology, 41(4), 371–393.
Helmiatin, Hidayat, A., & Kahar, M. R. (2024). Investigating the adoption of AI in higher 
education: A study of public universities in Indonesia. Cogent Education, 11(1), 
Article 2380175.
Henderson, J., & Corry, M. (2021). Teacher anxiety and technology change: A review of 
the literature. Technology, Pedagogy and Education, 30(4), 573–587.
Hill-Yardin, E. L., Hutchinson, M. R., Laycock, R., & Spencer, S. J. (2023). A Chat (GPT) 
about the future of scientific publishing. Brain, Behavior, and Immunity, 110, 
152–154.
Hollands, F., & Breazeal, C. (2024). Establishing AI literacy before adopting AI. The 
Science Teacher, 91(2), 35–42.
Holmes, W., Porayska-Pomsta, K., Holstein, K., Sutherland, E., Baker, T., Shum, S. B., … 
Koedinger, K. R. (2022). Ethics of AI in education: Towards a community-wide 
framework. International Journal of Artificial Intelligence in Education, 1–23.
Hossler, D., & Scalese-Love, P. (1989). Grounded meta-analysis: A guide for research 
synthesis. The Review of Higher Education, 13(1), 1–28.
Hu, J. (2021). Teaching evaluation system by use of machine learning and artificial 
intelligence methods. International Journal of Emerging Technologies in Learning 
(i JET), 16(5), 87–101.
Huang, L. (2023). Ethics of artificial intelligence in education: Student privacy and data 
protection. Science Insights Education Frontiers, 16(2), 2577–2587.
Huang, X., Zou, D., Cheng, G., Chen, X., & Xie, H. (2023). Trends, research issues and 
applications of artificial intelligence in language education. Educational Technology & 
Society, 26(1), 112–131.
Huong, X. V. (2024). The implications of artificial intelligence for educational systems: 
Challenges, opportunities, and transformative potential. The American Journal of 
Social Science and Education Innovations, 6(3), 101–111.
Ismail, A., Aliu, A., Ibrahim, M., & Sulaiman, A. (2024). Preparing teachers of the future 
in the era of artificial intelligence. Journal of Artificial Intelligence, Machine Learning 
and Neural Network, 44, 31–41.
Istenic, A., Bratko, I., & Rosanda, V. (2021). Are pre-service teachers disinclined to utilize 
embodied humanoid social robots in the classroom? British Journal of Educational 
Technology, 52(6), 2340–2358.
Jafari, F., & Keykha, A. (2024). Identifying the opportunities and challenges of artificial 
intelligence in higher education: A qualitative study. Journal of Applied Research in 
Higher Education, 16(4), 1228–1245.
Kaplan-Rakowski, R., Grotewold, K., Hartwick, P., & Papin, K. (2023). Generative AI and 
teachers’ perspectives on its implementation in education. Journal of Interactive 
Learning Research, 34(2), 313–338.
Kasneci, E., Seßler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., … 
Kasneci, G. (2023). Chat GPT for good? On opportunities and challenges of Large 
Language Models for education. Learning and Individual Differences, 103, Article 
102274.
Kemp, S. (2023). Digital 2023: Global overview report. https://datareportal.com/repo 
rts/digital-2023-global-overview-report.
Kim, H. W., Chan, H. C., & Gupta, S. (2007). Value-based adoption of mobile internet: An 
empirical investigation. Decision Support Systems, 43(1), 111–126.
Kiryakova, G., & Angelova, N. (2023). Chat GPT—a challenging tool for the university 
professors in their teaching practice. Education Sciences, 13(10), 1056.
Kramm, N., & Mc Kenna, S. (2023). AI amplifies the tough question: What is higher 
education really for? Teaching in Higher Education, 28(8), 2173–2178.
Lampropoulos, G., Ferdig, R. E., & Kaplan-Rakowski, R. (2023). A social media data 
analysis of general and educational use of Chat GPT: Understanding emotional educators. 
Available at: SSRN 4468181.
Limna, P., Jakwatanatham, S., Siripipattanakul, S., Kaewpuang, P., & Sriboonruang, P. 
(2022). A review of artificial intelligence (AI) in education during the digital era. 
Advance Knowledge for Executives, 1(1), 1–9.
Limna, P., Kraiwanit, T., Jangjarat, K., Klayklung, P., & Chocksathaporn, P. (2023). The 
use of Chat GPT in the digital era: Perspectives on chatbot implementation. Journal of 
Applied Learning and Teaching, 6(1), 64–74.
Liu, B. (2022). Sentiment analysis and opinion mining. Springer Nature. 
Lorenc, T., Felix, L., Petticrew, M., Melendez-Torres, G. J., Thomas, J., Thomas, S., … 
Richardson, M. (2016). Meta-analysis, complexity, and heterogeneity: A qualitative 
interview study of researchers’ methodological values and practices. Systematic 
Reviews, 5, 1–9.
Luckin, R., & Holmes, W. (2016). Intelligence unleashed: An argument for AI in education.
Ma, S., & Lei, L. (2024). The factors influencing teacher education students’ willingness 
to adopt artificial intelligence technology for information-based teaching. Asia 
Pacific Journal of Education, 44(1), 94–111.
Malik, M., Lamba, H., Nakos, C., & Pfeffer, J. (2015). Population bias in geotagged 
tweets. Proceedings of the International AAAI Conference on Web and Social Media, 9 
(4), 18–27.
Mamo, Y., Crompton, H., Burke, D., & Nickel, C. (2024). Higher education faculty 
perceptions of Chat GPT and the influencing factors: A sentiment analysis of X. 
Tech Trends, 68(3), 520–534.
Mao, J., Chen, B., & Liu, J. C. (2024). Generative artificial intelligence in education and 
its implications for assessment. Tech Trends, 68(1), 58–66.
Mc Carthy, T., Penny Rosenblum, L., Johnson, B. G., Dittel, J., & Kearns, D. M. (2016). An 
artificial intelligence tutor: A supplementary tool for teaching and practicing braille. 
Journal of Visual Impairment & Blindness, 110(5), 309–322.
Mir, M. M., Mir, G. M., Raina, N. T., Mir, S. M., Mir, S. M., Miskeen, E., … 
Alamri, M. M. S. (2023). Application of artificial intelligence in medical education: 
Current scenario and future perspectives. Journal of advances in medical education & 
professionalism, 11(3), 133.
Mishra, P., & Koehler, M. J. (2006). Technological pedagogical content knowledge: A 
framework for teacher knowledge. Teachers College Record, 108(6), 1017–1054.
Miyazaki, K., Murayama, T., Uchiba, T., An, J., & Kwak, H. (2024). Public perception of 
generative AI on Twitter: An empirical study based on occupation and usage. EPJ 
Data Science, 13(1), 2.
Mohammadi, L., Asadi, M., & Taheri, R. (2024). Transforming EFL lesson planning with 
’to teach AI’: Insights from teachers’ perspectives. Technology Assisted Language 
Education, 2(4), 97–119.
Molefi, R. R., Ayanwale, M. A., Kurata, L., & Chere-Masopha, J. (2024). Do in-service 
teachers accept artificial intelligence-driven technology? The mediating role of 
school support and resources. Computers and Education Open, 6, Article 100191.
Morgan, A. (1991). Case-study research in distance education.
Nagi, F., Salih, R., Alzubaidi, M., Shah, H., Alam, T., Shah, Z., & Househ, M. (2023). 
Applications of artificial intelligence (AI) in medical education: A scoping review. 
Healthcare Transformation with Informatics and Artificial Intelligence, 648–651.
Nasution, N. E. A. (2023). Using artificial intelligence to create biology multiple choice 
questions for higher education. Agricultural and Environmental Education, 2(1), 4–8.
Nazaretsky, T., Ariely, M., Cukurova, M., & Alexandron, G. (2022). Teachers’ trust in AI- 
powered educational technology and a professional development program to 
improve it. British Journal of Educational Technology, 53(4), 914–931.
Ng, G. W., & Leung, W. C. (2020). Strong artificial intelligence and consciousness. 
Journal of Artificial Intelligence and Consciousness, 7(1), 63–72.
Nguyen, A., Ngo, H. N., Hong, Y., Dang, B., & Nguyen, B. P. T. (2023). Ethical principles 
for artificial intelligence in education. Education and Information Technologies, 28(4), 
4221–4241.
Nja, C. O., Idiege, K. J., Uwe, U. E., Meremikwu, A. N., Ekon, E. E., Erim, C. M., … 
Cornelius-Ukpepi, B. U. (2023). Adoption of artificial intelligence in science 
teaching: From the vantage point of the African science teachers. Smart Learning 
Environments, 10(1), 42.
Nochumson, T. C. (2020). Elementary schoolteachers’ use of twitter: Exploring the 
implications of learning through online social media. Professional Development in 
Education, 46(2), 306–323. https://doi.org/10.1080/19415257.2019.1585382
O’shea, T., & Self, J. (1986). Learning and teaching with computers: The artificial intelligence 
revolution. Prentice Hall Professional Technical Reference. 
Ofosu-Ampong, K. (2024). Beyond the hype: Exploring faculty perceptions and 
acceptability of AI in teaching practices. Discover Education, 3(1), 38.
Pedro, F., Subosa, M., Rivas, A., & Valverde, P. (2019). Artificial intelligence in education: 
Challenges and opportunities for sustainable development. UNESCO. 
Pesek, I., Nosovi´c, N., & Kraˇsna, M. (2022). The Role of AI in education and for 
education. In 2022 11th mediterranean conference on embedded computing (MECO) 
(pp. 1–4). IEEE. 
Popenici, S. A., & Kerr, S. (2017). Exploring the impact of artificial intelligence on 
teaching and learning in higher education. Research and Practice in Technology 
Enhanced Learning, 12(1), 22.
Qadir, J. (2023). Engineering education in the era of Chat GPT: Promise and pitfalls of 
generative AI for education. In 2023 IEEE global engineering education conference 
(EDUCON) (pp. 1–9). IEEE. 
Quelle, D., & Bovet, A. (2025). Bluesky: Network topology, polarization, and algorithmic 
curation. PLo S One, 20(2), Article e0318034.
Rahman, M. M., & Watanobe, Y. (2023). Chat GPT for education and research: 
Opportunities, threats, and strategies. Applied Sciences, 13(9), 5783.
Rˆego, A. D. S., Radovanovic, C. A. T., Haddad, M. D. C. F. L., Santos, J. L. G. D., 
Carreira, L., Salci, M. A., … Büscher, A. (2023). Use of grounded theory in the 
extraction, coding and analysis of data in literature meta-analyses. Texto & Contexto- 
Enfermagem, 32, Article e20210445. https://doi.org/10.1590/1980-265X-TCE-2021- 
0445en
Rogers, E. M., Singhal, A., & Quinlan, M. M. (2014). Diffusion of innovations. In An 
integrated approach to communication theory and research (pp. 432–448). Routledge. 
Sabzalieva, E., & Valentini, A. (2023). Chat GPT and artificial intelligence in higher 
education: Quick start guide.
Savin-Baden, M., & Major, C. (2023). Qualitative research: The essential guide to theory and 
practice. Routledge. 
Schmidt, D. A., Baran, E., Thompson, A. D., Mishra, P., Koehler, M. J., & Shin, T. S. 
(2009). Technological pedagogical content knowledge (TPACK): The development 
and validation of an assessment instrument for preservice teachers. Journal of 
Research on Technology in Education, 42(2), 123–149.
Selwyn, N. (2016). Is technology good for education? Malden: Polity Press. 
Seufert, S., Guggemos, J., & Sailer, M. (2021). Technology-related knowledge, skills, and 
attitudes of pre-and in-service teachers: The current situation and emerging trends. 
Computers in Human Behavior, 115, Article 106552.
Shahid, M. K., Zia, T., Bangfan, L., Iqbal, Z., & Ahmad, F. (2024). Exploring the 
relationship of psychological factors and adoption readiness in determining 
university teachers’ attitude on AI-based assessment systems. International Journal of 
Management in Education, 22(2), Article 100967.
Smolansky, A., Cram, A., Raduescu, C., Zeivots, S., Huber, E., & Kizilcec, R. F. (2023). 
Educator and student perspectives on the impact of generative AI on assessments in 
higher education. In Proceedings of the tenth ACM conference on learning@ scale (pp. 
378–382).
Sollosy, M., & Mc Inerney, M. (2022). Artificial intelligence and business education: What 
should be taught. International Journal of Management in Education, 20(3), Article 
100720.
Stall-Meadows, C., & Hyle, A. (2010). Procedural methodology for a grounded meta- 
analysis of qualitative case studies. International Journal of Consumer Studies, 34(4), 
412–418.
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464 

--- Page 15 ---

Statista. (2025). Age distribution of worldwide Twitter users as of February 2025, by age 
group. Statista. https://www.statista.com/statistics/283119/age-distribution-of-gl 
obal-twitter-users/. 
Stockman, C., & Nottingham, E. (2022). Surveillance capitalism in schools: What’s the 
problem. Digital Culture & Education, 14(1), 1–15.
Stracqualursi, L., & Agati, P. (2024). Twitter users’ perceptions of AI-based e-learning 
technologies. Scientific Reports, 14(1), 5927.
Strauss, A., & Corbin, J. (1990). Basics of qualitative research (Vol. 15). Sage. 
Strzelecki, A., Cicha, K., Rizun, M., & Rutecka, P. (2024). Acceptance and use of Chat GPT 
in the academic community. Education and Information Technologies, 1–26.
Su, J., & Yang, W. (2023). Unlocking the power of Chat GPT: A framework for applying 
generative AI in education. ECNU Review of Education, 6(3), 355–366.
Sun, F., Tian, P., Sun, D., Fan, Y., & Yang, Y. (2024). Pre-service teachers’ inclination to 
integrate AI into STEM education: Analysis of influencing factors. British Journal of 
Educational Technology, 55(6), 2574–2596.
Swiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J. M., Milligan, S., … 
Gaˇsevi´c, D. (2022). Assessment in the age of artificial intelligence. Computers and 
Education: Artificial Intelligence, 3, Article 100075.
Tyson, M. M., & Sauers, N. J. (2021). School leaders’ adoption and implementation of 
artificial intelligence. Journal of Educational Administration, 59(3), 271–285.
UNESCO. (2019). Artificial intelligence in education: Challenges and opportunities. United 
Nations Educational, Scientific and Cultural Organization. https://unesdoc.unesco. 
org/ark:/48223/pf0000366994. 
Vargas-Murillo, A. R., de la Asuncion, I. N. M., & de Jesús Guevara-Soto, F. (2023). 
Challenges and opportunities of AI-assisted learning: A systematic literature review 
on the impact of Chat GPT usage in higher education. International Journal of 
Learning, Teaching and Educational Research, 22(7), 122–135.
Vashishth, T. K., Sharma, V., Sharma, K. K., Kumar, B., Chaudhary, S., & Panwar, R. 
(2024). Transforming classroom dynamics: The social impact of AI in teaching and 
learning. In AI-enhanced teaching methods (pp. 322–346). IGI Global. 
Velli, K., & Zafiropoulos, K. (2024). Factors that affect the acceptance of educational AI 
tools by Greek teachers—a structural equation modeling study. European Journal of 
Investigation in Health Psychology and Education, 14(9), 2560–2579.
Venkatesh, V., & Bala, H. (2008). Technology acceptance model 3 and a research agenda 
on interventions. Decision Sciences, 39(2), 273–315.
Venkatesh, V., & Davis, F. D. (2000). A theoretical extension of the technology 
acceptance model: Four longitudinal field studies. Management Science, 46(2), 
186–204.
Venkatesh, V., Morris, M. G., Davis, G. B., & Davis, F. D. (2003). User acceptance of 
information technology: Toward a unified view. MIS Quarterly, 425–478.
Venkatesh, V., Thong, J. Y., & Xu, X. (2012). Consumer acceptance and use of 
information technology: Extending the unified theory of acceptance and use of 
technology. MIS Quarterly, 157–178.
Vij, S., Tayal, D., & Jain, A. (2020). A machine learning approach for automated 
evaluation of short answers using text similarity based on Word Net graphs. Wireless 
Personal Communications, 111, 1271–1282.
Walter, Y. (2024). Embracing the future of artificial intelligence in the classroom: The 
relevance of AI literacy, prompt engineering, and critical thinking in modern 
education. International Journal of Educational Technology in Higher Education, 21(1), 
15.
Wang, T., & Cheng, E. C. K. (2021). An investigation of barriers to Hong Kong K-12 
schools incorporating Artificial Intelligence in education. Computers and Education: 
Artificial Intelligence, 2, Article 100031.
Warschauer, M., Tseng, W., Yim, S., Webster, T., Jacob, S., Du, Q., & Tate, T. (2023). The 
affordances and contradictions of AI-generated text for writers of English as a second 
or foreign language. Journal of Second Language Writing, 62.
Whalen, J., & Mouza, C. (2023). Chat GPT: Challenges, opportunities, and implications 
for teacher education. Contemporary Issues in Technology and Teacher Education, 23 
(1), 1–23.
Wijaya, T. T., Su, M., Cao, Y., Weinhandl, R., & Houghton, T. (2024). Examining Chinese 
preservice mathematics teachers’ adoption of AI chatbots for learning: Unpacking 
perspectives through the UTAUT2 model. Education and Information Technologies, 
1–29.
Williamson, B., & Eynon, R. (2020). Historical threads, missing links, and future 
directions in AI in education. Learning, Media and Technology, 45(3), 223–235. 
https://doi.org/10.1080/17439884.2020.1798995
Wohlin, C. (2014). Guidelines for snowballing in systematic literature studies and a 
replication in software engineering. In Proceedings of the 18th international conference 
on evaluation and assessment in software engineering (pp. 1–10). https://doi.org/ 
10.1145/2601248.2601268
Woo, J. H., & Choi, H. (2021). Systematic review for AI-based language learning tools. 
ar Xiv preprint ar Xiv:2111.04455. https://doi.org/10.48550/ar Xiv.2111.04455
Woodruff, K., Hutson, J., & Arnone, K. (2023). Perceptions and barriers to adopting artificial 
intelligence in K-12 education: A survey of educators in fifty states.
Wu, D., Zhang, X., Wang, K., Wu, L., & Yang, W. (2024). A multi-level factors model 
affecting teachers’ behavioral intention in AI-enabled education ecosystem. 
Educational Technology Research & Development, 1–33.
Xu, J. J., & Babaian, T. (2021). Artificial intelligence in business curriculum: The 
pedagogy and learning outcomes. International Journal of Management in Education, 
19(3), Article 100550.
Xu, W., & Ouyang, F. (2022). The application of AI technologies in STEM education: A 
systematic review from 2011 to 2021. International Journal of STEM Education, 9(1), 
59.
Yang, S., & Appleget, C. (2024). An exploration of preservice teachers’ perceptions of 
generative AI: Applying the technological acceptance model. Journal of Digital 
Learning in Teacher Education, 40(3), 159–172.
Yao, N., & Abd Halim, N. D. (2023). Analyzing factors influencing primary school 
teachers’ acceptance willingness of artificial intelligence technology. In Proceedings 
of the 2023 6th international conference on educational technology management (pp. 
35–41).
Yildiz, D., Munson, J., Vitali, A., Tinati, R., & Holland, J. A. (2017). Using Twitter data 
for demographic research. Demographic Research, 37, 1477–1514.
Yin, R. K., & Heald, K. A. (1975). Using the case survey method to analyze policy studies. 
Administrative Science Quarterly, 20(3), 371–381.
Zawacki-Richter, O., Marín, V. I., Bond, M., & Gouverneur, F. (2019). Systematic review 
of research on artificial intelligence applications in higher education–where are the 
educators? International Journal of Educational Technology in Higher Education, 16(1), 
1–27.
Zhai, X. (2022). Chat GPT user experience: Implications for education. Available at: SSRN 
4312418.
Zhang, C., Hu, M., Wu, W., Kamran, F., & Wang, X. (2024). Unpacking perceived risks 
and AI trust influences pre-service teachers’ AI acceptance: A structural equation 
modeling-based multi-group analysis. Education and Information Technologies, 1–28.
Zhang, C., Schießl, J., Pl¨oßl, L., Hofmann, F., & Gl¨aser-Zikuda, M. (2023). Acceptance of 
artificial intelligence among pre-service teachers: A multigroup analysis. 
International Journal of Educational Technology in Higher Education, 20(1), 49.
Zhang, J., & Zhang, Z. (2024). AI in teacher education: Unlocking new dimensions in 
teaching support, inclusive learning, and digital literacy. Journal of Computer Assisted 
Learning, 40(4), 1871–1885.
Zou, W., Li, J., Yang, Y., & Tang, L. (2023). Exploring the early adoption of open AI 
among laypeople and technical professionals: An analysis of Twitter conversations 
on# Chat GPT and# GPT3. International Journal of Human-Computer Interaction, 1–12.
R. Taheri et al.                                                                                                                                                                                                                                  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100464
