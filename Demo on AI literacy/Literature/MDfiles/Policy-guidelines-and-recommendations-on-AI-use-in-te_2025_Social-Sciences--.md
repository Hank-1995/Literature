# Policy guidelines and recommendations on AI use in teaching and learning: A meta-synthesis study

## Metadata
- **Author**: Aaron A. Funa
- **Subject**: Social Sciences & Humanities Open, 11 (2025) 101221. doi:10.1016/j.ssaho.2024.101221
- **Creator**: Elsevier
- **Producer**: Acrobat Distiller 8.1.0 (Windows)
- **Creation Date**: D:20250617032452Z
- **Modification Date**: D:20250617053254Z
- **Source File**: Policy-guidelines-and-recommendations-on-AI-use-in-te_2025_Social-Sciences--.pdf
- **Converted**: 2025-10-23 22:46:11

---

## Content

--- Page 1 ---

Review Article
Policy guidelines and recommendations on AI use in teaching and learning: 
A meta-synthesis study
Aaron A. Funa *, Renz Alvin E. Gabay
Sorsogon State University, Sorsogon, Philippines
A R T I C L E  I N F O
Keywords:
AI ethics
AI integration
AI in education
AI in teaching and learning
Artificial intelligence
Chat GPT
A B S T R A C T
As artificial intelligence becomes increasingly integral to educational systems, understanding policy guidelines 
and recommendations from various sources is crucial. This meta-synthesis examines AI policies and guidelines 
from peer-reviewed articles, reports, books, and websites from 2020 to 2024, with a focus on their implications 
for teaching and learning. Using a thematic analysis approach, the study categorizes findings into key themes and 
subthemes. Under the theme of policies and guidelines, notable subthemes include ethical AI use, AI literacy, and 
inclusivity and equity. In terms of implementation strategies, the synthesis identifies crucial areas such as student 
orientation and professional development, enhanced teaching tools and data-driven insights, improved student 
learning outcomes and engagement, and streamlined administrative processes. The study also determines 
practical constraints that challenge the successful integration of AI in education, including technical and inte-
gration challenges, training and support issues, ethical and fairness concerns, cost and accessibility, transparency 
and privacy issues, and misalignment with educational goals. Future research may explore the long-term impacts 
of AI integration policies and guidelines, refine practical implementation strategies, and foster collaboration 
among researchers, educators, and policymakers to tackle ongoing challenges and maximize AI’s potential in 
education.
1. Introduction
Artificial Intelligence (AI) has been a topic of interest since its 
inception in the 1950s, when early AI research sought to create systems 
capable of simulating human intelligence (Guo, 2015). Initially focused 
on problem-solving and symbolic reasoning, AI’s capabilities have since 
evolved significantly, especially with the advent of machine learning 
and big data in the 21st century. These advancements have sparked 
renewed interest in the application of AI across various fields, including 
education. Despite its long history, the recent integration of AI into 
educational settings marks a transformative shift, offering unprece-
dented opportunities to personalize learning, enhance student engage-
ment, and optimize educational outcomes (Zheng et al., 2021).
Recent developments have positioned AI as a transformative force in 
education, revolutionizing learning experiences and creating new op-
portunities for personalized education (Zheng et al., 2021). AI’s role in 
education, particularly through adaptive learning platforms like 
Dream Box and Khan Academy, has led to significant advancements in 
tailoring instruction to individual student needs (Huang et al., 2023). 
These technologies promise to improve engagement, learning outcomes, 
and preparedness for a technology-driven future (Gao et al., 2024; Zhai 
et al., 2021). However, despite these promising advancements, several 
challenges complicate the successful integration of AI in educational 
contexts, necessitating a thorough examination of existing policies and 
practices.
One critical issue is the diverse range of attitudes among students and 
teachers towards AI. While some teachers enthusiastically embrace the 
potential of AI to enhance educational practices and outcomes, others 
remain skeptical or resistant, often due to concerns about the risks 
associated with overreliance on AI tools (Crawford et al., 2024; Zhai 
et al., 2021). For instance, there is apprehension that AI could poten-
tially undermine critical thinking processes by reducing the need for 
students to engage in deep, analytical thinking or problem-solving (Xie 
& Wang, 2024). Additionally, there are concerns that AI tools might 
increase incidences of academic dishonesty, as students might find ways 
to exploit these technologies to gain unfair advantages (Xie et al., 2023). 
This reluctance underscores the necessity of adopting a balanced and 
thoughtful approach to integrating AI in education. It is essential to 
* Corresponding author.
E-mail address: funa.aaron@sorsu.edu.ph (A.A. Funa). 
Contents lists available at Science Direct
Social Sciences & Humanities Open
journal homepage: www.sciencedirect.com/journal/social-sciences-and-humanities-open
https://doi.org/10.1016/j.ssaho.2024.101221
Received 24 August 2024; Received in revised form 6 November 2024; Accepted 14 November 2024  
Social Sciences & Humanities Open 11 (2025) 101221 
Available online 19 November 2024 
2590-2911/© 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ). 

--- Page 2 ---

ensure that the benefits of AI are fully realized while carefully 
addressing and mitigating potential drawbacks, thereby fostering an 
educational environment where AI supports and enhances learning 
without compromising educational integrity or critical thinking skills.
Moreover, integrating AI into education raises significant ethical and 
bias-related concerns. AI systems, though designed to be impartial, may 
perpetuate or even exacerbate existing biases if they are trained on 
biased data or use flawed algorithms (Miao et al., 2021). Research has 
revealed that AI systems used in educational settings can inadvertently 
mirror racial or socioeconomic biases present in their training data. One 
notable example is the use of AI in grading and admissions processes, 
where systems trained on historical data may unfairly disadvantage 
certain student groups. Studies have found that algorithms used for 
predictive analytics in education can reflect and even magnify dispar-
ities in access to resources, leading to inequitable educational outcomes 
(Alvero et al., 2020; Jiang & Pardos, 2021). For example, systems pre-
dicting college admissions or scholarships might unintentionally disad-
vantage students from underrepresented backgrounds if they use 
historical data that shows existing disparities. This could lead to biased 
recommendations 
that 
perpetuate 
inequalities 
in 
educational 
opportunities.
Both students and teachers recognize the critical importance of 
establishing clear guidelines to prevent the misuse of AI, manage the 
associated risks, and safeguard data privacy in educational settings 
(Chan, 2023; Miao et al., 2021). There is a consensus that AI should be 
integrated as a supportive tool that complements rather than replaces 
traditional teaching methods. This integration should be approached 
with careful consideration of equitable access to AI technologies, 
ensuring that all students have the opportunity to benefit from these 
advancements. Additionally, there is a strong call for promoting AI lit-
eracy among students, equipping them with the skills needed to navigate 
and leverage AI technologies effectively across various fields. This 
perspective is consistent with Nemorin’s (2021) observation that current 
research frequently overlooks the necessity of critically assessing AI 
integration within the broader context of educational objectives. This 
includes evaluating the ethical implications of AI use and understanding 
its potential impacts on teaching and learning outcomes. By addressing 
these considerations, educational stakeholders can ensure that AI is used 
in a way that supports educational goals and fosters a positive learning 
environment.
Despite the existence of over 300 global AI policy initiatives, many of 
these efforts are primarily concentrated on building AI capacity within 
higher education institutions and retraining the workforce to adapt to 
technological advancements (OECD.AI., 2021). This focus leaves a sig-
nificant gap in the integration of AI education into K-12 contexts, where 
foundational AI knowledge and skills could be developed early in stu-
dents’ educational journeys. There is also a need to prepare citizens for 
effective and collaborative interactions with AI technologies in their 
everyday lives, a crucial aspect highlighted by the Sustainable Devel-
opment Goal 4 (SDG 4) which aims to ensure inclusive and equitable 
quality education and promote lifelong learning opportunities for all 
(Miao et al., 2021). UNESCO (2023) underscores the urgency of setting 
strategic targets, particularly in low and middle-income countries, to 
tailor AI readiness initiatives to local contexts. This involves addressing 
critical infrastructure and funding gaps, ensuring equitable access to AI 
technologies, and promoting AI literacy among students and teachers. 
Furthermore, it is essential to ensure that the use of educational data is 
transparent and subject to audit, to build trust and accountability in AI 
applications within educational settings.
Emerging economies like the Philippines encounter several signifi-
cant challenges in adopting AI technologies, which include the need to 
develop robust AI infrastructure and expertise, establish comprehensive 
regulatory frameworks, address pressing data privacy concerns, and 
navigate complex ethical considerations (Estrellado & Miranda, 2023; 
Kabalisa & Altmann, 2021). Despite these challenges, the proactive 
stance taken by countries such as the Philippines in formulating and 
implementing AI adoption strategies highlights their dedication to har-
nessing AI for both economic growth and societal advancement. In 
particular, the Philippines has begun to integrate smart campus tech-
nologies as part of its efforts to enhance educational infrastructure. For 
instance, according to Estrellado and Miranda (2023), the Mariano 
Marcos State University has been awarded a grant from the Commission 
on Higher Education to bolster its IT capabilities, aiming to improve 
technological resources and support educational innovation. Similarly, 
the University of Northern Philippines has embarked on initiatives to 
implement smart classroom approaches, which are designed to enhance 
the accessibility and effectiveness of learning resources (Estrellado & 
Miranda, 2023). These advancements are in alignment with the educa-
tion goals outlined in the Department of Education’s Basic Education 
Development Program (BEDP) 2030. This program emphasizes the use 
of AI for data-driven decision-making in schools, aiming to support 
informed and strategic improvements in educational practices and 
outcomes.
Given these considerations, this study undertakes a systematic 
literature review to critically assess the existing policies surrounding the 
integration of AI in teaching and learning. While AI technologies 
continue to evolve rapidly, there remains a significant gap in under-
standing how these advancements are being governed, particularly in 
educational contexts. Despite the increasing deployment of AI tools, the 
policies that guide their ethical and effective implementation are often 
broad, fragmented, outdated, or underdeveloped, most especially in the 
basic K-12 education (OECD.AI., 2021; UNESCO, 2023). This study 
seeks to address this gap by exploring key questions: What policies and 
guidelines are currently in place for AI integration in education? How do 
these policies support or hinder the adoption of AI technologies, and 
what tangible benefits do they provide to both educators and learners? 
Moreover, what challenges and constraints do teachers and students 
encounter when applying these policies in practice? By identifying these 
gaps and assessing the effectiveness of current policies, this research 
aims to contribute to the academic conversation by offering a clearer 
framework for policy development. The findings have the potential to 
inform educational institutions and policymakers, helping them create 
more robust, equitable, and effective AI governance that can optimize 
educational outcomes while safeguarding against risks.
2. Methodology
2.1. Research design
The researchers conducted a systematic literature review (SLR), 
specifically using Meta-synthesis, covering the period from 2020 to 2024 
to analyze existing policies on AI integration in education. This period is 
significant as it reflects the post-pandemic landscape, during which 
educational institutions increasingly adopted AI technologies to address 
challenges exacerbated by COVID-19. The SLR methodology was chosen 
to ensure a comprehensive and systematic synthesis of relevant research, 
providing a structured approach to identifying, evaluating, and inter-
preting available data related to AI policies in educational settings 
(Rother, 2007). Meta-synthesis was selected to integrate the findings 
from multiple qualitative studies, as this method allows for a deeper 
understanding of complex phenomena by interpreting and synthesizing 
the results of various studies (Sandelowski & Barroso, 2006), providing a 
more comprehensive perspective on AI policies in education. The re-
searchers adhered to the Enhancing Transparency in Reporting the 
Synthesis of Qualitative Research (ENTREQ) guidelines, which comprise 
21 items organized into five main areas: introduction, methods and 
methodology, literature search and selection, appraisal, and synthesis of 
findings (Tong et al., 2012). ENTREQ aids researchers in reporting the 
stages involved in synthesizing qualitative research, such as searching 
and selecting qualitative studies, appraising their quality, and synthe-
sizing their findings. On the other hand, the Preferred Reporting Items 
for Systematic Reviews and Meta-Analyses (PRISMA) diagram was used 
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 3 ---

to organize and visually represent the study selection process, providing 
transparency in how studies were identified, screened, and included. 
Together, these frameworks ensured a rigorous, transparent, and 
reproducible review.
2.2. Study search procedure
The study employed preplanned, comprehensive search strategies to 
locate relevant reports and studies. At the outset, the researchers 
established inclusion and exclusion criteria. Searches were conducted 
across the Internet and multiple databases, including Google Scholar, 
Pub Med, ERIC, and Scopus, which were selected for their extensive 
access to academic literature. The search targeted peer-reviewed arti-
cles, conference papers, and policy documents published between 2020 
and 2024. Harzing’s Publish or Perish tool (Harzing, 2007) was utilized 
to aid in identifying pertinent journal articles. Hand searches of grey 
literature were also considered, as important documents might not have 
been identified during electronic searches, particularly local documents. 
The search strategy utilized a combination of keywords focused on 
artificial intelligence and its application in education. Initially, key-
words like “artificial intelligence” 
OR “AI” 
were employed. 
Subsequently, additional keywords related to policy and education, such 
as “policy,” “guidelines,” “education,” “learning,” and “teaching,” were 
added. These terms were systematically entered into the meta-search 
engine to ensure a comprehensive search until all relevant studies 
were identified. Titles and abstracts of the retrieved articles underwent 
screening to assess their potential relevance to the research questions. 
Articles that did not primarily address AI in education were excluded. 
Full texts of the remaining articles were thoroughly reviewed to confirm 
their relevance and alignment with the established inclusion criteria. 
Only studies meeting these criteria were selected for the final analysis.
2.3. Inclusion and exclusion criteria
The researchers delimited the review using the following inclusion 
and exclusion criteria. Specifically, articles must: (a) Be a qualitative 
study published between 2020 and 2024, including electronic databases 
and grey literature. This timeframe captures the post-pandemic period 
when AI integration in education became more accessible and promi-
nent, ensuring the review reflects current research and policy de-
velopments. (b) Include an explicit reference to AI policy or guidelines in 
education in the title, abstract, or main text. (c) Focus on the teaching 
Fig. 1. PRISMA search strategy for AI policies in education.
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 4 ---

and learning processes (included AI policies from research publishers as 
teachers in the secondary and tertiary level used these policies in the 
absence of institutional policies), and pedagogies; and (d) pertain to any 
educational level, making insights applicable across K-12 and higher 
education. The exclusion criteria were: (a) not published in English, 
unless translation was feasible. Limiting the review to English publica-
tions ensures consistency and comprehensibility; and (b) not related to 
AI. This criterion maintains focus on relevant studies, eliminating un-
related information that could dilute findings regarding AI integration in 
education. Documents were filtered based on these inclusion criteria, 
and the detailed filtering process is shown in Fig. 1, the PRISMA diagram 
(Page et al., 2021). While PRISMA is typically used for meta-analyses, 
the researchers employed this framework to visually demonstrate the 
filtering of literature and studies.
2.4. Characteristics of the included studies and reports
This meta-synthesis explores the diverse AI teaching and learning 
guidelines in education as reflected in the included peer-reviewed 
articles (n = 15), reports (n = 3), books (n = 1), and websites (n = 4) (see 
Table 1). Peer-reviewed articles constitute the majority of the articles, 
with 15 such sources providing rigorous empirical research and theo-
retical analysis on AI’s role in educational settings. Reports, including 
those by Miao et al. (2021, 2023) and UNESCO (2023), offer significant 
policy guidance and strategic insights. Books and websites contribute to 
the discussion, with notable entries including Ong et al. (2024) and 
institutional guidelines from the University of the Philippines (UP) 
(2024) and Elsevier (2024).
As shown in Table 1, the reports address a broad spectrum of AI 
types. Generative AI, including applications like Chat GPT, is a focal 
point in several studies. For instance, Miao et al. (2023) and UNESCO 
(2023) provide comprehensive analyses of generative AI’s role in edu-
cation, while Wu (2023) and Baidoo-Anu and Ansah (2023) discuss its 
specific applications and benefits. Other studies explore general 
AI-based tools and strategies, with Kim et al. (2022) and Celik (2023)
focusing on their integration into teaching practices and learning 
designs.
Table 1 provides valuable insight into how AI is being implemented 
Table 1 
Reports included in the Meta-synthesis.
Year of 
Publication
Author(s)/Organization
Title
Country of 
publication/Author(s) 
affiliation
Type/ 
Methodology
AI type

Ong et al.
A Diversity of Pathways Through Science Education
Singapore
Book
AI

Crawford et al.
When artificial intelligence substitutes humans in higher 
education: the cost of loneliness, student success, and 
retention
Australia
Peer-reviewed 
Article
Generative AI

Wise et al.
A scholarly dialogue: writing scholarship, authorship, 
academic integrity and the challenges of AI
Australia & New 
Zealand
Peer-reviewed 
Article
Generative AI

Gao et al.
Ask Chat GPT first! Transforming learning experiences in the 
age of artificial intelligence
Spain
Peer-reviewed 
Article
Chat GPT (Large 
Language Model)
2024, 
Retrieved 
July
University of the Philippines 
(UP)
University of the Philippines Principles for Responsible and 
Trustworthy Artificial Intelligence
Philippines
Website
AI
2024, 
Retrieved 
June
Elsevier
The use of generative AI and AI-assisted technologies in 
writing for Elsevier
NA
Website
AI

University of the Philippines 
Los Ba˜nos (UPLB) Graduate 
School
Recommended use of AI tools in graduate studies
Philippines
Website
AI

Springer
Artificial Intelligence (AI)
NA
Website
AI

Holmes & Miao
Guidance for generative AI in education and research
France
Report
Generative AI

UNESCO
Education in the age of artificial intelligence
France
Report
Generative AI

Chan
A comprehensive AI policy education framework for 
university teaching and learning
Hong Kong
Peer-reviewed 
Article
AI

Ng et al.
A review of AI teaching and learning from 2000 to 2020
Hong Kong
Peer-reviewed 
article
AI

Baidoo-Anu & Ansah
Education in the era of generative artificial intelligence (AI): 
Understanding the potential benefits of Chat GPT in 
promoting teaching and learning
Canada & Ghana
Peer-reviewed 
article
Chat GPT (Large 
Language Model)

Mollick & Mollick
Using AI to implement effective teaching strategies in 
classrooms: Five strategies, including prompts
Pennsylvania
Peer-reviewed 
article
AI

Celik
Towards Intelligent-TPACK: An empirical study on teachers’ 
professional knowledge to ethically integrate artificial 
intelligence (AI)-based tools into education
Finland
Peer-reviewed 
article
AI

Wu
Integrating generative AI in education: how Chat GPT brings 
challenges for future learning and teaching
USA
Peer-reviewed 
article
Chat GPT (Large 
Language Model)

Kim et al.
Learning design to support student-AI collaboration: 
Perspectives of leading teachers for AI in education
Korea
Peer-reviewed 
Article
AI

Su et al.
A meta-review of literature on educational approaches for 
teaching AI at the K-12 levels in the Asia-Pacific region
Hong Kong
Peer-reviewed 
article
AI

Miao et al.
AI and education: A guidance for policymakers
France
Report
AI

Lin & Van Brummelen
Engaging teachers to co-design integrated AI curriculum for 
K-12 classrooms
USA
Peer-reviewed 
article
AI

Chiu
A holistic approach to the design of artificial intelligence 
(AI) education for K-12 schools
Hong Kong
Peer-reviewed 
article
AI

Berendt et al.
AI in education: Learner choice and fundamental rights
Germany
Peer-reviewed 
Article
AI

Rybinski & Kopciuszewska
Will artificial intelligence revolutionize the student 
evaluation of teaching? A big data study of 1.6 million 
student reviews
Poland
Peer-reviewed 
Article
Natural Language 
Processing AI
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 5 ---

across a variety of countries, including Singapore, the Philippines, 
Finland, France, Hong Kong, and Korea, among others. Hong Kong 
emerges as a significant contributor, with four studies originating from 
the region. France and Australia are another prominent contributor, 
with two studies each, offering insights into policy and strategic guid-
ance. The USA features studies from Lin and Van Brummelen (2021) and 
Wu (2023) contributing perspectives on AI integration. The Philippines 
is represented through institutional recommendations from the UP 
(2024) and the University of the Philippines Los Ba˜nos (UPLB) Graduate 
School (2024). Additionally, studies from Canada, Ghana, and Germany 
broaden the scope by addressing cross-national perspectives and ethical 
considerations.
Emerging economies like the Philippines and Ghana focus their 
policies on foundational challenges in AI integration, including infra-
structure limitations, access to technology, and disparities in digital 
literacy (Sharma et al., 2022). Studies from the Philippines highlight 
institutional recommendations for enhancing AI use in higher education 
and K-12 settings, emphasizing the need for comprehensive training and 
policies that address these gaps. For instance, UP (2024) stresses that 
effective AI integration must consider local contexts to ensure equitable 
access and successful implementation. However, although the Philip-
pine Dep Ed supports and promotes AI in education, there is no clear and 
specific policies on how to properly integrate AI in the basic curriculum 
(Estrellado & Miranda, 2023). In contrast, developed countries such as 
Hong Kong, USA, Korea, France, Australia, Poland, and Spain exhibit 
more advanced AI adoption policies and guidelines due to established 
technological infrastructure. USA’s approach emphasizes a holistic 
integration of AI, focusing on personalized learning and critical 
thinking. The studies from France illustrate how government policy 
supports strategic AI initiatives in education, demonstrating a proactive 
stance toward ethical guidelines.
2.5. Data analysis procedures
The researchers employed thematic analysis, following Braun, and 
Clarke’s (2006) framework, to systematically identify, analyze, and 
report patterns (themes) within the data. After selecting studies and 
reports for the meta-synthesis, the researchers, together with two col-
leagues—one with a master’s degree in education and the other with a 
Ph.D. in Science Education—grouped policy recommendations based on 
whether they pertained to learners, teachers, or administrators. An 
iterative coding process was used to identify significant features related 
to AI integration in education. Themes were developed inductively, 
emerging naturally from patterns in the data. The distribution of key 
themes across studies was analyzed to assess their frequency and sig-
nificance, identifying trends such as recurring concerns about AI’s 
ethical use and literacy among students and teachers. The themes were 
refined to ensure coherence and consistency, and they were named and 
defined to capture their core ideas within the broader context of AI 
policies in education. Throughout the process, the researchers critically 
reflected on potential biases. The final themes, presented in a structured 
format (see Fig. 2), offer insights into the landscape of AI in education 
policies and guidelines.
3. Results and discussion
This meta-synthesis assesses policies and guidelines on AI in educa-
tion from 2020 to 2024 from various sources. It focuses on the impli-
cations for teaching and learning, drawing from studies, reports, 
websites, and books. The primary themes identified are policies and 
guidelines, implementation strategies, and practical constraints faced by 
teachers and students (see Fig. 2).
3.1. Policies and guidelines on AI in teaching and learning
AI becomes increasingly embedded in educational environments, it is 
crucial to establish policies and guidelines that ensure its ethical and 
effective use. This section outlines key considerations under three main 
themes: Ethical AI Use, AI Literacy, and Inclusivity and Equity.
3.1.1. Ethical AI use
Based on the documents included in this meta-synthesis, Ethical AI 
Use encompasses several critical dimensions, including Academic 
Integrity, Transparency in AI Use, Human Oversight, Data Privacy, and 
Regulation and Monitoring. Ensuring ethical use of AI-driven educa-
tional tools requires adherence to these principles to uphold fairness and 
transparency.
Fig. 2. AI integration on teaching and learning policies and guidelines.
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 6 ---

3.1.1.1. Academic integrity. A central ethical concern with AI in edu-
cation is the risk of facilitating academic dishonesty. As AI-powered 
tools become increasingly accessible, there is a growing potential for 
students to exploit these technologies for cheating or plagiarism, thereby 
compromising the integrity of the educational process (Celik, 2023; 
Chan, 2023). Wise et al. (2024) highlight that generative AI introduces 
complexities in academic integrity, making it challenging to discern 
students’ actual capabilities when AI can polish language beyond their 
skill level. Moreover, Crawford et al. (2024) emphasize that the easy 
production of polished text by AI risks misrepresenting students’ actual 
understanding and skills, suggesting that reliance on AI may lead to 
surface-level proficiency without depth of knowledge. This issue urges 
educators to reconsider how academic honesty is defined and supported 
in AI-enabled learning environments.
According to Nguyen and Goto (2024), students hide AI-related 
cheating when asked directly, but an indirect method reveals cheating 
is nearly three times more common than first reported. It also found that 
older female students cheat more than younger ones, while male stu-
dents cheat at similar rates throughout, suggesting schools need new 
ways to use AI while protecting academic honesty (Nguyen & Goto, 
2024). This poses a challenge for teachers who must navigate the ethical 
implications of AI tools in their classrooms. Teachers need comprehen-
sive guidelines and targeted training to use AI technologies effectively 
and responsibly. This training should include understanding the un-
derlying algorithms and data-driven insights provided by AI tools to 
avoid misinterpretation or misuse (Kim et al., 2023). Moreover, teachers 
should be equipped to integrate AI in a manner that supports rather than 
undermines their teaching practices, ensuring that AI complements 
rather than replaces the critical human elements of education (Miao 
et al., 2021).
Defining academic dishonesty in an AI-integrated learning environ-
ment is crucial. Teachers must establish explicit criteria for what con-
stitutes cheating and develop robust strategies to detect and address the 
misuse of AI tools (Chan, 2023; Kim et al., 2023). Furthermore, it is vital 
to guard against an overreliance on AI tools among students. AI should 
be utilized to enhance, not diminish, students’ critical thinking and 
problem-solving abilities (Crawford et al., 2024; Wu, 2023). By focusing 
on supporting independent thought and analysis, AI tools can serve as a 
valuable complement to traditional educational practices rather than a 
replacement (Miao et al., 2021; Rybinski & Kopciuszewska, 2020). To 
promote academic integrity, educational institutions should consider 
implementing policies that require students to disclose their use of AI 
tools in assignments and assessments. Such declarations enhance 
transparency and accountability, allowing teachers to better assess 
genuine learning outcomes and ensuring that AI contributes positively 
to the educational process.
3.1.1.2. Transparency in AI Use. Transparency is essential for ensuring 
that AI applications are implemented effectively and ethically, 
providing clarity on how these systems influence educational outcomes. 
Transparency also plays a critical role in fostering trust among stake-
holders. Wise et al. (2024) emphasize the need for transparent and 
responsible AI use in student evaluation, warning that unchecked AI use 
can amplify biases and diminish trust. Similarly, although AI offers 
human-like connections to its consumers (Gao et al., 2024), Rybinski 
and Kopciuszewska (2020) warns that reliance on AI in higher education 
can lead to excessive automation, risking a loss of human connection 
and authentic social support for students. For example, UPLB Graduate 
School (2024) mandates that any use of AI tools in academic work, such 
as theses or dissertations, must be disclosed. This policy aims to uphold 
academic integrity by making clear the extent of AI’s involvement in 
producing scholarly outputs. Such disclosure ensures that the academic 
community can accurately assess the contribution of AI in research, 
thereby enhancing the credibility and authenticity of academic work.
Moreover, Springer (2024) highlights the need for documenting any 
use of AI tools in manuscripts, particularly concerning image creation 
and manipulation. This policy ensures that any AI-assisted processes are 
clearly reported, thus preventing misrepresentation of AI’s role in 
research findings. Similarly, Chan (2023) advocates for transparency 
about the functions and limitations of AI tools. This includes defining 
boundaries between acceptable AI assistance and academic misconduct, 
ensuring that AI tools are used ethically and responsibly. By adhering to 
such transparency guidelines, teachers can better manage the ethical 
implications of AI use and maintain the integrity of their students’ work.
Policies emphasize the need for AI systems in education to be un-
derstandable, clearly communicating their functions, biases, and po-
tential impacts (Chan, 2023; UP, 2024; Wu, 2023). AI transparency is an 
ongoing process embedded in the planning, development, and deploy-
ment of educational tools (see Fig. 3). Chaudhry et al. (2022) outline 
three tiers of transparency: Tier 1 for AI researchers and practitioners, 
Tier 2 for ed-tech experts and enthusiasts, and Tier 3 for public teachers, 
students, and parents. An AI system is considered transparent for edu-
cators, students, and parents if it incorporates user feedback, provides 
clear explanations, engages a responsible human in decision-making, 
includes training on its operation and limitations, addresses sensitive 
data distribution, shares the weaknesses of third-party tools, and dis-
closes its carbon footprint (Chaudhry et al., 2022). Hence, transparency 
must be tailored to the stakeholders’ technical expertise, ranging from 
detailed model insights for researchers to accessible explanations for 
educators, students, and parents.
3.1.1.3. Human Oversight. Human oversight ensures that AI technolo-
gies enhance rather than replace the roles of teachers and students 
(Elsevier, 2024; Springer, 2024; Wise et al., 2024). This approach em-
phasizes the need for active human involvement in the implementation, 
monitoring, and evaluation of AI tools to maintain educational quality 
and address ethical considerations. For example, if an AI tool can assess 
student essays and provide feedback on writing skills, it might generate 
suggestions based on patterns it has identified in past student work. 
However, if not carefully supervised, it could inadvertently favor certain 
writing styles or language patterns over others, potentially dis-
advantaging students from diverse linguistic backgrounds or those with 
non-traditional writing styles. A teacher’s role is to review the 
AI-generated feedback to ensure it is constructive and equitable, making 
Fig. 3. Continuous process of AI transparency in educational tool development.
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 7 ---

adjustments as needed to ensure that all students receive fair and helpful 
guidance (Miao et al., 2021). Additionally, teachers need to validate the 
AI’s recommendations for further learning activities or resources 
(Celiks, 2023). If the AI suggests additional exercises based on a stu-
dent’s performance, a teacher must assess whether these suggestions 
align with the student’s individual learning needs and educational goals. 
This oversight helps prevent situations where AI might recommend re-
sources that are too advanced or too basic, thereby maintaining a 
balanced and fair learning environment.
Students have recognized the learning benefits of Chat GPT and 
become more comfortable with its ethical use, although they still have 
concerns about its accuracy and feedback (Tossell et al., 2024). They 
have shifted from seeing Chat GPT as a ’cheating tool’ to viewing it as a 
helpful resource that requires human oversight and trust, highlighting 
important implications for education and the use of AI. While AI can 
automate tasks and provide valuable insights, understanding and 
applying this information still rely on human judgment. Teachers play a 
crucial role in ensuring that AI tools align with educational goals and 
teaching methods, while students must critically assess the outputs 
generated by AI. This includes monitoring the effectiveness of AI, 
addressing any issues that arise, and making necessary adjustments (Kim 
et al., 2021). Teachers also contextualize classroom activities and 
AI-generated content, ensuring that technology enhances the learning 
experience rather than controlling it. By closely monitoring AI tools, 
both teachers and students can prevent misuse, protect student privacy, 
and ensure that AI supports, rather than replaces, human interaction and 
judgment (Wise et al., 2024; Wu, 2023).
3.1.1.4. Data Privacy. As educational institutions integrate technology 
into classroom instruction, the management and protection of personal 
information must be addressed to safeguard the privacy of all stake-
holders involved (Chan, 2023; Miao et al., 2021). Students’ personal 
data, including academic records, behavioral data, and even biometric 
information, is often collected and analyzed through educational tech-
nologies. This data is essential for personalized learning and assessment 
but also raises significant privacy concerns. According to Berendt et al. 
(2021) and Crawford et al. (2024), the collection of such data can expose 
students to risks if not properly managed. Unauthorized access or 
breaches could lead to identity theft, misuse of information, or psy-
chological harm (Chan, 2023). Furthermore, students may feel uncom-
fortable or distrustful if they perceive that their data is being monitored 
or analyzed without their consent. This lack of trust can impact their 
engagement and willingness to fully participate in learning activities 
(Ng et al., 2022). It is crucial that educational institutions implement 
robust data protection measures and provide clear information to stu-
dents about how their data is used and safeguarded.
Teachers, too, are affected by data privacy issues, as they handle and 
store a significant amount of personal data related to their students. 
Teachers are often required to use various digital tools and platforms to 
track student progress, communicate with parents, and manage class-
room activities (Miao et al., 2021). These tools can collect sensitive in-
formation, which poses a risk if not adequately protected. According to 
Wu (2022), teachers must be trained not only in the use of these tech-
nologies but also in understanding and implementing data privacy 
protocols. This includes ensuring that data is stored securely, accessed 
only by authorized individuals, and used ethically in accordance with 
institutional policies. Teachers must comply with data protection reg-
ulations, such as the Family Educational Rights and Privacy Act (FERPA) 
in the U.S. (Toriano, 2007), which requires obtaining written consent 
before disclosing student information.
Fig. 4 shows the best practices for using AI tools in education include 
anonymizing data, using secure platforms, and reviewing privacy pol-
icies. Empirical examples highlight that some institutions effectively 
implemented AI-driven systems while maintaining compliance by 
enforcing data governance policies like encrypting sensitive information 
(Yanamala, 2023). Additionally, workshops on data privacy can foster 
transparency and empower students to understand the implications of AI 
technologies. By adopting these strategies, teachers can responsibly 
integrate AI into their classrooms while protecting student privacy.
3.1.1.5. Regulation and Monitoring. Effective regulation and monitoring 
ensure that AI tools are employed in a manner that aligns with educa-
tional objectives while safeguarding against potential risks and ethical 
concerns. Guidelines are essential, as emphasized by various sources, 
including UNESCO (2023) and Miao et al. (2023), and should address 
key areas like data protection, privacy, and preventing over-reliance on 
AI—issues highlighted by the European Union’s General Data Protection 
Regulation (GDPR). Monitoring mechanisms are equally crucial. In the 
U.S., for instance, AI tools used in classrooms are routinely assessed 
through initiatives like the Ed Tech Impact platform to ensure effec-
tiveness, accuracy, and to identify potential biases in AI algorithms. 
Baidoo-Anu and Ansah (2023) emphasize the need for regular evalua-
tions to ensure that AI applications support rather than replace tradi-
tional teaching methods, fostering student learning outcomes.
Fig. 4. AI data protection practices.
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 8 ---

Furthermore, Celik (2023) recommends creating accountability 
frameworks that hold AI providers responsible for addressing ethical 
concerns. The Accountability in AI Act proposed by the Canadian gov-
ernment, although not yet fully proposed, serves as a model for ensuring 
transparency and fairness in AI deployment in schools (Government of 
Canada, 2023). Such oversight mechanisms ensure that AI doesn’t un-
dermine critical thinking, problem-solving, and argumentation skills, 
which are central to education (Funa & Prudente, 2021; Funa et al., 
2024; Ramallosa et al., 2022). Continuous improvement of AI policies is 
also vital. For example, Singapore’s Ministry of Education regularly 
updates its AI guidelines based on the latest technological advancements 
and ethical challenges, ensuring relevance and effectiveness (Galindo 
et al., 2021). This dynamic approach ensures that AI integration in ed-
ucation not only enhances the learning experience but also addresses 
ethical and practical concerns. Thus, comprehensive regulation, 
continuous monitoring, and adopting best practices from various global 
frameworks are key to harnessing AI’s potential while ensuring 
responsible and equitable use in education.
3.1.2. AI literacy
As AI technologies become more prevalent, it is essential that both 
students and teachers develop a deep understanding of how these tools 
function, their applications, and their potential implications for privacy 
and ethics (Celik, 2023). AI literacy equips students with the skills 
necessary to interact with AI tools critically and responsibly. This in-
cludes the ability to assess the credibility of AI-generated content and 
recognize potential biases or inaccuracies. Ong et al. (2024) highlights 
the importance of incorporating AI literacy into the curriculum. 
Training students in fact-checking and critical questioning is crucial as 
AI tools become more integrated into educational practices. This 
training may not only help students navigate the complexities of AI but 
also ensures they are prepared to engage with these technologies in a 
manner that supports rather than undermines their educational devel-
opment. The UP (2024) reinforces this view by advocating for AI to 
support learner-centered approaches and enhance competency assess-
ment. This approach underscores the need for students to be equipped 
with skills that enable them to critically engage with AI technologies.
3.1.2.1. AI integration in the curriculum. The integration of AI into the 
curriculum is increasingly seen as essential for preparing students to 
thrive in a technology-driven world. Current educational policies 
emphasize the importance of equipping students with AI-related skills, 
enabling them to effectively navigate and harness these technologies. 
However, as the UPLB Graduate School (2024) cautions, while AI tools 
can greatly enhance academic work, they should not replace students’ 
intellectual engagement. This view aligns with Miao et al. (2021) and 
Wise et al. (2024), who argue that AI should complement, not substitute, 
core educational values such as critical thinking, creativity, and auton-
omy. In addition, Rybinski and Kopciuszewska (2020) propose that AI 
can play a supportive role in skills development across disciplines, 
noting that AI-driven tools, if integrated thoughtfully, can enrich the 
curriculum by offering personalized learning experiences and immedi-
ate feedback. However, they also caution that AI must be implemented 
in ways that align with traditional academic standards. Crawford et al. 
(2024), on the other hand, argue that while AI can complement the 
curriculum, it should not replace core competencies; instead, it should 
reinforce foundational skills and knowledge rather than serve as a 
shortcut or crutch. By following these recommendations, AI can become 
a powerful tool to support learning while preserving students’ cognitive 
efforts and the integrity of the learning process.
Despite the advantages, the integration of AI into curricula presents 
challenges, particularly the risk of misuse if AI tools are not properly 
regulated. Chan (2023) underscores the need for designing assessments 
that promote academic integrity, ensuring that AI does not enable un-
ethical behavior such as plagiarism or excessive dependence on 
automated tools. Similarly, Ng et al. (2023) advocate for continuous 
professional development for educators to keep pace with rapid tech-
nological advancements. Ensuring that teachers remain AI-literate is 
critical to fostering responsible AI use and guiding students in using 
these tools effectively.
In alignment with UNESCO’s guidelines (2023), AI literacy should be 
introduced at developmentally appropriate stages, with a recommended 
minimum age of 13. This approach ensures that AI education matches 
students’ cognitive development, allowing them to grasp foundational 
concepts before gradually advancing to more complex topics as their 
cognitive skills mature (Kim et al., 2022; Su et al., 2024). By introducing 
AI at this age, educators can build a solid foundation in logical thinking, 
problem-solving, and ethical considerations before diving into pro-
gramming and real-world applications.
However, Su and Zhong (2022) argue for an earlier introduction, 
suggesting that AI concepts can be introduced as early as kindergarten. 
At this stage, AI education focuses on basic concepts and engaging ac-
tivities, such as pattern recognition or simple decision-making pro-
cesses, which are developmentally suitable for young learners. In 
contrast, AI education in secondary and higher education tends to 
emphasize programming skills and the practical applications of AI 
technologies (Su & Zhong, 2022).
The debate between these approaches reflects differing views on how 
to balance the benefits of early exposure to AI with the cognitive read-
iness of young students. Introducing AI concepts at a young age can 
spark curiosity and foster early interest in technology (Gao et al., 2024), 
but it must be done carefully to avoid overwhelming students or sacri-
ficing depth in later stages of education. Thus, a phased approach (Chiu, 
2021) and gradual implementation (Rybinski & Kopciuszewska, 
2020)—tailoring AI literacy to different developmental stages—may be 
an effective way to cultivate AI understanding and skills over time.
3.1.2.2. AI orientation and training for teachers and students. The inte-
gration of AI in education requires comprehensive orientation and 
training for both teachers and students to fully maximize its benefits and 
address potential challenges. Before using AI tools, orientation for both 
groups are essential to familiarize them with AI’s capabilities, limita-
tions, and ethical considerations. This initial preparation helps students 
understand AI’s role in their learning process and encourages respon-
sible use, reducing the risk of misuse (Baidoo-Anu & Ansah, 2023; Chan, 
2023). For example, documents in this meta-synthesis suggest that AI in 
education should be aligned with learner needs and enhance compe-
tency assessments, emphasizing that schools must ensure students are 
adequately prepared to engage with AI tools responsibly (Elsevier, 2024; 
Miao et al., 2021; UP, 2024).
Teacher training, on the other hand, should focus not only on 
developing technical skills but also on understanding AI’s pedagogical 
implications. Miao et al. (2023) and Wise et al. (2024) advocate for 
training programs that equip teachers to use AI tools effectively while 
maintaining control over their application. This ensures that AI sup-
plements rather than replaces traditional teaching methods. Chan 
(2023) and Crawford et al. (2024) similarly highlight the need to pre-
pare educators to navigate the ethical dimensions of AI technologies and 
to design assessments that minimize the potential for AI misuse.
Beyond initial training, ongoing skill development is crucial for both 
teachers and students. AI technologies evolve rapidly, and continuous 
updates to training programs are necessary to stay aligned with these 
changes. Celik (2023) stresses the importance of regular professional 
development for teachers to remain current with AI advancements and 
pedagogical strategies, while Su et al. (2022) emphasize that continuous 
learning opportunities are key to supporting effective AI curriculum 
implementation.
3.1.3. Inclusivity and equity
AI tools should be designed to accommodate diverse learning needs 
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 9 ---

and backgrounds, thereby enhancing learner-centered approaches and 
competency assessments for underrepresented groups (UP, 2024). For 
example, adaptive learning platforms can customize educational content 
to match individual students’ proficiency levels, providing additional 
support to those who might struggle with standard materials. Further-
more, Wise et al. (2024) emphasize that AI should be implemented in 
ways that enhance inclusivity by providing equitable support to diverse 
learners. They note, “AI tools can help bridge learning gaps if applied 
thoughtfully, but their use must be monitored to avoid reinforcing 
existing disparities.” Such tools ensure that all students, regardless of 
their socio-economic status, have equal access to high-quality education. 
Crawford et al. (2024) and UNESCO (2023) highlights the importance of 
addressing challenges such as AI subscription costs to bridge the digital 
divide and ensure equal opportunities for all students.
AI tools must also cater to various learning styles and needs. Text-to- 
speech and speech-to-text applications, for instance, assist students with 
learning disabilities by providing alternative ways to engage with con-
tent. Ng et al. (2023) advocate for integrating AI literacy into the cur-
riculum, which helps students develop critical engagement skills. For 
example, AI-driven simulations in science classes allow students to 
interact with virtual experiments, accommodating different learning 
preferences. Kim et al. (2022) emphasize that AI-enhanced tasks should 
promote critical thinking and creativity. AI-powered brainstorming as-
sistants, which help students generate and refine ideas, ensure equitable 
access to educational benefits.
However, inclusivity and equity in AI tools must also address issues 
of gender bias. For example, many AI systems, including voice assistants 
like Siri, have been criticized for reinforcing gender stereotypes by using 
female voices and names (Manasi et al., 2022). Such biases can 
perpetuate gender stereotypes and affect students’ perceptions of gender 
roles. Further, according to Rybinski and Kopciuszewska (2020), AI 
systems tend to mirror the biases present in their training data, which 
can lead to unfair treatment of underrepresented groups. This underlines 
the need for equitable design in AI tools to prevent unintended biases 
that could negatively impact certain student populations. Hence, pol-
icies should ensure that AI systems are designed to avoid reinforcing 
stereotypes and instead support gender neutrality. Ensuring that AI tools 
are gender-inclusive involves designing systems that provide neutral 
options and avoid bias in their interactions.
When integrating AI into classroom instruction, it is essential to 
design adaptable tools that address diverse learning needs. AI-driven 
personalized learning systems, for instance, can adjust task complexity 
based on students’ proficiency levels, thereby accommodating various 
educational needs. Policies suggest developing AI-enhanced materials 
that prioritize accessibility and fairness. Berendt et al. (2020) recom-
mend ensuring that AI tools respect students’ rights and autonomy, such 
as providing options for students to opt out of data collection. Addi-
tionally, tools that support collective learning, like collaborative 
AI-driven project platforms, can enhance inclusivity. Su et al. (2022)
highlights those interactive methods, such as gamification and 
project-based learning, can boost understanding of AI concepts and 
promote equitable learning outcomes by making the learning process 
engaging and inclusive for all students.
3.2. Implementation strategies
The integration of AI in education requires thoughtful implementa-
tion strategies to enhance both teaching and learning experiences. This 
section focuses on key strategies for successfully implementing AI in 
educational settings, including student orientation and teacher profes-
sional development, enhancing teaching tools and providing data-driven 
insights, improving student learning outcomes, and streamlining 
administrative processes.
3.2.1. Student orientation and professional development
The findings from various sources underscore the importance of 
preparing students to effectively engage with AI tools. Integrating AI 
into curricula should involve clear guidelines for students on the ethical 
and practical use of these technologies (Miao et al., 2023). This prepa-
ration includes training students to understand AI’s capabilities and 
limitations, ethical considerations and practical applications, ensuring 
they are equipped to use AI responsibly and effectively (Wise et al., 
2024). UNESCO (2023) similarly emphasizes the importance of a 
structured orientation program to mitigate potential issues related to 
over-reliance on AI and the digital divide. Several sources highlight 
successful practices in student orientation. For instance, Chan (2023)
advocates for a balanced approach where AI is used as a supplementary 
tool rather than a replacement for traditional learning methods. This 
orientation should include training students on proper attribution of 
AI-generated content and the importance of maintaining academic 
integrity. Furthermore, Wu (2023) suggests that student orientation 
should also focus on cognitive load management to prevent information 
overload and encourage active learning strategies that complement AI 
tools.
Professional development for teachers is equally crucial in the suc-
cessful integration of AI into teaching and learning. According to Celik 
(2023) and Rybinski and Kopciuszewska (2020), professional develop-
ment programs should cover both the technical and pedagogical aspects 
of AI, without compromising academic standards. This includes training 
teachers on how to integrate AI into lesson plans, assess AI tools’ 
effectiveness, and address ethical considerations related to AI use. Kim 
et al. (2022) highlights that professional development should be 
continuous and aligned with the latest advancements in AI technology. 
This ensures that educators remain updated on new tools and method-
ologies, enhancing their ability to provide relevant and effective in-
struction. Ng et al. (2023) further recommend that professional 
development programs should include collaborative efforts with tech-
nology companies and universities to design and implement AI 
curricula, thus creating a robust support system for educators. In addi-
tion, according to Berendt et al. (2020), educators must be trained to 
handle issues related to data privacy and the ethical use of AI, ensuring 
that AI integration does not infringe on students’ rights or autonomy. 
This training should be comprehensive, covering the development of AI 
tools, their application in classrooms, and strategies to maintain aca-
demic integrity.
3.2.2. Enhance teaching tools and data-driven insights
The integration of AI into educational settings has significantly 
advanced the development of teaching tools and data analytics, forming 
a cornerstone of effective implementation strategies. AI-driven teaching 
tools offer personalized learning experiences and support various 
instructional strategies. Generative AI models, such as Chat GPT, can 
create customized content and explanations tailored to individual stu-
dent needs (Holmes & Miao, 2023). For example, Chat GPT can generate 
diverse examples, clarify complex concepts, and provide additional 
practice problems based on students’ questions and performance. This 
capability helps teachers address student misconceptions and enhance 
lesson effectiveness by offering immediate, personalized support 
(Mollick & Mollick, 2023). Additionally, AI technologies contribute to 
creating interactive and engaging learning environments. AI-driven 
educational games, such as those developed by Dream Box Learning, 
use adaptive learning technologies to adjust game difficulty based on 
student performance (Kim et al., 2022). Chat GPT can also be integrated 
into educational apps to facilitate real-time discussions and provide 
instant feedback on written assignments, fostering critical thinking and 
creativity. This approach not only enriches the learning experience but 
also prepares students for future AI-driven workplaces by integrating AI 
concepts into the curriculum.
AI applications generate data-driven insights that are crucial for 
refining teaching strategies and improving educational outcomes. Plat-
forms like Knewton analyze student performance data to identify pat-
terns and trends, enabling educators to tailor their instruction to meet 
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 10 ---

individual needs (Ng et al., 2023). Furthermore, AI-driven analytics 
support evidence-based practices by offering comprehensive reports on 
various educational metrics. Tools such as Edmodo Insights provide 
educators with data on student engagement, assignment completion 
rates, and academic progress (Berendt et al., 2020). These insights 
enable educators to design more effective assessments and adapt 
educational materials to better meet students’ needs, ultimately 
enhancing the learning experience.
3.2.3. Improve student learning outcomes and engagement
One key finding is the emphasis on using AI to personalize and adapt 
learning experiences, which has been linked to improved student 
engagement (Gao et al., 2024) and outcomes. For instance, Ng et al. 
(2023) highlight the importance of developing AI curricula that incor-
porate interactive and engaging teaching methods, such as gamification 
and 
project-based 
learning, 
to 
foster 
critical 
thinking 
and 
problem-solving skills. This approach not only aligns with educational 
standards but also enhances students’ active participation and interest in 
their learning activities. Moreover, the integration of AI tools like 
chatbots and practice platforms has been reported to facilitate more 
personalized feedback and tailored learning experiences. According to 
Wu (2023), encouraging students to use AI as a supplementary resource 
rather than a primary tool allows for a balanced approach that promotes 
critical thinking while leveraging the technology’s benefits. This strat-
egy ensures that AI tools complement rather than replace traditional 
learning methods, thereby maintaining the central role of human 
interaction and guidance.
3.2.4. Streamline administrative processes
The implementation of AI technologies in educational settings offers 
significant opportunities to streamline administrative processes, thereby 
enhancing efficiency and reducing operational burdens. Policies aimed 
at streamlining administrative processes highlight the potential for AI to 
revolutionize how educational institutions manage their operations. For 
example, UP emphasizes that AI should enhance decision-making and 
administrative efficiency while ensuring transparency and account-
ability (UP, 2024). This includes leveraging AI for tasks such as sched-
uling, resource allocation, and data management, which can help reduce 
manual workload and minimize errors. In practice, AI’s role in stream-
lining administrative tasks is evident in several areas. The integration of 
AI tools can automate routine tasks such as grading and attendance 
tracking, freeing up valuable time for educators to focus on instructional 
quality and student engagement (Chan, 2023; Rybinski & Kopciuszew-
ska, 2020). Additionally, AI can support the development of more effi-
cient communication channels between students and administrators, as 
well as between different departments within educational institutions 
(Ng et al., 2023).
3.3. Practical constraints
The implementation of AI in education faces several challenges, such 
as technical and integration issues, training and support limitations, and 
concerns about ethics and fairness. Additionally, cost and accessibility 
pose barriers, while transparency and privacy concerns require atten-
tion. There is also the possibility of misalignment with educational 
goals, which may affect the intended learning outcomes.
3.3.1. Technical and integration challenges
One primary technical challenge identified across the sources in this 
study is the disparity in technological infrastructure and resources 
available to educational institutions. For instance, Su et al. (2023) 
highlights the need for updated infrastructure and adequate tools to 
effectively integrate AI into curricula. Similarly, Ng et al. (2023) stress 
the importance of upgrading teaching equipment and incorporating 
AI-enhanced resources to create a smart learning environment. Inade-
quate technological infrastructure can hinder the adoption and effective 
use of AI tools, limiting their potential benefits and impacting educa-
tional outcomes.
Another technical challenge pertains to the compatibility and 
interoperability of AI systems with existing educational technologies. 
Chan (2023) notes that AI technologies should complement rather than 
replace traditional methods, yet the integration process often reveals 
issues related to system compatibility and user adaptation. This chal-
lenge underscores the necessity for seamless integration strategies and 
technical support to ensure that AI tools enhance rather than disrupt 
existing educational practices.
Integration challenges extend beyond technical issues to encompass 
organizational and pedagogical aspects. For example, Celik (2023) dis-
cusses the need for continuous professional development and training 
for teachers to effectively integrate AI tools into their teaching practices. 
Teachers often face difficulties in adapting to new technologies and 
integrating them into their instructional strategies, which can impede 
the successful implementation of AI policies. Effective integration re-
quires not only technical solutions but also ongoing support and pro-
fessional development to address these challenges.
Moreover, Miao et al. (2021) emphasizes the importance of main-
taining a balance between AI use and human interaction in education. 
Over-reliance on AI can reduce opportunities for critical thinking and 
peer interaction, which are essential for developing resourcefulness and 
self-efficacy in students. This challenge highlights the need for careful 
planning and management of AI integration to preserve the human el-
ements of education while leveraging technological advancements.
3.3.2. Training and support issues
A key challenge identified in the literature is the insufficient training 
provided to educators regarding AI tools and their applications in the 
classroom. According to Chan (2023), many teachers face difficulties in 
utilizing AI technologies due to inadequate initial training. This lack of 
comprehensive training limits teachers’ ability to effectively integrate 
AI into their teaching strategies, resulting in underutilization or inef-
fective application of these tools. Ng et al. (2023) also highlight that 
professional development programs often fail to cover the breadth of AI 
applications relevant to various subjects and teaching contexts, leading 
to gaps in educators’ understanding and capabilities.
Beyond initial training, ongoing support is crucial for the sustained 
integration of AI technologies in education. Su et al. (2023) emphasize 
that continuous technical and pedagogical support is necessary for 
addressing issues that arise during AI integration. Educators require 
access to resources and assistance to troubleshoot technical problems, 
adapt AI tools to their specific teaching needs, and stay updated on 
advancements in AI technology. However, many institutions lack robust 
support systems, which can result in frustration and hinder the effective 
use of AI tools in teaching. Furthermore, Celik (2023) notes that insti-
tutional support for professional development is often limited, affecting 
the quality and frequency of training opportunities available to 
educators.
3.3.3. Ethical and fairness concerns
The integration of AI in education brings with it significant ethical 
and fairness concerns that impact its practical application in teaching 
and learning environments. These concerns are central to ensuring that 
AI technologies are used in ways that promote equity and respect for all 
stakeholders. A primary ethical concern identified in the literature is the 
issue of data privacy and security. According to Crawford et al. (2024)
and Miao et al. (2021), the collection and use of student data by AI 
systems raise questions about how this data is managed and protected. 
Ensuring that student information is handled securely and ethically is 
crucial to maintaining trust and compliance with privacy regulations. 
Another ethical issue relates to the potential for bias in AI algorithms. As 
noted by Estrellado and Miranda (2023), AI systems can inadvertently 
perpetuate existing biases if not carefully designed and monitored. This 
bias can affect various aspects of education, from grading to 
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 11 ---

personalized learning recommendations, potentially disadvantaging 
certain student groups. These biases may lead to discriminatory prac-
tices (Crawford et al., 2024). Addressing this concern requires ongoing 
efforts to audit and refine AI algorithms to ensure fairness and prevent 
discrimination.
Fairness concerns in AI integration focus on ensuring equitable ac-
cess to technology and resources. As highlighted by Kabalisa and Alt-
mann (2021), disparities in access to AI tools and resources can 
exacerbate existing inequalities in education. Students from underpriv-
ileged backgrounds may have less access to AI-enhanced learning op-
portunities, further widening the educational gap. Addressing these 
disparities involves ensuring that AI technologies are accessible to all 
students and that resources are distributed fairly across different 
educational settings. Additionally, Chan (2023) emphasizes the impor-
tance of including diverse perspectives in the development and imple-
mentation of AI tools. Ensuring that AI systems reflect diverse 
viewpoints and are designed with inclusivity in mind is essential to 
preventing marginalization and promoting fairness. This approach in-
volves engaging a wide range of stakeholders in the design and evalu-
ation processes to ensure that AI tools meet the needs of all students.
3.3.4. Cost and accessibility
One of the most prominent constraints identified is the cost associ-
ated with acquiring and maintaining AI technologies. According to 
Estrellado and Miranda (2023), the initial investment required for AI 
tools and systems can be substantial, posing a barrier to adoption, 
particularly in underfunded educational institutions. This financial 
burden often limits the extent to which schools and universities can 
integrate AI into their curricula, resulting in disparities between 
well-resourced institutions and those with limited budgets. Additionally, 
ongoing costs related to software updates, system maintenance, and 
technical support further exacerbate the financial strain. As noted by 
Kabalisa and Altmann (2021), these recurring expenses can be prohib-
itive, especially for institutions with constrained financial resources. The 
high costs associated with AI technologies necessitate careful budget 
planning and financial management to ensure that institutions can 
sustain AI initiatives over the long term. Moreover, the availability of AI 
tools and resources varies significantly, with some regions and in-
stitutions having limited access to advanced technologies, including 
internet connectivity (Funa, Gabay, Esdicul, & Prudente, 2023; Funa & 
Talaue, 2021). Chan (2023) and Funa, Gabay, Deblois, et al. (2023)
highlight that disparities in technological infrastructure and internet 
connectivity can hinder the equitable distribution of AI resources, 
affecting the ability of all students and educators to benefit from these 
technologies. Furthermore, Celik (2023) emphasizes that AI tools are not 
uniformly accessible to all educators, particularly those in remote or 
underserved areas. The lack of access to AI training and professional 
development opportunities further compounds this issue, limiting the 
ability of educators to effectively use AI technologies in their teaching 
practices.
3.3.5. Transparency and privacy concerns
Transparency in AI applications within educational settings is crucial 
for ensuring that stakeholders are aware of how AI tools and systems 
operate and make decisions. Research indicates that a lack of trans-
parency can undermine trust and hinder the acceptance of AI technol-
ogies among educators and students. For example, according to Kabalisa 
and 
Altmann 
(2021), 
transparency 
issues 
arise 
when 
the 
decision-making processes of AI systems are not clearly communicated, 
leading to uncertainty and skepticism about the technology’s role in 
education. Furthermore, Nemorin (2021) highlights that effective 
transparency involves not only clear communication about how AI tools’ 
function but also the disclosure of data sources and algorithms used. 
Without this transparency, stakeholders may question the validity and 
fairness of AI-driven decisions, impacting the overall credibility and 
acceptance of AI in educational contexts.
Privacy is another critical issue associated with AI integration in 
education. The collection, storage, and use of personal data by AI sys-
tems raise significant concerns about data protection and user privacy. 
Chan (2023) emphasizes that educational institutions must implement 
robust data protection measures to safeguard sensitive information 
collected through AI tools. Failure to address privacy concerns can lead 
to data breaches and misuse, which can erode trust in AI systems and 
negatively impact student and educator engagement. Additionally, 
UNESCO (2023) points out that educational institutions must adhere to 
stringent data privacy regulations to ensure that personal information is 
handled responsibly. This involves implementing policies and practices 
that comply with legal requirements and best practices for data pro-
tection. Ensuring privacy is not only a matter of legal compliance but 
also a fundamental aspect of maintaining trust and fostering a positive 
learning environment.
3.3.6. Misalignment with educational goals
One major issue is the divergence between AI technologies and the 
core educational goals set by educational institutions. According to Chiu 
(2021), AI tools are often designed with general applications in mind, 
which may not always align with specific curriculum standards or 
learning outcomes. This misalignment can lead to the use of AI tools that 
do not adequately address the learning needs of students or support the 
educational goals of the institution. Further, Miao et al. (2021) highlight 
that AI systems sometimes prioritize efficiency and scalability over 
educational relevance, which can result in tools that streamline 
administrative tasks but offer limited pedagogical value. This 
misalignment can detract from the primary goal of enhancing student 
learning and engagement, as the focus shifts away from achieving 
educational objectives towards operational efficiency.
The misalignment between AI applications and educational goals can 
also affect learning outcomes. As noted by Chan (2023), AI tools that do 
not align with curriculum goals may lead to gaps in content coverage 
and a lack of coherence in instructional delivery. This misalignment can 
create inconsistencies in the learning experience, potentially hindering 
student achievement and overall educational effectiveness. Addition-
ally, AI technologies that are not designed with specific educational 
outcomes in mind may fail to address the diverse needs of students, 
particularly those requiring additional support. For instance, Miao et al. 
(2021) found that AI tools lacking customization for diverse learning 
needs could exacerbate educational inequities rather than mitigate 
them, thereby impacting the overall inclusivity of the educational 
process.
4. Conclusions and recommendations
This meta-synthesis provides a synthesis of research studies and re-
ports on AI in education from 2020 to 2024, with a focus on their im-
plications for teaching and learning. The analysis highlights several key 
themes, including policies and guidelines, implementation strategies, 
and practical constraints. Under the theme of policies and guidelines, 
significant subthemes include Ethical AI Use, AI Literacy, and Inclusivity 
and Equity. Ethical AI Use emphasizes the need for transparent, fair, and 
responsible AI practices that safeguard student interests and promote 
ethical decision-making. AI Literacy underscores the importance of 
integrating AI education into curricula to equip students and educators 
with the knowledge and skills necessary to navigate and leverage AI 
technologies effectively. Inclusivity and Equity highlight the necessity of 
ensuring that AI systems are designed and implemented to support 
diverse student needs and reduce educational disparities.
In terms of implementation strategies, the synthesis identifies several 
key areas: Student Orientation and Professional Development, Enhanced 
Teaching Tools and Data-Driven Insights, Improved Student Learning 
Outcomes and Engagement, and Streamlined Administrative Processes. 
Effective Student Orientation and Professional Development are crucial 
for preparing educators and students to utilize AI tools effectively. 
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 12 ---

Enhanced Teaching Tools and Data-Driven Insights can facilitate more 
personalized and effective teaching approaches, contributing to 
improved student learning outcomes and engagement. Streamlined 
Administrative Processes through AI can lead to greater efficiency and 
reduced administrative burdens, allowing educators to focus more on 
teaching.
However, practical constraints pose significant challenges to the 
successful integration of AI in education. These constraints include 
Technical and Integration Challenges, Training and Support Issues, 
Ethical and Fairness Concerns, Cost and Accessibility, Transparency and 
Privacy Concerns, and Misalignment with Educational Goals. Address-
ing Technical and Integration Challenges is vital for ensuring that AI 
systems work seamlessly within existing educational frameworks. 
Training and Support Issues must be resolved to provide adequate re-
sources and assistance to educators. Ethical and Fairness Concerns need 
to be carefully managed to prevent bias and ensure equitable outcomes. 
Cost and Accessibility issues require attention to ensure that AI tools are 
available to all educational institutions, regardless of their financial 
status. Transparency and Privacy Concerns must be addressed to protect 
student data and ensure that AI systems operate with clarity and 
accountability. Finally, aligning AI implementation with educational 
goals is essential to ensure that AI technologies enhance rather than 
detract from educational objectives.
Based on the findings, several recommendations emerge to guide the 
effective integration of AI in education. Emerging economies should 
prioritize AI implementation at basic educational levels, while devel-
oped countries are encouraged to conduct research that can inform 
evidence-based policies, serving as models for others. Establishing clear 
guidelines on ethical AI use is crucial, with a strong emphasis on 
providing comprehensive training for both teachers and students on the 
appropriate use of AI, ensuring clarity on when and how these tools 
should be employed. There should be a requirement for students to 
declare their use of AI and for teachers to disclose the detection tools 
they utilize for identifying AI-generated content and plagiarism. It is 
important to define the consequences of AI misuse and set clear 
boundaries regarding the extent to which AI can be involved in aca-
demic work. Additionally, data management protocols must be estab-
lished, ensuring that the information of all stakeholders is handled 
transparently and securely in AI analysis.
AI literacy should be tailored to different developmental stages, and 
educators must receive ongoing training on how to effectively integrate 
AI into teaching practices. To ensure that AI aligns with educational 
goals, it is recommended that both internal and external bodies be 
established to oversee the implementation of AI tools and evaluate their 
compatibility with educational objectives. It is also essential that AI 
systems be designed to accommodate diverse learning needs, including 
those of students with learning disabilities, while also mitigating gender 
bias and addressing the digital divide. Programs should be developed to 
promote responsible AI use, highlighting its ethical implications, and 
encouraging the adoption of AI-driven tools to enhance administrative 
efficiency. To support these efforts, funding must be allocated to 
improve access to necessary technology, and partnerships between 
educational institutions, policymakers, and technology providers should 
be fostered to facilitate the sharing of best practices in AI integration. 
Future research should explore the long-term impacts of AI integration 
on educational outcomes, particularly focusing on how AI influences 
student learning, teacher practices, and equity in access to education 
across diverse socioeconomic contexts.
CRedi T authorship contribution statement
Aaron A. Funa: Writing – review & editing, Writing – original draft, 
Methodology, Investigation, Formal analysis, Data curation, Conceptu-
alization. Renz Alvin E. Gabay: Conceptualization, Investigation, Re-
sources, Validation, Writing – review & editing.
Declaration of competing interest
The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper.
References
Alvero, A. J., Arthurs, N., Lising, A., Domingue, B. W., Gebre-Medhin, B., Giebel, S., & 
Stevens, M. L. (2020). AI and holistic review: Informing human reading in college 
admissions. In Proceedings of the 2020 AAAI/ACM conference on AI. Ethics, and 
Society (AIES). https://doi.org/10.1145/3375627.3375871. 
Baidoo-Anu, D., & Ansah, L. O. (2023). Education in the era of generative artificial 
intelligence (AI): Understanding the potential benefits of Chat GPT in promoting 
teaching and learning. Journal of AIDS, 7(1), 52–62. https://doi.org/10.2139/ 
ssrn.4337484
Berendt, B., Littlejohn, A., & Blakemore, M. (2020). AI in education: Learner choice and 
fundamental rights. Learning, Media and Technology, 45(3), 312–324. https://doi. 
org/10.1080/17439884.2020.1786399
Braun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative 
Research in Psychology, 3(2), 77–101. https://doi.org/10.1191/1478088706qp063oa
Celik, I. (2023). Towards intelligent-TPACK: An empirical study on teachers’ professional 
knowledge to ethically integrate artificial intelligence (AI)-based tools into 
education. Computers in Human Behavior, 138, Article 107468. https://doi.org/ 
10.1007/s40670-023-01786-z
Chan, C. K. Y. (2023). A comprehensive AI policy education framework for university 
teaching and learning. International Journal of Educational Technology in Higher 
Education, 20(1), 38. https://doi.org/10.1186/s41239-023-00408-3
Chaudhry, M. A., Cukurova, M., & Luckin, R. (2022). A transparency index framework 
for AI in education. In International conference on artificial intelligence in education (pp. 
195–198). Cham: Springer International Publishing. 
Chiu, T. K. (2021). A holistic approach to the design of artificial intelligence (AI) 
education for K-12 schools. Tech Trends, 65(5), 796–807. https://doi.org/10.1007/ 
s11528-021-00637-1
Crawford, J., Allen, K. A., Pani, B., & Cowling, M. (2024). When artificial intelligence 
substitutes humans in higher education: The cost of loneliness, student success, and 
retention. Studies in Higher Education, 49(5), 883–897. https://doi.org/10.1080/ 
03075079.2024.2326956
Elsevier. (2024). The use of generative AI and AI-assisted technologies in writing for 
Elsevier. Retrieved June 2024, from https://www.elsevier.com/about/policies-and- 
standards/the-use-of-generative-ai-and-ai-assisted-technologies-in-writing-for-el 
sevier.
Estrellado, C. J., & Miranda, J. C. (2023). Artificial intelligence in the Philippine 
educational context: Circumspection and future inquiries. International Journal of 
Scientific and Research Publications, 13(5). https://doi.org/10.29322/ 
IJSRP.13.04.2023.p13704
Funa, A. A., Gabay, R. A. E., Deblois, E. C. B., Lerios, L. D., & Jetomo, F. G. J. (2023). 
Exploring Filipino preservice teachers’ online self-regulated learning skills and 
strategies amid the COVID-19 pandemic. Social Sciences & Humanities Open, 7(1), 
Article 100470. https://doi.org/10.1016/j.ssaho.2023.100470
Funa, A. A., Gabay, R. A. E., Esdicul, K. L., & Prudente, M. S. (2023). Secondary teachers’ 
and students’ perceptions of distance education in science: Focus on learner- 
centered, action-oriented, and transformative learning. Dalat University Journal of 
Science, 156–181. https://doi.org/10.37569/Dalat University.13.3.1108, 2023.
Funa, A. A., & Prudente, M. S. (2021). Effectiveness of problem-based learning on 
secondary students’ achievement in science: A meta-analysis. International Journal of 
Instruction, 14(4). https://doi.org/10.29333/iji.2021.1445a
Funa, A. A., Roleda, L. S., & Prudente, M. S. (2024). Integrated science, technology, 
engineering, and mathematics—problem-based learning—education for sustainable 
development (I-STEM-PBL-ESD) framework. In A diversity of pathways through science 
education (pp. 151–172). Singapore: Springer Nature Singapore. 
Funa, A., & Talaue, F. (2021). Constructivist learning amid the COVID-19 pandemic: 
Investigating students’ perceptions of biology self-learning modules. International 
Journal of Learning, Teaching and Educational Research, 20(3), 250–264. https://doi. 
org/10.26803/ijlter.20.3.15
Galindo, L., Perset, K., & Sheeka, F. (2021). An overview of national AI strategies and 
policies. OECD going digital toolkit notes, No. 14. Paris: OECD Publishing. https://doi. 
org/10.1787/c05140d9-en
Gao, L., Xuehui, L´opez-P´erez, M. E., Melero-Polo, I., & Trifu, A. (2024). Ask Chat GPT 
first! Transforming learning experiences in the age of artificial intelligence.  Studies 
in Higher Education, 1–25. https://doi.org/10.1080/03075079.2024.2323571
Government of Canada. (2023). The artificial intelligence and data Act (AIDA) – 
companion document. Retrieved (October 06, 2024) https://ised-isde.canada.ca/site 
/innovation-better-canada/en/artificial-intelligence-and-data-act-aida-compan 
ion-document.
Guo, T. (2015). Alan Turing: Artificial intelligence as human self-knowledge. 
Anthropology Today, 31(6), 3–7. https://doi.org/10.1111/1467-8322.12209
Harzing, A. W. (2007). Publish or perish software. Retrieved from https://harzing.com/ 
resources/publish-or-perish.
Holmes, W., & Miao, F. (2023). Guidance for generative AI in education and research. 
UNESCO Publishing. https://unesdoc.unesco.org/ark:/48223/pf0000386693. 
Huang, A. Y., Lu, O. H., & Yang, S. J. (2023). Effects of artificial intelligence–enabled 
personalized recommendations on learners’ learning engagement, motivation, and 
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221 

--- Page 13 ---

outcomes in a flipped classroom. Computers & Education, 194, Article 104684. 
https://doi.org/10.1016/j.compedu.2022.104684
Jiang, W., & Pardos, Z. A. (2021). Towards equity and algorithmic fairness in student 
grade prediction. In Proceedings of the 2021 AAAI/ACM conference on AI, ethics, and 
society (AIES ’21) (p. 10). ACM. https://doi.org/10.1145/3461702.3462623. 
Kabalisa, R., & Altmann, J. (2021). AI technologies and motives for AI adoption by 
countries and firms: A systematic literature review. In Economics of grids, clouds, 
systems, and services: 18th international conference, GECON 2021, virtual event, 
september 21–23, 2021, proceedings (Vol. 18, pp. 39–51). Springer International 
Publishing. https://doi.org/10.1007/978-3-030-92916-9_4
Kim, J., Lee, H., & Cho, Y. H. (2022). Learning design to support student-AI 
collaboration: Perspectives of leading teachers for AI in education. Education and 
Information Technologies, 27(5), 6069–6104. https://doi.org/10.1007/s10639-021- 
10831-6
Lin, P., & Van Brummelen, J. (2021). Engaging teachers to co-design integrated AI 
curriculum for K-12 classrooms. In Proceedings of the 2021 CHI conference on human 
factors in computing systems (pp. 1–12). https://doi.org/10.1145/3411764.3445377
Manasi, A., Panchanadeswaran, S., Sours, E., & Lee, S. J. (2022). Mirroring the bias: 
Gender and artificial intelligence. Gender, Technology and Development, 26(3), 
295–305. https://doi.org/10.1080/09718524.2022.2128254
Miao, F., Holmes, W., Huang, R., & Zhang, H. (2021). AI and education: Guidance for 
policymakers. UNESCO Publishing. 
Mollick, E. R., & Mollick, L. (2023). Using AI to implement effective teaching strategies in 
classrooms: Five strategies, including prompts. The Wharton School Research Paper. 
https://doi.org/10.2139/ssrn.4391243
Nemorin, S. (2021). Fair-AI: Project update #6. Preliminary findings. Retrieved from 
https://www.fair-ai.com/projectupdate-6.
Ng, D. T. K., Lee, M., Tan, R. J. Y., Hu, X., Downie, J. S., & Chu, S. K. W. (2023). A review 
of AI teaching and learning from 2000 to 2020. Education and Information 
Technologies, 28(7), 8445–8501. https://doi.org/10.1007/s10639-022-11491-w
Nguyen, H. M., & Goto, D. (2024). Unmasking academic cheating behavior in the 
artificial intelligence era: Evidence from Vietnamese undergraduates. Education and 
Information Technologies, 29, 15999–16025. https://doi.org/10.1007/s10639-024- 
12495-4
OECD.AI.. (2021). Database of national AI policies. Retrieved https://oecd.ai. (Accessed 
30 June 2024).
Ong, Y. S., Tan, T. T. M., & Lee, Y. J. (2024). A diversity of pathways through science 
education. Singapore: Springer. https://doi.org/10.1007/978-981-97-2607-3
Page, M. J., Mc Kenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., 
… Thomas, J. (2021). The PRISMA 2020 statement: An updated guideline for 
reporting systematic reviews. BMJ, 372, n71. https://doi.org/10.1136/bmj.n71
Ramallosa, J. M., Funa, A. A., Geron, A. T., Ibardaloza, R. T., & Prudente, M. S. (2022). 
Meta-Analysis on the effectiveness of argument-based learning on students’ 
conceptual understanding. In Proceedings of the 2022 13th international conference on 
E-education, E-business, E-management, and E-learning (pp. 315–323). https://doi.org/ 
10.1145/3514262.3514305
Rother, E. T. (2007). Systematic literature review X narrative review. Acta Paulista de 
Enfermagem, 20. https://doi.org/10.1590/S0103-21002007000200001. v–vi.
Rybinski, K., & Kopciuszewska, E. (2020). Will artificial intelligence revolutionise the 
student evaluation of teaching? A big data study of 1.6 million student reviews. 
Assessment & Evaluation in Higher Education, 46(7), 1127–1139. https://doi.org/ 
10.1080/02602938.2020.1844866
Sandelowski, M., & Barroso, J. (2006). Handbook for synthesizing qualitative research. 
Springer Publishing Company. 
Sharma, H., Soetan, T., Farinloye, T., Mogaji, E., & Noite, M. D. F. (2022). AI adoption in 
universities in emerging economies: Prospects, challenges and recommendations. In 
Re-imagining educational futures in developing countries: Lessons from Global Health 
crises (pp. 159–174). Cham: Springer International Publishing. 
Springer. (2024). Artificial intelligence (AI). Retrieved August 2024, from https://www. 
springer.com/gp/editorial-policies/artificial-intelligence–ai-/25428500.
Su, J., & Zhong, Y. (2022). Artificial Intelligence (AI) in early childhood education: 
Curriculum design and future directions. Computers & Education: Artificial 
Intelligence, 3, Article 100072. https://doi.org/10.1016/j.caeai.2022.100072
Su, J., Zhong, Y., & Ng, D. T. K. (2022). A meta-review of literature on educational 
approaches for teaching AI at the K-12 levels in the Asia-Pacific region. Computers & 
Education: Artificial Intelligence, 3, Article 100065. https://doi.org/10.1016/j. 
caeai.2022.100065
Tong, A., Flemming, K., Mc Innes, E., Oliver, S., & Craig, J. (2012). Enhancing 
transparency in reporting the synthesis of qualitative research: Entreq. BMC Medical 
Research Methodology, 12, 181. https://doi.org/10.1186/1471-2288-12-181
Toriano, G. (2007). Family educational rights and privacy Act (FERPA). Journal of 
Empirical Research on Human Research Ethics, 2, 101. Retrieved: https://coursedo 
g-static-public.s3.us-east-2.amazonaws.com/bellarmine_colleague_ethos/2007-9 
_Catalog2028129.pdf.
Tossell, C. C., Tenhundfeld, N. L., Momen, A., Cooley, K., & de Visser, E. J. (2024). 
Student perceptions of Chat GPT use in a college essay assignment: Implications for 
learning, grading, and trust in artificial intelligence. IEEE Transactions on Learning 
Technologies.
UNESCO. (2023). Education in the age of artificial intelligence. UNESCO Publishing. https 
://unesdoc.unesco.org/ark:/48223/pf0000387029_eng. 
University of the Philippines Los Ba˜nos (UPLB) Graduate School. (2024). Recommended 
use of AI tools in graduate studies [Facebook post]. Retrieved July 2024, from htt 
ps://www.facebook.com/share/h Ds XVCgk EUCNX1NM/?mibextid=WC7FNe.
University of the Philippines (UP). (2024). University of the Philippines principles for 
responsible and trustworthy artificial intelligence. Retrieved July 2024, from https 
://up.edu.ph/up-principles-for-responsible-artificial-intelligence/.
Wise, B., Emerson, L., Van Luyn, A., Dyson, B., Bjork, C., & Thomas, S. E. (2024). 
A scholarly dialogue: Writing scholarship, authorship, academic integrity and the 
challenges of AI. Higher Education Research and Development, 43(3), 578–590. 
https://doi.org/10.1080/07294360.2023.2280195
Wu, Y. (2023). Integrating generative AI in education: How Chat GPT brings challenges 
for future learning and teaching. Journal of Advanced Research in Education, 2(4), 
6–10. https://doi.org/10.56397/JARE.2023.07.02
Xie, X., & Wang, T. (2024). Artificial intelligence: A help or threat to contemporary 
education. Should students be forced to think and do their tasks independently? 
Education and Information Technologies, 29(3), 3097–3111. https://doi.org/10.1007/ 
s10639-023-11947-7
Xie, Y., Wu, S., & Chakravarty, S. (2023). AI meets AI: Artificial Intelligence and 
academic integrity—a survey on mitigating AI-assisted cheating in computing 
education. In Proceedings of the 24th annual conference on information technology 
education (pp. 79–83). https://doi.org/10.1145/3585059.3611449
Yanamala, A. K. Y. (2023). Secure and private AI: Implementing advanced data 
protection techniques in machine learning models. International Journal of Machine 
Learning Research in Cybersecurity and Artificial Intelligence, 14(1), 105–132. 
Retrieved: https://ijmlrcai.com/index.php/Journal/article/view/25.
Zhai, X., Chu, X., Chai, C. S., Jong, M. S. Y., Istenic, A., Spector, M., … Li, Y. (2021). 
A review of artificial intelligence (AI) in education from 2010 to 2020. Complexity, 
2021(1), Article 8812542. https://doi.org/10.1155/2021/8812542
Zheng, L., Niu, J., Zhong, L., & Gyasi, J. F. (2021). The effectiveness of artificial 
intelligence on learning achievement and learning perception: A meta-analysis. 
Interactive Learning Environments, 31(9), 5650–5664. https://doi.org/10.1080/ 
10494820.2021.2015693
A.A. Funa and R.A.E. Gabay                                                                                                                                                                                                                
Social Sciences & Humanities Open 11 (2025) 101221
