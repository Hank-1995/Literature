# Fostering responsible AI literacy: A systematic review of K-12 AI ethics education

## Metadata
- **Author**: Ming Ma
- **Subject**: Computers and Education: Artificial Intelligence, 8 (2025) 100422. doi:10.1016/j.caeai.2025.100422
- **Creator**: Elsevier
- **Producer**: Acrobat Distiller 8.1.0 (Windows)
- **Creation Date**: D:20250612063344Z
- **Modification Date**: D:20250612080003Z
- **Source File**: Fostering-responsible-AI-literacy--A-systemat_2025_Computers-and-Education--.pdf
- **Converted**: 2025-10-23 22:46:14

---

## Content

--- Page 1 ---

Fostering responsible AI literacy: A systematic review of K-12 AI 
ethics education
Ming Ma a,*
, Davy Tsz Kit Ng b
, Zhichun Liu a
, Gary K.W. Wong a
a Faculty of Education, The University of Hong Kong, Hong Kong Special Administrative Region of China
b Department of Mathematics and Information Technology, The Education University of Hong Kong, Hong Kong Special Administrative Region of China
A R T I C L E  I N F O
Keywords:
AI ethics education
K-12 literacy
Responsible AI
Systematic review
A B S T R A C T
AI ethics education remains significantly underprioritized in classroom practice, despite the global push for AI 
literacy in K-12 curricula. This systematic review analyzes 68 peer-reviewed publications (from January 2014 to 
March 2025) to map the research landscape of K-12 AI ethics education. The results reveal global trends in the 
current research landscape, pedagogical designs addressing major responsible AI (RAI) principles, and various 
learning assessment methods, and students’ ethical learning outcomes manifested across cognitive, affective, and 
behavioral domains. By further synthesizing findings, we identify disparities of eastern and western contexts, 
gaps in addressing RAI principles and emerging ethical issues, limitations of methodological methods, and issues 
in assessing ethical learning outcomes. Building on this synthesis, we propose a competency-based responsible AI 
literacy framework that reconceptualizes AI ethics as a transformative learning dimension that progressively 
permeates all the learning dimensions of AI literacy development. The framework also provides actionable in-
sights to empower K-12 educators and policymakers in fostering students’ responsible AI literacy. The review 
concludes with three future research directions to advance this critical field.
1. Introduction
Artificial intelligence (AI) is transforming nearly every aspect of 
human society, delivering significant economic and societal benefits 
Tomaˇsev et al. (2020), while simultaneously raising complex ethical, 
legal, and governance challenges (Coeckelbergh, 2020; Qian et al., 
2024). AI was first defined in 1956 as the science and engineering of 
making intelligent machines (Ng et al., 2021). Over the decades, AI has 
evolved into sophisticated machines and algorithms capable of 
reasoning and adapting based on rules and inputs to mimic human in-
telligence. Mikalef and Gupta (2021), which defines AI as a system that 
can identify, interpret, make inferences, and learn from data to achieve 
predetermined organizational and societal goals. This highlight AI’s 
socio-technical and socio-cultural nature, emphasizing the interplay 
between technology, cultural context, and the social systems it in-
fluences (Dolata et al., 2022; Kim & Lee, 2024; Sartori & Theodorou, 
2022). The rapid advancement of AI has intensified global efforts to 
incorporate AI education into K-12 curricula in recent years, equipping 
teachers and students with essential AI literacy and competency (Miao & 
Shiohira, 2022).
While AI provides efficiency and convenience in our daily lives, 
workplaces, and learning environments, its malicious use can result in 
negative consequences. To address this, researchers have particularly 
emphasized the importance of AI ethics (Borenstein et al., 2021) and 
considered it as an essential component of AI literacy (Ng et al., 2021). 
In the early years, AI ethics seeks to mitigate the negative consequences 
brought by AI development, such as algorithmic bias, privacy violations, 
lack of opacity, and risks of manipulation (Coeckelbergh, 2020; Müller, 
2020). The recent rise of large language models (LLMs) like Chat GPT, a 
class of generative AI (Gen AI) systems trained on large text corpora to 
produce human-like language outputs, has further expanded AI’s ethical 
complexities, introducing concerns such as AI hallucinations, copyright 
infringement, and the erosion of human creativity (Hagendorff, 2024; 
Peng & Zhao, 2024). Together, these issues underscore the essence to 
implement AI ethics education, empowering people to critically 
examine AI’s societal implications as responsible digital citizens 
(Borenstein & Howard, 2021). In K-12 education, the global push of 
cultivating AI literacy for K-12 students are expected to prepare them 
with fundamental understanding and awareness about AI ethics 
(Dabbagh et al., 2024).
However, despite wide recognition on its importance of AI literacy 
conceptual frameworks (e.g., Chan, 2023; Kong & Zhang, 2021; Ng 
* Corresponding author.
E-mail address: mingma@connect.hku.hk (M. Ma). 
Contents lists available at Science Direct
Computers and Education: Artificial Intelligence
journal homepage: www.sciencedirect.com/journal/computers-and-education-artificial-intelligence
https://doi.org/10.1016/j.caeai.2025.100422
Received 1 January 2025; Received in revised form 12 May 2025; Accepted 17 May 2025  
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 
Available online 20 May 2025 
2666-920X/© 2025 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by- 
nc-nd/4.0/ ). 

--- Page 2 ---

et al., 2021), AI ethics education remains markedly absent from most AI 
teaching and learning classroom practices worldwide, revealing a crit-
ical gap between its theoretical recognition and practical implementa-
tion. UNESCO’s 2022 analysis of government-endorsed K-12 AI 
curricula revealed that despite strong policy commitments, AI ethics and 
societal impacts receive minimal instructional time, averaging 24 % of 
overall AI teaching content (Miao & Shiohira, 2022). Implementation 
challenges are evident across diverse contexts: in the United States, 
some teachers report confusions in delivering ethics-focused curricula, 
for example MIT’s AI ethics middle school program (Miao & Shiohira, 
2022; Williams et al., 2021). The disparity is even more pronounced in 
China, where video analyses of 98 AI literacy lessons show just 5.1 % 
address AI ethics, while higher-order competencies (Evaluating & 
Creating AI at 35.71 %) appear much less frequently than basic com-
petencies (Knowing & Understanding AI and Using & Applying AI, both 
at 93.88 %) (Wu et al., 2024). This pattern culminates in concerning 
outcomes: an AI education survey conducted in Qingdao, China, found 
that near-total absence of AI ethics teaching in K-9 classrooms, resulting 
in ‘almost zero’ students’ awareness of the ethical issue around AI (Gong 
et al., 2020).
These gaps highlight the urgent need for a systematic review of AI 
ethics education to inform educators to teach AI ethics in K-12 settings 
and foster well-round AI literacy. While existing reviews have explored 
broader aspects of AI education (e.g., Casal-Otero et al., 2023; Li et al., 
2024; Liu & Zhong, 2024; Ng et al., 2023), none have comprehensively 
examined (1) the pedagogical designs for specific AI ethics topics across 
diverse cultural and curricular contexts, (2) the evaluation methods 
employed for assessing ethical learning, and (3) the ethical learning 
outcomes engaged with overall AI literacy development. To address 
these gaps, this review synthesizes current empirical studies of K-12 AI 
ethics education.
2. Literature review
2.1. AI literacy
Although there is no consensus in defining AI literacy yet, AI ethics is 
widely acknowledged as a critical component of AI literacy frameworks 
(Almatrafi et al., 2024; Yim, 2024a). In the early years, AI literacy or 
education was viewed from technological and cognitive dimensions. The 
Five Big Ideas framework pioneered by AI4K-12 experts positions the 
“Societal Impact of AI”, highlighting both positive and negative conse-
quences of AI applications as a central learning dimension, surrounded 
by four technical dimensions: Perception, Representation & Reasoning, 
Learning, and Natural Interaction (Touretzky et al., 2019). Building on 
this, Long and Magerko (2020) proposed a working definition of AI 
literacy as “a set of competencies that enables individuals to critically eval-
uate AI technologies; communicate and collaborate effectively with AI; and 
use AI as a tool online, at home, and in the workplace” (p. 2), implicitly 
integrating ethical considerations. They further identified ethics as one 
of the seventeen key competencies under How Should AI Be Used? 
—specifically, Competence 16 (Ethics) – “identify and describe different 
perspectives on the key ethical issues surrounding AI (i.e. privacy, employ-
ment, misinformation, the singularity, ethical decision making, diversity, 
bias, transparency, accountability)." However, this overlaps with other 
competencies of other categories, such as Competency 6 (Imagine future 
AI), which involves envisioning AI’s future societal impacts, and Com-
petency 13 (Critically Interpreting Data), which emphasizes questioning 
data validity.
Subsequent frameworks have further refined the role of AI ethics by 
explicitly distinguishing it as a distinct domain separate from technical 
knowledge or skills. Wong et al. (2020) introduced a succinct 
three-dimensional AI literacy model (i.e., AI knowledge, AI applications, 
and AI safety & ethics), while Chiu (2021) outlined a curriculum design 
framework encompassing Knowledge in AI, Process in AI, Impact of AI. 
Kong and Zhang (2021) identified three core components—AI concepts, 
evaluation, and problem-solving—while emphasizing the need to “pro-
tect benefits and privacy” (p. 1), reinforcing ethical considerations. 
Similarly, Yue et al. (2025) expanded this into a four-dimensional model 
(i.e., AI knowledge, skills, ethics, and attitudes). Other frameworks adopt a 
competence-based approach but similarly isolate ethics as a critical 
domain: Ng et al. (2021)’ aligned AI literacy with Bloom’s Taxonomy 
(Bloom et al., 1956), structuring competencies into four tiers: Knowing & 
understanding AI, Using & applying AI, Evaluating & creating AI, and AI 
ethics, while Carolus et al. (2023) conceptualized AI literacy with four 
similar domains: Using & applying AI, Understanding AI, Detecting AI, and 
Ethics. Ng, Wu, et al. (2024) further extended the digital AI literacy to 
other dimensions such as affective, behavioral, and ethical learning 
domains (see Fig. 1) and updated their formerly proposed AI literacy 
framework proposed in 2021.
However, these conceptualizations share a less examined facet: the 
ethical dimension, which holds systemic importance yet remains 
ambiguously intertwined with other domains, whether foundational 
knowledge (e.g., understanding algorithmic bias), user attitudes (e.g., 
critically evaluating AI systems), or practical applications (e.g., ethically 
deploying tools). Recent studies highlight ethics’ growing prominence. 
Chan (2023) defined an AI-literate learner as one who comprehends AI 
terminology, uses applications critically, discerns realistic AI capabilities, and 
prioritizes safety, security, and responsible use. O’Dea et al. (2024) argued 
that ethical dimensions should span cognitive domains, highlighting the 
need for users to understand ethical principles, apply AI applications 
responsibly, and create ethical artifacts and systems. This needs further 
effort to specify the exact AI ethical knowledge, skills, and attitudes 
required for each cognitive phase. To address this, our study adopts Ng, 
Wu, et al. (2024)’s framework while advancing a key reconceptualiza-
tion: rather than treating ethics as a compartmentalized domain, we 
position it as a transformative dimension that actively intersects with 
and enriches all facets of AI literacy development. This perspective po-
sitions ethical considerations as: (1) integral to cognitive understandings 
(e.g., interrogating training data biases), (2) foundational to affective 
attributes (e.g., fostering ethical awareness), and (3) inseparable from 
behavioral engagements (e.g., embedding human values when 
designing models). It addresses the current limitation by making ethics 
both more explicit in each learning dimension and more cohesive across 
the entire AI literacy framework.
2.2. Review studies of K-12 AI education
Although numerous literature reviews on K-12 AI education have 
been published in recent years, none of them systematically examine AI 
ethics education as a central learning domain. Existing studies pre-
dominantly suffer from two critical limitations: First, while pre-2022 
empirical studies on K-12 AI education existed, few specifically inves-
tigated ethics components, resulting in superficial treatment that posi-
tions AI ethics as a peripheral subtopic rather than documenting what 
ethical concepts are taught or how they’re delivered, as clearly evi-
denced by their quantitative analyses. For example, Rizvi et al. (2023)’s 
systematic review of AI teaching and learning identified only 7 empirical 
studies (2019–2022) addressing socio-ethical aspects, compared to 24 
studies on AI applications and 27 on AI models. Similarly, Casal-Otero 
et al. (2023) found merely 6 articles among their 179 reviewed docu-
ments, addressing ethical and societal implications of student learning 
experiences focused on understanding AI. These marginalizations per-
sists in results sections of these review studies (e.g., Ng et al., 2023; Su 
et al., 2023; Tan & Tang, 2024; Yue et al., 2022), typically limited to 
single-paragraph mentions in most of these studies without breaking 
down into specific ethical topics and teaching pedagogies, despite 
frequent acknowledgments of ethics’ importance in discussion and im-
plications sections, indicating a troubling disconnect between recog-
nized priorities and research findings.
Second, although existing literature has provided comprehensive 
syntheses of K-12 AI education as a whole, few studies have specifically: 
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 3 ---

(1) critically evaluated pedagogical designs for teaching AI ethics- 
related topics, or (2) systematically analyzed how students engage 
with ethical learning across developmental stages through cognitive, 
affective, and behavioral dimensions. For instance, Lee and Kwon 
(2024) identified several ethical issues taught in K-12 classrooms but 
presented them through overlapping, poorly differentiated categories (i. 
e., AI ethics and bias, societal considerations, social impacts and chal-
lenges of AI, and ethical implications). Although their study explored 
linkages between ethical learning and critical thinking, its narrow 
sample of AI ethics studies (n = 6) precluded meaningful analysis of how 
these ethical competencies develop across age groups. On the other 
hand, Liu and Zhong (2024) advanced this work by systematically 
mapping AI learning content—including Knowledge in AI, Impact of AI, 
Process in AI—across grade bands. However, while they analyzed 
age-appropriate progression of students’ learning outcomes, their study 
did not identify the specific ethical topics taught when briefly summa-
rizing the Impact of AI domain. These oversights neglect the nuanced 
nature of ethical issues surrounding AI, blurring this domain into an 
undifferentiated whole rather than examining how specific ethical 
principles (e.g., fairness, transparency) are taught and learned across 
developmental stages.
2.3. Responsible AI principles
In response to the increasing ethical challenges and societal impacts 
brought by AI, terms such as ‘Ethical AI’, ‘Trustworthy AI’, and 
‘Responsible AI (RAI)’, often used interchangeably (Díaz-Rodríguez 
et al., 2023; Dignum, 2019; Mc Govern et al., 2022), have emerged as 
guiding sets of standards for the research, creation, deployment, and use 
of AI in ways that aligns with human values. The International Orga-
nization for Standardization (ISO) defines responsible AI as “An 
approach to developing and deploying artificial intelligence from both 
an ethical and legal standpoint. The goal is to employ AI in a safe, 
trustworthy and ethical way (ISO, 2023)." RAI extends beyond the dis-
cussion of AI ethics by emphasizing the integration of ethical consider-
ations into practical design and implementation, ensuring that AI 
technologies are developed and applied responsibly (Mikalef et al., 
2022; Peters et al., 2020).
Companies and organizations worldwide have established their own 
RAI guidelines. For instance, OECD (2021) supports RAI through four 
main pillars: Inclusive Growth, Sustainable Development, & Well-being, 
Human-centered Values & Fairness, Transparency & Explainability, and 
Robustness, Security, & Safety. Microsoft released their RAI standard with 
six adherences: Accountability, Transparency Fairness, Inclusiveness, Reli-
ability & Safety, Privacy & Security. UNESCO (2022) outlines ten ethical 
AI principles to align with the UN’s sustainable development goals 
(SDGs), including Proportionality & Do No Harm, Safety & Security, 
Fairness & Non-discrimination, Sustainability, Right to Privacy & Data 
Protection, Human Oversight & Determination, Transparency & Explain-
ability, Responsibility & Accountability, Awareness & Literacy, and 
Multi-stakeholder, Adaptive Governance & Collaboration. While these 
frameworks vary in structure, they converge on core ethical imperatives: 
ensuring AI benefits society while mitigating risks.
Recently, Papagiannidis et al. (2025) distilled seven core pillars of 
RAI principles from 48 foundational documents on AI governance, 
including: Accountability, Human agency and oversight, technical robust-
ness and safety, Privacy and data governance, Transparency, Diversity, 
Non-discrimination, and fairness, and Societal and environmental well-being. 
Accountability refers to establishing clear responsibility for AI system 
outcomes and addressing harms. Human agency and oversight emphasize 
maintaining meaningful human control over AI systems. Technical 
robustness and safety require AI to perform reliably under varying con-
ditions with safeguards against failures. Privacy and data governance 
involves ethical collection, use, and protection of personal data 
throughout the AI lifecycle. Transparency means AI systems should be 
understandable and their decision-making processes explainable. Di-
versity, non-discrimination and fairness entail preventing biased or 
exclusionary outcomes in AI systems. Societal and environmental well--
being consider the broader impacts of AI on communities and ecosys-
tems, including sustainability concerns.
In the education arena, the call-to-actions of introducing RAI in ed-
ucation are gaining momentum (Pargman et al., 2024). Nevertheless, 
most studies focus on proposing the ethical principles for applying AI in 
Education (AIED) (e.g., Adams et al., 2023; An et al., 2024; Nguyen 
et al., 2023). While there is a study of introducing RAI in higher edu-
cation teaching and practices (Aler Tubella et al., 2024), it does not 
extend to K-12 educational contexts. Most recently, Fu and Weng (2024)
identified five key characteristics of RAI in education through synthesis 
of 40 K-20 studies; however, although they include a few studies of AI 
ethics education, the study have yet to examine the effects of the 
pedagogical designs for addressing these ethical principles.
2.4. The present study
According to previous sections, existing studies lack systematic ex-
amination of key pedagogical designs, assessment methods, and learning 
Fig. 1. The ABCE AI literacy Framework modified from Ng, Wu, et al. (2024).
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 4 ---

outcomes specifically addressing K-12 AI ethics education. This gap 
leaves an incomplete understanding of how AI ethics is taught and 
assessed in K-12 settings, as well as how ethical learning outcomes 
contribute to students’ developing AI literacy across cognitive, affective, 
and behavioral domains. To address these limitations, this study con-
ducts a systematic review of empirical research on AI ethics education in 
K-12, addressing core RAI principles (Papagiannidis et al., 2025) and 
ABCE AI literacy framework (Ng, Wu, et al., 2024) By synthesizing 
existing work, this study seeks to overview the global trends of K-12 AI 
ethics education, identify effective practices and assessments, and 
highlight areas needing further development to advance AI literacy in 
alignment with RAI Principles. Specifically, this study seeks to answer 
the following research questions: 
1. What are the key trends in the current empirical research on teaching 
and learning AI ethics in K-12 education settings, across various 
cultural and curricular contexts?
2. What are pedagogical designs for teaching and learning AI ethics in 
K-12 settings, addressing key responsible AI principle pillars?
3. What evaluative methods are employed to assess students’ ethical 
learning across cognitive, affective, and behavioral domains?
4. What are the ethical learning outcomes across K-12 students’ 
developmental stages, in terms of AI literacy development?
By addressing these questions, this review addresses the critical gap 
in examining K-12 AI ethics education. It advances AI literacy research 
by demonstrating how AI ethics progressively permeate all aspects of AI 
literacy development. The practical implications provide K-12 educators 
and policymakers with evidence-based insights for designing develop-
mentally appropriate ethical learning experiences that foster responsible 
AI literacy.
3. Method
This review was carried out in four stages: data collection, data se-
lection, data extraction, and data analysis, in accordance with the 
Preferred Reporting Items for Systematic Reviews and Meta-Analyses 
(PRISMA) guidelines (Page et al., 2021).
3.1. Data collection
We searched four databases (i.e., Scopus, Web of Science, IEEE, 
ERIC) in March 2025 using Boolean-connected terms covering (1) AI and 
subdomains, (2) Ethics-related terms, (3) teaching and learning activ-
ities, and (4) K-12 education (see Table 1 for full terms).
3.2. Data selection
The study selection occurred in two stages: (1) Preliminary screening 
stage: we retained studies published between January 2014 and March 
2025 (including pre-access) that were English-written, peer-reviewed 
articles/conference proceedings related to AI or education, with dupli-
cates removed; (2) Eligibility assessment stage: we applied the criteria 
outlined in Table 2 to examine the titles/abstracts, followed by full-text 
review, excluding review articles, opinion papers, and studies not 
addressing AI ethics teaching/learning in K-12 contexts. The final corpus 
comprised 68 studies, including 48 journal articles and 20 conference 
papers. The details of data collection and data selection are illustrated in 
the PRISMA diagram (see Fig. 2).
3.3. Data extraction
The extraction process occurred in two stages: (1) Demographic in-
formation (per-study analysis) capturing publication details (title, year, 
country/region, article type), educational context (grade levels, set-
tings), and research methods; followed by (2) Detailed data extraction 
(per-case analysis) for some studies involving multiple teaching & 
learning cases, organized into five categories as specified in Table 3.
3.4. Data analysis
The analysis employed distinct coding schemes for each research 
question: (1) For RQ1, descriptive statistics and keyword frequency 
analysis identified key trends in K-12 AI ethics education research; (2) 
For RQ2, we first categorized the teaching and learning activities ac-
cording to the seven pillars of RAI principles, then employed an induc-
tive approach to identify the pedagogical designs that address each 
principle; (3) For RQ3, we categorized the assessment methods of AI 
ethics education used by researchers to evaluate students’ performance 
in the cognitive, affective, and behavioral domains, based on Ng, Wu, 
et al. (2024)’s AI literacy framework; (4) For RQ4, deductive qualitative 
content analysis applied the same framework to trace ethical learning 
progression across all three domains.
The first and second authors independently reviewed and catego-
rized the papers according to the established coding scheme. All dis-
crepancies were resolved through discussion between the two coders, 
with inter-coder reliability of Cohen’s Kappa coefficient (0.88), indi-
cating the high-level of agreement between them. After completing the 
coding process, the findings were descriptively analyzed focusing on 
frequency, identified categories and exemplar excerpts.
4. Results
4.1. The key trends of current research in K-12 AI ethics education (RQ1)
This section analyzes publications on AI ethics education in K-12 
settings, exploring yearly trends, global distribution, research methods, 
and mapping out the learning contexts with K-12 developmental stages. 
We highlight key patterns in the reviewed studies and compare the 
differences across various educational contexts.
Table 1 
The search terms.
Categories
Search terms
AI
(“Artificial Intelligence” OR “Machine Learning” OR “Deep 
Learning” OR “Neural networks” OR “Natural Language 
Processing” OR “Generative AI” OR “Large language 
models")
Ethics
(“Ethics” OR “Ethical issues” OR “Societal implications” OR 
“Social impact” OR “Socio-technical” OR “Socio-cultural")
Teaching & Learning 
activities
(“Teaching” OR “Learning” OR “Education” OR 
“Curriculum” OR “Curricula” OR “Workshop” OR 
“Activities")
K-12 education
(“K-12″ OR "K12″ OR “High school” OR “Secondary school” 
OR “Middle school” OR “Primary school” OR “Elementary 
school” OR “Kindergarten” OR “Preschool")
Table 2 
Inclusion and exclusion criteria.
Inclusion criteria
Exclusion criteria
Empirical studies that involve K-12 
students as participants.
Review studies 
Conceptual/Opinion paper 
Editorials/comments
Primarily focusing on teaching and 
learning AI ethics
Ethics of applying AI in Education 
Using Gen AI to facilitate learning other 
subjects 
Discussing human-AI relationship in 
education
Formal/Informal K-12 educational 
settings
Higher Educational levels 
Adult Education 
Tertiary Education
Teaching and learning programs including 
AI ethics or social implications of AI
Survey studies without implementation 
AI education studies without any 
details related to ethical dimension
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 5 ---

As illustrated in Fig. 3, research on AI ethics education in K-12 set-
tings has grown steadily since its inception, reflecting increasing 
scholarly engagement with this emerging field. The first study appeared 
in 2019, marking the beginning of dedicated inquiry in this domain. 
Early contributions were sparse and predominantly conference papers. 
In 2020, the field expanded slightly with 1 journal article and 6 con-
ference papers, followed by a modest increase in 2021 (3 journal articles 
and 7 conference papers). A pivotal shift occurred in 2022 when journal 
articles (n = 11) first outnumbered conference papers (n = 2), signaling 
the burst of interest. This trend continued in 2023 (15 journal articles 
and 1 conference paper) and 2024 (11 journal articles and 5 conference 
papers). Preliminary data of 2025 (up to March) includes 2 published 
journal articles and 3 pre-proofs, suggesting a sustained momentum in 
this critical area of research.
As illustrated in Fig. 4, the United States dominates the field with 28 
of the 68 reviewed studies, reflecting its prominent role in shaping 
discourse on AI ethics education. In Asia, Hong Kong emerges as a 
regional leader with 12 studies, followed by China (5), South Korea (2), 
Japan (1), India (1), and Taiwan (1). European contributions are more 
evenly distributed, with Denmark (3), Finland (2), Spain (3), Greece (2), 
and smaller outputs from Ireland (2), Sweden (1), and the United 
Kingdom (1). Nigeria stands out in Africa with 3 published studies, while 
the Middle East (Israel, 1) and Latin America (Brazil, 1) show early but 
limited engagement.
Regarding the research methods (see Table 4), 25 employed quali-
tative approaches to explore students’ ethical learning process, offering 
in-depth insights into shifts in their perceptions and understandings of 
these topics. Quantitative methods (n = 8) were used to assess key 
constructs across three domains: (1) cognitive (e.g., AI concepts, critical 
thinking), (2) affective (e.g., AI ethical awareness, attitudes toward AI), 
and (3) behavioral (e.g., behavioral intentions). Most studies (n = 35 out 
of 68) adopted a mixed-methods approach (see Table 5), collecting both 
qualitative and quantitative data from multiple sources of students’ 
learning outcomes of AI ethics education.
As detailed in Table 5, studies on AI ethics education are most 
extensively explored at the middle school level (n = 27 out of 68), where 
a significant imbalance exists between informal learning contexts (n =
19) and formal contexts (n = 8). In contrast, elementary, high school, as 
well as elementary school & middle school and middle school & high 
school levels exhibit a more balanced distribution of studies across 
formal and informal learning contexts, albeit with emerging research 
engagement. At the kindergarten level, research remains limited, with 
Fig. 2. PRISMA diagram.
Table 3 
Detailed data extraction categories.
Research Design
Participants & Learning contexts
Pedagogical 
Designs
Assessment methods
Students’ learning process
Specific research 
approaches employed
Sample size, time durations, & 
specific learning contexts
Specific teaching & 
learning activities
Assessment methods used 
to evaluate
Reported students’ learning progression of the 
ethical learning activities
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 6 ---

only three studies identified. Notably, there is one study spanning across 
K-12 and university level, an emerging attempt to explore the usage of 
LLMs’ impact on student understanding of AI ethics, across grade levels 
(Kajiwara & Kawabata, 2024).
4.2. The pedagogical designs addressed responsible AI principles (RQ2)
We analyzed 188 instances of teaching activities extracted from 68 
studies, mapping pedagogical designs to the seven responsible AI prin-
ciples across K-12 education. Through qualitative content analysis, we 
first deductively categorized these instances by the seven RAI principle 
pillars, then inductively identified 16 pedagogical designs from the in-
stances (Fig. 5), revealing how these principles translate into develop-
mentally appropriate practices. Subsequent sections detail each 
principle’s associated pedagogical designs.
Accountability. Three major pedagogical designs were spotlighted 
addressing Accountability (see Fig. 5). First, students were prompt to map 
responsibility in using AI (n = 8), particularly when they may cause 
harm. For instance, Sanusi, Omidiora, et al. (2023) had middle school 
students examine a case where their town’s police department used 
facial recognition technology. Through ethical discussion, students 
explored the risks of unjust arrests and emphasized the deploying party’s 
responsibility in addressing such concerns. However, Kajiwara and 
Kawabata (2024) identified a notable challenge for students in deter-
mining who should be responsible for using misinformation generated 
by LLMs. The second pedagogical design involved analyzing multiple 
stakeholders in the AI ecosystem (n = 5). Researchers used impact 
matrices to help students assess the roles and perspectives of different 
stakeholders in redesigning You Tube’s recommendation algorithms 
(Pang et al., 2024; Williams et al., 2023; Zhang et al., 2023). Lastly, 
prompting accountability in AI prototyping (n = 4) engaged students in 
co-design activities. For example, Bilstrup et al. (2020) engaged high 
Fig. 3. Yearly trend of publications.
Fig. 4. Global distribution of AI ethics education studies.
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 7 ---

school students to responsibly reflect on how their choices of AI algo-
rithms and datasets could lead to unintended ethical or social 
consequences.
Transparency. Two major pedagogical designs were identified 
addressing Transparency (see Fig. 5). First, the AI algorithm demystifi-
cation (n = 22) involves using various pedagogical methods to reveal the 
‘black box’ nature of AI decision-making. For example, the Neural 
Network game had students role-play as nodes in a network, passing 
information through layers to understand node, link, and layer in-
teractions (Lee et al., 2021; Zhang et al., 2023). Dai et al. (2024) and 
Zhou et al. (2025) both utilized analogy-based approaches, comparing 
human-AI decision-making and using bee pollination metaphors 
respectively, to explain how AI algorithms select similar data patterns. 
The second design (n = 14) is about explainable AI (XAI) techniques (e. 
g., Alonso, 2020; Martins et al., 2024; Ng et al., 2022). For instance, 
Melsi´on et al. (2021) used Grad-CAM, a visualized explainability tech-
nique, to demonstrate how machine learning algorithms can amplify 
gender bias, enabling students to critically evaluate AI systems.
Diversity, Non-discrimination, & Fairness. Four major pedagog-
ical designs addressing this principle in AI education were identified (see 
Fig. 5). The most common design was bias origins analysis (n = 25), 
where students interacted with tangible tools like Scratch and Google 
Teachable Machine to explore how dataset biases affect outcomes - for 
example, Ali et al. (2019) presented an Google Teachable Machine 
activities, showing middle school students how biased animal datasets 
influence AI results. The second design focused on bias identification in 
AI applications (n = 16), with pedagogical practices that guided stu-
dents to analyze daily-use platforms like You Tube, or Spotify. For 
example, high school students recognized image generators (i.e., 
DALLE-2) disproportionately represented ‘pretty girls’ as young, white 
blondes (Ali et al, 2024). The third design involved bias mitigation (n =
11), featuring structured exercises where students learned to address 
gender and racial biases through dataset curation (e.g., Alonso, 2020; 
Zhou et al., 2025). Finally, the fairness audits (n = 3) encourage students 
to design fair AI systems. For example, Skinner et al. (2020) demon-
strated a project-based learning where students assessed and redesigned 
an AI librarian system to examine fairness trade-offs.
Societal and Environmental Well-being. Two major pedagogical 
designs were identified addressing this principle (See Fig. 5). Most 
studies (n = 25) guided students in evaluating AI’s societal impacts, 
examining systems like self-driving cars, such as decision-making for 
self-driving cars (Choi et al., 2024), AI generated media by Deepfake 
(Durall Gazulla et al., 2025). For example, activities like the ‘Unantici-
pated Consequences’ exercise involved students to reflect on how poorly 
designed AI systems can lead to significant negative impacts and po-
tential of lawsuits (Lee et al., 2021). Similarly, Lin et al. (2023) used AR 
applications to facilitate dilemma discussions about automated road 
trollers’ effects on employment and local economies. Another (n = 6) 
focusing on designing AI for social or environmental good. Burriss et al. 
(2024) had middle school and high students role-play as policymakers 
analyzing gaps for teenagers in the White House Blueprint for an AI Bill 
of Rights. Both Kim and Kwon (2024) and Ng, Su, and Chu (2024)
engaged elementary and middle students to build recycle bins based on 
AI selection.
Technical robustness & safety. A few studies addressed this prin-
ciple through two pedagogical designs (see Fig. 5). The majority (n = 4) 
focused on spotting AI-generated misinformation. For example, middle 
school students analyzed how Deepfake celebrity images on social media 
can mislead audiences, emphasizing the need to evaluate the credibility 
of AI-generated content (Ali et al., 2021). The second design involved 
conducting reliability checks for AI systems. For example, students 
assessed COVID-19 information chatbots created with Microsoft Azure 
Qn A Maker, highlighting the importance of expert validation (Kong 
et al., 2024).
Privacy & Data governance. Two pedagogical designs addressing 
Privacy & Data governance were highlighted (see Fig. 5). The first 
focused on raising awareness of privacy risks. For example, students 
critically examined why their schools implemented AI-powered screen 
monitoring software that tracked activities beyond school hours without 
consent (Burriss et al., 2024). Lee et al. (2022) and Bendechache et al. 
(2021) asked students to evaluate the privacy settings and data 
trade-offs in popular AI-based applications like You Tube and Spotify. 
The second design engaged students in mitigating risks of data breaches 
(n = 4). For example, Chang et al. (2025) involved high school students 
in co-designing a classroom collaboration AI application, establishing an 
ethical privacy framework through iterative prototyping discussions. 
Kim and Kwon (2024) guided elementary students training AI models 
using non-sensitive gesture data, avoiding personal data privacy 
concerns.
Human Agency & Oversight. A distinctive pedagogical design 
addressing this principle is human-in-the-loop design (n = 6) (see 
Fig. 5). For example, Schaper et al. (2020) involved elementary students 
explore robot limitations in interpreting cultural diversity through sce-
narios involving robot presidents, highlighting the need for 
human-programmed rules. Yue et al. (2025) encouraged elementary 
students to recognize if AI-generated contents need human verification. 
Similarly, Zhou et al. (2025) engaged middle school students in 
co-designing AI systems human feedback buttons for flagging inappro-
priate AI-generated content or recommendations.
Table 4 
Research methods of included studies.
Research 
Methods
n
Studies
Mixed

Ali et al. (2019); Ali et al. (2021); Alonso (2020); Amplo 
and Butler (2023); Bendechache et al. (2021); Chiu et al. 
(2021); Choi et al. (2024); Dai et al. (2024); Dipaola et al. 
(2020); Kahila et al. (2024); Kajiwara and Kawabata 
(2024); Kim and Kwon (2024); Kong et al. (2023); 
Krakowski et al. (2022); Lee et al. (2021); Martins et al. 
(2024); Ng et al. (2022); Ng, Su, and Chu (2024); Norouzi 
et al. (2020); Shamir and Levin (2022); Su and Yang 
(2024a); Su and Yang (2024b); Van Brummelen et al. 
(2021); Zammit et al. (2022); Williams et al. (2023); 
Williams et al. (2024); Yim (2024b); Zhan et al. (2022); 
Zhang et al. (2023); Yue et al. (2025); Zhou et al. (2025); 
Kong et al. (2024); Ahuja and Kumar (2024); Zhao et al. 
(2024); Zhang et al. (2024)
Qualitative

Bilstrup et al. (2020); Burriss et al. (2024); Durall Gazulla 
et al. (2025); Henry et al. (2021); Irgens et al. (2022); 
Kaspersen et al. (2022); Kim et al. (2023); Kim et al. 
(2024); Lee et al. (2022); Relmasira et al. (2023); Reddy 
et al. (2021); Sabuncuoglu (2020); Sanusi, Omidiora, et al. 
(2023); Sanusi et al. (2024); Sanusi, Oyelere, et al. (2023); 
Schaper et al. (2020); Schaper et al. (2022); Skinner et al. 
(2020); Solyst et al. (2023); Ali, Ravi, Williams, Dipaola, 
and Breazeal (2024); Yang et al. (2024); Chang et al. 
(2025); Kim et al. (2025); Zhou et al. (2024); Zhou et al. 
(2025)
Quantitative

Fern´andez-Martínez et al. (2021); Lin et al. (2023); 
Oskotsky et al. (2022); Park and Kwon (2024); Xia et al. 
(2022); Melsi´on et al. (2021); Zammit et al. (2022); Dai 
(2024)
Table 5 
Sums of learning contexts and grade levels.
Grade Levels
Formal
Formal & Informal
Informal
Across K-12



Elementary School



Elementary & Middle



Kindergarten



Middle School



Middle & High



High School



M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 8 ---

4.3. Assessment methods to measure AI ethics development (RQ3)
We categorized methods for evaluating ethical AI learning into three 
domains: cognitive, attitudinal, and behavioral (Ng, Wu, et al., 2024), 
Ng, Wu, et al., 2024ligned with specific assessment targets (see Table 6), 
including both quantitative and qualitative methods. For cognitive 
domain, researchers focused on assessing students’ cognitive under-
standing of AI ethics. For example, Lee et al. (2021) and Zhang et al. 
(2023) who administered the AI Concept Inventory (AI-CI) to evaluate 
students’ comprehension of AI concepts and their ethical and societal 
implications, and triangulated the results of open-end survey and 
semi-structured interviews. Martins et al. (2024) applied a scoring 
rubric to evaluate student-developed machine learning models based on 
criterions of originality and design appropriateness, with analyzing the 
semi-structured interviews of students’ reflections on the design process 
and their evolving understanding of machine learning concepts. Lin 
et al. (2023) employed higher-order thinking tendency questionnaire, 
which include five key dimensions: creativity tendency, team cooperation 
tendency, communicative tendency, metacognitive awareness, complex 
problem-solving tendency. Ng et al. (2022) analyzed the narratives of the 
digital stories created by students to showcase their understanding of AI 
and its societal implications.
For affective attributes, researchers examined shifts in students’ at-
titudes, values, or perceptions toward AI. The most important construct 
is ethical awareness, which refers to students’ values and attitudes to-
ward AI ethical issues, including their ability to identify, assess, and 
respond to these issues responsibly (Stahl, 2021). For example, Kong 
et al. (2023) used a pre- and post-ethical awareness survey with 12 
items, guided by ethical principles of human autonomy, beneficence of AI, 
and fairness of AI, whereas Dai et al. (2024) assessed ethical awareness 
by employing scenario-based multiple-choice questions, requiring stu-
dents to analyze real-life situations and make ethical decisions. In 
another study, Dai (2024) measured the change of students learning 
attitudes, using three questionnaires: AI learning confidence (AICF), 
intrinsic motivation to learn AI (AIIM), and AI learning anxiety (AIAX). 
Lee et al. (2021) administered AI career futures survey to explore stu-
dents’ awareness of AI-related careers, the skills required for those roles, 
and their career motivations in STEM fields. Kajiwara and Kawabata 
Fig. 5. Map of K-12 pedagogical designs addressing responsible AI principles.
Table 6 
Assessment methods employed by researchers.
Assessed 
Changes
Research 
Methods
Examples
Sample studies
Cognitive 
domains
Quantitative
- AI concept inventory 
(AI-CI)
- Scoring Rubric
- Higher-order thinking 
tendency 
questionnaire
Lee et al. (2021); 
Zhang et al. (2023); 
Martins et al. 
(2024); 
Lin et al. (2023).
Qualitative
- Student-created 
artifacts
- Open-ended survey
- Semi-structed 
interviews
Ng et al. (2022); 
Irgens et al. (2022); 
Martins et al. 
(2024); 
Zhang et al. (2023); 
Kim et al. (2023)
Affective 
domains
Quantitative
- Ethical awareness
- Learning Attitudes
- Self-efficacy/ 
confidence
- Technology 
acceptance
- Career interest in AI
- AI for social good
Kong et al. (2023); 
Dai et al. (2024); 
Dai (2024); (Yue 
et al., 2025) 
Kim and Kwon 
(2024); 
Kajiwara and 
Kawabata (2024); 
Lee et al. (2021); 
Kim and Kwon 
(2024)
Qualitative
- Reflection paper
- Art creations
- Group discussions
Bilstrup et al. 
(2020); 
Yim (2024); Ali 
et al. (2024); 
Durall Gazulla et al. 
(2025).
Behavioral 
domains
Quantitative
- Lag Sequential 
analysis
- Behavioral Intentions
- Dispositional 
autonomy
Lin et al. (2023); 
Kim and Kwon 
(2024); 
Zhou et al. (2025)
Qualitative
- Observation of design
- Embodied Activities
Kaspersen et al. 
(2022); Pang et al. 
(2024); 
Kim et al. (2025); 
Zhou et al. (2025)
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 9 ---

(2024) adopted a questionnaire-based survey to measure students’ 
acceptance of LLMs, focusing on their perceptions of social impact, per-
formance expectancy, effort expectancy, and attitudes towards LLM use. Kim 
and Kwon (2024) measured students’ self-efficacy and motivation for 
use AI for social good. In terms of qualitative methods, researchers 
analyze the aesthetics, symbolism, and choices made during the design 
process can uncover underlying values and attitudes of students towards 
AI ethics (e.g., Bilstrup et al., 2020; Durall Gazulla et al., 2025; Yim, 
2024a). For example, Ali et al. (2024) analyzed students’ discussions of 
the AI-generated images they created depicting their dream jobs, along 
with their reflections on how these tools might transform future creative 
professions.
Regarding behavioral domains, researchers focus on analyzing 
changes in students’ behaviors or behavioral intentions. For example, 
Lin et al. (2023) employed lag sequential analysis (LSA) to examine 
student behavioral patterns in the ethical dilemma-based discussion 
activity, which helps track and identify key sequences of actions or re-
sponses that contributed to effective ethical learning. Kim and Kwon 
(2024) assessed students’ AI readiness and behavioral intentions in 
learning AI before and after curriculum implementation of AI curricu-
lum with tangible tools. Notably, Zhu et al. (2025) measured changes in 
children’s dispositional autonomy, which represents their intentional 
inclinations to determine their own actions when interacting with AI 
systems. Kaspersen et al. (2022) recorded students’ discussions during 
collaborative design activities, analyzing critical incidents related to the 
application of machine learning concepts during the design process. Kim 
et al. (2025) and Zhou et al. (2025) recorded and analyzed students’ 
interactions of embodied learning activities in stimulating AI 
algorithms.
4.4. Students’ ethical learning outcomes (RQ4)
Our analysis of learning outcomes from 68 studies across diverse 
contexts reveals that ethical learning outcomes manifest through three 
dimensions: cognitive gains (e.g., understanding algorithmic fairness), 
affective shifts (e.g., increased ethical awareness), and behavioral 
changes (e.g., implementing accountable designs). These manifestations 
can be further mapped across progressive competence levels of AI lit-
eracy development: from knowing & understanding AI to applying & 
using AI, and ultimately to evaluating & creating. Representative ex-
amples are detailed in Table 7.
Knowing & Understand AI. After receiving AI ethics education, 
students developed a fundamental understanding of AI’s socio-technical 
nature. In the cognitive domain, students shifted from perceiving AI as 
inherently objective to recognizing its potential biases, data misuse, and 
the importance of ethical considerations (Kim et al., 2023). In the 
affective domain, Dai et al. (2024) found that an analogy-based 
approach of teaching fundamental concepts of AI significantly 
improved upper elementary students’ AI ethical awareness (p < 0.05,
Cohen’s d = 0.95). In a subsequent study, she reported that dual-contrast 
approach significantly improved girls’ ethical awareness in the experi-
mental group, F(1, 143) = 30.26; p < .001, η2
p = .18, though no sig-
nificance difference with boys F(1, 143) = 1.49; p = .22, η2
p = .01 (Dai, 
2024). Kong et al. (2023) claimed that secondary students have diffi-
culty in understanding abstract ethical principles comparing to univer-
sity students in their previous studies. After they modified their teaching 
methods with project-based learning, they reported a significant in-
crease 
in 
secondary 
students’ 
comprehension 
of 
AI 
ethics 
(
Mdiff = 0.09, Z = −2.73, p < 0.01
)
(Kong et al., 2024). In the behav-
ioral domain, Pang et al. (2024) observed that female students of color 
were particularly active in identifying and discussing bias in AI systems. 
Solyst et al. (2023) found that girls in their workshop readily pinpointed 
potential harms from digital assistant technology, whereas most chil-
dren aged 7–11 who typically prioritize playing with AI over considering 
technical drawbacks. Kim et al. (2025) demonstrated an episode of 
students’ embodied learning activities, where the disagreements be-
tween “AI agent” and “labeler” roles exposed inherent biases in classi-
fication tasks when distinguishing student hair colors.
Using & Applying AI. Students demonstrated the competency of 
responsible and ethical use of AI tools, considering ethical data usage. In 
the cognitive domain, Kajiwara and Kawabata (2024) reported that 
around 70 % of students understood the importance of proper data 
management and minimizing harm when using Chat GPT. Yue et al. 
(2025) demonstrated that students reflected on the consequences and 
social impact of using AI, especially in the scenarios involving image 
recognition, with questioning the accuracy. In the affective domain, they 
also revealed that students held more rational and neutral attitudes to-
ward AI, in terms of certain items, such as “AI system can outperform 
human” (from 3.50 to 3.02), “I shiver with discomfort when I think 
about future uses of AI” (from 3.10 to 2.67). Kim and Kwon (2024) re-
ported 
that 
students’ 
self-efficacy 
in 
learning 
AI 
(
F [1, 112] = 28.85, p < 0.001, η2
p = 0.21
)
and motivations to use AI for 
social good 
(
F [1, 112] = 20.45, p < 0.001, η2
p = 0.15
)
significantly 
improved after using tangible computing tools. In the behavioral 
domain, Ali et al. (2021) found no significant change in the survey of 
middle school students’ ability to detect AI-generated pictures after the 
Spot the Deepfakes activity (54.68 to 53.87,p = .488), whereas students 
highlighted impersonation and misinformation as key harms, with one 
student suggesting government regulation to counter Deepfakes.
Evaluate & Create AI. Students developed the competency to 
Table 7 
Examples of AI ethics learning outcomes in K-12 education.
AI literacy 
competencies
Cognitive outcomes
Affective outcomes
Behavioral outcomes
Knowing & 
Understanding 
AI
Students demonstrated an increased 
understanding of AI’s socio-technical nature, 
recognizing that AI is not inherently objective but 
reflects the biases of its creators and the training 
datasets (Kim et al., 2025; Sanusi, Oyelere et al., 
2023; Yim, 2024b).
Students’ ethical awareness significantly 
increased after learning fundamental AI 
concepts, as exemplified by human-AI 
comparisons and analogies discussions (Dai, 
2024; Dai et al., 2024).
Students actively participated in or group 
discussions, or embodied activities particularly the 
ones who are from underrepresented groups (Kim 
et al., 2025; Pang et al., 2024; Solyst et al., 2023).
Using & Applying
Students understood the importance of proper 
data management and the potential harms, such 
as, bias of generated contents, misinformation, 
issues of plagiarisms when using generative AI (Ali 
et al, 2024; Kajiwara & Kawabata, 2024; Yue 
et al., 2025).
Students’ self-efficacy in learning AI and 
motivations for using AI for social good 
significantly improved, as exemplified by their 
engagement in manipulating tangible 
computing tools (Kim & Kwon, 2024).
Students made their commitments to responsible AI 
use through their choices and actions by actively 
recognizing AI-generated misinformation on social 
media (Ali et al., 2021).
Evaluating & 
Creating AI
Students showed an increased AI ethical reasoning 
capability and higher-order thinking tendency 
after participating AR-based dilemma-based 
discussion of real-world examples. (Lin et al., 
2023).
Students demonstrated increased career interest 
in AI-related careers, as becoming responsible 
creators of accountable AI systems for human 
well-being (Pang et al., 2024; Park & Kwon, 
2024).
Students conducted audits of AI systems they 
designed, evaluate datasets for representativeness, 
and propose solutions and reducing potential ethical 
issues (Alonso, 2020; Bilstrup et al., 2020; Yue et al., 
2025).
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 10 ---

critically evaluate AI systems and design AI with ethical principles. In 
cognitive domain, Lin et al. (2023) found that elementary students in 
AR-based ethical dilemma discussions showed greater higher-order 
thinking skills tendency, scoring significantly higher on post-tests than 
the mobile app control group 
(
F = 4.420, p = .004, η2
p = 0.05
)
. In the 
affective domain, students are motivated to purse AI-related careers to 
address AI ethics issues. For example, Park and Kwon (2024) reported 
that their AI education program for South Korean middle school stu-
dents, focused on AI’s social impact, ethics, physical computing, and 
problem-solving, led to significant increases in students’ “interest in 
technology” (3.96 to 4.17, p < 0.05) and “career aspirations in tech-
nology” (3.83 to 4.12, p < 0.01). In the behavioural domain, students 
actively engaged in evaluating AI systems and their design decisions 
with a critical perspective. For example, Kaspersen et al. (2022)
observed that students questioned the fairness and accuracy of pre-
dictions based on limited data and the potential for bias of the results 
produced by Votestrates ML for democratic elections. Kahila et al. (2024)
also observed that students critically test classifiers, explain observa-
tions, and iteratively refine apps—enabling them to analyze model 
behavior, identify training data biases, and understand data-to-output 
relationships for responsible AI development. Yue et al. (2025) re-
ported that four students critically recognized potential malicious use 
risks in their AI product designs, by bad people like poachers.
5. Discussion
By further synthesizing the findings, this discussion examines four 
prominent gaps identified in the current empirical research of K-12 AI 
ethics education: (1) East-West contextual disparities, (2) Gaps in 
addressing RAI principles and emerging LLMs’ ethical challenges, (3) 
methodological limitations, (4) Issues in assessing ethical learning 
outcomes.
5.1. East-West contextual disparities of K-12 AI ethics education
Our systematic comparison reveals distinct cultural approaches to AI 
ethics education between Western and Eastern contexts. In Western 
settings, particularly the U.S. and Europe, AI ethics education predom-
inantly occurs in informal learning contexts such as after-school work-
shops and summer school programs, often emphasizing critical 
engagement with specific ethical issues like bias, privacy, and societal 
well-being (e.g., Bendechache et al., 2021; Chang et al., 2025; Durall 
Gazulla et al., 2025; Lee et al., 2022). This approach is exemplified by 
students identifying how generative AI applications perpetuate beauty 
standards by defaulting to white, blonde features for “pretty girls” (Ali et 
al, 2024), as well as projects where African American students develop 
community-specific applications to address local inequities (Pang et al., 
2024). Such activities often involve ethnically diverse participants to 
mirror multicultural demographics (e.g., Lee et al., 2021; Zhang et al., 
2023).
By contrast, Eastern education systems, particularly in Hong Kong, 
China, and South Korea, typically integrate AI ethics into formal class-
room curricula as part of holistic AI literacy frameworks (e.g., Chiu, 
2021; Dai, 2024; Kong et al., 2023; Yue et al., 2025). Here, the focus 
shifts toward broader societal impacts, examining issues like algorithmic 
fairness in food delivery platforms (Zhu et al., 2025) or ethical dilemmas 
for autonomous vehicles (Lin et al., 2023)—topics that resonate with 
these regions’ rapid AI adoptions. Student projects often prioritize social 
benefits in a broader sense, as seen in environmental well-being initia-
tives like AI recycling bins (Kim & Kwon, 2024; Ng, Su, & Chu, 2024). 
The disparities between eastern and western contexts suggest a cultur-
ally responsive design to approach K-12 AI ethics education in the future 
research and curriculum development (Eguchi et al., 2021).
5.2. Gaps in addressing RAI principles and emerging LLMs’ ethical 
challenges
Our analysis also reveals that some critical responsible AI principles 
lack addressing in K-12 education levels. While Diversity, Non- 
discrimination, Fairness and Societal/Environmental Well-being dominate 
the K-12 AI ethics curricula, Technical Robustness & Safety receive scant 
attention. As Kajiwara and Kawabata (2024) noted that younger stu-
dents are more likely to rely on information generated by Chat GPT 
making them susceptible to misinformation without proper safeguards. 
To mitigate these risks, it is imperative to incorporate reliability checks 
and critical evaluation skills through AI ethics education from an early 
age.
Moreover, Human Oversight & Agency in AI systems require greater 
attention. While a few studies have explored human-in-the-loop features 
in design activities (e.g., Yue et al., 2025; Zhu et al., 2025), a funda-
mental understanding of key mechanisms, such as how reinforcement 
learning with human feedback works in LLMs (Gonz´alez Barman et al., 
2025), remains essential. This knowledge could help children demystify 
the inner workings of these complex systems, fostering greater trans-
parency, trust, and agency in their interactions with LLMs.
Furthermore, Accountability need to be further strengthened. Current 
studies primarily address Accountability for designers and deployers of AI 
applications (e.g., Bilstrup et al., 2020; Zhang et al., 2024), whether 
through stakeholder analysis or responsibility mapping, but neglect the 
responsibilities of end-users. Only a few studies have briefly noted the 
accountability of students using LLMs (e.g., Ali et al, 2024; Kajiwara & 
Kawabata, 2024), yet without further discussing how they should up-
hold ethical principles in their responsible usage. This gap is critical to 
address, as students’ accountability directly impacts their academic 
integrity and the ethical adoption of AI in education (Han et al., 2025; 
Meça & Shk¨elzeni, 2024).
Additionally, a few studies noted the emerging issues of data 
ownership and copyright concerns brought by ubiquitous AI-generated 
content (AIGC) on social media. For instance, students agreed that all 
stakeholders—from data providers and AI developers to end-users—-
should have ownership rights over AIGC and exercise detailed audit 
control, but they disagreed on how to allocate ownership, with some 
advocating for user control and others emphasizing stricter human 
oversight of content (Zhu et al., 2025). Ali et al. (2024) observed that 
while using Gen AI to envision their career futures, students also 
expressed concerns that AI-generated content could threaten creative 
jobs. These emerging issues aroused by LLMs-based Gen AI need to be 
further addressed by the future studies.
5.3. The limitations of methodological approaches
Most studies of AI ethics education collect data from multiple data 
sources, evaluating changes before and after implementing the curric-
ulum, yet remains primarily focused on immediate cognitive and af-
fective outcomes (e.g., conceptual knowledge gains, attitude/values 
shifts) (e.g., Dai, 2024; Kong et al., 2023; Lin et al., 2023). While 
emerging studies analyze behavioral data during learning activities, 
such as embodied role-playing games or project-based design tasks (e.g., 
Chang et al., 2025; Kim et al., 2025; Zhou et al., 2025), a critical gap still 
persists: none of longitudinal studies exist to examine how these AI 
ethics interventions impact students’ long-term ethical awareness, crit-
ical thinking, and sense of responsibility when interacting with AI sys-
tems outside of educational contexts. This gap is especially critical 
because children encounter ubiquitous AI everywhere, such as navi-
gating social media recommendation systems, using generative AI for 
homework, or interacting with customer service chatbots, which present 
more complex and ambiguous ethical challenges than controlled class-
room activities.
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 11 ---

5.4. The issues of assessing ethical learning outcomes
The current state of AI ethics education research suffers from sig-
nificant heterogeneity in assessing learning outcomes, and the varied 
contexts of implementation. This diversity makes meaningful meta- 
analyses nearly impossible. For example, studies by Dai et al. (2024)
and Zhou et al. (2025), both employing analogical learning approaches, 
assessed different domains—cognitive and affective gains versus 
behavioral learning engagements—rendering their findings incompa-
rable in terms of pedagogical efficacy. Addressing these issues requires a 
comprehensive strategy that incorporates both qualitative and quanti-
tative methods to capture a holistic understanding of how individuals 
perceive and act on AI ethics.
Researching and measuring AI ethics effectively faces challenges in 
integrating diverse methodologies. While critics often argue that quan-
titative methods are at odds with ethical deliberation, tools like ques-
tionnaires and surveys can facilitate self-assessment and reflection, yet 
they require careful design to ensure meaningful insights into ethical 
decision-making. Instruments such as the AI Concept Inventory (Lee 
et al., 2021) and the Ethical Measurement of AI Literacy (Ng, Wu, et al., 
2024) offer ways to quantitatively assess students’ self-efficacy in AI 
ethics and track changes over time. However, it is crucial to recognize 
the limitations of these tools and the need to complement them with 
evaluations of how individuals exercise moral reasoning and 
decision-making processes.
Ethical reasoning involves predicting outcomes and examining mo-
tives, which are essential for understanding moral responsibilities. The 
challenge lies in effectively exploring students’ ethical development by 
analyzing projects, observations, and artifact-based interviews to reveal 
how they embed values like respect, transparency, and fairness into their 
learning processes. This requires a structured method to assess and 
enhance both students’ self-efficacy and ethical behaviors, ensuring that 
researchers and educators can understand how students perceive their 
ethical reasoning and decision-making, and how those perceptions 
translate into action.
6. Implications
To address the issues addressed in 5.4 section, we propose recon-
ceptualizing AI ethics as a transformative competency within ABCE AI 
literacy frameworks, structured to: (1) establish ethics as a core pillar, 
rather than an ancillary topic in AI curricula; (2) assess ethical learning 
outcomes across cognitive, affective, and behavioral domains; and (3) 
sequence ethical learning to progressively address key responsible AI 
principles along a developmental continuum—from foundational un-
derstanding, such as recognizing bias origins, to advanced skills, like 
building equitable AI applications. This approach highlights the unique 
role of AI ethics in AI literacy development and facilitates rigorous, 
comparable evaluations of educational interventions across various 
contexts.
By integrating AI ethics as a transformative dimension across the 
learning domains, the framework ensures that ethical considerations are 
embedded throughout AI literacy development, enabling students to 
engage with responsible AI principles while acquiring technical 
knowledge and skills. As depicted in Fig. 6, the ethical dimension per-
meates the cognitive, affective, and behavioral domains, infusing them 
with human-centered values while preserving their distinct roles. 
Detailed learning outcomes and competency development aligned with 
ethical learning are mapped out in Table 8, illustrating how these 
principles manifest across the three domains.
For educators, this competency-based responsible AI literacy 
framework provides practical pathways to embed ethical learning into 
K-12 AI curricula. For instance, teachers can introduce ethical concepts 
such as algorithmic bias, data privacy, and transparency through 
analogy-based pedagogies, using embodied activities to help students 
grasp the data practices underlying AI mechanisms (e.g., Dai, 2024; 
Zhou et al., 2025). Role-playing games can be employed to encourage 
students to critically reflect on their personal responsibilities when 
interacting with AI systems in their daily lives, promoting empathy and 
ethical awareness (e.g., Ali et al., 2021; Kim et al., 2025). Design-based 
activities can be structured as collaborative learning experiences, where 
students work together to integrate ethical principles into the creation of 
their artifacts, thus enhancing critical thinking and teamwork skills (e.g, 
Chang et al., 2025; Williams et al., 2024). The framework supports 
flexible learning assessments across cognitive, affective, and behavioral 
domains, enabling educators to tailor evaluations to specific learning 
objectives and track students’ ethical development accordingly.
Education policymakers are crucial in expanding access to respon-
sible AI ethics literacy. Key priorities should focus on: (1) Updating K-12 
education standards to explicitly incorporate AI ethics benchmarks at 
Fig. 6. The Responsible AI literacy Framework.
Table 8 
Competency-oriented responsible AI literacy framework.
Key 
Dimension
Cognitive
Affective
Behavioral
Know & 
Understand 
AI from a 
socio- 
technical 
Perspective
Develop a 
fundamental 
understanding of 
AI’s socio-technical 
nature, including 
ethical concepts 
like algorithmic 
biases and 
explainability.
Develop a 
fundamental 
understanding of 
AI’s socio- 
technical nature, 
including ethical 
concepts like 
algorithmic biases 
and explainability.
Articulate 
informed 
perspectives on 
AI’s societal role; 
actively engage in 
discussions or 
activities on AI 
ethical challenges.
Use & Apply 
AI in a 
responsible 
manner
Understand 
accountability, 
ethical 
considerations, 
risks, and benefits 
of AI deployment.
Foster 
responsibility and 
empathy for 
individuals/groups 
affected by AI 
applications.
Make ethical 
decisions when 
using AI; 
demonstrate 
accountability in 
AI interactions.
Evaluate & 
Create AI 
Systems 
with a 
critical lens
Develop higher- 
order thinking 
skills; analyze 
societal 
implications, 
resolving 
dilemmas).
Commit to ethical 
design principles; 
maintain a critical 
mindset toward AI 
impacts.
Create AI for social 
good, designing 
responsible AI 
systems that 
address biases and 
inequities.
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 12 ---

each grade level, ensuring core responsible AI principles are integrated 
into the AI curricula; (2) Designing adaptive policy frameworks with 
students and teachers to ensure these resources effectively address their 
specific needs and ethical challenges (e.g., Ali et al., 2021; Burriss et al., 
2024); and (3) Establishing educational programs to assist schools in 
marginalized communities in accessing AI ethics tools and teacher 
training, ensuring equitable and inclusive opportunities for all students 
(e.g., Chiu, 2021; Williams et al., 2024; Kim et al 2025).
Ultimately, the framework empowers K-12 students not only not 
only enhances students’ cognitive understanding of AI ethics but also 
equips them with affective attributes and behavioral engagement 
needed to navigate the ethical challenges of the AI-driven society. It 
develops their capacity for ethical decision-making whether they engage 
with AI as informed citizens, responsible end-users, or accountable de-
signers. Together, these interconnected competences cultivate respon-
sible AI literacy—preparing K-12 students to build futures where 
technology advances both economic prosperity and human well-being.
7. Future research directions
First, future research can address the emerging ethical challenges 
aroused by LLMs-based Gen AI technologies (e.g., Ali et al, 2024; Kaji-
wara & Kawabata, 2024; Zhu et al., 2025). While issues like academic 
dishonesty have gained increasing attention in higher education (Yusuf 
et al., 2024), its exploration within K-12 education, especially in relation 
to AI ethics education, remains limited. The inherent complexity of 
LLMs further complicates efforts to address responsible AI principles 
including Accountability, Transparency and Human Oversight & Agency. 
Future research can also explore developmentally appropriate peda-
gogical designs to help K-12 students understand LLM functionality and 
emerging ethical issues to teach these critical principles.
The second research direction is developing students’ ability to 
create fair and accountable AI systems. Studies show students frequently 
struggle to consider diverse perspectives beyond their immediate ex-
periences, limiting their capacity to design inclusive technologies 
(Williams et al., 2024). Some students also tend to shift ethical re-
sponsibility to end-users through oversimplified solutions (Bilstrup 
et al., 2020). To address this, researchers should adopt empathy-driven 
approaches that highlight real-world societal impacts, fostering both 
designer accountability in AI development and student awareness of 
end-user responsibilities.
Another emerging area of focus involves engaging K-12 students 
directly in AI policy analysis and development. As AI governance 
frameworks continue evolving, there’s growing recognition that K-12 
students can participate in shaping the policies that will affect their 
digital futures (Ali et al., 2021; Burriss et al., 2024). This approach 
cultivates both critical thinking skills and their dispositional autonomy 
in AI governance (Zhu et al., 2025). By creating structured opportunities 
for students to analyze, critique, and contribute to policy discussions, 
researchers can empower the next generation to advocate for AI systems 
that align with human values.
8. Conclusion
In conclusion, this systematic review elucidates AI ethics’ pivotal 
role in shaping responsible AI literacy for K-12 students. We first map-
ped out global trends in current K-12 AI ethics education research. Then, 
we examined the teaching and learning activities addressing even major 
responsible AI principles pillars, highlighting 16 effective pedagogical 
designs of K-12 AI ethics education. We also analyzed the methodolog-
ical approaches and instruments of the included studies. Finally, we 
mapped out students’ ethical learning outcomes across cognitive, af-
fective, and behavioral domains.
By further synthesizing the results, we discussed the disparities of 
eastern and western disparities, gaps in addressing responsible AI 
principles and emerging ethical issues brought by LLMs-based Gen AI, 
limitations of methodological approaches, and issues in assessing ethical 
learning. Building on the synthesis, we proposed a competency-based 
responsible AI literacy framework that regards ethical learning as a 
transformative dimension for nurturing responsible digital citizens with 
higher-order thinking, to inform K-12 educators and policymakers. We 
also suggest future research directions to address ethical issues of 
emerging AI technologies, enhance students’ skills and empathy in 
creating fair AI systems, and involve K-12 students in AI policy analysis 
and development.
CRedi T authorship contribution statement
Ming Ma: Writing – review & editing, Writing – original draft, 
Methodology, Data curation, Conceptualization. Davy Tsz Kit Ng: 
Writing – review & editing, Formal analysis, Conceptualization. Zhi-
chun Liu: Writing – review & editing, Supervision, Methodology. Gary 
K.W. Wong: Supervision.
Statements on open data and ethics
This systematic review is based on data extracted from publicly 
accessible databases and scholarly publications. All sources are appro-
priately acknowledged in the reference section, with detailed citations 
for each included study. Ethical approval and consent were not required, 
as this research involves a comprehensive analysis of existing literature.
Declare of use generative AI
During the preparation of this work the authors used Deepseek-R1 
model to improve the readability. After using this tool/service, the au-
thors reviewed and edited the content as needed and took full re-
sponsibility for the content of the publication.
Declaration of competing interest
The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper.
References
Adams, C., Pente, P., Lemermeyer, G., & Rockwell, G. (2023). Ethical principles for 
artificial intelligence in K-12 education. Computers and Education: Artificial 
Intelligence, 4, Article 100131. https://doi.org/10.1016/j.caeai.2023.100131
Ahuja, S., & Kumar, J. (2024). Cultivating ethics sensitivity in design: Impact of 
integrating ethics within K-12 digital design education. International Journal of 
Technology and Design Education, 35(2), 507–529. https://doi.org/10.1007/s10798- 
024-09925-2
Aler Tubella, A., Mora-Cantallops, M., & Nieves, J. C. (2024). How to teach responsible 
AI in higher education: Challenges and opportunities. Ethics and Information 
Technology, 26(1), 3. https://doi.org/10.1007/s10676-023-09733-7
Ali, S., Dipaola, D., Lee, I., Sindato, V., Kim, G., Blumofe, R., & Breazeal, C. (2021). 
Children as creators, thinkers and citizens in an AI-driven future. Computers and 
Education: Artificial Intelligence, 2, Article 100040. https://doi.org/10.1016/j. 
caeai.2021.100040
Ali, S., Payne, B. H., Williams, R., Park, H. W., & Breazeal, C. (2019). Constructionism, 
ethics, and creativity: Developing primary and middle school artificial intelligence 
education. In Presented in the international workshop on education in artificiation 
intelligence K-12 (EDUAI ’19). Palo Alto, CA, USA.
Ali, S., Ravi, P., Williams, R., Dipaola, D., & Breazeal, C. (2024). Constructing dreams 
using generative AI. Proceedings of the AAAI Conference on Artificial Intelligence, 38 
(21), 23268–23275. https://doi.org/10.1609/aaai.v38i21.30374
Almatrafi, O., Johri, A., & Lee, H. (2024). A systematic review of AI literacy 
conceptualization, constructs, and implementation and assessment efforts (2019- 
2023). Computers and Education Open, 6, Article 100173. https://doi.org/10.1016/j. 
caeo.2024.100173
Alonso, J. M. (2020). Teaching explainable artificial intelligence to high school students. 
International Journal of Computational Intelligence Systems, 13(1), 974–987. https:// 
doi.org/10.2991/ijcis.d.200715.003
Amplo, E., & Butler, D. (2023). Design-based learning and constructionist learning 
principles to promote artificial intelligence literacy and awareness in K-12, a Pilot 
Study. In The IAFOR international conference on education - IICE2023 (pp. 807–818).
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 13 ---

An, Q., Yang, J., Xu, X., Zhang, Y., & Zhang, H. (2024). Decoding AI ethics from users’ 
lens in education: A systematic review. Heliyon, 10(20), Article e39357. https://doi. 
org/10.1016/j.heliyon.2024.e39357
Bendechache, M., Tal, I., Wall, P., Grehan, L., Clarke, E., Odriscoll, A., Haegen, L. V. D., 
Leong, B., Kearns, A., & Brennan, R. (2021). AI in my life: AI, ethics & privacy 
workshops for 15-16-year-olds. In Companion publication of the 13th ACM Web science 
conference (pp. 34–39). ACM. 
Bilstrup, K. E. K., Kaspersen, M. H., & Petersen, M. G. (2020). Staging reflections on 
ethical dilemmas in machine learning: A card-based design workshop for high school 
students. In Proceedings of the 2020 ACM designing interactive systems conference (pp. 
1211–1222). ACM. 
Bloom, B. S., Engelhart, M. D., Furst, E., Hill, W. H., & Krathwohl, D. R. (1956). Handbook 
I: Cognitive domain. David Mc Kay. 
Borenstein, J., Grodzinsky, F. S., Howard, A., Miller, K. W., & Wolf, M. J. (2021). AI 
ethics: A long history and a recent burst of attention. Computer, 54(1), 96–102. 
https://doi.org/10.1109/MC.2020.3034950
Borenstein, J., & Howard, A. (2021). Emerging challenges in AI and the need for AI ethics 
education. AI and Ethics, 1(1), 61–65. https://doi.org/10.1007/s43681-020-00002-7
Burriss, S. K., Hutchins, N., Conley, Z., Deweese, M. M., Doe, Y. J., Eeds, A., 
Villanueva, A., Ziegler, H., & Oliver, K. (2024). Redesigning an AI bill of rights with/ 
for young people: Principles for exploring AI ethics with middle and high school 
students. Computers and Education: Artificial Intelligence, 7, Article 100317. https:// 
doi.org/10.1016/j.caeai.2024.100317
Carolus, A., Koch, M. J., Straka, S., Latoschik, M. E., & Wienrich, C. (2023). MAILS-Meta 
AI literacy scale: Development and testing of an AI literacy questionnaire based on 
well-founded competency models and psychological change-and meta-competencies. 
Computers in Human Behavior: Artificial Humans, 1(2), Article 100014. https://doi. 
org/10.1016/j.chbah.2023.100014
Casal-Otero, L., Catala, A., Fern´andez-Morante, C., Taboada, M., Cebreiro, B., & Barro, S. 
(2023). AI literacy in K-12: A systematic literature review. International Journal of 
Stem Education, 10(1), 29. https://doi.org/10.1186/s40594-023-00418-7
Chan, C. K. Y. (2023). A comprehensive AI policy education framework for university 
teaching and learning. International Journal of Educational Technology in Higher 
Education, 20(1), 38. https://doi.org/10.1186/s41239-023-00408-3
Chang, M. A., Tissenbaum, M., Philip, T. M., & D’Mello, S. K. (2025). Co-designing AI 
with youth partners: Enabling ideal classroom relationships through a novel AI 
relational privacy ethical framework. Computers and Education: Artificial Intelligence, 
8, Article 100364. https://doi.org/10.1016/j.caeai.2025.100364
Chiu, T. K. F. (2021). A holistic approach to Artificial Intelligence (AI) curriculum for K- 
12 schools. Tech Trends, 65, 796–807. https://doi.org/10.1007/s11528-021-00637-1
Chiu, T. K., Meng, H., Chai, C. S., King, I., Wong, S., & Yam, Y. (2021). Creation and 
evaluation of a pretertiary artificial intelligence (AI) curriculum. IEEE Transactions 
on Education, 65(1), 30–39. https://doi.org/10.1109/TE.2021.3085878
Choi, J. I., Yang, E., & Goo, E. H. (2024). The effects of an ethics education program on 
artificial intelligence among middle school students: Analysis of perception and 
attitude changes. Applied Sciences, 14(4), 1588. https://doi.org/10.3390/ 
app14041588
Coeckelbergh, M. (2020). AI ethics. The MIT Press. 
Dabbagh, H., Earp, B. D., Mann, S. P., Plozza, M., Salloch, S., & Savulescu, J. (2024). AI 
ethics should be mandatory for schoolchildren. AI and Ethics, 5, 87–92. https://doi. 
org/10.1007/s43681-024-00462-1
Dai, Y. (2024). Dual-contrast pedagogy for AI literacy in upper elementary schools. 
Learning and Instruction, 91, Article 101899. https://doi.org/10.1016/j. 
learninstruc.2024.101899
Dai, Y., Lin, Z., Liu, A., Dai, D., & Wang, W. (2024). Effect of an analogy-based approach 
of artificial intelligence pedagogy in upper primary schools. Journal of Educational 
Computing Research, 61(8), 159–186. https://doi.org/10.1177/07356331231201342
Díaz-Rodríguez, N., Del Ser, J., Coeckelbergh, M., de Prado, M. L., Herrera-Viedma, E., & 
Herrera, F. (2023). Connecting the dots in trustworthy Artificial Intelligence: From AI 
principles, ethics, and key requirements to responsible AI systems and regulation, 99 p. 
101896). Information Fusion. https://doi.org/10.1016/j.inffus.2023.101896.
Dignum. (2019). Responsible artificial intelligence: How to develop and use AI in a responsible 
way, 2156. Cham: Springer. 
Dipaola, D., Payne, B. H., & Breazeal, C. (2020). Decoding design agendas: An ethical 
design activity for middle school students. In Idc ’20: Proceedings of the interaction 
design and children conference (pp. 1–10). ACM. 
Dolata, M., Feuerriegel, S., & Schwabe, G. (2022). A sociotechnical view of algorithmic 
fairness. Information Systems Journal, 32(4), 754–818. https://doi.org/10.1111/ 
isj.12370
Durall Gazulla, E., Hirvonen, N., Sharma, S., Hartikainen, H., Jylh¨a, V., Iivari, N., 
Kinnula, M., & Baizhanova, A. (2025). Youth perspectives on technology ethics: 
Analysis of teens’ ethical reflections on AI in learning activities. Behaviour & 
Information Technology, 44(5), 888–911. https://doi.org/10.1080/ 
0144929X.2024.2350666
Eguchi, A., Okada, H., & Muto, Y. (2021). Contextualizing AI education for K-12 students 
to enhance their learning of AI literacy through culturally responsive approaches. KI- 
Künstliche Intelligenz, 35(2), 153–161. https://doi.org/10.1007/s13218-021-00737-3
Fern´andez-Martínez, C., Hern´an-Losada, I., & Fern´andez, A. (2021). Early introduction of 
AI in Spanish middle schools. A motivational study. KI-Künstliche Intelligenz, 35(2), 
163–170. https://doi.org/10.1007/s13218-021-00735-5
Fu, Y., & Weng, Z. (2024). Navigating the ethical terrain of AI in education: A systematic 
review on framing responsible human-centered AI practices. Computers and 
Education: Artificial Intelligence, 7, Article 100306. https://doi.org/10.1016/j. 
caeai.2024.100306
Gong, X., Tang, Y., Liu, X., Jing, S., Cui, W., Liang, J., & Wang, F. Y. (2020). K-9 artificial 
intelligence education in Qingdao: Issues, challenges and suggestions. In 2020 IEEE 
international Conference on networking, Sensing and control (ICNSC) (pp. 1–6). IEEE. 
Gonz´alez Barman, K., Lohse, S., & De Regt, H. W. (2025). Reinforcement learning from 
human feedback in LLMs: Whose culture, whose values, whose perspectives? 
Philosophy & Technology, 38(2), 1–26. https://doi.org/10.1007/s13347-025-00861-0
Hagendorff, T. (2024). Mapping the ethics of generative AI: A comprehensive scoping 
review. Minds and Machines, 34(4), 39. https://doi.org/10.1007/s11023-024-09694- 
w
Han, B., Nawaz, S., Buchanan, G., & Mckay, D. (2025). Students’ perceptions: Exploring 
the interplay of ethical and pedagogical impacts for adopting AI in higher education. 
International Journal of Artificial Intelligence in Education, 1–26. https://doi.org/ 
10.1007/s40593-024-00456-4
Henry, J., Hernalesteen, A., & Collard, A. S. (2021). Teaching artificial intelligence to K- 
12 through a role-playing game questioning the intelligence concept. KI-Künstliche 
Intelligenz, 35(2), 171–179. https://doi.org/10.1007/s13218-021-00733-7
Irgens, G. A., Vega, H., Adisa, I., & Bailey, C. (2022). Characterizing children’s 
conceptual knowledge and computational practices in a critical machine learning 
educational program. International Journal of Child-Computer Interaction, 34, Article 
100541. https://doi.org/10.1016/j.ijcci.2022.100541
ISO. (2023). Building a responsible AI: How to manage the AI ethics debate. https: 
//www.iso.org/artificial-intelligence/responsible-ai-ethics.
Kahila, J., Vartiainen, H., Tedre, M., Arkko, E., Lin, A., Pope, N., Jormanainen, I., & 
Valtonen, T. (2024). Pedagogical framework for cultivating children’s data agency 
and creative abilities in the age of AI. Informatics in Education, 23(2), 323–360. 
https://doi.org/10.15388/infedu.2024.15
Kajiwara, Y., & Kawabata, K. (2024). AI literacy for ethical use of chatbot: Will students 
accept AI ethics? Computers and Education: Artificial Intelligence, 6, Article 100251. 
https://doi.org/10.1016/j.caeai.2024.100251
Kaspersen, M. H., Bilstrup, K. E. K., Van Mechelen, M., Hjort, A., Bouvin, N. O., & 
Petersen, M. G. (2022). High school students exploring machine learning and its 
societal implications: Opportunities and challenges. International Journal of Child- 
Computer Interaction, 34, Article 100539. https://doi.org/10.1016/j. 
ijcci.2022.100539
Kim, Y. J., Kim, G., & Stoiber, A. (2025). Playful design for AI literacy: Creating inclusive 
learning and assessment opportunities. International Journal of Human-Computer 
Studies, 199, Article 103508. https://doi.org/10.1016/j.ijhcs.2025.103508
Kim, K., & Kwon, K. (2024). Tangible computing tools in AI education: Approach to 
improve elementary students’ knowledge, perception, and behavioral intention 
towards AI. Education and Information Technologies, 29(13), 16125–16156. https:// 
doi.org/10.1007/s10639-024-12497-2
Kim, K., Kwon, K., Ottenbreit-Leftwich, A., Bae, H., & Glazewski, K. (2023). Exploring 
middle school students’ common naive conceptions of Artificial Intelligence 
concepts, and the evolution of these ideas. Education and Information Technologies, 28 
(8), 9827–9854. https://doi.org/10.1007/s10639-023-11600-3
Kim, S. W., & Lee, Y. (2024). Investigation into the influence of socio-cultural factors on 
attitudes toward artificial intelligence. Education and Information Technologies, 29(8), 
9907–9935. https://doi.org/10.1007/s10639-023-12172-y
Kim, D. Y., Ravi, P., Williams, R., & Yoo, D. (2024). App planner: Utilizing generative AI 
in K-12 mobile app development education. In Proceedings of the 23rd annual ACM 
interaction design and children conference (pp. 770–775). ACM. 
Kong, S. C., Cheung, W. M. Y., & Tsang, O. (2023). Evaluating an artificial intelligence 
literacy programme for empowering and developing concepts, literacy and ethical 
awareness in senior secondary students. Education and Information Technologies, 28 
(4), 4703–4724. https://doi.org/10.1007/s10639-022-11408-7
Kong, S. C., Cheung, M. Y. W., & Tsang, O. (2024). Developing an artificial intelligence 
literacy framework: Evaluation of a literacy course for senior secondary students 
using a project-based learning approach. Computers and Education: Artificial 
Intelligence, 6, Article 100214. https://doi.org/10.1016/j.caeai.2024.100214
Kong, S. C., & Zhang, G. (2021). A conceptual framework for designing artificial 
intelligence literacy programmes for educated citizens. In The 25th global Chinese 
conference on computers in education (GCCCE 2021) (pp. 11–15). The Education 
University of Hong Kong. 
Krakowski, A., Greenwald, E., Hurt, T., Nonnecke, B., & Cannady, M. (2022). Authentic 
integration of ethics and AI through sociotechnical, problem-based learning. 
Proceedings of the AAAI Conference on Artificial Intelligence, 36(11), 12774–12782. 
https://doi.org/10.1609/aaai.v36i11.21556
Lee, I., Ali, S., Dipaola, D., & Breazeal, C. (2021). Developing middle school students’ AI 
literacy. In Sigcse ’21: Proceedings of the 52nd ACM technical symposium on computer 
science education (pp. 191–197). ACM. 
Lee, C. H., Gobir, N., Gurn, A., & Soep, E. (2022). In the black mirror: Youth 
investigations into artificial intelligence. ACM Transactions on Computing Education, 
22(3), 1–25. https://doi.org/10.1145/3484495
Lee, S. J., & Kwon, K. (2024). A systematic review of AI education in K-12 classrooms 
from 2018 to 2023: Topics, strategies, and learning outcomes. Computers and 
Education: Artificial Intelligence, 6, Article 100211. https://doi.org/10.1016/j. 
caeai.2024.100211
Li, L., Yu, F., & Zhang, E. (2024). A systematic review of learning task design for K-12 AI 
education: Trends, challenges, and opportunities. Computers and Education: Artificial 
Intelligence, 6, Article 100217. https://doi.org/10.1016/j.caeai.2024.100217
Lin, X. F., Wang, Z., Zhou, W., Luo, G., Hwang, G. J., Zhou, Y., Wang, J., Hu, Q., Li, W., & 
Liang, Z. M. (2023). Technological support to foster students’ artificial intelligence 
ethics: An augmented reality-based contextualized dilemma discussion approach. 
Computers & Education, 201, Article 104813. https://doi.org/10.1016/j. 
compedu.2023.104813
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 14 ---

Liu, X., & Zhong, B. (2024). A systematic review on how educators teach AI in K-12 
education. Educational Research Review, 45, Article 100642. https://doi.org/ 
10.1016/j.edurev.2024.100642
Long, D., & Magerko, B. (2020). What is AI literacy? Competencies and design 
considerations. In Proceedings of the 2020 CHI conference on human factors in 
computing systems (pp. 1–16). ACM. 
Martins, R. M., Von Wangenheim, C. G., Rauber, M. F., & Hauck, J. C. (2024). Machine 
learning for all!—introducing machine learning in middle and high school. 
International Journal of Artificial Intelligence in Education, 34(2), 185–223. https://doi. 
org/10.1007/s40593-022-00325-y
Mc Govern, A., Ebert-Uphoff, I., Gagne, & Bostrom, A. (2022). Why we need to focus on 
developing ethical, responsible, and trustworthy artificial intelligence approaches 
for environmental science. Environmental Data Science, 1, e6. https://doi.org 
/10.1017/eds.2022.5.
Meça, A., & Shk¨elzeni, N. (2024). Academic integrity in the face of generative language 
models. In Emerging technologies in computing (i CETi C 2023) (pp. 58–70). Springer. 
Melsi´on, G. I., Torre, I., Vidal, E., & Leite, I. (2021). Using explainability to help children 
understandgender bias in AI. In Proceedings of the 20th annual ACM interaction design 
and children conference (pp. 87–99). ACM. 
Miao, F., & Shiohira, K. (2022). K-12 AI curricula. A mapping of government-endorsed AI 
curricula. https://unesdoc.unesco.org/ark:/48223/pf0000380602.
Mikalef, P., Conboy, K., Lundstr¨om, J. E., & Popoviˇc, A. (2022). Thinking responsibly 
about responsible AI and ‘the dark side’of AI. European Journal of Information 
Systems, 31(3), 257–268. https://doi.org/10.1080/0960085X.2022.2026621
Mikalef, P., & Gupta, M. (2021). Artificial intelligence capability: Conceptualization, 
measurement calibration, and empirical study on its impact on organizational 
creativity and firm performance. Information and Management, 58(3), Article 103434. 
https://doi.org/10.1016/j.im.2021.103434
Müller, V. C. (2020). Ethics of artificial intelligence and robotics. In E. N. Zalta (Ed.), 
Stanford encyclopedia of philosophy (pp. 1–70).
Ng, D. T. K., Lee, M., Tan, R. J. Y., Hu, X., Downie, J. S., & Chu, S. K. W. (2023). A review 
of AI teaching and learning from 2000 to 2020. Education and Information 
Technologies, 28(7), 8445–8501. https://doi.org/10.1007/s10639-022-11491-w
Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI 
literacy: An exploratory review. Computers and Education: Artificial Intelligence, 2, 
Article 100041. https://doi.org/10.1016/j.caeai.2021.100041
Ng, D. T. K., Luo, W., Chan, H. M. Y., & Chu, S. K. W. (2022). Using digital story writing 
as a pedagogy to develop AI literacy among primary students. Computers and 
Education: Artificial Intelligence, 3, Article 100054. https://doi.org/10.1016/j. 
caeai.2022.100054
Ng, D. T. K., Su, J., & Chu, S. K. W. (2024a). Fostering secondary school students’ AI 
literacy through making AI-driven recycling bins. Education and Information 
Technologies, 29(8), 9715–9746. https://doi.org/10.1007/s10639-023-12183-9
Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024b). Design and 
validation of the AI literacy questionnaire: The affective, behavioural, cognitive and 
ethical approach. British Journal of Educational Technology, 55(3), 1082–1104. 
https://doi.org/10.1111/bjet.13411
Nguyen, A., Ngo, H. N., Hong, Y., Dang, B., & Nguyen, B. P. T. (2023). Ethical principles 
for artificial intelligence in education. Education and Information Technologies, 28(4), 
4221–4241. https://doi.org/10.1007/s10639-022-11316-w
Norouzi, N., Chaturvedi, S., & Rutledge, M. (2020). Lessons learned from teaching 
machine learning and natural language processing to high school students. 
Proceedings of the AAAI Conference on Artificial Intelligence, 34(9), 13397–13403. 
https://doi.org/10.1609/aaai.v34i09.7063
O’Dea, X., Ng, D. T. K., O’Dea, M., & Shkuratskyy, V. (2024). Factors affecting university 
students’ generative AI literacy: Evidence and evaluation in the UK and Hong Kong 
contexts. Policy Futures in Education, Article 14782103241287401.
OECD. (2021). AI principles. https://www.oecd.org/en/topics/ai-principles.html.
Oskotsky, T., Bajaj, R., Burchard, J., Cavazos, T., Chen, I., Connell, W. T., Eaneff, S., 
Grant, T., Kanungo, I., Lindquist, K., Myers-Turnbull, D., Naing, Z. Z. C., Tang, A., 
Vora, B., Wang, J., Karim, I., Swadling, C., Yang, J.,  AI4ALL Student Cohort 2020, 
Lindstaedt, B., … Sirota, M. (2022). Nurturing diversity and inclusion in AI in 
Biomedicine through a virtual summer program for high school students. PLo S 
Computational Biology, 18(1), Article e1009719. https://doi.org/10.1371/journal. 
pcbi.1009719
Page, M. J., Mc Kenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., 
Shamseer, L., Tetzlaff, J. M., Akl, E. A., Brennan, S. E., Chou, R., Glanville, J., 
Grimshaw, J. M., Hr´objartsson, A., Lalu, M. M., Li, T., Loder, E. W., Mayo-Wilson, E., 
Mc Donald, S., Mc Guinness, L. A., … Moher, D. (2021). The PRISMA 2020 statement: 
An updated guideline for reporting systematic reviews. BMJ. British Medical Journal 
(Clinical Research Ed.), 372, n71. https://doi.org/10.1186/s13643-021-01626-4
Pang, H. N., Parks, R., Breazeal, C., & Abelson, H. (2024). “How can I code A.I. 
responsibly?”: The effect of computational action on K-12 students learning and 
creating socially responsible A.I. In Proceedings of the AAAI conference on artificial 
intelligence (pp. 16017–16024). AAAI. 
Papagiannidis, E., Mikalef, P., & Conboy, K. (2025). Responsible artificial intelligence 
governance: A review and research framework. The Journal of Strategic Information 
Systems, 34(2), Article 101885. https://doi.org/10.1016/j.jsis.2024.101885
Pargman, T. C., Mc Grath, C., & Milrad, M. (2024). Towards responsible AI in education: 
Challenges and implications for research and practice. In Computers and education: 
Artificial intelligence, Article 100345.
Park, W., & Kwon, H. (2024). Implementing artificial intelligence education for middle 
school technology education in Republic of Korea. International Journal of Technology 
and Design Education, 34(1), 109–135. https://doi.org/10.1007/s10798-023-09812- 

Peng, L., & Zhao, B. (2024). Navigating the ethical landscape behind Chat GPT. Big Data 
and Society, 11(1), Article 20539517241237488. https://doi.org/10.1177/ 

Peters, D., Vold, K., Robinson, D., & Calvo, R. A. (2020). Responsible AI—two 
frameworks for ethical design practice. IEEE Transactions on Technology and Society, 1 
(1), 34–47. https://doi.org/10.1109/TTS.2020.2974991
Qian, Y., Siau, K. L., & Nah, F. F. (2024). Societal impacts of artificial intelligence: 
Ethical, legal, and governance issues. Societal Impacts, 3, Article 100040. https://doi. 
org/10.1016/j.socimp.2024.100040
Reddy, T., Williams, R., & Breazeal, C. (2021). Text classification for AI education. In 
Proceedings of the 52nd ACM technical symposium on computer science education (p. 
1381). ACM. 
Relmasira, S. C., Lai, Y. C., & Donaldson, J. P. (2023). Fostering AI literacy in elementary 
science, technology, engineering, art, and mathematics (STEAM) education in the 
age of generative AI. Sustainability, 15(18), Article 13595. https://doi.org/10.3390/ 
su151813595
Rizvi, S., Waite, J., & Sentance, S. (2023). Artificial intelligence teaching and learning in 
K-12 from 2019 to 2022: A systematic literature review. Computers and Education: 
Artificial Intelligence, 4, Article 100145. https://doi.org/10.1016/j. 
caeai.2023.100145
Sabuncuoglu, A. (2020). Designing one year curriculum to teach artificial intelligence for 
middle school. In Proceedings of the 2020 ACM conference on innovation and technology 
in computer science education (pp. 96–102). ACM. 
Sanusi, I. T., Omidiora, J. O., Oyelere, S. S., Vartiainen, H., Suhonen, J., & Tukiainen, M. 
(2023a). Preparing middle schoolers for a machine learning-enabled future through 
design-oriented pedagogy. IEEE Access, 11, 39776–39791. https://doi.org/10.1109/ 
ACCESS.2023.3269025
Sanusi, I. T., Oyelere, S. S., Vartiainen, H., Suhonen, J., & Tukiainen, M. (2023b). 
Developing middle school students’ understanding of machine learning in an African 
school. Computers and Education: Artificial Intelligence, 5, Article 100155. https://doi. 
org/10.1016/j.caeai.2023.100155
Sanusi, I. T., Sunday, K., Oyelere, S. S., Suhonen, J., Vartiainen, H., & Tukiainen, M. 
(2024). Learning machine learning with young children: Exploring informal settings 
in an African context. Computer Science Education, 34(2), 161–192. https://doi.org/ 
10.1080/08993408.2023.2175559
Sartori, L., & Theodorou, A. (2022). A sociotechnical perspective for the future of AI: 
Narratives, inequalities, and human control. Ethics and Information Technology, 24(1), 
4. https://doi.org/10.1007/s10676-022-09624-3
Schaper, M. M., Malinverni, L., & Valero, C. (2020). Robot presidents: Who should rule 
the world? Teaching critical thinking in AI through reflections upon food traditions. 
In Proceedings of the 11th nordic conference on human-computer interaction: Shaping 
experiences (pp. 1–4). Shaping Society. ACM.
Schaper, M. M., Smith, R. C., Tamashiro, M. A., Van Mechelen, M., Lunding, M. S., 
Bilstrup, K. E. K., Kaspersen, M. H., Jensen, K. L., Petersen, M. G., & Iversen, O. S. 
(2022). Computational empowerment in practice: Scaffolding teenagers’ learning 
about emerging technologies and their ethical and societal impact. International 
Journal of Child-Computer Interaction, 34, Article 100537. https://doi.org/10.1016/j. 
ijcci.2022.100537
Shamir, G., & Levin, I. (2022). Teaching machine learning in elementary school. 
International Journal of Child-Computer Interaction, 31, Article 100415. https://doi. 
org/10.1016/j.ijcci.2021.100415
Skinner, Z., Brown, S., & Walsh, G. (2020). Children of color’s perceptions of fairness in 
AI: An exploration of equitable and inclusive co-design. In Extended abstracts of the 
2020 CHI conference on human factors in computing systems (pp. 1–8). ACM. 
Solyst, J., Axon, A., Stewart, A. E., Eslami, M., & Ogan, A. (2023). Investigating girls’ 
perspectives and knowledge gaps on ethics and fairness in Artificial Intelligence in a 
Lightweight workshop. ar Xiv. https://doi.org/10.48550/ar Xiv.2302.13947
Stahl, B. C. (2021). Ethical issues of AI. Springer. 
Su, J., Guo, K., Chen, X., & Chu, S. K. W. (2023). Teaching artificial intelligence in K-12 
classrooms: A scoping review. Interactive Learning Environments, 32(9), 5207–5226. 
https://doi.org/10.1080/10494820.2023.2212706
Su, J., & Yang, W. (2024a). AI literacy curriculum and its relation to children’s 
perceptions of robots and attitudes towards engineering and science: An intervention 
study in early childhood education. Journal of Computer Assisted Learning, 40(1), 
241–253. https://doi.org/10.1111/jcal.12867
Su, J., & Yang, W. (2024b). Artificial Intelligence (AI) literacy in early childhood 
education: An intervention study in Hong Kong. Interactive Learning Environments, 32 
(9), 5494–5508. https://doi.org/10.1080/10494820.2023.2217864
Tan, Q., & Tang, X. (2024). Unveiling AI literacy in K-12 education: A systematic 
literature review of empirical research. Interactive Learning Environments, 1–17. 
https://doi.org/10.1080/10494820.2025.2482586
Tomaˇsev, N., Cornebise, J., Hutter, F., Mohamed, S., Picciariello, A., Connelly, B., 
Belgrave, D. C. M., Ezer, D., Haert, F. C. V., Mugisha, F., Abila, G., Arai, H., 
Almiraat, H., Proskurnia, J., Snyder, K., Otake-Matsuura, M., Othman, M., 
Glasmachers, T., Wever, W., Teh, Y. W., … Clopath, C. (2020). AI for social good: 
Unlocking the opportunity for positive impact. Nature Communications, 11(1), 2468. 
https://doi.org/10.1038/s41467-020-15871-z
Touretzky, D., Gardner-Mccune, C., Martin, F., & Seehorn, D. (2019). Envisioning AI for 
K-12: What should every child know about AI?. In Proceedings of the AAAI conference 
on artificial intelligence (pp. 9795–9799). AAAI.
UNESCO. (2022). Recommendation on the ethics of artificial intelligence. https://une 
sdoc.unesco.org/ark:/48223/pf0000381137.
Van Brummelen, J., Heng, T., & Tabunshchyk, V. (2021). Teaching tech to talk: K-12 
conversational artificial intelligence literacy curriculum and development tools. In 
Proceedings of the AAAI conference on artificial intelligence (pp. 15655–15663). AAAI. 
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422 

--- Page 15 ---

Williams, R., Alghowinem, S., & Breazeal, C. (2024). Dr. RO bott will see you now: 
Exploring AI for wellbeing with middle school students. Proceedings of the AAAI 
Conference on Artificial Intelligence, 38(21), 23309–23317. https://doi.org/10.1609/ 
aaai.v38i21.30379
Williams, R., Ali, S., Devasia, N., Dipaola, D., Hong, J., Kaputsos, S. P., Jordan, B., & 
Breazeal, C. (2023). AI+ ethics curricula for middle school youth: Lessons learned 
from three project-based curricula. International Journal of Artificial Intelligence in 
Education, 33(2), 325–383. https://doi.org/10.1007/s40593-022-00298-y
Williams, R., Kaputsos, S. P., & Breazeal, C. (2021). Teacher perspectives on how to train 
your robot: A middle school AI and ethics curriculum. In Proceedings of the AAAI 
conference on artificial intelligence (pp. 15678–15686). AAAI. 
Wong, G. K., Ma, X., Dillenbourg, P., & Huan, J. (2020). Broadening artificial intelligence 
education in K-12: Where to start? ACM Inroads, 11(1), 20–29. https://doi.org/ 
10.1145/3381884
Wu, D., Chen, M., Chen, X., & Liu, X. (2024). Analyzing K-12 AI education: A large 
language model study of classroom instruction on learning theories, pedagogy, tools, 
and AI literacy. Computers and Education: Artificial Intelligence, 7, Article 100295. 
https://doi.org/10.1016/j.caeai.2024.100295
Xia, Q., Chiu, T. K., Lee, M., Sanusi, I. T., Dai, Y., & Chai, C. S. (2022). A self- 
determination theory (SDT) design approach for inclusive and diverse artificial 
intelligence (AI) education. Computers & Education, 189, Article 104582. https://doi. 
org/10.1016/j.compedu.2022.104582
Yang, W., Hu, X., Yeter, I. H., Su, J., Yang, Y., & Lee, J. C. K. (2024). Artificial intelligence 
education for young children: A case study of technology-enhanced embodied 
learning. Journal of Computer Assisted Learning, 40(2), 465–477. https://doi.org/ 
10.1111/jcal.12892
Yim, I. H. Y. (2024a). A critical review of teaching and learning artificial intelligence (AI) 
literacy: Developing an intelligence-based AI literacy framework for primary school 
education. Computers and Education: Artificial Intelligence, 7, Article 100319. https:// 
doi.org/10.1016/j.caeai.2024.100319
Yim, I. H. Y. (2024b). Artificial intelligence literacy in primary education: An arts-based 
approach to overcoming age and gender barriers. Computers and Education: Artificial 
Intelligence, 7, Article 100321. https://doi.org/10.1016/j.caeai.2024.100321
Yue, M., Jong, M. S. Y., & Dai, Y. (2022). Pedagogical design of K-12 artificial 
intelligence education: A systematic review. Sustainability, 14(23), Article 15620. 
https://doi.org/10.3390/su142315620
Yue, M., Jong, M. S. Y., Dai, Y., & Lau, W. W. F. (2025). Students as AI literate designers: 
A pedagogical framework for learning and teaching AI literacy in elementary 
education. Journal of Research on Technology in Education, 1–22. https://doi.org/ 
10.1080/15391523.2025.2449942
Yusuf, A., Pervin, N., & Rom´an-Gonz´alez, M. (2024). Generative AI and the future of 
higher education: A threat to academic integrity or reformation? Evidence from 
multicultural perspectives. International Journal of Educational Technology in Higher 
Education, 21(1), 21. https://doi.org/10.1186/s41239-024-00453-6
Zammit, M., Voulgari, I., Liapis, A., & Yannakakis, G. N. (2022). Learn to machine learn 
via games in the classroom. Frontiers in Education, 7, Article 913530. https://doi.org/ 
10.3389/feduc.2022.913530
Zhan, Z., He, G., Li, T., He, L., & Xiang, S. (2022). Effect of groups size on students’ 
learning achievement, Motivation, cognitive load, collaborative problem-solving 
quality, and in-class interaction in an introductory ai course. Journal of Computer 
Assisted Learning, 38(6), 1807–1818. https://doi.org/10.1111/jcal.12722
Zhang, H., Lee, I., Ali, S., Dipaola, D., Cheng, Y., & Breazeal, C. (2023). Integrating ethics 
and career futures with technical learning to promote AI literacy for middle school 
students: An exploratory study. International Journal of Artificial Intelligence in 
Education, 33(2), 290–324. https://doi.org/10.1007/s40593-022-00293-3
Zhang, H., Lee, I., & Moore, K. (2024). An effectiveness study of teacher-led AI literacy 
curriculum in K-12 classrooms. In Proceedings of the AAAI conference on artificial 
intelligence (pp. 23318–23325). AAAI. 
Zhao, H. G., Li, X. Z., & Kang, X. (2024). Development of an artificial intelligence 
curriculum design for children in Taiwan and its impact on learning outcomes. 
Humanities and Social Sciences Communications, 11(1), 1–17. https://doi.org/ 
10.1057/s41599-024-03839-z
Zhou, X., Gong, Y., Zhou, Y., Jiang, Y., & Bai, Z. (2025). Co-design of analogical and 
embodied representations with children for child-centered AI learning experiences. 
International Journal of Human-Computer Studies, 199, Article 103462. https://doi. 
org/10.1016/j.ijhcs.2025.103462
Zhou, X., Zhou, Y., Gong, Y., Cai, Z., Qiu, A., Xiao, Q., … Bai, Z. (2024). Bee and I need 
diversity!" Break filter bubbles in recommendation systems through embodied AI 
learning. In Proceedings of the 23rd annual ACM interaction design and children 
conference.
Zhu, Y., Johnston, S. K., Zhu, C., & Li, Y. (2025). Fostering children’s dispositional 
autonomy and AI understanding through co-designing AI systems: A learning science 
perspective. International Journal of Human-Computer Studies, 196, Article 103412. 
https://doi.org/10.1016/j.ijhcs.2024.103412
M. Ma et al.                                                                                                                                                                                                                                      
Computers and Education: Artiϧcial Intelligence 8 (2025) 100422
