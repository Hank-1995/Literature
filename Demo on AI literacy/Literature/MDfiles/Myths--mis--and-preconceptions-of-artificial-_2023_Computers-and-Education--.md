# Myths, mis- and preconceptions of artificial intelligence: A review of the literature

## Metadata
- **Author**: Arne Bewersdorff
- **Subject**: Computers and Education: Artificial Intelligence, 4 (2023) 100143. doi:10.1016/j.caeai.2023.100143
- **Creator**: Elsevier
- **Producer**: Acrobat Distiller 8.1.0 (Windows)
- **Creation Date**: D:20230617040331Z
- **Modification Date**: D:20230619080639Z
- **Source File**: Myths--mis--and-preconceptions-of-artificial-_2023_Computers-and-Education--.pdf
- **Converted**: 2025-10-23 22:46:12

---

## Content

--- Page 1 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143
Available online 26 May 2023
2666-920X/© 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
Myths, mis- and preconceptions of artificial intelligence: A review of 
the literature 
Arne Bewersdorff a,*, Xiaoming Zhai b, Jessica Roberts c, Claudia Nerdel a 
a Technical University of Munich, Munich, Germany 
b University of Georgia, Athens, USA 
c Georgia Institute of Technology, Atlanta, USA   
A R T I C L E  I N F O   
Keywords: 
Artificial intelligence 
Misconceptions 
Preconceptions 
Review 
A B S T R A C T   
Artificial Intelligence (AI) is prevalent in nearly every aspect of our lives. However, recent studies have found a 
significant amount of confusion and misunderstanding surrounding AI. To develop effective educational pro-
grams in the field of AI, it is vital to examine and understand learners’ pre- and misconceptions as well as myths 
about AI. This study examined a corpus of 591 studies. 25 relevant studies were identified by applying the 
following eligibility criteria: English-written original empirical research on education and AI and reporting AI 
conceptions in a formal learning context. The review found studies from six continents, with the majority 
conducted in Europe and North America. The studies predominantly focus on the school and university levels. 
Findings reveal a range of preconceptions, misconceptions, and myths about AI, such as: Learners often have 
limited understanding of AI on a technical level. They tend to attribute human-like characteristics or attributes to 
AI systems and may have narrow views of AI’s scope, capabilities, and limitations. The review also shows that 
learners often have binary and unspecific views about the threats, dangers, and benefits of AI. Effective 
educational programs are key to empower learners’ understanding of AI, thus helping them make informed 
decisions about the integration of AI in our society, rather than being swayed by misinformation and unnecessary 
fear. This review may help inform the development of more effective teaching and outreach strategies in AI 
education.   
1. Introduction 
The field of artificial intelligence (AI) has seen significant progress in 
recent years, with advancements in many fields like machine learning 
and natural language processing leading to the development of 
increasingly sophisticated AI systems (Jiang, Li, Luo, Yin, & Kaynak, 
2022; Latif et al., 2023). While AI is rushing into our lives and work-
places, there is still a significant amount of confusion, mis-
understandings and uncertainty surrounding AI (Oh et al., 2017). There 
is confusion about technical terms concerning AI (Lindner & Berges, 
2020), the misunderstanding to conceptualize AI as embodied (Kreinsen 
& Schulz, 2021) and uncertainty like unspecific fear as well as hope 
towards AI (Antonenko & Abramowitz, 2022). 
Given the increasing importance of AI in our society, it is crucial that 
the general public has a basic understanding of the capabilities and 
limitations of AI, as well as the ethical implications of its use. Exploring 
these myths, mis- and preconceptions about AI among learners can 
provide valuable insights into their prior understanding of the field and 
help develop effective learning programmes. Although there is some 
research on how learners conceptualize AI (e.g. Antonenko & Abramo-
witz, 2022; Chounta, Bardone, Raudsep, & Pedaste, 2022; Lindner & 
Berges, 2020; Lindner & Romeike, 2019; Teng et al., 2022), it is still 
considered to be in the early stages of development (Mertala, Fagerlund, 
& Calderon, 2022). This literature review synthesizes myths, mis- and 
preconceptions about AI among learners, with the goal of informing the 
development of more effective teaching and outreach strategies in the 
field. Under the term ‘learners’ we summarize individuals engaged in a 
formal process of learning, like students from schools and universities as 
well as participants of professional developments. 
The objectives of this review are 1) to identify and consolidate 
common mis- and preconceptions about AI among learners, 2) cluster 
them into themes under a framework, and 3) identify possible research 
gaps in the literature. To identify these potential research gaps it will be 
important to see which groups of learners are already covered quite 
* Corresponding author. Technical University of Munich, Arcisstraße 31, 80333, Munich, Germany. 
E-mail address: arne.bewersdorff@tum.de (A. Bewersdorff).  
Contents lists available at Science Direct 
Computers and Education: Artificial Intelligence 
journal homepage: www.sciencedirect.com/journal/computers-and-education-artificial-intelligence 
https://doi.org/10.1016/j.caeai.2023.100143 
Received 18 March 2023; Received in revised form 2 May 2023; Accepted 25 May 2023   

--- Page 2 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

satisfactorily by existing studies and which groups might be not repre-
sented yet. 
The review is guided by the questions.  
1. Which group of learners are already covered by existing studies; 
which groups might be not represented?  
2. What are some common myths, misconceptions, and preconceptions 
that appear in the literature? 
To obtain a comprehensive, qualitative understanding without 
limiting our perspective we searched for any empirically reported myth 
or pre- or misconception about AI among learners. We define the terms 
pre- or misconception in line with ¨Ozdemir and Clark (2007) as 
phenomenological primitives, facts, facets, narratives, concepts, and 
mental models at various stages of development and sophistication and 
enhance it with the understanding of myths in AI as an understanding of 
beliefs and cultural implications about AI. To improve readability 
throughout this paper we will substitute the term ‘pre- or misconception 
and myths about AI’ with ‘conceptions of AI’. 
2. Framework 
While educational programs in the field of AI are gaining popularity 
among instructors, researchers and in curricula (Su, Zhong, & Ng, 2022), 
most learners did not have the opportunity to participate in any formal 
AI courses (for university students: Hornberger et al. (in prep.)). How-
ever, AI has been a topic in the news and popular media for decades, and 
learners have likely encountered it in various contexts (Leufer, 2020). 
Research has shown that conceptions of AI are heavily influenced by the 
way AI is represented in the media and the language used to describe it 
(Chao, Hsu, Liu, & Cheng, 2021; Kerr, Barry, & Kelleher, 2020; Zhai & 
Krajcik, 2022). Especially the concepts of embodied or general AI have a 
long-standing tradition in media and the movies (e.g. The Terminator 
Series; I, Robot). This can lead to the development of naive mental 
models prior to the development of formal knowledge in that area 
(Taber, 2014). Learners’ existing beliefs and knowledge about AI likely 
guide the interpretation of new information they encounter. This pro-
cess can sometimes lead to or perpetuate misconceptions (Gooding & 
Metz, 2011), as learners’ prior knowledge and believes may not align 
with the true nature of AI. Driven by the diversity of prior knowledge, 
believes and ideas acquired through informal learning, one central 
model of learning in AI education is conceptual change. Conceptual 
change means the commitment to a new conception about a principle or 
a phenomenon, and the abandoning of an old one (White & Gunstone, 
1989). In recent discussions, the term “conceptual change” has been 
replaced with “conceptual reconstruction”, recognizing that current 
conceptions frequently don’t require complete abandonment but instead 
are more likely to evolve progressively toward formal knowledge (Pot-
vin, 2022). It builds on the precise and comprehensive knowledge of 
learners pre- and misconceptions and believes (cf. ¨Ozdemir & Clark, 
2007). Therefore, understanding of the pre- and misconceptions as well 
as believes and myths about AI among learners is crucial. Deeper un-
derstanding of popular conceptions about AI could help educators and 
researchers in the field develop more effective teaching and outreach 
strategies. These teaching strategies could eventually support learners to 
gain a more accurate and nuanced understanding of AI based on their 
prior conceptions. 
Additionally, exploring the myths, mis- and preconceptions about AI 
among learners can provide valuable insights into the general public’s 
understanding of the field. Given the increasing importance of AI in our 
society, it is crucial that the general public has a basic understanding of 
the capabilities and limitations of AI, as well as the ethical implications 
of its use (Ng, Leung, Chu, & Qiao, 2021). 
Often myths and pre- and misconceptions in the field of AI are re-
ported in gray literature like tech articles or reports lacking empirical 
foundation (e.g.: Google, 2022; Liang, 2021; VK, 2022). It remains 
uncertain whether these myths, preconceptions, and misconceptions 
actually exist. This study provides an overview of common myths and 
pre- and misconceptions about AI and consolidates them empirically. 
Overall, this study of myths, mis- and preconceptions about AI among 
learners has the potential to provide valuable insights into their un-
derstanding of the field, and can inform the development of more 
effective teaching and outreach strategies in the field of AI. 
There are alternative terms and labels to describe the naive mental 
models held by learners prior to the development of formal knowledge 
in an area (Taber, 2014). The terms preconceptions and misconceptions are 
commonly invoked in discussions around conceptual change, though no 
universal definition of these terms is agreed upon across disciplines (Chi 
& Roscoe, 2002). Misconceptions are used to describe a flawed mental 
model held by learners, which conflicts with commonly accepted sci-
entific consensus (Clement 1993; Sanger & Greenbowe 1997; Smith 
et al. 1994). While the term of misconceptions may have a negative 
connotation, alternative terms are preconception or naive knowledge 
structures, which include, but are not limited to phenomenological 
primitives, facts, facets, narratives, concepts, and mental models at 
various stages of development and sophistication (¨Ozdemir & Clark, 
2007) without a negative bias. Preconceptions are generally loosely held 
beliefs that, though incorrect, are easily replaced with instruction, 
whereas misconceptions are more difficult to repair (Chi & Roscoe, 
2002). By contrast, when discussing AI in popular scientific articles (e.g. 
www.aimyths.org from Leufer, Steinbrück, & Liptakova, 2020), news 
articles (e.g. Forbes, 2022) and articles in the scientific discipline of 
computer science itself (Emmert-Streib, Yli-Harja, & Dehmer, 2020) as 
well as the social sciences (e.g. Atkinson, 2016) the term of myths in AI 
rather than the term pre- or misconceptions resonates widely. Myths are 
not true or false and focus more on the beliefs and cultural aspects than 
knowledge (Natale & Ballatore, 2020). 
3. Method 
3.1. Search procedure 
The aim of this review is to get a broad, qualitative overview of any 
empirically reported conceptions about AI among learners. In order to 
maintain a comprehensive perspective, the original corpus consisted of 
not just peer-reviewed papers but also conference proceedings and 
institutional reports. 
The systematic review presented in this paper was planned, con-
ducted, and reported according to the PRISMA 2020 statement (Page 
et al., 2020). The PRISMA 2020 statement comprises a 27-item checklist 
guiding the introduction, methods, results and discussion sections of a 
literature review. 
For the database search, we selected databases representing different 
disciplines related to education, psychology and computer science. 
These included the Education Resource Centre (ERIC, www.eric.org) by 
the US Department of Education for the field of educational sciences, the 
Web of Science by Thomson Reuters in all fields but limited to the topic 
of ‘Education & Educational Research’ and the IEEE Xplore as academic 
database in the field of engineering and computer science. 
Search terms for IEEE Xplore were “artificial intelligence” AND 
“students” AND “misconceptions“, “artificial intelligence” AND “stu-
dents” AND “preconceptions” and “artificial intelligence” AND “stu-
dents” AND “myths”. 
The term “students” was omitted for the search of the ERIC and the 
Web of Science database because of their a priori focus (ERIC) on the 
field of educational research or by limiting the search to the topic of 
‘Education & Educational Research’ (Web of Science). 
To broaden the view on possible conceptions about AI the sample 
was augmented by searches conducted by Google Scholar as Google 
Scholar is considered to be important sources of gray literature, con-
ference proceedings and institutional reports (Haddaway, Collins, 
Coughlin, & Kirk, 2015). Therefore, although Google Scholar has its 
A. Bewersdorff et al.                                                                                                                                                                                                                           

--- Page 3 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

limitations and should not be used as the only source for systematic 
reviews, it seemed to be apt for the purposes of this qualitative and 
explorative review. 
Search terms for Google Scholar were identical to the search terms of 
IEEE Xplore. We limited the included results for every single search with 
Google Scholar to 150. 
In the database search of IEEE Xplore and the search on Google 
Scholar we included the term ‘students’ to focus on educational studies 
and persons who are somehow engaged in a learning process as it was 
not possible to limit the search to a specific field. Using the by far not so 
prominent term of ‘learners’ would have cropped results too vigorous to 
achieve the goal of a broad review. 
We did not omit studies e.g. reporting misconceptions among 
teachers from this qualitative literature review. Therefore, in this article 
we use the broader term of ‘learners’. The search was conducted on 13th 
and 14th of December 2022. Over all databases as well as the aug-
menting Google Scholar searches 591 records were identified. 
3.3. Eligibility criteria 
We first reduced redundant articles. All duplicates of articles were 
removed. This led to the reduction of the corpus by 24 records. To 
identify the most relevant literature, we then identified a set of eligi-
bility criteria.  
a) Written in English  
b) Original, empirical research  
c) Scope relates to education and artificial intelligence  
d) Report on any conceptions about AI  
e) study conducted in context of a formal learning process or institution 
(like school or university) 
Based on the criteria, we screened the titles of the articles, and 
removed any articles with obviously no connection to myths, pre- and 
misconceptions about AI (in total 260 of 426). We then read the ab-
stracts of the 163 articles and further excluded 136 articles that do not 
meet all five criteria. Five of the remaining articles could not be 
retrieved and were excluded from the review, which resulted in 25 
articles to be reviewed. The process is visualized in the flowchart shown 
in Fig. 1. 
3.3. Identifying AI conceptions via content analysis 
All articles included in the analysis were reviewed by experts in AI 
education with respect to the reported conceptions. Descriptions of the 
items (individual myths, mis- or preconceptions) mentioned in the 
studies were identified and extracted. This was done by highlighting 
relevant texts in the results of the reviewed paper and saved for further 
processing in a table document. We then further employed qualitative 
content analysis to analyze the highlighted texts (Mayring, 2021). This 
involved paraphrasing (deleting text components that do not fit the 
content focus), splitting into separate conceptions if necessary, and 
generalization (generalizing the conceptions to the desired abstraction 
level, e.g. omitting references to the sample group). This led to 110 
conceptions (items) which could be identified. An example of analysis is 
illustrated in Table 1. 
3.4. Clustering the conceptions into categories and themes 
As our data basis we used the items gained from the content analysis 
(see section 3.3). For pooling the conceptions (items) into categories and 
the categories into themes, we followed a structured process containing 
three steps: 
Identifying the Conceptions. First, we read through the items multiple 
times to become familiar with the content and identify recurring themes, 
ideas, or patterns. After this, we started to identify relationships and 
connections between the different items. This process, called axial 
coding (Cliff & Melissa, 2017), created categories based on the patterns 
and relationships observed in the data. Using the axial coding, we 
identified categories that are closely related or overlap in meaning and 
merged them into a single, more comprehensive category. Therefore we 
defined an algorithm: We iterated through each of the 110 items. The 
first item created an initial category. We checked if the next item was 
similar to any existing category by comparing it with all existing cate-
gories. If the item was found to be similar to a category, it was included 
in that category. The check for similarity was always guided by the 
heuristics of internal homogeneity (maximizing cohesive validity with 
Fig. 1. Prisma flowchart.  
Table 1 
Example of the process of qualitative content analysis (Mayring, 2021) on 
reviewed papers.  
Original finding 
Paraphrasing 
Splitting 
Generalization 
“Medical students 
were unsure if AI 
would 
particularly affect 
their specialty of 
choice (31.7% 
agree, 35.1% 
disagree), but 
agreed that they 
will need to 
understand AI 
throughout their 
career (68.3% 
agree; 104 
strongly agree, 
212 agree) and 
that they would 
use applications of 
AI during their 
careers (72.9% 
agree; 110 
strongly agree, 
223 agree).” ( 
Pucchio et al., 
2022, p. 4, p. 4) 
Medical students 
agreed that they 
will need to 
understand AI 
throughout their 
career and that 
they would use 
applications of AI 
during their 
careers. 
Medical students 
agreed that they 
will need to 
understand AI 
throughout their 
career 
thinking of the 
need to 
understand AI in 
their careers 
Medical students 
agreed that they 
would use 
applications of AI 
during their 
careers 
AI will be 
essential and 
commonly used 
in medicine  
A. Bewersdorff et al.                                                                                                                                                                                                                           

--- Page 4 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

clear similarity among all content within a category) and external ho-
mogeneity (establishing discriminant validity with clear differentiation 
between the content of two different categories) (Kelle & Kluge, 2010). 
If the category name needed revision after adding the item, we updated 
the category name accordingly. For example the category ‘General 
limited knowledge of AI or some specifics (methods, algorithms, terms, 
features)’ was augmented to ‘General limited or inaccurate knowledge of 
AI or some specifics (methods, algorithms, terms, features)’ after adding 
the item ‘Not knowing what AI is or having an inaccurate understanding 
of AI’ (Teng et al., 2022). The iteration continued to check all remaining 
categories for similarity. If the item was not similar to any of the existing 
categories, a new category was created using the item. This new cate-
gory would then be added to the list of categories with the item included 
in the new category. This process was repeated for all items in the list, 
ensuring that each item was assigned to a category based on its simi-
larity with other items. The algorithm for categorization of the items 
into the categories is described in the flowchart in Fig. 2. 
At last, we reassessed the categories to ensure that each category was 
accurately coded with the updated category name and made minor 
changes in their names as well as their descriptions. This procedure 
finally led to 43 categories. 
Identifying the Themes. We conducted a second pooling to consolidate 
categories into themes. This process was similar to the categorization 
method previously depicted in Fig. 2, except that we used categories to 
generate themes instead of items to generate the categories of 
conceptions. 
This procedure resulted in eight overarching themes. The second 
pooling was done to organize the 43 diverse categories into thematic 
structures and make sense of the findings. For an illustration of the 
relationship between items, categories and themes, please refer to Fig. 3 
as an example. This is the foundation for determining if overarching 
themes can be derived from the identified categories. 
We verified the identified conceptions and their assignment to 
different categories and themes through an expert rating. Three experts 
from the areas of education, psychology and computer science assigned 
the conceptions with the categories as well as the themes. The expert 
rating revealed a close similarity of two categories (‘Anthropomorphi-
zation of AI systems’ and ‘Conception that AI systems are humanoid or 
mimicking humans’). This led to the merge of these two categories into 
one (‘Anthropomorphization of AI systems, such as the perception that 
they are humanoid or mimic human behavior’). Hence, the final number 
of categories is 42. The theme ‘Impact on society and industry’ was 
slightly redefined by adding the term ‘healthcare’ and now is labeled as 
‘Impact on society, healthcare and industry’. 
The interrater agreement for the three raters was calculated using 
Fleiss Kappa (Fleiss, 1981). For the categories interrater agreement of κ 
= .83 was achieved, for the themes κ = .86 can be reported. Both 
interrater agreements can therefore be described as “almost perfect” (κ 
> 0.81) (Landis & Koch, 1977). 
3.5. Other information sought from the reviewed studies 
Besides the conceptions we retrieved descriptive variables from the 
studies. These variables retrieved from the studies are the country(ies) of 
study, the reported sample size, and the educational institution where 
the study was conducted. 
4. Results 
4.1. Descriptive findings of the literature 
We found that studies in this review were conducted in various re-
gions including North America, Europe, Asia, South America, Africa, 
Oceania, and the Middle East (see Fig. 4). Most studies were (partly) 
conducted in Europe (15 countries mentioned) followed by North 
Fig. 2. Flowchart of the categorization process.  
Fig. 3. Schematic representation of the relationship between items, categories, 
and themes. 
Fig. 4. Countries of origin of the studies included in the review by number of 
contributions (number of studies in brackets): North America: USA (5), Canada 
(3). Europe: Germany (5), Greece (2), UK (2), Finland (1), Bulgaria (1), Italy 
(1), Romania (1), Portugal (1), Estonia (1). Asia without the Middle East: South 
Korea (1), Japan (1). South America: Argentina (1x) Africa: Nigeria (1), Ghana 
(1), Tanzania (1), Kenya (1), South Africa (1), Namibia (1). Oceania: Australia 
(1). Middle East: Israel (1), Qatar (1), Lebanon (1), Syria (1). Many of the 
reviewed studies involve multiple countries. 
A. Bewersdorff et al.                                                                                                                                                                                                                           

--- Page 5 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

America (eight studies mentioned). There were individual studies in 
Asian, Middle Eastern, and African countries. South America and Oce-
ania are each mentioned with one study. Many of the reviewed studies 
involve multiple countries. 
The studies included in this review have a diverse group of partici-
pants, ranging from elementary school students (eight studies) to uni-
versity students (eight studies), and the latter were with a focus on 
medical science (six studies) and informatics (one study). There are also 
eight studies focused on teachers and two studies with participants from 
other or unspecified backgrounds. One study focuses on students as well 
as teachers, therefore mentioned twice. 
The studies under review had a wide range of sample sizes, varying 
from 6 to 2167 participants. The median sample size is 81, the mean 
sample size is 245. 
4.2. Themes of conceptions on AI 
In this section, we present the conceptions of AI in eight themes 
entailing each a table that lists its categories, references, and a brief 
description for each category. 
It is important to acknowledge the variety of phenomenological 
primitives, facts, facets, narratives, concepts, and mental models at 
various stages of development and sophistication (¨Ozdemir & Clark, 
2007) as well as myths described in this review. The notions are not 
consistently erroneous or simplistic, necessitating a comprehensive 
conceptual shift. Some of these ideas exhibit an advanced understanding 
of AI literacy (e.g. Long & Magerko, 2020). 
The Theme ‘Confusion and constrictive conceptions of AI at a 
technical level’ (Table 2) includes misunderstandings and confusion 
about the definitions and concepts of AI such as machine learning, 
neural networks, and deep learning. 
The Theme ‘Anthropomorphization and embodied AI’ (Table 3) 
entails conceptions which refer to the tendency to attribute human-like 
characteristics or attributes to AI systems. The conceptualization of AI as 
embodied arises from the idea of AI systems being embodied in physical 
form, such as robots with arms, legs, and the ability to exhibit human- 
like behaviors and responses. 
Conceptions in the theme ‘Understanding of the scope, capabilities 
and limitations of AI and its future potential and development’ 
(Table 4) reflect a narrow view of AI and its potential applications with 
focus on robotics and sensors as well as digital assistants, especially 
recommender systems. Other conceptions relate to the future potential 
and development of AI, including the idea that it is a technology that is 
an upcoming trend in its infancy and is constantly improving and 
evolving. 
Conceptions which relate to the potential dangers posed by AI and 
unspecific fears connected to AI are grouped into the theme ‘Threats, 
dangers and benefits of AI’ (Table 5). Many learners tend to view AI 
with binary, simultaneous attitudes of fear and hope; they show a more 
nuanced understanding. Generally, these views remain rather 
unspecific. 
Conceptions in the theme ‘Autonomy of AI’ (Table 6) suggest that 
people may have the belief that AI systems are fully autonomous tech-
nologies that can function and develop without the need for human 
intervention. 
The theme ‘Impact on society, healthcare and industry’ (Table 7) 
entails conceptions about how AI will affect various industries and 
fields, and the potential impact on daily lives and society as a whole. 
Conceptions pooled in the theme ‘Role of AI in education and ca-
reers’ (Table 8) show a range of attitudes towards learning with and 
about AI, from hopeful optimism to skepticism and uncertainty. 
Overall, conceptions of the theme ‘Inclusiveness, bias and trust’ 
(Table 9) show a range of attitudes towards the cost and objectivity of 
AI, from skepticism about its accessibility and impartiality to confidence 
in its capabilities. All these conceptions can be only found by one paper. 
They are theoretically derived and empirically tested. 
Table 2 
Identified categories in the theme ‘confusion and constrictive conceptions of AI 
at a technical level’.  
Category 
Reference(s) 
Brief description of the 
category 
Limited understanding 
of how a robot 
functions 
Ellis, Lauer, Silva, and 
Nina (2007) 
This conception does not 
entirely focusses on AI, it 
encompasses a lack of 
awareness of the software, 
algorithms, and hardware 
that make up a robot and 
how they interact to produce 
the desired outcome. 
Inability to describe or 
distinguish technical 
terms related to AI 
such as machine 
learning, neural 
networks, and deep 
learning 
Antonenko & 
Abramowitz, 2022;  
Lindner & Berges, 
2020; Pucchio et al., 
2022; Teng et al., 2022 
Having these knowledge 
gaps might be hindering 
one’s ability to effectively 
engage with discussions and 
decision-making related to 
AI. 
General limited or 
inaccurate knowledge 
of AI or some specifics 
(methods, algorithms, 
terms, features) 
Antonenko & 
Abramowitz, 2022;  
Chounta et al., 2022;  
Lindner & Berges, 
2020; Lindner & 
Romeike, 2019; Teng 
et al., 2022 
Having limited or inaccurate 
knowledge of AI is hindering 
the effective use of AI and 
the understanding of 
potential impacts on society. 
AI algorithms make 
mistakes 
Antonenko and 
Abramowitz (2022) 
It is important to understand 
that AI systems are not 
perfect and can sometimes 
produce incorrect results, 
especially when working 
with complex or novel 
problems, limited data, or 
when there are biases in the 
training data. 
AI is considered 
technically complex 
and unpredictable in 
terms of its results 
Lindner and Berges 
(2020) 
While AI systems can be 
complex, with many 
interrelated components and 
algorithms, they are 
designed and programmed 
by humans and can be made 
to operate in a transparent 
and explainable manner. At 
the same time, the results of 
AI systems can be influenced 
by the data and algorithms 
used in their development, 
as well as by the conditions 
under which they are used. 
Definition of AI focused 
on programming and 
robotics 
Evangelista, Blesio, and 
Benatti (2018) 
This narrow definition can 
lead to misunderstandings 
about the nature and 
capabilities of AI, as well as 
to misconceptions about the 
ways in which AI systems 
can be used to solve 
problems and make 
decisions. Understanding the 
full range of AI is crucial for 
effectively utilizing AI and 
for understanding its 
potential impacts on society. 
Rudimentary 
conceptions of 
machine learning 
Evangelista et al., 
2018; Sanusi, Oyelere, 
& Omidiora, 2022 
As learners may not have a 
deep understanding of the 
mathematical foundations of 
machine learning or the 
technical details of how 
these algorithms are 
implemented and optimized 
they might be able to 
understand the overall 
concept and can engage in 
basic discussions about the 
potential applications of AI 
and machine learning. 
(continued on next page) 
A. Bewersdorff et al.                                                                                                                                                                                                                           

--- Page 6 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

4.3. Most frequent conceptions on AI 
In our review of AI literature, we encountered numerous conceptions 
on AI that were repeatedly discussed in different papers. The following 
summarizes the most frequent conceptions found about AI (four findings 
or more). Firstly, we discovered that many learners struggle to describe 
or differentiate between technical terms associated with AI such as 
machine learning, neural networks, and deep learning (four studies). 
Additionally, they possess a limited or incorrect understanding of AI and 
its various components in general (five studies). This limited knowledge 
of AI seems to lead often to a narrow focus on specific applications of AI, 
such as robotics, digital assistants, and recommender systems (five 
studies) and the anthropomorphization of AI systems (five studies). 
Furthermore, our findings indicate a growing concern about AI causing 
unemployment and job loss, as well as negative views on its potential 
impact on human life and society in general (6 studies). However, there 
seems to be a lack of belief that their own profession as physicians, ra-
diologists or teachers will be replaced by AI (five studies). 
5. Discussion 
This study found that the studies published were with significant 
diversity in terms of territories, participants, and sample sizes. The 
western countries such as the US, Germany conducted more studies 
compared to countries in other regions. This might be due to economic 
resources and broad academic infrastructure in western countries as 
well as language barriers as we focussed solely on research published in 
English. Findings from studies conducted in Europe and North America 
may not necessarily apply to other regions due to these differences in 
economic and academic infrastructure as well as cultural and social 
contexts. As a result, the generalizability of the findings of the reported 
studies (and therefore this review) to other regions might be limited, 
leading to less effective interventions and strategies for addressing AI 
misconceptions globally. 
We also found that four different groups of learners were under 
investigation: elementary students and high school students, university 
students with a huge focus on medical students and (soon to be) 
teachers. This is a very limited sample of learners. The focus on students 
might stem from a desire to understand the conceptions that arise during 
the formative years of education. By targeting conceptions at this stage, 
researchers hope to better inform and improve educational practices, 
curricula, and materials to encounter misconceptions and promote a 
more accurate understanding of AI in future generations. To the best of 
our knowledge, there are currently no existing studies with samples 
covering professions affected by AI advances. These include fields such 
as law, management, journalism, social sciences, arts, music, philoso-
phy, and natural sciences, among others. This might indicate that there 
is an assumption that certain professions, such as medicine and educa-
tion, are more directly impacted by AI advancements, and therefore get 
more attention. This could bias researchers toward focusing on these 
groups, even though AI is affecting a wide range of fields. The findings 
call for studies to broaden the sample to verify prominent conceptions as 
well as to possibly identify conceptions not described yet. 
The studies found eight themes of misconceptions of AI. Specifically, 
the findings show that there is limited technical understanding about AI 
among learners, including confusions about definitions and concepts 
such as machine learning, neural networks, and deep learning. Learners 
also may not be able to distinguish between technical terms related to 
AI. This might be a result from getting most of the ideas, often only it’s 
‘buzzwords’ about AI, from the media (Lindner & Romeike, 2019; Sul-
mont, Patitsas, & Cooperstock, 2019) which is not backed by a basic 
understanding. 
The tendency to attribute human-like characteristics or attributes to 
AI systems and the conceptualization of AI as embodied might originate 
Table 2 (continued) 
Category 
Reference(s) 
Brief description of the 
category 
Very limited 
understanding of AI 
research methods 
Pucchio et al. (2022) 
This conception can lead to 
difficulties in evaluating the 
quality and reliability of AI 
research findings, as well as 
in making informed 
decisions about the use and 
development of AI 
technology. Having this 
conception might be not as 
problematic for learners on a 
basic level as for learners in 
the field of computer 
science.  
Table 3 
Identified Categories in the Theme ‘Anthropomorphization and embodied AI’.  
Category 
Reference(s) 
Brief description of the 
category 
Anthropomorphization of AI 
systems, such as the 
perception that they are 
humanoid or mimic 
human behavior 
Antonenko & 
Abramowitz, 2022; 
Evangelista et al., 
2018; Lindner & 
Berges, 2020;  
Mertala et al., 
2022; Oh et al., 

Anthropomorphization can 
result in a misleading 
understanding that AI 
systems can perform tasks 
that they are not capable of, 
or can understand and 
respond to human behavior 
in the same way that a 
human would. This 
conception may also 
influence how people 
interact with and perceive 
AI, even leading to ethical 
concerns. 
Belief that AI works like the 
human brain 
Antonenko & 
Abramowitz, 2022; 
Ellis et al., 2007;  
Lindner & Berges, 

This conception can lead to 
incorrect assumptions about 
the way AI processes and 
stores information. 
Understanding the 
differences between AI and 
the human brain is important 
for effectively evaluating the 
potential and limitations of 
AI technology. 
Conceptualization of AI as 
embodied (e.g., robots 
with arms, legs, and 
feelings) 
Kreinsen and 
Schulz (2021) 
While some AI systems may 
be embodied, many AI 
technologies, such as 
machine learning algorithms 
or natural language 
processing systems, are not 
physically embodied and 
exist only in software. Not 
knowing the different forms 
that AI can take and the ways 
in which AI systems interact 
with the world can lead to a 
limited conceptualization of 
AI. 
AI is nothing like the human 
brain and does not solve 
problems the way humans 
can 
Antonenko and 
Abramowitz 
(2022) 
While AI systems do operate 
differently from the human 
brain, they are capable of 
solving problems and 
making decisions that are 
beyond the capabilities of 
humans in some areas. At the 
same time, AI systems also 
have limitations and may not 
be able to perform certain 
tasks that are easy for 
humans, such as 
understanding context and 
recognizing emotions. 
Understanding these 
differences is key for AI 
literacy.  
A. Bewersdorff et al.                                                                                                                                                                                                                           

--- Page 7 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

from encounters from media like famous movies like ‘The Terminator’ 
(Cave et al., 2018). While, from a perspective to foster AI literacy, 
human-like characteristics or attributes to AI systems should be avoided, 
programmers and designers often strive to create AI systems that possess 
strong anthropomorphic features, behavior, and interaction to gain 
higher acceptance from humans towards these AI systems (Pelau, 
Dabija, & Ene, 2021). Unfortunately, this has resulted in misleading 
conceptions. 
Concerning the perceived threats and dangers as well as possible 
benefits and potential, many learners tend to view AI somewhat binary, 
beneficial and dangerous simultaneously. Studies show that learners 
with a lower degree have a more negative outlook on AI. Learners with a 
higher degree have a more positive or a mixed view on threads and 
potential (Marrone et al., 2022). More generally, different demographic 
groups often seem to exhibit vastly differing levels of trust towards AI 
(Richardson, Prioleau, Alikhademi, & Gilbert, 2020, pp. 489–496). 
There is a recognition that AI is present in daily life and AI leads to a 
general, somewhat unspecific, social change. Views on the overall 
impact of AI on society are not uniform. Some have concerns about the 
Table 4 
Identified Categories in the Theme ‘Understanding of the Scope, Capabilities and 
Limitations of AI and its future Potential and Development’.  
Category 
Reference(s) 
Brief description of the 
category 
Mixed views on the 
convenience and 
abilities, like 
creativity, of AI 
Antonenko & 
Abramowitz, 2022; Oh 
et al., 2017 
Learners with mixed 
views on AI likely 
understand the potential 
benefits and limitations 
of AI, but are uncertain 
about the full extent of its 
abilities and the impact it 
will have on society. This 
nuanced perspective is a 
central aspect of AI 
literacy, as it encourages 
critical thinking and 
balanced assessments of 
the role of AI. 
Focus on specific 
applications of AI such 
as robotics, digital 
assistants or 
recommender systems 
Clark, 2021; Evangelista 
et al., 2018; Kreinsen & 
Schulz, 2021; Marrone, 
Taddeo, & Hill, 2022;  
Ottenbreit-Leftwich et al., 

Learners who have a 
limited or focused 
understanding of AI 
based solely on their 
exposure to specific 
applications, such as 
robotics, digital 
assistants, or 
recommender systems 
may have a narrow view 
of AI and its capabilities. 
They may not fully 
appreciate its broader 
impact on society. For 
example, someone who 
only has experience with 
AI-powered digital 
assistants may not 
understand the 
implications of AI in areas 
such as privacy or ethics. 
This type of conception 
might hinder individuals 
from critically examining 
the role of AI in society. 
Conceptualization of AI 
as a sensory 
technology that uses 
sensors to acquire 
information from its 
surroundings 
Mertala et al. (2022) 
Learners have an 
understanding that AI is 
primarily a sensory 
technology that collects 
information from its 
surroundings through the 
use of sensors. This 
limited view of AI may 
lead to 
misunderstandings about 
the nature and 
capabilities of AI, and 
eventually cause learners 
to underestimate the 
potential impact of AI. 
AI viewed as a novel and 
mysterious problem 
space 
Greenwald, Leitner, and 
Wang (2021) 
These learners might be 
somehow fascinated by 
the complexity of AI and 
its potential to solve 
difficult problems, but 
may also have 
misconceptions about its 
capabilities and the 
potential consequences of 
its use. 
AI cannot be creative or 
match human 
creativity 
Antonenko & 
Abramowitz, 2022;  
Marrone et al., 2022 
Learners who hold this 
conception may see AI 
mainly as a tool for 
automating repetitive 
tasks, but not as a capable 
source of creative output. 
They may not fully 
appreciate the potential  
Table 4 (continued) 
Category 
Reference(s) 
Brief description of the 
category 
of AI in areas such as art, 
music, or writing, and 
therefore might not 
understand the role of AI 
in shaping our cultural 
landscape.  
Table 5 
Identified categories in the theme ‘threats, dangers and benefits of AI’.  
Category 
Reference(s) 
Brief description of the 
category 
Negative views (risk 
and threats) of AI’s 
impact on humans 
and society 
Eagle, Lander, & Hall, 
2021; Ghotbi, Ho, & 
Mantello, 2022; Joshi, 
Rambola, & Churi, 2021;  
Lopes, 2022; Mertala 
et al., 2022; Oh et al., 

Learners may be concerned 
about the unintended 
consequences of AI, such as 
biased decision-making or 
the erosion of human 
agency. This type of 
conception can lead to a 
one-sided view of AI, and 
may cause individuals to 
underestimate its potential 
benefits and to overstate the 
risks and threats associated 
with its use. 
Lack of trust in AI due 
to absence of human 
qualities such as 
emotions and affect 
Nazaretsky, Cukurova, 
and Alexandron (2022) 
Learners who hold this view 
may see AI as being 
impersonal, uncaring, or 
lacking in empathy. This 
may cause individuals to 
reject or be skeptical of AI- 
powered technologies and 
systems. 
Unspecific fears about 
AI 
Antonenko & 
Abramowitz, 2022;  
Lindner & Berges, 2020 
Learners who hold this 
abstract fear may be 
concerned about the 
potential consequences of 
AI, but may struggle to 
articulate or identify 
specific risks or threats 
associated with its use. 
Individuals therefore could 
be skeptical of or even 
reject AI-powered 
technologies and systems 
without fully understanding 
their potential benefits and 
risks.  
A. Bewersdorff et al.                                                                                                                                                                                                                           

--- Page 8 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

impact of AI on employment and the overall impact on society, as well as 
anxiety about its use in specific industries. Opposing this, there is the 
belief that almost no humans like physicians, radiologists, teachers 
would be replaced by AI – interestingly the learners spare only the 
profession they are studying (Nazaretsky et al., 2022; Pucchio et al., 
2022). The participants see the impact of AI on employment as a whole 
but think their jobs won’t be affected in a negative way by this trans-
formation. This conception might be caused by a self-protection mech-
anism. If they would acknowledge their own profession is challenged by 
the advancements of AI they would have to seriously reconsider their 
profession of choice. However, learners think that AI can also be useful, 
especially in healthcare, and have optimism towards the impact of AI on 
society. 
Concerning the inclusiveness, bias and trust of AI learners seem to 
have heterogeneous conceptions (AI is biased vs. AI can be 100% 
objective). These conceptions were described by one paper and are 
theoretically derived but empirically tested. Other studies seem not to 
put focus on investigating conceptions in this field which might be 
allocated in ethics of AI. 
There is an awareness that AI will be important in the future and that 
having a basic understanding of it is crucial. However, this awareness is 
accompanied by a feeling of being unprepared for this new technology. 
Additionally, there is some concern that AI is too complex to understand. 
This might be due to the belief that AI is for computer scientists and 
other professionals only (Sulmont et al., 2019). Despite this, there is 
generally a positive attitude towards AI education as a tool. 
6. Conclusion and limitations 
Especially in the last two years research on pre- and misconceptions 
of AI is getting more attention all around the globe. Some conceptions 
about AI seem described in various studies with different foci, samples 
and methods (qualitative and quantitative). We tried to allocate the 
identified conceptions to overarching themes. The high interrater 
agreement for the attribution of the conceptions to the categories and 
themes might be an indicator for a first, yet tentative, framework for 
classification of conceptions. The strong agreement among raters in 
assigning conceptions to categories and themes may be a first, albeit 
preliminary, approval of our inductively derived framework for classi-
fying conceptions. 
Besides being a central aspect in many AI literacy frameworks (e. g. 
Long & Magerko, 2020; Michaeli, Romeike, & Seegerer, 2022) 
Table 6 
Identified categories in the theme ‘autonomy of AI’.  
Category 
Reference(s) 
Brief description of the 
category 
Conceptualization of AI as 
an autonomous 
technology that can 
conduct tasks without 
human input 
Antonenko & 
Abramowitz, 2022; 
Mertala et al., 2022 
Learners who hold this view 
may believe that AI systems 
have the ability to make 
decisions and carry out 
actions on their own, 
without the need for human 
intervention, similar to the 
perception that AI systems 
can independently change 
and extend their program 
code. This conception can 
lead, as the conception 
mentioned before, to a 
misunderstanding of the 
nature of AI systems, as well 
as the role of human 
decision-makers in their 
development and use. 
AI cannot learn or function 
independently of humans 
Antonenko and 
Abramowitz 
(2022) 
This conception is the 
opposite of the conception 
described before.  
Table 7 
Identified categories in the theme ‘impact on society, healthcare and industry’.  
Category 
Reference(s) 
Brief description of the 
category 
No Believe that (they) 
humans like 
physicians, 
radiologists, teachers 
would be replaced 
Antonenko & 
Abramowitz, 2022;  
Clark, 2021; Gong 
et al., 2019; Lopes, 
2022; Pucchio et al., 

Learners who hold this view 
may believe that their 
specific job or profession is 
immune to automation, or 
that AI systems are not 
capable of performing the 
tasks that they perform. 
Learners might have a false 
sense of security and a lack 
of preparedness for the 
future of work in the age of 
AI. 
Expectation that AI will 
be essential and 
commonly used to 
improve medicine in 
the future 
Doumat, Daher, 
Ghanem, & Khater, 
2022; Pucchio et al., 
2022; Swed et al., 2022 
This conception describes 
the conception that AI will 
revolutionize the field of 
medicine by enabling more 
accurate diagnoses, 
personalized treatment 
plans, and improved patient 
outcomes. This can lead to a 
positive outlook on the 
potential of AI to improve 
healthcare, but also may lead 
to unrealistic expectations 
and a lack of understanding 
of the limitations and 
challenges associated with 
using AI in medicine. 
AI is present in our daily 
lives 
Lindner & Berges, 
2020; Mertala et al., 

Learners who hold this view 
might acknowledge AI as 
ubiquitous and constantly 
surrounding them. 
AI is useful and makes 
things easier for 
people 
Joshi et al., 2021;  
Mertala et al., 2022 
This very broad and 
unspecific conception may 
lead to seeing AI as a 
technology that can 
automate routine tasks, 
provide personalized 
recommendations, and solve 
problems more efficiently 
than humans. It might be 
connected with a positive 
outlook on the potential of AI 
to improve quality of life, but 
also may entail a lack of 
understanding of the 
limitations and challenges 
associated with using AI. 
Concern of inability to 
follow and control the 
advancement of AI 
Oh et al. (2017) 
Learners who hold this view 
may feel that the rapid 
advancements in AI are 
outpacing their ability to 
understand and keep up with 
it, leading to feelings of 
unease and uncertainty 
about the future. This type of 
conception can stem from a 
lack of understanding about 
AI and eventually may lead 
to fear or mistrust of AI 
technology. 
AI leads to a general 
social change, 
although this impact 
is often not specific 
Lindner and Berges 
(2020) 
Learners have the 
conception that AI has the 
potential to revolutionize the 
way we live, work, and 
interact with each other, but 
may not be able to articulate 
exactly how or why this will 
occur. While it shows a 
general awareness of AI and 
its growing presence in 
various aspects of life it also 
(continued on next page) 
A. Bewersdorff et al.                                                                                                                                                                                                                           

--- Page 9 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

conceptions about inclusiveness, bias and trust of AI did not appear in 
any study but one. Either conceptions in the general field of ethics may 
be not very common or this field wasn’t a focus in the reviewed studies. 
More research about conceptions of AI in the field of learners would help 
to make sense out of the findings. 
This exploratory review showed that there is a variety of pre- and 
misconceptions and myths about AI among learners. This calls for 
educational efforts across all professions to achieve real AI literacy 
among learners and promote a deeper understanding of the technology 
and its potential applications. Through education, learners can gain a 
deeper understanding of the technology and its capabilities, as well as 
the potential social and economic implications of its use. This knowledge 
empowers them to make informed decisions about the integration of AI 
in our society, rather than being swayed by misinformation and fear. 
Promoting AI literacy may help to ensure that the technology is devel-
oped and used in ways that are beneficial to society as a whole. 
One limitation of this study is the complementary use of Google 
Scholar as an additional source of records for our review. As Google 
Scholar is not a scientific database but a scientific search engine, repli-
cation of results might be limited. We argue that using Google Scholar as 
an additional source might provide a more holistic picture of this 
emerging research field. 
Another point of discussion might be the definition of our search 
terms. An alternative search term instead of “students” might be 
“learners”. We have chosen the term of “students” besides being nar-
rower because it seems the term mostly referred to in educational sci-
ences: The database ERIC reports 76 000 results for the term “learners” 
while reporting around 452 000 results (around 6x more) for the term 
“students”. 
The allocation of the single items to categories and overarching 
themes is our first approach to sorting the very heterogeneous concep-
tions found in the reviewed studies. While there are other category 
systems published we decided to inductively derive categories and 
themes. The process of pooling the items into categories and themes 
depends on parameters like the given emphasis on coherence and pre-
cision as well as the selected initial item constituting the first category 
and therefore might lead to (slightly) different outcomes depending on 
the persons conducting the pooling. Although first quality checks are 
encouraging, alternative classifications may be more suitable. As these 
themes arose from an exploratory search they are open to further 
development like identification of themes not described yet or the split 
of themes as more studies about conceptions of AI are published. 
Declaration of AI and AI-assisted technologies in the writing 
process 
During the preparation of this work the authors used Chat GPT (GPT- 
3.5) in order to improve readability and language of single sentences as 
some authors are not native English speakers. After using this tool, the 
authors reviewed and edited the content as needed and take full re-
sponsibility for the content of the publication. 
Funding 
This study was partially funded by National Science Foundation 
grants Award ID: 2101104 (PI Zhai). The findings, conclusions, or 
opinions herein represent the views of the authors and do not necessarily 
represent the view of personnel affiliated with the National Science 
Table 7 (continued) 
Category 
Reference(s) 
Brief description of the 
category 
reveals a lack of in-depth 
understanding of AI. 
Limited knowledge and 
skepticism about how 
AI could be used in 
practice at work 
Chounta et al., 2022;  
Clark, 2021; Pucchio 
et al., 2022 
Learners who hold this view 
may have limited knowledge 
of how it can be used to 
improve work processes and 
outcomes. They may 
question the potential 
benefits of AI and be 
skeptical about how it could 
be integrated into the 
workplace. It might originate 
from a lack of exposure to AI 
in the workplace, limited 
understanding or a general 
skepticism towards new 
technology. 
AI holds optimism and 
promise for individual 
fields or society 
Antonenko & 
Abramowitz, 2022;  
Teng et al., 2022 
These learners believe that 
AI has the ability to solve 
complex problems and 
improve outcomes, and that 
it can be used to create new 
products, services, and 
opportunities. This 
conception might come with 
limited awareness of possible 
threats and dangers of AI.  
Table 8 
Identified categories in the theme ‘role of AI in education and careers’.  
Category 
Reference(s) 
Brief description of the 
category 
Feeling unprepared and 
thinking of the need to 
use and understand AI in 
their careers 
Pucchio et al., 
2022; Teng et al., 

These learners may feel 
unprepared or ill-equipped to 
handle AI, and believe that 
they must take steps to gain an 
understanding of it in order to 
remain competitive in the job 
market. 
High motivation and 
positive attitude towards 
AI as tool for learning 
Polak, Schiavo, 
and Zancanaro 
(2022) 
Some learners, in this case 
teachers, might tend to have a 
proactive mindset and may be 
willing to invest time and effort 
to understand AI and its 
applications. 
Anyone can understand 
how AI works 
Antonenko and 
Abramowitz 
(2022) 
This conception, while 
encouraging from the 
perspective of an educator, 
might entail a lack of 
recognition of the complexity 
and technical nature of AI, and 
an overestimation of the ease 
of learning and understanding 
AI systems and algorithms.  
Table 9 
Identified categories in the theme ‘inclusiveness, bias and trust’.  
Category 
Reference(s) 
Brief description of the category 
AI is expensive and 
only for huge 
corporates 
Antonenko and 
Abramowitz (2022)  
AI is infallible and 
can be 100% 
objective 
Antonenko and 
Abramowitz (2022) 
This belief is misguided, as AI 
systems are only as objective as the 
data they are trained on, the 
algorithms they use, and the ways in 
which they are used in practice. 
Understanding the ways in which AI 
systems can be designed and 
developed to minimize bias and error 
is critical for effectively utilizing AI 
technology and for ensuring that it is 
used in a responsible and ethical 
manner. 
AI is always biased 
Antonenko and 
Abramowitz (2022) 
This refers to the conception that all 
AI systems are inherently biased, 
which is true as AI systems 
perpetuate and amplify existing 
biases in the data they are trained on.  
A. Bewersdorff et al.                                                                                                                                                                                                                           

--- Page 10 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

Foundation. 
Declaration of competing interest 
The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper. 
References 
Antonenko, P., & Abramowitz, B. (2022). In-service teachers’ (mis)conceptions of 
artificial intelligence in K-12 science education. Journal of Research on Technology in 
Education, 1–15. 
Atkinson, R. D. (2016). It’s going to kill Us!" and other myths about the future of artificial 
intelligence.  Information Technology & Innovation Foundation.  
Cave, S., Craig, C., Dihal, K., Dillon, S., Montgomery, J., Singler, B., et al. (2018). 
Portrayals and perceptions of AI and why they matter. Apollo - University of Cambridge 
Repository. https://doi.org/10.17863/CAM.34502 
Chao, P. J., Hsu, T. H., Liu, T. P., & Cheng, Y. H. (2021). Knowledge of and competence in 
artificial intelligence: Perspectives of Vietnamese digital-native students. IEEE 
Access, 9, 75751–75760. https://doi.org/10.1109/access.2021.3081749 
Chi, M. T. H., & Roscoe, R. D. (2002). The processes and challenges of conceptual change. 
In M. Lim´on, & L. Mason (Eds.), Reconsidering conceptual change: Issues in theory and 
practice. Dordrecht: Springer. https://doi.org/10.1007/0-306-47637-1_1.  
Chounta, I.-A., Bardone, E., Raudsep, A., & Pedaste, M. (2022). Exploring teachers’ 
perceptions of artificial intelligence as a tool to support their practice in Estonian K- 
12 education. International Journal of Artificial Intelligence in Education, 32(3), 
725–755. 
Clark, R. (2021). Perspectives on machine learning and artificial intelligence from trainee 
radiologists. Swansea: Swansea University.  
Cliff, S., & Melissa, M. (2017). Axial coding. In Matthes (Ed.), The international 
encyclopedia of communication research methods. Hoboken: Wiley. https://doi.org/ 
10.1002/9781118901731.iecrm0012.  
Doumat, G., Daher, D., Ghanem, N.-N., & Khater, B. (2022). Knowledge and attitudes of 
medical students in Lebanon toward artificial intelligence: A national survey study. 
Frontiers in artificial intelligence, 5, Article 1015418. 
Eagle, R., Lander, R., & Hall, P. D. (2021). Questioning ‘what makes us human’: How 
audiences react to an artificial intelligence–driven show. Cognitive Computation and 
Systems, 3(2), 91–99. 
Ellis, G., Lauer, J., Silva, K., & Nina, N. (2007). Assessing high school girls’ preconceptions 
about artificial intelligence to improve learning intelligence to improve learning (pp. 
1–15). Engineering: Faculty Publications. 
Emmert-Streib, F., Yli-Harja, O., & Dehmer, M. (2020). Artificial intelligence: A 
clarification of misconceptions, myths and desired status. Frontiers in artificial 
intelligence, 3, Article 524339. Retrieved December 09, 2021. 
Evangelista, I., Blesio, G., & Benatti, E. (2018). Why are we not teaching machine learning at 
high school? A proposal (pp. 1–6). World Engineering Education Forum - Global 
Engineering Deans Council. 
Fleiss, J. L. (1981). The measurement of interrater agreement. In Statistical methods for 
rates and proportions (pp. 212–236). New York: Wiley.  
Forbes, M. (2022). The 6 myths (and realities) of AIOps. Forbes Magazine. from https:// 
www.forbes.com/sites/splunk/2022/04/01/the-6-myths-and-realities-of-aiops/. 
Ghotbi, N., Ho, M. T., & Mantello, P. (2022). Attitude of college students towards ethical 
issues of artificial intelligence in an international university in Japan. AI & Society, 
37(1), 283–290. 
Gong, B., Nugent, J. P., Guest, W., Parker, W., Chang, P. J., Khosa, F., et al. (2019). 
Influence of artificial intelligence on Canadian medical students’ preference for 
radiology specialty: A national survey study. Academic Radiology, 26(4), 566–577. 
Gooding, J., & Metz, B. (2011). From misconceptions to conceptual change. The Science 
Teacher, 78(4), 34. 
Google. (2022). Exploring 6 AI myths. from https://ai.google/static/documents/explo 
ring-6-myths.pdf. 
Greenwald, E., Leitner, M., & Wang, N. (2021). Learning artificial intelligence: Insights into 
how youth encounter and build understanding of AI concepts. 
Haddaway, N. R., Collins, A. M., Coughlin, D., & Kirk, S. (2015). The role of Google 
scholar in evidence reviews and its applicability to grey literature searching. PLo S 
One, 10(9), Article e0138237. 
Hornberger, M., Bewersdorff, A., Nerdel, C. (in prep.). What do university students know 
about AI? Development and validation of an AI literacy test. 
Jiang, Y., Li, X., Luo, H., Yin, S., & Kaynak, O. (2022). Quo vadis artificial intelligence? 
Discover Artificial Intelligence, 2(4). https://doi.org/10.1007/s44163-022-00022-8 
Joshi, S., Rambola, R. K., & Churi, P. (2021). Evaluating artificial intelligence in 
education for next generation. Journal of Physics: Conference Series, 1714(1), Article 
12039. 
Kelle, U., & Kluge, S. (2010). Vom Einzelfall zum Typus. Fallvergleich und Fallkontrastierung 
in der qualitativen Sozialforschung [From case to type. Case comparison in qualitative 
research]. Wiesbaden, Germany: Springer.  
Kerr, A., Barry, M., & Kelleher, J. D. (2020). Expectations of artificial intelligence and the 
performativity of ethics: Implications for communication governance. Big Data & 
Society, 7(1). https://doi.org/10.1177/2053951720915939 
Kreinsen, M., & Schulz, S. (2021). Students’ conceptions of artificial intelligence. In The 
16th workshop in primary and secondary computing education (pp. 1–2). https://doi. 
org/10.1145/3481312.3481328 
Landis, J. R., & Koch, G. G. (1977). The measurement of observer agreement for 
categorical data. Biometrics, 33(1), 159–174. from http://www.jstor.org/stable/ 
2529310. 
Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., et al. (2023). Artificial general 
intelligence (AGI) for education. ar Xiv:2304.12479. Retrieved April 01, 2023, from htt 
ps://arxiv.org/abs/2304.12479. 
Leufer, D. (2020). Why we need to bust some myths about AI. Patterns, 1(7), 1–3. https:// 
doi.org/10.1016/j.patter.2020.100124 
Leufer, D., Steinbrück, A., & Liptakova, Z. (2020). AI myths. from www.aimyths.org. 
Liang, Y. (2021). Common misconceptions of AI – and why they must Be overcome. Seattle: 
Pactera.  
Lindner, A., & Berges, M. (2020). Can you explain AI to me? Teachers’ pre-concepts 
about artificial intelligence. In 2020 IEEE Frontiers in education conference (FIE) (pp. 
1–9). IEEE.  
Lindner, A., & Romeike, R. (2019). Teachers’ perspectives on artificial intelligence. In 
12th International conference on informatics. 
Long, D., & Magerko, B. (2020). What is AI literacy? Competencies and design 
considerations. In Proceedings of the 2020 CHI conference on human factors in 
computing systems (Vols. 1–16). 
Lopes, G. (2022). Soft version of approaching artificial intelligence and humans what do 
they think? Proceedings of Co PDA2022, 66–73. 
Marrone, R., Taddeo, V., & Hill, G. (2022). Creativity and artificial intelligence-A student 
perspective. Journal of Intelligence, 10(3). 
Mayring, P. (2021). Qualitative content analysis: A step-by-step guide. Los Angeles, London, 
New Delhi, Singapore, Washington DC, Melbourne: Sage.  
Mertala, P., Fagerlund, J., & Calderon, O. (2022). Finnish 5th and 6th grade students’ 
pre-instructional conceptions of artificial intelligence (AI) and their implications for 
AI literacy education. Computers & Education: Artificial Intelligence, 3, Article 100095. 
Michaeli, T., Romeike, R., & Seegerer, S. (2022). What students can learn about artificial 
intelligence - recommendations for K-12 computing education. In Proceedings of IFIP 
WCCE 2022: World conference on computers in education (Hiroshima). 
Natale, S., & Ballatore, A. (2020). Imagining the thinking machine: Technological myths 
and the rise of artificial intelligence. Convergence: The International Journal of 
Research Into New Media Technologies, 26(1), 3–18. 
Nazaretsky, T., Cukurova, M., & Alexandron, G. (2022). An instrument for measuring 
teachers’ trust in AI-based educational technology. In LAK22: 12th international 
learning analytics and knowledge conference (LAK22) (pp. 56–66). New York, NY, USA: 
Association for Computing Machinery. https://doi.org/10.1145/3506860.3506866 
Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI 
literacy: An exploratory review. Computers & Education: Artificial Intelligence, 2, 
Article 100041. https://doi.org/10.1016/j.caeai.2021.100041 
Oh, C., Lee, T., Kim, Y., Park, S., Kwon, S., & Suh, B. (2017). Us vs. Them: Understanding 
artificial intelligence technophobia over the Google Deep Mind challenge match. In 
Proceedings of the 2017 ACM SIGCHI conference on human factors in computing systems 
(pp. 2523–2534). 
Ottenbreit-Leftwich, A., Glazewski, K., Jeon, M., Hmelo-Silver, C., Mott, B., Lee, S., et al. 
(2021). How do elementary students conceptualize artificial intelligence?, ’21. Poster: 
SIGCSE.  
¨Ozdemir, G., & Clark, D. B. (2007). An overview of conceptual change theories. Eurasia 
Journal of Mathematics, Science and Technology Education, 3(4), 351–361. 
Page, M. J., Mc Kenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., 
et al. (2020). The PRISMA 2020 statement: A guideline for reporting systematic reviews. 
Pelau, C., Dabija, D.-C., & Ene, I. (2021). What makes an AI device human-like? The role 
of interaction quality, empathy and perceived psychological anthropomorphic 
characteristics in the acceptance of artificial intelligence in the service industry. In 
Computers in human behavior (Vol. 122). 
Polak, S., Schiavo, G., & Zancanaro, M. (2022). Teachers’ perspective on artificial 
intelligence education: An initial investigation. In Extended abstracts of the 2022 CHI 
conference on human factors in computing systems (CHI EA ’22) (pp. 1–7). https://doi. 
org/10.1145/3491101.3519866 
Potvin, P. (2022). From conceptual change to conceptual prevalence. In M. B´elanger, 
P. Potvin, S. Horst, A. Shtulman, & E. F. Mortimer (Eds.), Multidisciplinary perspectives 
on representational pluralism in human cognition: Tracing points of convergence in 
psychology, science education, and philosophy of science. Routledge. https://doi.org/ 
10.4324/9781003189930.  
Pucchio, A., Rathagirishnan, R., Caton, N., Gariscsak, P. J., Del Papa, Nabhen, J., et al. 
(2022). Exploration of exposure to artificial intelligence in undergraduate medical 
education: A Canadian cross-sectional mixed-methods study. BMC Medical Education, 
22(1), 815. https://doi.org/10.1186/s12909-022-03896-5 
Richardson, B., Prioleau, D., Alikhademi, K., & Gilbert, J. E. (2020). Public accountability: 
Understanding sentiments towards artificial intelligence across dispositional identities. 
Sanusi, I. T., Oyelere, S. S., & Omidiora, J. O. (2022). Exploring teachers’ preconceptions 
of teaching machine learning in high school: A preliminary insight from Africa. 
Computers and Education Open, 3, Article 100072. 
Sulmont, E., Patitsas, E., & Cooperstock, J. R. (2019). Can you teach me to machine 
learn? SIGCSE, 19, 948–954. February 27–March 2, 2019, Minneapolis, MN, USA. 
Su, J., Zhong, Y., & Ng, D. Z. K. (2022). A meta-review of literature on educational 
approaches for teaching AI at the K-12 levels in the Asia-Pacific region. Computers & 
Education: Artificial Intelligence, 3, Article 100065. https://doi.org/10.1016/j. 
caeai.2022.100065 
Swed, S., Alibrahim, H., Elkalagi, N. K. H., Nasif, M. N., Rais, M. A., Nashwan, A. J., et al. 
(2022). Knowledge, attitude, and practice of artificial intelligence among doctors 
and medical students in Syria: A cross-sectional online survey. Frontiers in artificial 
intelligence, 5, Article 1011524. 
A. Bewersdorff et al.                                                                                                                                                                                                                           

--- Page 11 ---

Computers and Education: Artificial Intelligence 4 (2023) 100143

Taber, K. S. (2014). Alternative conceptions/frameworks/misconceptions. In 
R. Gunstone (Ed.), Springer Reference. Encyclopedia of science education. A springer live 
reference (pp. 1–5). Dordrecht, Heidelberg: Springer Reference.  
Teng, M., Singla, R., Yau, O., Lamoureux, D., Gupta, A., Hu, Z., et al. (2022). Health care 
students’ perspectives on artificial intelligence: Countrywide survey in Canada. JMIR 
medical education, 8(1), Article e33390. 
Vk, A. (2022). 10 most common myths about AI. from https://www.spiceworks.com/tech/ 
artificial-intelligence/articles/common-myths-about-ai/. 
White, R. T., & Gunstone, R. F. (1989). Metalearning and conceptual change. 
International Journal of Science Education, 11(5), 577–586. https://doi.org/10.1080/ 

Zhai, X., & Krajcik, J. (2022). Pseudo AI bias. ar Xiv preprint ar Xiv:2210.08141. 
A. Bewersdorff et al.
