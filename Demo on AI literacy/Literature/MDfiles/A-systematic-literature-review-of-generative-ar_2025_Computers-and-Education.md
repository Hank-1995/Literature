# A systematic literature review of generative artificial intelligence (GenAI) literacy in schools

## Metadata
- **Author**: Joonhyeong Park
- **Subject**: Computers and Education: Artificial Intelligence, 9 (2025) 100487. doi:10.1016/j.caeai.2025.100487
- **Creator**: Elsevier
- **Producer**: Acrobat Distiller 8.1.0 (Windows)
- **Creation Date**: D:20251010080011Z
- **Modification Date**: D:20251010151109Z
- **Source File**: A-systematic-literature-review-of-generative-ar_2025_Computers-and-Education.pdf
- **Converted**: 2025-10-23 22:46:13

---

## Content

--- Page 1 ---

A systematic literature review of generative artificial intelligence (Gen AI) 
literacy in schools
Joonhyeong Park
National Institute of Education, Nanyang Technological University, Singapore
A R T I C L E  I N F O
Keywords:
Generative artificial intelligence
Generative AI literacy
AI literacy
Gen AI literacy
Systematic review
A B S T R A C T
Given the rapid integration of generative artificial intelligence (Gen AI) technologies, such as large language 
models, into educational contexts, fostering students’ Gen AI literacy has become essential. However, previous AI 
literacy frameworks may inadequately reflect specific competencies necessary for proficient Gen AI use. To 
address this gap, this study aimed to conceptualise a Gen AI specific literacy framework tailored explicitly for 
educational settings and systematically examine recent research trends concerning Gen AI literacy. Employing a 
systematic literature review approach, 51 empirical studies published in 2023 and 2024 were selected and 
analysed based on five identified competencies of Gen AI literacy: (1) know and understand Gen AI, (2) use and 
apply Gen AI, (3) evaluate and incorporate Gen AI, (4) Gen AI ethics, and (5) attitudes towards Gen AI. The findings 
indicate that students demonstrated moderate understanding of Gen AI concepts but frequently faced challenges 
in prompt engineering and critical evaluation of AI-generated outputs. Ethical considerations, particularly 
related to academic integrity, privacy, and data security, were highlighted as significant concerns. Furthermore, 
positive student attitudes towards Gen AI, including curiosity and self-efficacy, emerged as vital components 
enhancing engagement with Gen AI tools. A five-step interaction model was proposed to help in fostering stu-
dents’ Gen AI literacy, emphasising iterative and dynamic engagement with Gen AI tools. This study underscores 
the necessity of explicitly integrating Gen AI-specific competencies into educational practices and recommends 
clear institutional policies, and further empirical research to support the responsible, effective, and reflective use 
of Gen AI in school settings.
1. Introduction
Artificial intelligence (AI) has played a transformative role in the 
digital era, leading to a high demand for its integration into schools 
(OECD, 2024), along with growing attention to ethical concerns 
(UNESCO, 2022). One significant effort to integrate AI into school 
curricula has been educating students about AI concepts, ideas, appli-
cations and ethics, which has resulted in the development of pedagogical 
approaches aimed at fostering students’ AI literacy (Casal-Otero et al., 
2023). These efforts involve not only teaching knowledge about AI but 
also guiding students in using and applying AI ethically, particularly in 
educational contexts. In general, AI literacy has been defined as “a set of 
competencies that enable individuals to critically evaluate AI technol-
ogies, communicate with AI, and use AI effectively as a tool” (Long & 
Magerko, 2020, p. 2). Fostering students’ AI literacy, therefore, involves 
helping them understand AI concepts and apply those ideas by using AI 
tools critically and effectively, given ethical considerations, aiming to 
equip students with AI literacy as one of their fundamental skills (Ng 
et al., 2021). As AI integration into schools has still been in its nascent 
stages (Chiu et al., 2023), substantial efforts have been made to 
conceptualise AI literacy and frameworks and develop AI curricula, 
AI-integrated curricula, and AI-integrated lesson packages. For instance, 
Touretzky et al. (2019) proposed the Five Big Ideas in AI as an organ-
ising framework for teaching AI, particularly to K-12 students in the U.S. 
This framework includes five key concepts: perception, representation 
and reasoning, learning, natural interaction, and societal impact. Using 
this framework, various curricula where AI is treated as a stand-alone 
subject have been developed and implemented (Touretzky et al., 
2023). An interdisciplinary approach has also been taken; for example, 
Park et al. (2023) developed AI-integrated science lessons focused on 
building predictive models using big data sets and machine learning 
algorithms and implemented the lesson package to explore teachers’ 
perspectives.
A number of studies, including the examples above, have primarily 
focused on teaching AI concepts such as machine learning, supervised 
and unsupervised learning, and neural networks using big data sets 
E-mail address: joonhyeong.park@nie.edu.sg. 
Contents lists available at Science Direct
Computers and Education: Artificial Intelligence
journal homepage: www.sciencedirect.com/journal/computers-and-education-artificial-intelligence
https://doi.org/10.1016/j.caeai.2025.100487
Received 3 May 2025; Received in revised form 21 September 2025; Accepted 4 October 2025  
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 
Available online 6 October 2025 
2666-920X/© 2025 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC license ( http://creativecommons.org/licenses/by- 
nc/4.0/ ). 

--- Page 2 ---

(Touretzky et al., 2023), significantly contributing to educational in-
novations. However, with the release of Chat GPT by Open AI at the end 
of 2022, there has been a huge interest in generative AI (Gen AI), which 
generate content with various forms such as texts, diagrams, sounds, and 
video clips by natural language, across various industries and educa-
tional fields (Mishra et al., 2023). In addition, newer and more powerful 
large language models (LLMs), such as Gemini 2.5 Flash, Claude 4.5, and 
GPT-5—as of September 2025—have been developed and made publicly 
available. A key reason for the widespread adoption of Gen AI worldwide 
has been the advancement of natural language processing technologies, 
enabling even non-experts in computer languages to interact seamlessly 
with LLMs (Yi et al., 2022). Specifically, availability and adaptability in 
using LLMs have been significantly enhanced, ensuring the quality of 
AI-generated content. This advancement allows users to interact with 
Gen AI chatbots by inputting natural human language through text and 
voice and to generate quality responses in various modes, including 
voices, texts, and images. Consequently, teachers and students can now 
engage in human-like conversations with Gen AI chatbots during 
teaching and learning (Jiahong & Weipeng, 2023), heralding a major 
paradigm shift in education (Bozkurt, 2023).
Given the improved availability and adaptability of the use of Gen AI 
and its versatility, capabilities, and limitations, many educational re-
searchers have investigated how to incorporate Gen AI into classrooms 
theoretically and empirically. A key benefit of Gen AI in education is its 
ability to provide personalised learning environments, enabling students 
to engage more deeply with tasks while receiving immediate feedback. 
Through interactions with Gen AI chatbots, students can ask questions, 
receive tailored responses, and access further information (Hsain & 
Housni, 2024; M. Liu, Zhang, & Biebricher, 2024; Mai et al., 2024). This 
facilitates self-regulated learning, allowing students to enhance their 
understanding, engagement, and motivation at their own pace and ac-
cording to their interests (Ng, Tan, & Leung, 2024). As personalised 
tutors, Gen AI chatbots are able to provide on-demand information, 
detailed explanations, and comprehensive feedback, accessible instantly 
and repeatedly through student prompts (Neumann et al., 2024). 
However, several challenges and considerations accompany Gen AI 
integration into classrooms related to the features of Gen AI tools and 
their usage by students. One concern is the issue of hallucinations, where 
seemingly plausible but incorrect information is generated by Gen AI 
tools due to the probabilistic reasoning inherent in LLMs (Martin & 
Graulich, 2024; Nafar et al., 2024; Xu et al., 2024). Such inaccuracies, 
which would be difficult to identify during the lessons, may mislead 
students, making it difficult to manage their learning effectively. In 
addition, Gen AI tools may produce culturally biased responses due to 
biases in their training data, requiring careful interpretation (Zhang & 
Tur, 2024). Improper usage of Gen AI in classrooms also raises ethical 
concerns, including issues related to fairness, privacy, and data protec-
tion, which should be addressed and educated in schools to ensure 
responsible and ethical use (Kajiwara & Kawabata, 2024).
To mitigate the critical challenges of integrating Gen AI into schools, 
it is essential for students to develop the knowledge, skills, and attitudes 
required for its effective use. However, AI literacy frameworks con-
ceptualised and developed in earlier years may not fully align with the 
competencies needed for proficient Gen AI use in classrooms. This 
highlights the need for a Gen AI-specific literacy framework tailored to 
its use in schools, rather than relying on general AI literacy frameworks 
(Annapureddy et al., 2024; Bozkurt, 2024). For example, earlier AI lit-
eracy frameworks placed relatively limited emphasis on prompt engi-
neering whereas the use of Gen AI demands significant focus on using 
proper prompt to shape AI-content generation properly. In addition, 
these initial frameworks did not prioritise prompt engineering, a critical 
skill for shaping precise and accurate Gen AI-generated responses given 
particular purposes. Despite the growing body of empirical and review 
studies on Gen AI use, earlier AI literacy frameworks have been more 
broadly used in educational research. Recognising the necessity of a 
Gen AI-specific literacy framework and considering the extensive 
research on Gen AI in school contexts from late 2022 to the present, this 
study aimed to conceptualise such a framework and further examine 
how recent research trends on Gen AI use align with the proposed Gen AI 
literacy framework.
2. Conceptual framework for Gen AI literacy
To conceptualise the Gen AI literacy framework for this study, this 
review identified key specific competencies in using Gen AI, which are 
distinct features from AI literacy in general, incorporated into Ng et al.’s 
(2021) AI literacy framework, which has been widely used and highly 
cited in educational studies—1500 times as of September 2025. Ng et al. 
suggested four elements of AI literacy in a boarder manner for all 
educational levels: ‘know and understand AI’, ‘use and apply AI’, 
‘evaluate and create AI’, and ‘AI ethics.’ Although the descriptions of Ng 
et al.’s framework broadly cover competencies of Gen AI, as discussed 
above, more specific aspects of Gen AI need to be highlighted. This is 
because using Gen AI more effectively and properly in generating con-
tent requires different skill sets from using a general AI application, for 
example, developing a model using a machine learning algorithm. Given 
recent review and empirical studies on Gen AI and AI literacy, as shown 
in Fig. 1 and Table 1, the five components of Gen AI literacy were con-
ceptualised for this review study: (1) know and understand Gen AI, (2) 
use and apply Gen AI, (3) evaluate and incorporate Gen AI, (4) Gen AI 
ethics, and (5) attitudes towards Gen AI. Although the first four com-
ponents are similar to the initial AI literacy framework, the Gen AI lit-
eracy framework particularly focuses on Gen AI instead of broader AI 
and involves the details of Gen AI. In addition to the four original com-
ponents, the attitudes towards Gen AI component (Ng et al., 2023, 2024) 
was added, since the affective domain is interrelated to students’ 
engagement of the use of Gen AI. One critical consideration of this 
conceptualisation is adopting a human-centred approach, which is 
strongly aligned with the values in UNESCO’s ethics recommendation 
(UNESCO, 2022). For example, this framework centres students’ ideas 
and agency, emphasises the evaluation and incorporation of Gen AI 
outputs, and highlights the responsible and fair use of Gen AI. In the 
following sections, the details of each component are illustrated to show 
how these competencies collectively support responsible, effective, and 
reflective engagement with Gen AI.
Fig. 1. Gen AI literacy framework.
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 3 ---

2.1. Know and understand Gen AI
Basic Gen AI knowledge, including how it works, along with its un-
derlying principles and mechanisms, forms the foundation for under-
standing Gen AI-related concepts, tools, and applications in the digital 
era. This knowledge encompasses how Gen AI creates new multimodal 
texts, such as written texts, images, music, and video clips, by using the 
large datasets it has been trained on (Miao & Shiohira, 2024, p. 80). 
With this foundational understanding, students can develop a more 
nuanced awareness of Gen AI’s capabilities, limitations, and its appli-
cations in various contexts, along with their benefits. For example, since 
Gen AI typically relies on probabilistic patterns derived from pre-trained 
large datasets and does not extract exact information from these datasets 
(Xu et al., 2024), students can better appreciate how AI-generated 
content may sometimes be incorrect or produce hallucinations. This 
also underscores the importance of data quality in generating new 
content (Farrokhnia et al., 2024). Students can gain also insight into 
how biased content might be generated by Gen AI, depending on the data 
used for training large language models (Zhai, 2022). The depth of basic 
Gen AI knowledge required may vary depending on students’ levels. For 
example, students at higher educational levels should understand more 
detailed processes of how Gen AI functions, including training and gen-
eration processes (Annapureddy et al., 2024). This might involve con-
cepts such as machine learning, natural language processing, large 
language models, and the varying capabilities and limitations of Gen AI 
depending on specific tasks and domains (Open AI, 2023).
2.2. Use and apply Gen AI
It is crucial for students to develop competencies in using Gen AI to 
generate multimodal content in diverse contexts through prompt engi-
neering and/or customising Gen AI tools. By interacting with various 
Gen AI tools (e.g., Chat GPT, DALL-E, Claude, Gemini, Sora, Microsoft 
Copilot, Synthesia, Jasper, and Canva), students can create diverse 
content such as written text, images, graphs, video clips, and songs with 
specific goals (Annapureddy et al., 2024). To achieve more targeted and 
high-quality output using Gen AI tools, students should create and apply 
input statements, known as prompts, which typically consist of a set of 
instructions and guidelines (Knoth et al., 2024). While advancements in 
natural language processing technology have significantly enhanced the 
availability of Gen AI, it is not straightforward to craft prompts that will 
effectively produce high-quality output (Zamfirescu-Pereira et al., 2023, 
pp. 1–21). Prompt engineering, being a form of human-Gen AI interac-
tion rather than human-to-human interaction, requires a systematic 
approach. Students can benefit from applying prompt engineering 
techniques such as few-shot prompting (Touvron et al., 2023) and chai-
n-of-thought prompting (Wei et al., 2022). Advanced-level students can 
further develop and customise Gen AI chatbots or fine-tune specific 
Gen AI applications using targeted datasets, thereby setting appropriate 
conditions for purposeful and effective Gen AI usage (Annapureddy 
et al., 2024).
2.3. Evaluate and incorporate Gen AI
The importance of collaboration between humans and AI cannot be 
overstated in the use of Gen AI. Reflecting this significance, the term 
‘incorporate’ has been selected instead of ‘create’ from Ng et al.’s (2021)
AI literacy framework, which was informed by Bloom’s taxonomy. To 
achieve effective human-AI collaboration, it is essential to develop 
competencies for critically evaluating Gen AI outputs based on needs and 
expectations regarding accuracy, quality, coherence, task relevance, and 
potential biases (Annapureddy et al., 2024). This process demands 
higher-order thinking skills (Ng et al., 2021) and domain-specific 
knowledge relevant to the tasks. It also requires the ability to evaluate 
and verify AI-generated content using other resources and engaging 
with teachers and peers. Since AI-generated content may contain inac-
curacies, hallucinations, incomplete ideas, and biases, students should 
be capable of assessing Gen AI output adequately to prevent the misuse 
or inappropriate dissemination of such information (UNESCO, 2022). By 
conducting proper evaluations and verifications, students can refine and 
integrate AI-generated ideas and content into their own, enabling them 
to complete tasks, solve identified or given problems, and make more 
informed decisions (Yim, 2024). This highlights that students should not 
solely depend on AI-generated content but use it appropriately and 
responsibly while exercising their own agency. This perspective is 
closely tied to Gen AI ethics, discussed in the following section.
2.4. Gen AI ethics
The competencies related to Gen AI ethics have become increasingly 
significant as public attention has shifted from general AI to Gen AI. 
These competencies involve the responsible and fair use of Gen AI by 
students, with careful consideration of ethical issues related to societal 
values and their learning processes (Kajiwara & Kawabata, 2024; Miao 
& Shiohira, 2024, p. 80). When using Gen AI, human users should take 
intellectual, ethical, and legal responsibility for the AI-generated con-
tent they utilise, which has been highlighted (UNESCO, 2022). For 
example, students’ use of Gen AI should adhere to regulations of aca-
demic integrity, guided by teachers and instructors who provide clear 
guidelines on the appropriate and ethical use of Gen AI (Jeon & Lee, 
2023). Since the use of Gen AI in schools presents various risks—such as 
plagiarism, copyright violations, cheating, biased perspectives, and 
over-reliance (Farrokhnia et al., 2024; Mai et al., 2024)—students 
should be adequately prepared to engage with Gen AI responsibly and 
fairly while exercising their own agency and maintaining a balanced 
perspective. In addition, students should understand regulations gov-
erning the use of Gen AI, particularly those related to data privacy and 
security (Annapureddy et al., 2024).
2.5. Attitudes towards Gen AI
Students’ attitudes towards Gen AI significantly influence their 
engagement with its use (Ng et al., 2023). Attitudes towards Gen AI re-
fers to students’ motivation, interest in using Gen AI, confidence, and 
perception of their own competency in employing it effectively. These 
attitudes are critical because they shape how students approach and 
engage in the use of Gen AI and their ability to develop the necessary 
competencies. Moreover, students’ attitudes are closely tied to their 
psychological needs, which can stimulate interest and motivation for 
greater autonomy and competency in relation to Gen AI use (Chiu & 
Chai, 2020).
3. Research questions
This study aimed to examine research trends related to Gen AI liter-
acy education in schools. While most previous studies have focused on 
Table 1 
Description for the Gen AI literacy framework.
Gen AI literacy
Description
Know and understand 
Gen AI
Understanding basic Gen AI knowledge, including how it 
works and its capabilities, limitations and applications
Use and apply Gen AI
Using Gen AI in generating content in various contexts 
involving different scenarios and multimodal interactions 
by prompting engineering and customising Gen AI tools
Evaluate and 
incorporate Gen AI
Critically evaluating and refining Gen AI outputs to 
effectively incorporate them with human ideas and 
contributions
Gen AI ethics
Ensuring responsible and fair use of Gen AI through a 
human-centred approach by understanding various 
societal values and regulations
Attitudes towards 
Gen AI
Fostering curiosity, interest, and self-efficacy in engaging 
with Gen AI
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 4 ---

AI literacy in general, there is a need to highlight Gen AI-specific com-
petencies, particularly those related to generating content powered by 
LLMs. Addressing this research gap, the following research questions 
(RQs) were formulated to guide this study: 
RQ1. What are the general research trends in Gen AI literacy educa-
tion in schools?
RQ2. What findings have been reported by studies in terms of Gen AI 
literacy education in schools?
Following the systematic review addressing these two research 
questions, the significance of the findings will be further discussed, with 
particular attention to their implications for educational practices and 
policy development.
4. Methodology
This study adopted a systematic review approach to examine recent 
Gen AI literacy studies by identifying, selecting, and screening relevant 
articles and summarising their findings. The review process followed the 
updated Preferred Reporting Items for Systematic Reviews and Meta- 
Analysis Protocols (PRISMA-P) statement (Moher et al., 2015). The re-
view had three stages: Identifying relevant articles, screening the iden-
tified articles with the criteria, and selecting articles for analysis.
4.1. Identification of relevant articles
To ensure the inclusion of high-quality, impactful scientific articles, 
four databases—Web of Science, Scopus, ACM, and IEEE—were used. 
This study focused on peer-reviewed journal articles published in En-
glish. Given the focus on Gen AI literacy and the widespread attention 
Gen AI has received after Chat GPT’s release in late 2022, our initial 
intention was to define the review period as two years, covering 
November 2022 to November 2024. However, no eligible studies 
meeting the inclusion criteria were published in 2022. Moreover, it was 
technically challenging to specify publication periods by individual 
months across the selected databases, whereas year-based search ranges 
were feasible. Consequently, the review period was set from 1 January 
2023 to 15 November 2024 to capture the most relevant and recent 
studies. The scope of education levels was limited to primary, secondary, 
and undergraduate education, as graduate-level education may involve 
different approaches to Gen AI literacy. In addition, one of the inclusion 
criteria was that only primary empirical studies (Thomas & Harden, 
2008), which refer to studies involving new data collected and analysed 
first-hand by researchers, were included. Therefore, empirical studies 
such as experimental, quasi-experimental, survey, case, and interven-
tion studies were considered, while secondary studies such as systematic 
reviews, theoretical articles, and commentaries were excluded.
One challenge in determining the search string was the large number 
of articles using terms such as ‘artificial intelligence’ or ‘AI’ instead of 
‘generative artificial intelligence’ or ‘Gen AI.’ To address this, the 
following measures were taken: (1) terms were broadly selected, as 
shown in Table 2, and (2) non-relevant studies, meaning non-Gen AI 
studies, were manually screened and excluded during the later stages. 
Terms such as ‘artificial intelligence’ and ‘AI’ were included alongside 
‘generative artificial intelligence’, ‘Generative AI’, ‘Gen AI’, ‘large lan-
guage model’, ‘LLM’, ‘chatbot’, and ‘Chat GPT’ because some studies did 
not explicitly reference Gen AI in their titles or abstracts. During the 
screening stage, both at the title/abstract and full-text levels, articles 
irrelevant to the focus of this study were excluded. The initial database 
search yielded 1517 records, of which 413 duplicate articles were 
removed using Rayyan software. Ultimately, 1104 articles were identi-
fied for further consideration.
4.2. Screening the identified articles with the criteria
As shown in Fig. 2, 1104 identified articles were screened and 
excluded at both the abstract and full-text levels based on the following 
criteria: (1) conference proceedings, (2) literature review articles, (3) 
non-empirical studies such as commentaries and systematic reviews, (4) 
articles not relevant to Gen AI, (5) articles focused on non-school con-
texts, (6) articles investigating only teachers, and (7) articles investi-
gating graduate students. At the abstract level, 993 articles were 
excluded because they were non-school context (n = 486), non-Gen AI (n 
= 222), teacher-focused (n = 94), non-empirical (n = 84), literature/ 
systematic review (n = 63), and conference article (n = 46). At the full- 
text level, 62 articles were excluded because they were non-school 
contexts (4), non-Gen AI (35), teacher-focused (2), non-empirical (4), 
non-target population (e.g., graduate level) (4), non-AI literacy (1), full 
text not available (12). The screening resulted in 51 articles being 
selected and reviewed within the context of the conceptualised Gen AI 
literacy framework.
4.3. Data coding and analysis process
The overall analysis consisted of two parts, each addressing one RQ. 
To address RQ1, the coding process involved categorising the 51 studies 
by school level (e.g., primary, secondary, and undergraduate educa-
tion), methodology (e.g., qualitative, quantitative, or mixed methods; 
intervention vs. non-intervention), and, for intervention studies, by 
domain (e.g., STEM, writing, AI in general, English education; see 
Table 6). To address RQ2, the findings of the selected studies were 
analysed using the Gen AI literacy framework as the conceptual foun-
dation of this review. This analysis followed the three stages of thematic 
synthesis (Thomas & Harden, 2008). First, the findings of each study 
were coded according to the five components of the Gen AI literacy 
framework: (1) knowing and understanding Gen AI, (2) using and 
applying Gen AI, (3) evaluating and incorporating Gen AI, (4) Gen AI 
ethics, and (5) attitudes towards Gen AI. Studies addressing more than 
one component were also coded accordingly. Second, additional details 
within each study were identified to capture nuances and categorised 
into sub-themes. Finally, more generalised themes which were drawn 
Table 2 
Database and search strings.
Database
Search string
Web of Science
(All fields: “generative AI” OR “generative artificial intelligence” 
OR “gen AI” OR “AI” OR “artificial Intelligence” OR “LLM” OR 
“large language model” OR “chatbot” OR “chatgpt”) 
AND (All fields: “school” OR “education” OR “teaching” OR 
“learning”) 
AND (All fields: “literacy”)
Scopus
(Title-abstract-keywords: “artificial intelligence” OR “AI” OR 
“generative AI” OR “generative artificial intelligence” OR 
“generative AI” OR “gen AI” OR “LLM” OR “large language 
model” OR “chatbot” OR “chatgpt") 
AND (Title-abstract-keywords: “literacy") 
AND (Title-abstract-keywords: “school” OR “education” OR 
“teaching” OR “learning”)
ACM Digital 
Library
(Title: “generative artificial intelligence”) OR (Title: “generative 
ai”) OR (Title: “genai”) OR (Title: “large language model”) OR 
(Title: “chatbot”) OR (Title: “chatgpt”) OR (Title: “artificial 
intelligence”) OR (Title: “ai") 
AND (Abstract: “literacy") 
AND (Abstract: “school”) OR (Abstract: “education”) OR 
(Abstract: “teaching”) OR (Abstract: “learning")
IEEE
(Full Text & Metadata: “generative artificial intelligence” OR 
“generative AI” OR “gen AI” OR " large language model” OR 
“chatbot” OR “chatgpt” OR “AI OR “artifical intelligence”) 
AND (Abstract: “literacy”) OR (Title:“literacy”) OR 
(Keyword:“literacy”) 
AND (Abstract: “school” OR “education” OR “learning” OR 
“teaching”)
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 5 ---

from sub-themes from the second stage were derived to support the 
overall discussion under each component. For example, one sub-theme 
identified in the second stage of the analysis was ‘holding mis-
conceptions about the mechanisms of Gen AI’, which is shown in Table 5. 
This was later generalised into one of the challenges within the first 
component, knowing and understanding Gen AI, as described in Section 
5.2.1. To ensure reliability, an independent researcher was involved in 
both parts of the analysis. The author and another researcher indepen-
dently coded approximately 10 % of the randomly selected articles using 
the Gen AI literacy framework. They then discussed discrepancies in 
their coding and, based on these discussions, re-coded the initially 
selected articles and coded another 10 % of the articles. This iterative 
process continued until consensus was reached. Following this agree-
ment, the author completed the coding of the remaining articles.
5. Results
This section presents key findings from the systematic review of 51 
articles, addressing the research questions on trends in Gen AI education 
in schools and students’ competencies in Gen AI literacy. Section 5.1
outlines the distribution of studies across different educational stages (i. 
e., primary, secondary, and undergraduate education) and discusses the 
prevalence of quantitative, qualitative, and Mixed methods-method 
research designs. Section 5.2 highlights how these studies empirically 
reported students’ competencies in relation to the Gen AI literacy 
framework.
5.1. General research trends in school levels and methodologies
The 51 articles were categorised into three school levels based on 
their target populations, as shown in Table 3. The majority of studies 
focused on undergraduate education (73.6 %), with fewer addressing 
secondary education (18.9 %) and only a small proportion on primary 
education (7.5 %). As one study involved both primary and secondary 
education, and another involved both secondary and undergraduate 
education, the number of articles includes overlapping counts.
In terms of methodology, as shown in Table 4, quantitative ap-
proaches, such as surveys and quasi-experimental designs, were the 
most common, featuring in 50 % of the articles. Qualitative methods, 
including interviews, observations, and analyses of written or 
Fig. 2. Flow diagram showing the process of selecting eligible articles.
Table 3 
School levels.
School level
Number of articles (n)
Percentage (%)
Primary education

7.5
Secondary education

18.9
Undergraduate education

73.6
Total

100.0
Note. The number of articles includes multiple counts. Two of the 51 articles 
involved two different school levels.
Table 4 
Methodologies for intervention studies.
Methodology
Number of articles (n)
Percentage (%)
Design
Intervention
Qualitative
Intervention

23.5
Non-intervention

2.0
Sub-total

25.5
Quantitative
Intervention

15.7
Non-intervention

35.3
Sub-total

51.0
Mixed methods
Intervention

9.8
Non-intervention

13.7
Sub-total

23.5
Total

100.0
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 6 ---

interviews, were the second most common approach; all of these 
involved interventions using Gen AI tools. Mixed methods-methods 
studies, accounting for roughly one-fifth of the articles, were also 
conducted.
5.2. Research trends in terms of Gen AI literacy framework
This section illustrates how the 51 articles reported on students’ 
understanding, performance, and competencies in using Gen AI tools, 
framed within the Gen AI literacy framework. This framework comprises 
five components: knowing and understanding Gen AI, using and 
applying Gen AI, evaluating and incorporating Gen AI, Gen AI ethics, and 
attitudes towards Gen AI. Summaries of all reviewed articles can be 
found in the Appendix, while key findings and research trends are 
illustrated and discussed in this section. Table 5 highlights the themes 
and sub-themes identified in the studies along with example studies 
whereas the main text discusses the generalised trends derived from 
these themes, focusing on each component.
Table 5 
Research trends in terms of Gen AI literacy framework.
Gen AI literacy
Theme
Sub-theme and example
Know and understand 
Gen AI
Understanding of how Gen AI works
Understanding the basic mechanism of Gen AI (Dai, 2024; Kajiwara & Kawabata, 2024; O’Dea et al., 
2024)
Understanding the capabilities and limitations of Gen AI (Chen et al., 2023; Ko & Song, 2024; Wang, 
2024; Zou et al., 2024) 
Challenges in understanding of how Gen AI 
works
Holding misconceptions about the mechanism of Gen AI (Cheung et al., 2024; Ding et al., 2023; 
Vartiainen et al., 2024; ˇCerný, 2024)
Challenges in technical understanding (Chan & Tsi, 2024; Gasaymeh et al., 2024; Iwasawa et al., 
2023; Laupichler et al., 2024; ˇCerný, 2024)
Understanding the benefits, limitations, and 
applications of Gen AI
Providing personalised feedback (Cahill and Mc Cabe, 2024; Chan & Hu, 2023; Oktarin et al., 2024)
Enhancing academic performance (Acosta-Enriquez et al., 2024; Al-Abdullatif & Alsubaie, 2024; 
Chan & Hu, 2023; Dalgıç et al., 2024; Jang, 2024; Y. Liu, Zhang, & Biebricher, 2024; Musyaffi et al., 
2024; Ngo & Hastie, 2025; Wang, 2024)
Improving creativity (Gasaymeh et al., 2024; Jiang et al., 2024; Relmasira et al., 2023; Tsao & 
Nogues, 2024)
Saving time and effort (Alzubi, 2024; Zou et al., 2024)
Understanding the limitation of Gen AI (Liu, Zhang, & Biebricher, 2024; Naamati-Schneider, 2024; 
Zou et al., 2024)
Use and apply Gen AI
Generation of content using Gen AI
Brainstorming ideas (Chan & Tsi, 2024; Folmeg et al., 2024; Wang, 2024)
Improving the quality of writing outcomes (Alzubi, 2024; Chan & Tsi, 2024; Oktarin et al., 2024)
Personalised learning (Khoudri et al., 2024; ˇCerný, 2024)
Using various Gen AI tools (Joseph et al., 2024; Relmasira et al., 2023)
Multimodal content generation (Kazanidis & Pellas, 2024; Relmasira et al., 2023; Tsao & Nogues, 
2024; Vartiainen et al., 2024)
Prompt Engineering
Challenges in prompting (Chen et al., 2023; Folmeg et al., 2024; Hwang et al., 2024)
Scaffolding for prompt generation (Dillon, 2024; Levine et al., 2024; Naamati-Schneider & Alt, 2024; 
Ngo & Hastie, 2025)
Evaluate and incorporate 
Gen AI
Critical evaluation of AI-generated content
Understanding the necessity of critical evaluation (Zou et al., 2024)
Evaluating based on domain-specific knowledge (Chiu, 2024; Kajiwara & Kawabata, 2024; Young 
et al., 2024)
Evaluating clarity (Dillon, 2024; Lee & Song, 2024)
Evaluating through peer discussion (Ngo & Hastie, 2025)
Evaluating epistemic nature (Cheung et al., 2024)
Evaluating using higher-order questions (Casey, 2024)
Critiquing ineffective AI-generated ideas (Gasaymeh et al., 2024; Ko & Song, 2024; 
Naamati-Schneider & Alt, 2024)
Challenges in critical evaluation (Chiu, 2024; Folmeg et al., 2024; Iwasawa et al., 2023)
Need for scaffolding in evaluation (Chen et al., 2024; Hwang et al., 2024; Ko & Song, 2024; Mah 
et al., 2024; Relmasira et al., 2023)
Incorporation of Gen AI into human ideas
Enhancing critical and higher order thinking (Casey, 2024)
Incorporating AI-brainstormed ideas (Chan & Lee, 2023; Chen et al., 2024; Hwang et al., 2024; Tsao 
et al., 2024)
Improving essays or academic writings (Chan & Lee, 2023; Hwang et al., 2024; Jiang et al., 2024; 
Levine et al., 2024; Y. Liu, Zhang, & Biebricher, 2024; Ngo et al., 2024; Tsao et al., 2024)
Problem solving (Cahill and Mc Cabe, 2024; Chan & Lee, 2023; Chen et al., 2023; Hu et al., 2024; 
Laupichler et al., 2024; Mah et al., 2024)
Self-regulated learning (Hu et al., 2024; Hwang et al., 2024; Ngo et al., 2024; Wang, 2024)
Gen AI ethics
Gen AI ethics at individual level
Lack of awareness of data privacy and security (Chan & Hu, 2023; Kajiwara & Kawabata, 2024; 
O’Dea et al., 2024)
Over-reliance on Gen AI related to student agency and academic integrity (Khoudri et al., 2024; Ko & 
Song, 2024; Mah et al., 2024; Wang, 2024)
Responsible and critical usage (Chen et al., 2024; Gasaymeh et al., 2024)
Gen AI ethics at social level
Societal values (Ko & Song, 2024; ˇCerný, 2024)
Ethical regulation (Kajiwara & Kawabata, 2024; Lee & Song, 2024; Y. Liu, Zhang, & Biebricher, 
2024; Mah et al., 2024; Vidaurre et al., 2024)
Need for clear institutional policies (Chan & Hu, 2023; Mah et al., 2024)
Attitudes towards Gen AI
Individual attitudes
Curiosity and interest (Chan & Hu, 2023; Chen et al., 2024; Gasaymeh et al., 2024; Y. Liu, 
Zhang, & Biebricher, 2024; Masa’deh et al., 2023)
​
Self-efficacy (Chiu et al., 2023; Dai, 2024; Dalgıç et al., 2024; Kazanidis & Pellas, 2024; Musyaffi 
et al., 2024)
Note. Articles were included in multiple categories when relevant.
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 7 ---

5.2.1. Know and understand Gen AI
5.2.1.1. Understanding of how Gen AI works. Understanding basic con-
cepts such as how Gen AI works, along with its capabilities and limita-
tions, plays a foundational role in enhancing competencies for the 
proper usage and application of Gen AI. Of the 51 articles reviewed, 34 
reported that students generally demonstrated a moderate level of un-
derstanding of basic Gen AI concepts when appropriate pedagogical 
approaches or prior experiences with Gen AI usage were provided. For 
example, Kajiwara and Kawabata (2024) designed and implemented a 
curriculum focused on teaching Gen AI concepts, including basic 
knowledge, explainability, benevolence, non-maleficence, justice and 
fairness, responsibility, and autonomy. A group of 107 Japanese stu-
dents aged 12 to 24 showed general improvement in their basic un-
derstanding of Gen AI. This curriculum employed a role-playing 
pedagogy to teach about LLMs, illustrating the pre-training processes of 
LLMs, and proved significantly effective in enhancing students’ under-
standing of Gen AI. On the other hand, O’Dea et al. (2024) reported that 
students’ prior learning about AI had a significant effect on improving AI 
literacy, but no significant differences were found across age groups or 
educational levels. In addition, they noted that Hong Kong students were 
more confident than UK students in understanding Gen AI, possibly due 
to more frequent experiences with and usage of Gen AI tools in Hong 
Kong. Iwasawa et al. (2023) also found that students who could describe 
Chat GPT had a better understanding of how Gen AI works than those 
who had only heard of it but could not explain it, or who had never 
heard of it. These findings from the two survey studies may imply that 
students’ experiences with using Gen AI could foster a better under-
standing of how Gen AI works.
5.2.1.2. Challenges in understanding of how Gen AI works. Two key 
challenges were identified in terms of students’ understanding of how 
Gen AI works: conceptualising Gen AI and gaining an in-depth under-
standing of its mechanism. One approach that students used to 
conceptualise Gen AI was employing metaphors such as Google or a 
normal human. However, this approach often led to misconceptions, 
even among undergraduate students. Although students identified sim-
ilarities between Gen AI and their chosen metaphors, the metaphors did 
not align with how Gen AI works, which could hinder the development of 
accurate understanding. For example, Cheung et al. (2024) found that 
some secondary school students equated Chat GPT with Google, 
perceiving that AI retrieves information directly from the internet; 
rather, it generates responses by predicting the most likely and con-
textually relevant answers, a process that is inherently probabilistic in 
nature (Xu et al., 2024). As such, relying on metaphors to conceptualise 
Gen AI often caused misunderstandings. In a similar vein, Ding et al. 
(2023) also reported that about one-quarter of university-level physics 
students viewed interactions with Chat GPT as resembling human-like 
interactions, which might further lead to misconceptions. These stu-
dents, observing an 85 % accuracy rate from Chat GPT, tended to trust its 
responses, overlooking the probabilistic nature of AI content generation.
Although many studies indicated that students had a moderate un-
derstanding of how Gen AI works, their understanding was often su-
perficial rather than sophisticated. For example, ˇCerný (2024) reported 
that some students perceived Gen AI as operating with deterministic 
algorithms, which revealed a lack of understanding of its probabilistic 
nature. This misconception could be attributed to the difficulty of con-
ceptual change, where students are resistant to altering their perspec-
tives. Related to this, Vartiainen et al. (2024) found that students did not 
significantly change their views about the origins of biases, as known 
limitation of Gen AI, even after participating in hands-on workshops. 
Another key factor was the lack of familiarity with technical knowledge 
related to Gen AI. Gasaymeh et al. (2024) noted that university students 
were less knowledgeable in technical aspects than they were in areas 
such as ethical considerations and AI applications. Similarly, Laupichler 
et al. (2024) found that students perceived their technological under-
standing to be limited compared to their ability to critically evaluate and 
practically use Gen AI. While these challenges persist, practical usage of 
Gen AI tools combined with critical evaluation can help overcome them 
(Ngo & Hastie, 2025). Young et al. (2024) suggested adopting a sceptical 
stance towards information generated by Gen AI as an essential step in 
developing a more comprehensive understanding of its capabilities and 
limitations.
5.2.1.3. Understanding the benefits, limitations, and applications of Gen-
AI. It is critically important to understand the potential benefits and 
limitations of Gen AI in order to apply it appropriately across different 
contexts and scenarios. This understanding may facilitate more effective 
use of Gen AI, which may subsequently enhance students’ Gen AI literacy 
(Annapureddy et al., 2024). There was a tendency that many studies 
revealed that students acknowledged both the benefits of using Gen AI, 
such as enhancing academic performance, saving time and effort, and 
fostering creativity, and concerns about its use, including ethical issues 
and its potential to hinder critical thinking, across various contexts. This 
suggests that students generally maintained a balanced view, consid-
ering both the benefits of and concerns about Gen AI usage. The most 
prominent perception among students regarding the benefits of Gen AI 
was its ability to improve academic performance and learning outcomes 
(Al-Abdullatif & Alsubaie, 2024; Chan & Hu, 2023; Dalgıç et al., 2024; 
Jang, 2024; Y. Liu, Zhang, & Biebricher, 2024; Musyaffi et al., 2024; Ngo 
& Hastie, 2025; Wang, 2024). For example, Chan and Hu (2023) found 
that students recognised the usefulness of Gen AI for providing unique 
insights and personalised feedback. Similarly, Alzubi (2024) and Zou 
et al. (2024) reported that students considered Gen AI practically bene-
ficial, as it saved time and effort, ultimately boosting academic pro-
ductivity. On the other hand, several studies highlighted students’ 
balanced perspective on Gen AI usage. For example, Wang (2024) found 
that students recognised several benefits of Gen AI in writing tasks, 
including accelerating the writing process, reducing cognitive load, 
fostering new learning opportunities, and promoting positive feelings 
about writing. However, students were also aware of Gen AI’s limita-
tions, including inaccuracy, misinformation, unreliable evidence and 
lack of source transparency, and expressed a need for more explicit in-
struction on its use. Liu, Zhang, and Biebricher (2024) surveyed 475 
undergraduate students learning English in China and found that they 
recognised Gen AI’s limitations in providing feedback on critical 
thinking, creativity, and speaking skills, while acknowledging its use-
fulness in supporting writing, grammar, vocabulary, and reading. In the 
same regard, Naamati-;Schneider (2024) found that health management 
students using Gen AI (Chat GPT) recognised benefits like rapid access to 
information, but also its limitations, such as potential inaccuracies and 
fabricated content, and that it is insufficient on its own for constructing 
evidence-based arguments on complex dilemmas. Jiang et al. (2024)
reported that students appreciated Gen AI’s effectiveness in generating 
ideas for creating more innovative products. However, they also 
expressed concerns that it might diminish their own agency and 
Table 6 
Domain targeted by involving the use of Gen AI tools.
Domain
Number of articles (n)
Percentage (%)
AI focused content

33.3
Writing

16.7
STEM (science, physics, problem 
solving)

16.7
Tourism

8.3
English education

8.3
Moral education

4.2
Digital literacy

4.2
Information literacy

4.2
Health management

4.2
Total

100.0
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 8 ---

creativity during writing tasks.
In summary, 47 out of 51 studies (92.2 %) examined students’ 
knowledge and understanding of Gen AI. Students generally demon-
strated a moderate understanding of Gen AI’s mechanisms, capabilities, 
and limitations when provided with opportunities to learn about Gen AI 
and experience its appropriate use. They also fairly understood the 
benefits of the Gen AI application while recognising its limitations, such 
as hallucinations, inaccurate information, potential biases, and the risk 
of inappropriate use. Nonetheless, students faced challenges in devel-
oping an in-depth understanding of Gen AI, particularly regarding 
technical knowledge, such as the detailed mechanisms of how Gen AI 
works.
5.2.2. Use and apply Gen AI
5.2.2.1. Generation of content using Gen AI. Along with acquiring 
knowledge and understanding of Gen AI, students should be able to use 
and apply Gen AI to generate content by interacting with Gen AI tools 
through prompts and customised Gen AI applications. Among the 51 
reviewed articles, 24 investigated students’ use of Gen AI in designed 
tasks, while the remaining 27 explored students’ perceptions related to 
understanding, usage, and/or attitudes toward Gen AI via surveys and 
interviews. As shown in Table 6, of the 24 studies, 8 (33.3 %) focused on 
Gen AI in general, examining how students use it to create content, while 
16 (66.6 %) incorporated Gen AI applications into other disciplines, such 
as academic writing (n = 4), STEM (n = 4), tourism (n = 2), English 
education (n = 2), moral education (n = 1), digital literacy (n = 1), 
information literacy (n = 1), and health management (n = 1). More than 
half of the intervention studies adopted an interdisciplinary approach to 
examine how Gen AI literacy education had an impact on other disci-
plines or how the integration of two disciplines can be achieved. In 
contrast, slightly less than half of the studies primarily aimed to enhance 
students’ Gen AI literacy.
On the other hand, with advancements in Gen AI technologies, given 
the increase ease of access, many studies have tasked students with using 
Gen AI in various ways, such as brainstorming ideas (Folmeg et al., 2024; 
Wang, 2024), improving the quality of writing (Alzubi, 2024; Chan & 
Tsi, 2024; Oktarin et al., 2024), and supporting personalised learning 
(Khoudri et al., 2024; ˇCerný, 2024). For example, Oktarin et al. (2024)
asked undergraduate students to use Gen AI to receive feedback on their 
writing and to incorporate that feedback into class assignments. The use 
of Gen AI significantly improved the quality of their written work. Dur-
ing interviews, students shared that they were able to strengthen their 
weaker areas through the personalised feedback and guidance provided 
by Gen AI. However, studies investigating students’ multimodal content 
generation have still been rare, with only a few (n = 4) exploring this 
area. For example, Vartiainen et al. (2024) assigned tasks requiring 
students to generate images using text-based prompts and evaluate the 
generated images and Gen AI systems for potential biases. This study 
primarily focused on fostering students’ competencies related to Gen AI 
literacy. In another example, Tsao and Nogues (2024) tasked students 
with creating graphic short stories or poems. Students observed crea-
tivity in AI-generated images, which inspired them through a combi-
nation of unexpectedness and intentionality. Since the creation process 
of AI differs from that of humans, it presents opportunities for exploring 
the use of Gen AI in generating creative works.
5.2.2.2. Prompt engineering. Prompting skills play a critical role in 
generating accurate and targeted responses from Gen AI tools (Chan 
et al., 2025; Wei et al., 2022). Prompt engineering involves an iterative 
process of crafting instructions to guide Gen AI in creating content and 
refining these instructions to produce more specific and relevant output 
(Open AI, 2022). This process requires competencies to critically eval-
uate AI-generated content. Given the inherent limitations of Gen AI, such 
as hallucinations and potential biases, students can mitigate these 
challenges and enhance response quality through well-structured 
prompts (Young et al., 2024). Among the 51 reviewed studies, 17 
focused on either training students in prompting techniques or evalu-
ating their perceived proficiency in prompting. While a few studies 
demonstrated that students improved their prompting skills through 
targeted approaches with adequate facilitation (Dillon, 2024; Ngo & 
Hastie, 2025), several studies revealed that students struggled to craft 
effective prompts or enhance their prompting abilities. For example, 
Chen et al. (2023) found that students faced difficulties when Chat GPT 
generated unexpected responses, realising the need for more specific 
and informed prompts to shape Gen AI outputs. Similarly, Folmeg et al. 
(2024) reported that Hungarian university students were unable to 
provide well-defined instructions for generating responses. Hwang et al. 
(2024) observed that international students in an advanced English 
writing course often used general prompts for specific tasks, typically 
addressing surface-level aspects such as grammar and errors rather than 
higher-order writing skills such as organisation and content. This may 
suggest it is challenging for students to craft prompts aligning with 
specific tasks and objectives. To mitigate these challenges, several 
studies recommended targeted and explicit prompting training. Sug-
gestions included employing a metacognitive approach (Levine et al., 
2024; Naamati-Schneider & Alt, 2024), using frameworks that guide 
prompt generation with examples (Ngo & Hastie, 2025).
In summary, 28 out of 51 studies (54.9 %) examined students’ use 
and application of Gen AI. Students were competent in the use of Gen AI 
tools in various contexts, including their academic tasks, not only to 
enhance their competencies with Gen AI but also to develop skills in 
other disciplines and literacies. They demonstrated the ability to use 
Gen AI for various purposes, such as brainstorming ideas, finding infor-
mation, drafting and revising articles, correcting grammar in their 
writing, and even generating multimodal content. However, while stu-
dents were able to generate content using prompts, they found it chal-
lenging to structure and craft more effective prompts tailored to specific 
targeted objectives.
5.2.3. Evaluate and incorporate Gen AI
5.2.3.1. Critical evaluation of AI-generated content. Given that the ca-
pabilities and limitations of Gen AI, critically evaluating AI-generated 
content is one of the most important competencies for more appro-
priate and effective use of Gen AI to establish student agency. Since 
students were generally aware that Gen AI generate content which may 
contain hallucinations, biased perspectives, out-dated information, and 
misinformation, they also recognised the necessity of critical evaluation 
of AI-generated content and critical thinking skills (Zou et al., 2024). 
With this recognition along with appropriate guidance, students were 
able to evaluate Gen AI outputs in terms of various criteria such as 
consistency and hallucinations (Kajiwara & Kawabata, 2024), depth of 
knowledge and accuracy (Casey, 2024; Young et al., 2024), clarity 
(Dillon, 2024; Lee & Song, 2024), epistemic nature of AI and science 
(Cheung et al., 2024), and helpfulness and identification of the source of 
explanations (Lee & Song, 2024).
There were various method approaches for evaluation such as peer 
discussions, comparing Gen AI tools, cross-referencing information, 
using domain-specific knowledge, to practice critical evaluation of 
Gen AI outputs by students. For example, Ngo and Hastie (2025) tasked 
undergraduate students to use various Gen AI tools such as Elicit, 
Consensus, Perplexity, and Quillbot in writing an essay involving idea 
generation, outlining, paraphrasing and to evaluate where Gen AI tools 
were used and whether the outputs were appropriate by peer discus-
sions. Over 10 weeks of the intervention using Gen AI for the entire 
writing process improved students’ critical evaluation competency of 
Gen AI. On the other hand, Casey (2024) instructed students to draft a 
1000-word policy brief using Gen AI throughout the process and to assess 
the writing process. To make the assessment more critical, students were 
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 9 ---

given various questions including reference check and higher-order 
thinking questions. Those higher-order thinking questions involved 
how Gen AI outputs were politically responsive, what was it missing but 
important, analytically reasonable. Beyond the factual checking, these 
higher-order thinking questions might be useful in critically evaluate 
AI-generated content.
Although students were generally capable to critically evaluate 
Gen AI outputs by appropriate guidance, there could be challenges in 
thoroughly evaluate the responses. For example, Chiu (2024) found that 
90 % of student felt that solid disciplinary knowledge is necessary to 
evaluate AI-generated content. In more particular, a student expressed 
that it was limited to evaluate the efficacy of the study designs as the 
student did not have a solid ground of understanding of methodology. 
On the other hand, Iwasawa et al. (2023) found that students with 
limited understanding of how Gen AI works tended to over-rely on 
Chat GPT’s responses without engaging in critical evaluation.
This implies that teacher facilitation would be essential to help stu-
dents critically evaluate AI-generated content by providing not only 
criteria for assessment but also relevant and useful information and 
perspectives. When evaluation requires more in-depth understanding, 
such as given higher order thinking questions beyond factual check, 
teachers’ proper support and facilitation would be even more important.
5.2.3.2. Incorporation of Gen AI into students’ ideas to enhance student 
agency. By critical evaluation of Gen AI outputs, students would be able 
to incorporate them into their own idea development. There are mainly 
four identified types of AI incorporation: brainstorming, writing, prob-
lem solving, and supporting self-regulation. First, students valued Gen-
AI’s feature that propose multiple perspectives with diverse examples, 
ultimately broadening the scope of ideas they might not have initially 
considered (Chen et al., 2024; Tsao et al., 2024). Students were therefore 
integrating AI generated ideas into their initial thoughts in refining 
questions have and concept they were creatively proposing (Chan & Lee, 
2023; Hwang et al., 2024). However, some students also expressed un-
certainty about the accuracy of AI-generated content and highlighted 
critical evaluation to avoid misinformation and error or bias (Gasaymeh 
et al., 2024; Ko & Song, 2024). Several studies (e.g., Lee & Park, 2023; 
Lee & Song, 2024) stressed the importance of appropriate guidelines for 
prompting strategies and critical evaluation skills, to ensure that 
brainstorming using Gen AI leads to more meaningful idea development 
and enhances student agency.
Second, writing has emerged as a core domain where students use 
Gen AI to refine initial ideas, generate drafts, or edit and proofread their 
text (Chan & Lee, 2023; Hwang et al., 2024; Y. Liu, 2024). Many stu-
dents regarded Chat GPT or equivalent systems as virtual partners that 
offer real-time feedback on grammar, structure, or tone (Levine et al., 
2024; Ngo et al., 2024). Although these functionalities could save time 
and boost confidence, students repeatedly cautioned that over-reliance 
on Gen AI may dilute their agency and mask deeper writing or 
thinking gaps (Mah et al., 2024; Wang, 2024). Some even framed Gen AI 
as a co-author, noting that it could not align with a conventional notion 
of human authorship while also encouraging iterative revisions and 
higher-quality prose (Jiang et al., 2024; Tsao et al., 2024). Nonetheless, 
across several studies, researchers consistently underscored the need for 
transparent guidelines in writing classrooms to ensure student agency 
and maintain academic integrity (Lee & Song, 2024; Mah et al., 2024), 
which is highly related to Gen AI ethics.
Third, students leveraged Gen AI’s capabilities to solve problems by 
processing data and proposing solutions, thereby supporting assign-
ments (Cahill and Mc Cabe, 2024; Chen et al., 2023; Marrone et al., 
2024). In these contexts, Gen AI served as a readily accessible support 
tool, providing partial solutions or relevant information that prompted 
problem solving (Laupichler et al., 2024). As students explored multiple 
reasoning paths, issues arose when AI suggestions were accepted un-
critically, leading at times to inaccurate, biased, or superficial outputs 
(Chan & Lee, 2023). In the similar vein, several studies (e.g., Chen et al., 
2024; Mah et al., 2024) emphasised the need for structured scaffolds 
such as reflective prompts to support students in critically evaluating 
and verifying Gen AI outputs.
Finally, several studies revealed that students utilised Gen AI tools to 
assist with self-regulated tasks, including scheduling, reading compre-
hension support, and iterative revision planning (Hu et al., 2024; Wang, 
2024). In these situations, AI-generated suggestions helped students set 
bite sized goals, track their progress, and stay accountable (Hwang et al., 
2024; Ngo et al., 2024). The potential gained in metacognitive aware-
ness was significant, as students who regularly posed questions to Gen AI 
became more practised at monitoring their own study strategies and 
identifying gaps to be addressed (Hu et al., 2024). Nevertheless, several 
challenges also were reported: the persistent risk of diminished student 
agency if the AI-generated ideas and recommendations supplant per-
sonal decision-making, and ethical questions regarding data privacy or 
subtle biases in the algorithmic nudges (Ko & Song, 2024). Overall, these 
studies suggest that when effectively integrated, Gen AI fosters innova-
tive, student-centred learning experiences for keeping their agency in 
brainstorming, writing, problem solving, and self-regulation. Yet, such 
incorporation clearly requires more supportive guidance, including 
institutional guidelines and scaffolds, to mitigate the pitfalls of Gen AI 
usage and enhance their agency.
In summary, 34 out of 51 studies (66.7 %) examined students’ 
evaluation and incorporation of Gen AI. Students demonstrated a mod-
erate ability to critically evaluate Gen AI outputs and to engage in 
prompt engineering to generate more accurate and targeted responses. 
They also showed the capacity to incorporate Gen AI into their idea 
development across four types: brainstorming, writing, problem solving, 
and supporting self-regulated learning. In the process of evaluating and 
integrating Gen AI, the tools were used to expand students’ perspectives, 
refine their ideas and work, and scaffold their learning processes. 
Through guided practice, students not only were able to enhance their 
academic performance but also developed metacognitive awareness and 
self-regulated learning when interacting with Gen AI properly. However, 
appropriate guidance and structured support would be necessary to 
ensure the critical use of Gen AI as well as to build student agency in 
educational contexts.
5.2.4. Gen AI ethics
As Gen AI becomes increasingly integrated into education, ethical 
and responsible usage has emerged as a critical competency. The 
reviewed studies indicate that students are expected to use Gen AI ethi-
cally at both individual and social levels, taking into account relevant 
regulations and potential risks. At the individual level, this involves 
protecting data privacy and security and maintaining academic integ-
rity. At the social level, it includes respecting broader societal values, 
adhering to ethical regulations, and recognising the institutional pol-
icies. Developing awareness and competence in these areas is essential 
not only to prevent misuse but also to foster ethical and responsible 
learning with Gen AI.
5.2.4.1. Gen AI ethics at individual level. In several studies, students 
showed limited understanding of data privacy and security in Gen AI use, 
often underestimating the risks involved. Chan and Hu (2023) found 
that students across disciplines, particularly in the social sciences and 
arts, expressed concerns about Gen AI collecting and utilising their per-
sonal inputs, yet lacked knowledge of how these systems functioned or 
how their data might be used. O’Dea et al. (2024) also pointed out this, 
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 10 ---

observing that many students engaged with Gen AI tools without 
awareness of privacy and data protection policies of using third-party 
platforms. On the other hand, Kajiwara and Kawabata (2024) found 
that students’ awareness of data security was related to their under-
standing of Gen AI mechanisms such as how data sharing in Gen AI may 
lead to bias or misuse. Furthermore, students’ ability to manage privacy 
concerns was limited, indicating a critical necessity for targeted in-
struction on data privacy and security in the context of Gen AI use.
On the other hand, students themselves expressed awareness of the 
risks of over-reliance on Gen AI, explicitly linking such dependence to 
the erosion of their agency and the blurring of academic integrity. Wang 
(2024) reported that students, while making extensive use of Chat GPT in 
drafting and revising, consistently voiced concerns that excessive reli-
ance might weaken their authorial voice, reduce critical thinking, and 
cross ethical boundaries. Similarly, Khoudri et al. (2024) found that 
Moroccan and Indonesian undergraduates highlighted “overdependence 
and lack of responsibility” as key worries, fearing that leaning too 
heavily on Gen AI would undermine their academic growth. Jiang et al. 
(2024) showed that students valued Chat GPT for generating ideas and 
streamlining writing but expressed unease that its use could complicate 
authorship and risk diminishing creativity and over-reliance, alongside 
concerns about trustworthiness and academic integrity. These common 
concerns may mean that students often treated Gen AI as a supportive 
partner yet remained wary that it might supplant their contributions or 
taking overly rely on the outputs of Gen AI, weakening student agency 
and undermining integrity if left unmoderated. Such awareness aligns 
with UNESCO’s ethical recommendations (Miao & Shiohira, 2024, p. 
80), which underscore that safeguarding student agency and integrity is 
fundamental for ensuring Gen AI enhances students’ learning and 
development.
In addition, students’ Gen AI ethics at the individual level also 
encompassed responsible and critical usage in relation to Gen AI’s limi-
tations. Chen et al. (2024) noted that students maintained a cautious 
stance towards Gen AI outputs, recognising limitations related to accu-
racy. Similarly, Gasaymeh et al. (2024) found that students with mod-
erate familiarity expressed ongoing concerns about misinformation and 
ethical use, highlighting the importance of responsible and critical 
engagement with Gen AI. These findings indicate the need for explicit 
training and clear policy frameworks to support responsible usage of 
Gen AI.
5.2.4.2. Gen AI ethics at societal level. Students’ awareness of Gen AI’s 
societal implications was found to be uneven, with varying degrees of 
recognition regarding its risks, broader ethical impacts, and effects on 
equity and personal development. Chan and Hu (2023) documented 
concerns about Gen AI’s negative impact on personal development, job 
prospects, and equity in education, including fears that students who did 
not use AI would be disadvantaged. On the other hand, Ko and Song 
(2024) reported that some students lacked awareness of broader societal 
dimensions, focusing primarily on personal utility rather than the 
ethical impacts on communities or marginalised groups. These findings 
suggest that fostering ethical sensitivity toward societal values may 
require deliberate instructional designs to address these challenges.
Students’ awareness in navigating ethical regulations around Gen AI 
use also remained inconsistent, largely due to a lack of institutional 
guidance. Y. Liu, Zhang, and Biebricher (2024) found that students were 
unsure whether using Chat GPT to draft essays constituted cheating, even 
though many claimed to understand plagiarism. This reflects a broader 
issue: without transparent policies, students may struggle to differen-
tiate acceptable support from academic misconduct. Chan and Hu 
(2023) further emphasised that students called for well-balanced usage 
policies, expressing uncertainty about ethical guidelines and feeling at a 
loss without institutional frameworks. Similarly, Mah et al. (2024)
highlighted tensions between student and teacher perceptions of what 
constitutes cheating versus learning with Gen AI, showing that students’ 
ethical reasoning was shaped by their interpretations of vaguely defined 
rules. These findings suggest that student awareness in this area depends 
significantly on institutional transparency and co-constructed norms 
around responsible AI use.
In summary, 28 out of 51 studies (54.9 %) examined students’ Gen AI 
ethical awareness and their performance in the ethical use of Gen AI. 
Students demonstrated uneven performance across the two levels of 
Gen AI ethics. At the individual level, awareness of data privacy and 
security was generally low without explicit instruction, and many stu-
dents lacked awareness of how to protect their information when 
engaging with Gen AI. Their awareness of student agency issue and ac-
ademic integrity was also frequently challenged by over-reliance on 
Gen AI. At the social level, students exhibited a baseline awareness of 
potential risks and issues related to fairness and ethics in terms of so-
cietal values. In addition, there was a consistent call for clear policies 
and institutional guidelines to prevent inconsistent behaviour and 
inadvertent violations. These challenges may underscore the need for 
systemic, curriculum-integrated ethics education that goes beyond 
compliance measures to empower students with the competencies to use 
Gen AI tools responsibly, fairly, and thoughtfully within and beyond the 
classroom.
5.2.5. Attitudes towards Gen AI
5.2.5.1. Individual attitudes. Attitudes towards Gen AI is a critical 
component of Gen AI literacy, significantly influencing students’ 
engagement, motivation, and perceived competency in effectively 
employing these Gen AI tools. Understanding students’ attitudes is 
essential to leverage Gen AI’s educational benefits and to address its 
associated challenges responsibly. Students generally exhibit strong 
curiosity and interest in Gen AI. 31 studies indicated students expressed 
their positive attitudes in the use of Gen AI, recognising its numerous 
educational advantages, while few studies (e.g., Casey, 2024; Marrone 
et al., 2024) reported some student scepticism due to its limitations. 
Chan and Hu (2023) reported that students maintained positive atti-
tudes toward Gen AI technologies, appreciating benefits such as per-
sonalised learning support, improved writing skills, and facilitation of 
academic activities. Similarly, Chan and Lee (2023) observed Genera-
tion Z students’ optimistic outlook on adopting Gen AI, particularly 
valuing its potential to increase productivity, efficiency, and personal-
ised educational experiences. Chen et al. (2023) indicated that students 
leveraged Gen AI support in collaborative tasks, which enhanced their 
active participation and engagement in knowledge building activities. 
Self-efficacy, another key dimension of attitudes toward Gen AI, reflects 
students’ confidence in effectively utilising these tools. Chiu et al. 
(2023) found that students’ motivation and perceived competency in 
using Gen AI tools for learning were significantly bolstered by structured 
teacher support. Kazanidis and Pellas (2024) similarly highlighted that 
clearly structured experiences and practical exposure to Gen AI tools 
significantly enhanced students’ satisfaction and perceived effective-
ness, demonstrating the importance of guided instructional contexts.
In summary, 42 out of 51 studies (82.3 %) examined students’ atti-
tudes towards Gen AI, focusing on curiosity, interest, and self-efficacy. 
This represents the second-highest number of studies among the five 
components, underscoring the importance of students’ attitudes. Such 
attitudes are critical because they influence how effectively students 
engage with and utilise Gen AI in conjunction with other competencies in 
educational contexts. Recognising and fostering these attitudes through 
targeted instructional strategies and supportive policies can significantly 
enhance the responsible and beneficial use of Gen AI technologies among 
students. On the other hand, these studies primarily addressed individ-
ual attitudes, while investigations into social attitudes were very rare. 
Given that Gen AI can also be utilised in collaborative and social con-
texts, future research could usefully explore attitudes at the social level 
as competency.
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 11 ---

6. Discussion
6.1. A necessity for a holistic approach to enhance students’ Gen AI 
literacy
A holistic approach is imperative to enhance students’ Gen AI liter-
acy, particularly given the intertwined nature of the five competencies 
identified in this review: (1) know and understand Gen AI, (2) use and 
apply Gen AI, (3) evaluate and incorporate Gen AI, (4) Gen AI ethics, and 
(5) attitudes towards Gen AI. These competencies are interconnected, 
each influencing the effectiveness of the others, underscoring the ne-
cessity for an integrated pedagogical strategy.
First, understanding the fundamental operations of Gen AI signifi-
cantly influences students’ ability to effectively use and apply these 
tools. Schiavo et al. (2024) found that students who comprehend the 
underlying mechanisms of AI are better positioned to critically evaluate 
the outputs generated by Gen AI tools, distinguishing between reliable 
information and potential misinformation. This indicates that a 
comprehensive understanding of Gen AI’s mechanisms directly enhances 
students’ critical evaluation skills. Ngo and Hastie (2025) also illustrated 
this relationship through their empirical findings, where critical evalu-
ation exercises significantly improved students’ understanding of Gen-
AI’s limitations, including its susceptibility to inaccuracies and biases. 
This suggests that fostering students’ critical evaluative competencies 
concurrently may enhance their understanding and informed usage of 
Gen AI, creating a reinforcing cycle among understanding, application, 
and evaluation.
The role of ethics in Gen AI literacy further underscores the need for a 
holistic instructional approach. Ethical competencies ensure responsible 
use and mitigate the risks associated with privacy, data security, and 
academic integrity, critical for building positive attitudes towards Gen AI 
and confidence among students. For example, Acosta-Enriquez et al. 
(2024) found a positive correlation between the responsible use of 
Gen AI and a positive attitude, while Vidaurre et al. (2024) reported that 
students’ academic integrity was strongly influenced by their percep-
tions of and interactions with Gen AI. Kajiwara and Kawabata (2024)
developed a curriculum that integrated both conceptual understanding 
of LLMs and their ethical aspects, resulting in significant improvements 
in both areas, particularly in creativity and decision support. Further-
more, Wang (2024) pointed out that students explicitly requested 
clearer ethical guidelines, recognising that ethical comprehension is 
integral to their competent and confident use of Gen AI. The affective 
dimension, encapsulated in the attitudes towards Gen AI, is critically 
interconnected with the other competencies. Students’ curiosity, inter-
est, and self-efficacy significantly influence their engagement levels and 
persistence in acquiring technical skills, ethical understanding, and 
critical evaluation abilities. For example, Chan and Hu (2023) observed 
that students who had greater understanding and familiarity with Gen AI 
demonstrated higher willingness and confidence to engage with these 
tools, highlighting that positive attitudes reinforce and sustain learning 
and skill development in Gen AI.
In summary, an integrated and holistic instructional approach is 
crucial to fostering students’ Gen AI literacy. Recognising and explicitly 
teaching the interconnectedness of knowledge, practical skills, critical 
evaluation, ethics, and attitudes will significantly enhance students’ 
competencies, preparing them for responsible and effective engagement 
with Gen AI tools. For the holistic approach to ensure interactive nature 
of these competencies, it would be necessary to develop an instructional 
model containing key components which can enhance students’ Gen AI 
literacy. The following section suggests an interaction model as a holistic 
instructional approach to address challenges identified in this review 
and how it can be utilised to enhance students’ Gen AI literacy.
6.2. Addressing challenges in fostering AI literacy
As discussed in the Introduction, Gen AI is a distinct subset of AI that 
generates new content such as text, images, audio, and video, and 
therefore requires specific knowledge and skills for its appropriate use 
(Bozkurt, 2023). This distinctiveness highlights the necessity of 
Gen AI-specific competencies, which the proposed Gen AI literacy 
framework seeks to address. However, findings from the reviewed 
studies reveal that students face persistent challenges in developing 
these competencies across the five domains of Gen AI literacy. While 
learners often demonstrated curiosity and interest in using Gen AI, three 
issues consistently emerged as critical: sustaining student agency, 
developing prompt engineering skills, and ensuring critical evaluation of 
AI-generated outputs.
A first challenge relates to sustaining student agency. While many 
students reported that Gen AI supported brainstorming, idea generation, 
and writing, studies also revealed concerns that over-reliance could 
diminish their ownership of ideas and weaken authorship (Jiang et al., 
2024; Khoudri et al., 2024; Wang, 2024). For example, students valued 
Gen AI’s ability to propose multiple perspectives but expressed unease 
that excessive dependence might compromise creativity and diminish 
their active role in knowledge building (Ko & Song, 2024). Preserving 
agency requires encouraging students to articulate their own ideas 
before engaging Gen AI and to incorporate AI-generated outputs only 
after critical reflection. Such practices align with UNESCO’s 
human-centred approach to AI education, emphasising the importance 
of student autonomy and academic integrity (Miao & Shiohira, 2024, p. 
80).
A second challenge lies in the development of prompt engineering 
skills. Across multiple studies, students struggled to formulate effective 
prompts, often defaulting to vague or surface-level queries (Chen et al., 
2023; Hwang et al., 2024). These difficulties stemmed from both a lack 
of clarity about task objectives (Folmeg et al., 2024) and limited un-
derstanding of Gen AI’s probabilistic nature, with some students treating 
it as a deterministic system or search engine (Cheung et al., 2024; ˇCerný, 
2024). As a result, they were unable to effectively shape Gen AI outputs. 
Addressing this challenge requires explicit instruction in clarifying the 
purpose of prompts, fostering conceptual understanding of how Gen AI 
generates responses, and providing opportunities to practise structured 
prompting strategies. Studies highlight the promise of few-shot and 
chain-of-thought prompting for improving response quality (Touvron 
et al., 2023; Wei et al., 2022), and targeted training has been shown to 
enhance students’ confidence in prompting (Dillon, 2024; Ngo & Hastie, 
2025).
A third persistent issue involves students’ ability to critically eval-
uate AI-generated content. While many recognised the necessity of 
scrutiny, they often lacked systematic approaches or disciplinary 
knowledge to do so effectively (Chiu, 2024; Iwasawa et al., 2023). 
Without explicit scaffolds, some accepted Gen AI outputs uncritically, 
leading to superficial or erroneous incorporation of ideas (Gasaymeh 
et al., 2024; Ko & Song, 2024). Structured guidance can mitigate these 
risks. For instance, Casey (2024) demonstrated how embedding 
higher-order evaluation questions encouraged students to interrogate 
Gen AI outputs beyond factual accuracy, while Ngo and Hastie (2025)
showed that peer discussion supported deeper evaluation of 
AI-generated texts. Such approaches highlight that evaluation should be 
an explicit and collaborative stage in the learning process, encompassing 
not only task relevance and clarity but also ethical implications such as 
bias, fairness, and academic integrity (Kajiwara & Kawabata, 2024; Lee 
& Song, 2024).
To address these challenges holistically, a structured five-step 
interaction model, developed primarily based on this review, can 
guide responsible and ethical engagement with Gen AI, as shown in 
Table 7. The model begins with clarifying the question, which supports 
students in approaching Gen AI with a clear intent and specific objectives 
(Ngo & Hastie, 2025). Clearly defined purposes facilitate targeted in-
teractions, promoting meaningful engagement and supporting student 
agency (Chen et al., 2023). The second step, thinking first, encourages 
students to generate ideas independently. This deliberate pause enables 
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 12 ---

students to compare their original thoughts and assumptions with 
AI-generated information, fostering agency and stimulating reflective 
practices about their own knowledge and reasoning processes (Wang, 
2024). The third step, interacting with Gen AI and shaping responses, 
centres on purposeful engagement through iterative prompting and 
refinement. Explicit training in structured techniques has been shown to 
enhance both output quality and students’ self-efficacy in managing 
Gen AI (Dillon, 2024; Mabrito, 2024). The fourth step, evaluating and 
discussing, ensures that students critically assess outputs through reli-
able sources, peer review, and ethical reflection, addressing known risks 
of inaccuracy or bias (Casey, 2024; Young et al., 2024; Zou et al., 2024). 
Finally, the incorporation and reflection stage emphasises responsible 
integration of AI-generated outputs into students’ own work, with op-
portunities to reflect on ethical implications and academic integrity 
(Kajiwara & Kawabata, 2024; Lee & Song, 2024).
Although presented sequentially, the model should be inherently 
iterative: students often revisit earlier steps as their ideas evolve, 
engaging in cycles of prompting, evaluation, and reflection (Chen et al., 
2023; Ngo & Hastie, 2025). By embedding agency, prompting, and 
evaluation within this dynamic process, the model may directly mitigate 
the key challenges identified while also fostering the five competencies 
of Gen AI literacy in a coherent and human-centred manner. While this 
model has highlighted agency, prompting, and evaluation, other com-
petencies are also integral. A sound understanding of how Gen AI works, 
including its probabilistic nature and susceptibility to bias, should be 
explicitly taught to support effective use and evaluation (Cheung et al., 
2024; ˇCerný, 2024). Students’ attitudes, curiosity, self-efficacy, and 
critical awareness, further shape how they engage with Gen AI, influ-
encing both persistence and reflective caution (Chan & Hu, 2023; 
Gasaymeh et al., 2024). Likewise, ethical concerns extend beyond 
evaluation to issues of privacy, fairness, and institutional policies, 
requiring explicit attention and guidance (Kajiwara & Kawabata, 2024; 
O’Dea et al., 2024), particularly in Steps 4 and 5. Taken together, these 
dimensions reinforce that fostering Gen AI literacy requires a compre-
hensive approach that integrates knowledge, skills, ethics, and attitudes 
into a reflective and human-centred practice.
7. Significance and implications
This systematic review underscores the critical significance of clearly 
defining and cultivating Gen AI literacy among students. With the pro-
liferation and rapid integration of powerful Gen AI technologies, such as 
LLMs, into teaching and learning environments, developing compre-
hensive literacy frameworks specific to Gen AI becomes paramount 
(Annapureddy et al., 2024). Given the distinctive competencies required 
for effectively interacting with Gen AI compared to general AI literacy 
frameworks, the conceptualisation of a Gen AI-specific literacy frame-
work through this review study provides a timely and practical response 
to emerging educational needs. Specifically, highlighting competencies 
such as understanding Gen AI capabilities and limitations, effective 
prompt engineering, critical evaluation of AI-generated content, ethical 
considerations, and maintaining positive and critical attitudes towards 
Gen AI, the review contributes substantively to the ongoing discourse on 
AI education in schools.
From a practical standpoint, this review has several significant im-
plications for educational practices at various school levels. Firstly, 
schools can explicitly integrate the five identified competencies: (1) 
know and understand Gen AI, (2) use and apply Gen AI, (3) evaluate and 
incorporate Gen AI, (4) Gen AI ethics, and (5) attitudes towards Gen AI, 
into curricula and instructional design. Ample research in this field 
consistently shows that competencies such as prompt engineering and 
critical evaluation of AI-generated outputs are not intuitive and require 
deliberate instructional scaffolding (Dillon, 2024; Ngo & Hastie, 2025). 
Therefore, educators may need targeted professional development pro-
grammes that enable them to effectively guide students through struc-
tured interactions with Gen AI, emphasising iterative prompting 
techniques, critical assessments, and ethical usage guidelines. In addi-
tion, given students’ common misconceptions regarding how Gen AI 
functions, such as the belief that it operates through deterministic sys-
tems or simple information retrieval tools (ˇCerný, 2024), schools should 
implement curricula that clarify fundamental principles of Gen AI, 
including the probabilistic nature of AI content generation and the 
mechanisms underlying potential biases and inaccuracies (Young et al., 
2024). Doing so would ensure students develop their competencies, 
enabling them to approach Gen AI interactions with realistic expecta-
tions and critical awareness.
On the policy level, the findings of this review may strongly and 
urgently advocate for establishing clear institutional guidelines 
addressing ethical issues around the use of Gen AI in academic contexts. 
Students frequently demonstrate uncertainty regarding what constitutes 
ethical or unethical use of Gen AI tools, largely due to the lack of 
transparent, standardised policies in educational institutions (Kajiwara 
& Kawabata, 2024; Wang, 2024). Therefore, educational institutions 
should formulate explicit and comprehensive policy frameworks clari-
fying permissible and impermissible uses of Gen AI, addressing academic 
integrity, data privacy, fairness, and intellectual property rights. Such 
policies, accompanied by well-defined enforcement mechanisms and 
continuous student education, can significantly mitigate risks associated 
with Gen AI misuse.
The structured five-step interaction model proposed in this study (i. 
e., clarify the question, think first, interact and shape, evaluate and 
discuss, and incorporate and reflect) suggests practical guidelines to 
educators for fostering student agency and self-regulated learning. 
Studies highlighted in the review emphasise the importance of sup-
porting students in critically evaluating Gen AI-generated information 
and integrating it responsibly into their learning tasks (Casey, 2024; 
Wang, 2024). By consistently embedding such structured interaction 
models within classroom practices, educators can reinforce students’ 
active roles and their agency in their own learning processes, thereby 
enhancing both their cognitive engagement and metacognitive 
awareness.
Lastly, this review study is posing several directions for future 
research. There is an evident need for empirical investigations into the 
effectiveness of structured pedagogical interventions designed explicitly 
around the proposed Gen AI literacy competencies. Such studies should 
explore how effectively students can apply these competencies across 
diverse disciplinary contexts. In addition, building on recent findings 
that the use of Gen AI positively impacts students’ academic perfor-
mance (Dong et al., 2025) and their engagement of learning (Heung & 
Chiu, 2025), research should further examine the relationships between 
specific competencies such as prompt engineering, critical evaluation, 
and ethical awareness, to provide deeper insights into how these com-
petencies collectively influence students’ overall Gen AI literacy and 
academic performance. Longitudinal studies exploring how structured 
scaffolds affect students’ perceptions, competencies, and attitudes to-
wards Gen AI over time would also contribute significantly to this 
emerging field.
Table 7 
Steps for the use of Gen AI.
Step
Description
1. Clarify the question
Define and clarify the question, breaking it down into 
key concepts where necessary
2. Think first
Attempt to answer or discuss the question before 
using Gen AI
3. Interact with Gen AI and 
shape responses
Ask Gen AI chatbots about the specific question(s), 
refine responses by prompting
4. Evaluate and discuss
Cross-check and evaluate AI-generated responses 
through discussion, reliable sources and ethical 
considerations, and explore different perspectives
5. Incorporate and reflect
Responsibly incorporate AI-generated responses into 
original ideas or work and reflect on the process
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 13 ---

In conclusion, the conceptualisation of the Gen AI literacy framework 
and a systematic review in terms of this framework provide significant 
implications for educational practices, institutional policy, and student 
agency. By addressing the nuanced competencies required for respon-
sible and effective interaction with Gen AI, schools can better help stu-
dents to navigate the evolving landscape of Gen AI-integrated teaching 
and learning, ensuring that they emerge as competent, reflective, and 
ethically responsible users of Gen AI technologies.
Funding
This study was funded by Singapore Ministry of Education (MOE) 
under the Education Research Funding Programme (ERFP 19/23 PJ). 
Any opinions, findings, and conclusions or recommendations expressed 
in this material are those of the author(s) and do not necessarily reflect 
the views of the Singapore MOE.
Declaration of competing interest
The author declares that there are no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper.
Acknowledgment
The author gratefully acknowledges the assistance of Mohammad 
Shafiq Anshad and Yixin Peng in database searching, literature 
screening, and initial data extraction as research assistants for this sys-
tematic review.
Appendix 
Table A1 
A summary of the 51 reviewed articles
Authors
Methodology
Gen AI literacy (n out of 51 studies, %)
School level
Design
Intervention Domain
Know and 
understand Gen AI 
(n = 47, 92.2 %)
Use and apply Gen AI 
(n = 28, 54.9 %)
Evaluate and 
incorporate Gen AI 
(n = 34, 66.7 %)
Gen AI ethics (n =
28, 54.9 %)
Attitudes towards 
Gen AI (n = 42, 
82.3 %)

Acosta-Enriquez 
et al. (2024)
Undergraduate 
education
Quantitative non- 
intervention
​
- Benefits in 
academic 
activities
​
​
- A positive 
correlation 
between 
responsible use 
and positive 
attitudes
- Positive 
attitudes 
affected by 
frequent use 
intention

AL-Abdullatif et al. 
(2024)
Undergraduate 
education
Quantitative non- 
intervention
​
- Writing 
assistance, 
conducting 
research, 
learning new 
concepts
​
- Gamification of 
AI interaction to 
increase 
engagement
- Priority of the 
perceived value 
of Gen AI despite 
concerns about 
privacy and 
accuracy
- Linked to 
contribution to 
academic 
success and 
efficiency

Alzubi (2024)
Undergraduate 
education
Mixed 
methods
non- 
intervention
​
- Ease of use, 
reliability, and 
time and effort 
savings in 
writing tasks
- Using Gen AI to 
improve writing 
and receive 
language feedback
​
​
- Confident in the 
use of Gen AI for 
simple writing 
tasks

Cahill et. (2024)
Undergraduate 
education
Quantitative non- 
intervention
​
- Providing 
feedback, data 
visualisation
​
- Evaluating AI 
content 
inconsistently
​
- Uneven 
confidence in 
their ability to 
use AI 
appropriately

Casey (2024)
Undergraduate 
education
Qualitative
Intervention AI in general - Several brief 
tasks which were 
to understand 
the capabilities 
and limitations 
of Gen AI
- Augmenting 
human 
intelligence
- Writing a 1000 
word essay by 
Gen AI
- Need to learn how 
to craft effective 
prompts for quality 
answers
- Reference check
- Evaluation of 
Gen AI written 
essay by higher- 
order thinking 
questions
- Reflection on 
the use of Gen AI 
in drafting a 
policy brief, 
considering the 
limitations of its 
outputs
- Techno- 
scepticism

ˇCerný (2024)
Undergraduate 
education
Mixed 
methods
non- 
intervention
​
- Conceptualising 
AI as a tool, a 
learning system, 
or an imitation of 
human thought
- Limited 
technical 
understanding
- Text creation, 
image generation, 
translation, and 
content 
personalisation
- Specifying the 
style, length, or 
structure of output 
through prompts
- Evaluating AI- 
generated con-
tent critically, 
given its 
limitations
- Using AI as 
inspiration, then 
adapting, 
rewriting, or 
further 
developing the 
content to suit 
their needs
- A strong 
awareness of 
responsible and 
ethical AI use 
related to issues 
such as 
discrimination, 
fairness, and 
accountability
- Ethical 
awareness and 
knowledge of 
regulations
- Moderately 
confident in 
using specific AI 
tools
(continued on next page)
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 14 ---

Table A1 (continued)
Authors 
Methodology 
Gen AI literacy (n out of 51 studies, %)
School level 
Design 
Intervention Domain 
Know and 
understand Gen AI 
(n = 47, 92.2 %) 
Use and apply Gen AI 
(n = 28, 54.9 %) 
Evaluate and 
incorporate Gen AI 
(n = 34, 66.7 %) 
Gen AI ethics (n =
28, 54.9 %) 
Attitudes towards 
Gen AI (n = 42, 
82.3 %)

Chan and Hu 
(2023)
Undergraduate 
education
Quantitative non- 
intervention
​
- A good 
understanding of 
how Gen AI 
works
- Less aware of 
risks related to 
emotional 
intelligence
- Support for 
personalised 
learning, 
writing, research 
and analysis, 
visual and audio 
content, and 
administrative 
tasks
​
​
- Privacy and 
ethical issues, 
plagiarism
- Uncertain or 
unclear policies 
and regulations 
related to Gen AI
- A positive 
attitude and 
willingness to 
adopt Gen AI 
tools
- Generally 
confident in the 
use of AI

Chan and Lee 
(2023)
Undergraduate 
education
Quantitative non- 
intervention
​
- Factually 
inaccurate 
outputs and 
biases
- Enhanced 
productivity, 
efficiency, 
personalised 
learning, and 
brainstorming
​
​
- Academic 
integrity, bias 
recognition
- Optimistic view 
of Gen AI

Chan and Tsi 
(2024)
Undergraduate 
education
Mixed 
methods
non- 
intervention
​
- Limited 
awareness of the 
potential risks 
and limitations
- Course design, 
personalised 
learning, 
immediate 
feedback
- Brainstorming, 
generating ideas, 
providing 
inspiration, 
improving writing, 
learning 
programming
​
​
- A more positive 
perception and 
attitude toward 
the use of AI 
technologies
- Generally 
confident in the 
use of AI
10 Chen et al. (2023)
Secondary 
education
Qualitative
Intervention AI in general - A rudimentary 
understanding of 
the mechanism 
of Gen AI, but 
practical 
understanding of 
its capabilities 
and limitations
- Understanding 
Gen AI as an 
information 
generation tool, 
a serendipity 
engine, and an 
assistant for 
mundane tasks
- Various 
applications in 
knowledge- 
building processes
- Iteratively crafting, 
probing, and 
refining prompts to 
elicit desirable 
outputs from 
Chat GPT
- Cross-checking 
Chat GPT’s 
responses using 
Google and 
reflecting 
critically on its 
outputs
- Using Chat GPT’s 
responses as 
inspiration, and 
sometimes 
directly 
integrating its 
suggestions into 
their work
- Setting 
boundaries on 
how to use 
Chat GPT
- Engaging with 
Chat GPT for 
various learning 
purposes, 
reflecting 
curiosity and 
willingness to 
explore AI’s 
capabilities
- Varying levels of 
confidence in 
using AI
11 Chen et al. (2024)
Undergraduate 
education
Quantitative non- 
intervention
​
​
- Idea generation
- Use of iterative 
questioning and 
step-by-step 
prompting
- Concerns 
regarding the 
reliability and 
accuracy of 
Gen AI outputs
- Developing ideas 
with the 
assistance of 
Gen AI
- Concerns about 
academic 
integrity
- Need for explicit 
guidelinesa
- High interest in 
Gen AI
12 Cheung et al. 
(2024)
Secondary 
education
Mixed 
methods
Intervention STEM
- A mixed 
understanding of 
how Gen AI 
works and its 
capabilities
​
- Assessing 
Chat GPT- 
generated texts 
on climate 
change, focusing 
on their ability to 
interpret, reason 
and evaluate
​
​
13 Chiu (2024)
Undergraduate 
education
Qualitative
Intervention AI in general - Awareness of 
Gen AI’s 
capabilities and 
- Gathering 
information for 
courses and 
- A need for solid 
disciplinary 
knowledge to 
​
​
(continued on next page)
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 15 ---

Table A1 (continued)
Authors 
Methodology 
Gen AI literacy (n out of 51 studies, %)
School level 
Design 
Intervention Domain 
Know and 
understand Gen AI 
(n = 47, 92.2 %) 
Use and apply Gen AI 
(n = 28, 54.9 %) 
Evaluate and 
incorporate Gen AI 
(n = 34, 66.7 %) 
Gen AI ethics (n =
28, 54.9 %) 
Attitudes towards 
Gen AI (n = 42, 
82.3 %)
of the 
importance of 
understanding 
how it works
- Transformative 
impact of Gen AI 
on higher 
education
writing 
assignments
evaluate Gen AI 
outputs
14 Chiu et al. (2023)
Secondary 
education
Quantitative Intervention Tourism
​
​
​
- Intrinsic 
motivation to 
learn with the 
chatbot
- Relationship 
between self- 
regulated 
learning and 
digital literacy
15 Dai (2024)
Primary 
education
Qualitative
Intervention AI in general - Significant 
growth in 
understanding 
how AI works, 
including its 
capabilities and 
limitations
- Viewing AI as 
inherently useful 
and helpful, 
emphasising its 
potential to 
make life more 
convenient and 
to assist with 
tasks
​
- Machine 
discrimination, 
the binary and 
heartless nature 
of AI decision- 
making, and the 
influence of 
biased training 
data
- Embodied 
analogies and 
constructionist 
activities
- Increasing 
ethical 
awareness and 
critical attitudes
- Expressing 
curiosity about 
how AI works 
and its 
applications
- Becoming more 
confident
16 Dalgic et al. (2024) Undergraduate 
education
Quantitative Intervention Tourism
- Access required 
information 
without time/ 
space limitations
​
- Facilitating the 
research process 
and 
understanding 
other cultures
​
- Increasing 
motivation and 
engagement 
when 
experiencing 
benefits
- The higher the 
digital literacy, 
the more 
confident they 
are in using AI
17 Dillon (2024)
Undergraduate 
education
Mixed 
methods
Intervention English 
education
- Awareness of 
both the 
strengths and 
weaknesses of 
Gen AI in 
language 
learning
- Benefits such as 
difficulty 
adjustment, 
scripting, and 
summarisation
- Tasks such as 
information 
gathering, 
translation, 
drafting, and 
revising reports
- Creating prompts 
to generate 
conversation 
topics, initiating 
reverse prompting 
activities, and 
combining 
requests into meta- 
strategic prompts
- Identifying 
limitations such 
as inaccurate or 
unclear 
responses
- Combining AI- 
generated con-
tent with their 
own ideas to 
achieve learning 
goals and create 
personalised 
learning 
environments
​
- Gen AI as a 
compelling and 
engaging tool 
for language 
learning
- Confident in the 
use of Gen AI
18 Ding et al. (2023)
Undergraduate 
education
Mixed 
methods
Intervention STEM
- Misconceptions, 
such as 
perceiving 
Chat GPT as 
super-intelligent, 
infallible, or 
equating it with 
a search engine 
or robot
- The usefulness of 
Gen AI for 
immediate 
assistance and as 
​
- Blindly trusting 
Chat GPT’s 
answers
​
​
(continued on next page)
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 16 ---

Table A1 (continued)
Authors 
Methodology 
Gen AI literacy (n out of 51 studies, %)
School level 
Design 
Intervention Domain 
Know and 
understand Gen AI 
(n = 47, 92.2 %) 
Use and apply Gen AI 
(n = 28, 54.9 %) 
Evaluate and 
incorporate Gen AI 
(n = 34, 66.7 %) 
Gen AI ethics (n =
28, 54.9 %) 
Attitudes towards 
Gen AI (n = 42, 
82.3 %)
a resource for 
tackling 
academic 
problems
19 Folmeg et al. 
(2024)
Undergraduate 
education
Qualitative
non- 
intervention
​
- Lack of 
substantial 
background 
knowledge on 
the operation of 
AI
- Understanding 
the usefulness of 
different text 
types
- Brainstorming, 
topic selection, 
searching for 
information, 
translation, 
creating and 
reformatting texts, 
writing essays and 
CVs, language 
learning, and 
transcription
- Lack of well- 
defined requests
- Tending to 
accept outputs 
without 
sufficient 
scrutiny of 
reliability, 
limitations, or 
potential biases
- Integrating AI- 
generated con-
tent into their 
ideas and 
assignments
- Mixed levels of 
responsibility 
and ethics in 
Gen AI use
- Perceiving 
themselves as 
proficient and 
confident in 
using Chat GPT
20 Gasaymeh et al. 
(2024)
Undergraduate 
education
Quantitative non- 
intervention
​
- Concerns about 
misinformation, 
data security, 
plagiarism, and 
limited technical 
understanding
- Simulating 
creativity and 
fostering 
innovation
- Moderate practical 
experience with 
generative AI 
writing tools
​
- A need for more 
ethical 
guidelines, 
training, and 
discussions to 
support the 
responsible and 
ethical use of 
Gen AI
- A high level of 
interest and 
engagement in 
generative AI 
writing tools
21 Hu et al. (2024)
Undergraduate 
education
Quantitative Intervention Information 
literacy
- Improving 
information 
literacy self- 
efficacy and 
enhancing 
perception of 
self-regulated 
learning abilities
- Interacting with an 
existing AI 
learning 
companion (virtual 
librarian) and 
using AI visual 
guidance
​
- A need for clear 
policies on AI 
integration with 
library systems
- Positive 
experiences 
with the AI 
learning 
companion and 
AI visual 
guidance
- Increased 
confidence in 
managing 
academic 
projects and 
library research 
using AI
22 Hwang et al. (2024) Undergraduate 
education
Qualitative
Intervention Writing
- Objectives for 
using Gen AI in 
English writing 
tasks
- Drafting and 
revising English 
writing
- Misalignment 
between objectives 
and approaches
- Surface level of 
prompting
​
​
​
23 Iwasawa et al. 
(2023)
Undergraduate 
education
Quantitative non- 
intervention
​
- Generally 
familiar with 
basic AI terms 
such as machine 
learning
- Gathering 
information 
more efficiently 
and enhancing 
their 
comprehension
​
- Not critically 
evaluating AI- 
generated 
content
- Limited 
understanding 
of responsible 
and ethical AI 
usage
- Positive 
impressions of 
Chat GPT
- Generally not 
very confident 
in using AI
24 Jang (2024)
Undergraduate 
education
Quantitative non- 
intervention
​
- Enhancing 
academic 
performance
​
​
- Varying levels 
of ethical use
- Expressing 
intentions to use 
Gen AI tools for 
learning
- Confidence and 
willingness to 
engage with AI
25 Jiang et al. (2024)
Undergraduate 
education
Qualitative
Intervention Writing
- An 
understanding of 
both the 
capabilities and 
limitations of 
- Using Gen AI for a 
research writing 
project
- Verifying the 
accuracy of 
information 
generated by 
Chat GPT and 
- Concerns about 
reliability and 
creative 
limitations
- Thoughtful 
interest in the 
role of AI in 
their academic 
work
(continued on next page)
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 17 ---

Table A1 (continued)
Authors 
Methodology 
Gen AI literacy (n out of 51 studies, %)
School level 
Design 
Intervention Domain 
Know and 
understand Gen AI 
(n = 47, 92.2 %) 
Use and apply Gen AI 
(n = 28, 54.9 %) 
Evaluate and 
incorporate Gen AI 
(n = 34, 66.7 %) 
Gen AI ethics (n =
28, 54.9 %) 
Attitudes towards 
Gen AI (n = 42, 
82.3 %)
generative AI 
such as Chat GPT
- Generating 
ideas, enhancing 
the overall 
quality of their 
writing, and 
positively 
influencing their 
writing process
refining content 
to align with 
specific goals
- Using AI for 
inspiration and 
integrating its 
suggestions into 
their writing 
process
- Awareness of 
over-reliance 
and the impor-
tance of human 
agency
- Generally 
confident in 
using AI
26 Joseph et al. (2024) Undergraduate 
education
Quantitative non- 
intervention
​
- Providing 
creative 
solutions and 
enhancing 
analytical 
understanding of 
abstract concepts
- Use of various AI 
tools such as 
Duolingo, Ed X, and 
audio-video-text 
generation and 
editing tools
​
​
- Expressing 
intentions to use 
Gen AI tools for 
learning 
purposes
- Positive 
correlations 
between 
students’ digital 
literacy, use of 
AI tools, and 
collaborative 
learning
27 Kajiwara and 
Kawabata (2024)
Secondary 
education
Quantitative Intervention AI in general - Understanding 
of large language 
model concepts, 
including their 
capabilities and 
ethical use in 
decision support
- Information 
retrieval and 
creative support
- Application in 
decision support
- Evaluating outputs 
with varied 
prompts
- Correcting errors 
in AI outputs
- Fairness of AI- 
generated 
responses
- Monitoring 
Gen AI responses 
by humans
- Fairness and 
accountability 
emphasised
- Privacy and 
data protection
- Exploration of 
AI’s creative 
potential
- Confidence in 
ethical AI usage 
after training
28 Kazanidis and 
Pellas (2024)
Undergraduate 
education
Quantitative Intervention STEM
- AI-generated 
images and 
videos especially 
useful for 
students’ field 
(Early Childhood 
Education and 
Computer 
Education)
- AI-generated 
Images and videos
- Integrating AI- 
generated con-
tent into educa-
tional materials
​
- A greater 
intention to 
explore AI’s 
potential after 
participating
- A general 
confidence in 
the use of Gen AI
29 Khoudri et al. 
(2024)
Undergraduate 
education
Quantitative non- 
intervention
​
​
- Feedback, 
engagement, 
motivation, 
personalised 
learning, and 
autonomy
​
- Concerns 
including 
privacy and 
security, over- 
reliance, lack of 
responsibility, 
and plagiarism; 
as well as the 
importance of 
fostering critical 
thinking and 
creativity
- Optimistic view 
of Gen AI for 
learning English
30 Ko and Song (2024) Secondary 
education
Qualitative
Intervention Moral 
education
- Recognising bias 
and fairness 
issues in the use 
of Gen AI
​
​
- Recognising the 
importance of 
human dignity 
and expressing 
disagreement 
with the 
unequal 
distribution of 
AI
- Receiving 
Gen AI as a 
concern for 
personal data 
protection and 
emphasising 
mitigating AI- 
related risks
- Varying degrees 
of engagement 
and interest in 
AI depending on 
how Gen AI is 
perceived
(continued on next page)
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 18 ---

Table A1 (continued)
Authors 
Methodology 
Gen AI literacy (n out of 51 studies, %)
School level 
Design 
Intervention Domain 
Know and 
understand Gen AI 
(n = 47, 92.2 %) 
Use and apply Gen AI 
(n = 28, 54.9 %) 
Evaluate and 
incorporate Gen AI 
(n = 34, 66.7 %) 
Gen AI ethics (n =
28, 54.9 %) 
Attitudes towards 
Gen AI (n = 42, 
82.3 %)
31 Laupichler et al. 
(2024)
Undergraduate 
education
Mixed 
methods
non- 
intervention
​
- Lower technical 
understanding of 
how Gen AI 
works
​
​
- Critically using 
Gen AI with 
regard to data 
privacy, 
security, ethics, 
risks, and 
weaknesses
- A strong positive 
correlation 
between AI 
literacy and 
positive 
attitudes 
towards AI
- Confident in 
their ability to 
critically 
evaluate AI
32 Lee and Park 
(2023)
Undergraduate 
education
Quantitative non- 
intervention
​
- Information and 
knowledge 
acquisition, as 
well as 
entertainment 
and leisure
​
- Chat GPT literacy 
that helps with 
fact-checking 
and practical use
​
- User 
satisfaction, 
which is 
positively 
related to 
Chat GPT 
literacy
- The higher the 
Chat GPT 
literacy, the 
greater the 
confidence
33 Lee and Song 
(2024)
Primary 
education
Mixed 
methods
non- 
intervention
​
- Limited 
understanding of 
how Gen AI 
works and its 
capabilities and 
limitations
​
- Prioritising 
relatability and 
clarity when 
evaluating 
explanations
​
​
34 Levine et al. (2024) Secondary 
education
Quantitative non- 
intervention
​
- Recognising the 
usefulness of 
Gen AI in 
generating ideas, 
clarifying 
concepts, and 
editing their 
writing
- Planning, 
translating and 
reviewing writing 
tasks
- Asking for outlines, 
reasons, and data 
points, and 
requesting edits for 
grammar and 
coherence through 
prompts
- Assessing 
Chat GPT’s 
responses for 
relevance and 
accuracy, 
sometimes 
choosing not to 
use its 
suggestions
- Using Gen AI to 
develop their 
own work
​
​
35 Y. Liu, Zhang, and 
Biebricher (2024)
Undergraduate 
education
Mixed 
methods
non- 
intervention
​
- Understanding 
the capabilities 
and limitations 
of Gen AI
- Daily academic 
practices such as 
using time- 
saving tools, 
engaging with 
user-friendly 
platforms, and 
learning English 
academic 
communication
​
​
- Concerns about 
information 
reliability, 
ethical issues, 
and academic 
integrity
- A lack of clear 
university 
guidelines at the 
time
- Strong interest 
in AI
- Confident in 
integrating 
Gen AI into their 
learning 
strategies
36 Mah et al. (2024)
Secondary 
education
Qualitative
Intervention AI in general - Improving their 
learning by 
evaluating the 
suggestions or 
using them to 
deepen their 
own thinking
- Asking for first 
sentences, outlines, 
editing a 
paragraph, or 
generating 
counterarguments 
using prompts
- Using Chat GPT 
to scaffold 
further ideas
- Evaluating and 
integrating AI- 
generated ideas 
thoughtfully, 
rather than sim-
ply copying
- Cheating 
evaluated based 
on cognitive 
load and the 
types of tasks 
offloaded
​
37 Marrone et al. 
(2024)
Secondary 
education
Mixed 
methods
Intervention STEM
- Partial 
understanding of 
the capabilities 
of AI
​
- Critical 
evaluation of AI 
errors
- Collaboration 
with AI for basic 
​
- Mixed 
confidence and 
trust issues
(continued on next page)
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 19 ---

Table A1 (continued)
Authors 
Methodology 
Gen AI literacy (n out of 51 studies, %)
School level 
Design 
Intervention Domain 
Know and 
understand Gen AI 
(n = 47, 92.2 %) 
Use and apply Gen AI 
(n = 28, 54.9 %) 
Evaluate and 
incorporate Gen AI 
(n = 34, 66.7 %) 
Gen AI ethics (n =
28, 54.9 %) 
Attitudes towards 
Gen AI (n = 42, 
82.3 %)
- Differentiation 
practices and 
assistance with 
homework
tasks and 
problem solving
38 Masa’deh et al. 
(2024)
Undergraduate 
education
Quantitative non- 
intervention
​
- Factual mistakes, 
bias, lack of 
thorough 
understanding
- Increasing 
learning quality 
and making 
academic tasks 
quicker and 
more effective
​
​
​
- Perceived 
usefulness that 
influenced the 
intent to use
- Increasing 
confidence 
observed with 
consistent use of 
Chat GPT
39 Musyaffi et al. 
(2024)
Undergraduate 
education
Quantitative non- 
intervention
​
- Quickly 
obtaining 
information, 
assisting with 
assignments, and 
providing 
significant 
advantages over 
other media
​
​
- Ethical concerns 
about 
dependency and 
personal data 
misuse
- The higher the 
self-confidence, 
the greater the 
enthusiasm for 
learning AI
40 Naamati-Schneider 
(2024)
Undergraduate 
education
Qualitative
Intervention Health 
management
- A good 
understanding of 
both the 
capabilities and 
limitations of 
Gen AI tools
- Ability to quickly 
provide relevant 
information and 
improve learning 
efficiency
- Refining questions 
posed to Chat GPT 
to increase 
precision and 
understanding
- Verifying facts, 
checking 
sources, and 
cross-referencing 
with academic 
literature
- Combining AI- 
generated con-
tent with their 
own knowledge 
and critical 
evaluation
​
- Describing their 
experience with 
Chat GPT 
positively
- Initially lacked 
confidence in 
data credibility 
and effective 
prompting, but 
showed 
improvement 
after training
41 Naamati-Schneider 
and Alt (2024)
Undergraduate 
education
Quantitative Intervention Digital 
literacy
- Chat GPT’s 
efficiency and 
availability for 
information 
retrieval and 
learning
- Exploring the 
accreditation 
dilemma in health 
management and 
enhance digital 
literacy
- Repeatedly 
adjusting prompts 
to obtain more 
accurate and 
relevant answers
- Evaluation of 
Gen AI outputs 
from three 
perspectives: 
management, 
worker, and 
patient
- Incorporating 
Gen AI outputs to 
learn about the 
accreditation 
dilemma
​
​
42 Ngo and Hastie 
(2025)
Secondary 
education
Quantitative Intervention Writing
- Perceiving 
Gen AI as a useful 
tool for 
achieving 
academic goals
- Use of Gen AI for 
essay writing, 
including 
generating and 
outlining ideas, 
and paraphrasing 
sentences
- Character, request, 
examples, 
adjustment, type of 
output, extras 
(CREATE) 
framework
- Analysing and 
assessing AI- 
generated con-
tent rather than 
blindly trusting 
it
- Using AI as a 
collaborative 
tool to enhance 
their academic 
work
- Becoming more 
aware of 
appropriate and 
inappropriate 
uses of AI
- Development of 
guidelines for 
the use of Gen AI
- Appreciation for 
learning about 
prompt 
engineering and 
new AI use cases
- Improved 
confidence in 
using Gen AI 
after the 
programme
43 O’Dea et al. (2024) Undergraduate 
education
Quantitative non- 
intervention
​
- A basic 
understanding of 
Gen AI functions
- Writing, 
generating 
multimedia, and 
programming
- Refining prompts 
to enhance the 
generated 
outcomes
- Modifying AI 
outputs (HK 
students 
performed better 
than UK 
students)
- A lack of full 
understanding 
of AI ethics
- Confident in 
using AI to solve 
a problem but 
less confident in 
evaluating AI 
applications and 
comprehending 
underlying AI 
concepts
44 Oktarin et al. 
(2024)
Undergraduate 
education
Mixed 
methods
Intervention English 
education
- Improvements in 
writing 
outcomes, 
- Receiving and 
incorporating 
personalised 
- Accuracy of AI 
feedback
​
- Making learning 
more enjoyable, 
(continued on next page)
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 20 ---

Table A1 (continued)
Authors 
Methodology 
Gen AI literacy (n out of 51 studies, %)
School level 
Design 
Intervention Domain 
Know and 
understand Gen AI 
(n = 47, 92.2 %) 
Use and apply Gen AI 
(n = 28, 54.9 %) 
Evaluate and 
incorporate Gen AI 
(n = 34, 66.7 %) 
Gen AI ethics (n =
28, 54.9 %) 
Attitudes towards 
Gen AI (n = 42, 
82.3 %)
engagement, and 
personalised 
feedback
feedback guided by 
Gen AI
- Acting upon AI- 
generated feed-
back during 
writing
motivating, and 
engaging
- Increasing 
confidence in 
the use of Gen AI 
and writing 
proficiency
45 Relmasira et al. 
(2023)
Primary 
education
Qualitative
Intervention AI in general - Understanding 
the importance 
of data quality in 
AI training
- Using AI in 
everyday life and 
for good 
purposes
- Manipulating 
images using 
multiple tools
- Enhancing the 
ability to 
critically 
evaluate AI 
through hands- 
on activities
- Understanding 
harmful AI 
content (e.g., 
deepfakes) and 
how AI is 
embedded in 
daily life, such 
as Instagram 
filters
​
46 Tsao and Nogues 
(2024)
Undergraduate 
education
Qualitative
Intervention Writing
​
- Co-creation of 
graphic short 
stories and poems 
with Gen AI
- Employing varied 
prompts according 
to the mode of 
content creation
- Evaluation of 
creativity
​
- Varying self- 
confidence 
across creative 
domains
47 Vartiainen et al. 
(2024)
Primary 
education, 
secondary 
education
Qualitative
Intervention AI in general - Increasing 
understanding of 
how Gen AI 
works, 
particularly 
regarding the 
training data and 
bias
- Creating 71 
different apps 
using Gen AI, 
designed to 
recognise patterns 
and respond in 
various ways
- Using prompts to 
create various 
images
- Reflecting on 
algorithmic 
biases in the 
images 
generated by 
Gen AI
- Creating 
personalised 
projects using 
their own data 
with Gen AI
- Considering the 
potential harms 
and 
inconveniences 
caused by 
biased AI 
outputs
- Showing 
interest in AI
- Becoming more 
confident in 
using AI as a 
result of the 
workshops
48 Vidaurre et al. 
(2024)
Undergraduate 
education
Quantitative non- 
intervention
​
- Optimising and 
facilitating 
academic 
activities and 
adaptive 
learning
​
- Concerning 
issues of 
academic 
integrity
​
- Positive 
perceptions of 
AI
- Moderate level 
of confidence
49 Wang (2024)
Undergraduate 
education
Mixed 
methods
non- 
intervention
​
- Hallucinations, 
lack of 
reliability, 
reduced 
creativity, and 
diminished 
critical thinking
- Reducing 
cognitive load 
and improving 
immediate 
feedback, 
editing, and 
revision
- Brainstorming, 
outlining, revising, 
and editing
- Phrasing their 
requests to 
Chat GPT to get 
more useful or 
specific feedback
- Validating and 
critically 
assessing the 
information it 
generated
- Using Chat GPT 
as a starting 
point
- Being cautious 
about over- 
reliance on 
Chat GPT and 
recognising the 
ethical line be-
tween assis-
tance and 
plagiarism
- Overall positive 
experiences 
with generative 
AI-assisted 
writing
- Tempered 
confidence 
given critical 
awareness of 
AI’s limitations
50 Young et al. (2024) Undergraduate 
education
Quantitative non- 
intervention
​
- Different levels 
of understanding 
depending on 
scepticism
- Increased 
productivity and 
effectiveness in 
learning and 
studying 
chemistry
​
- Critical 
reflections on the 
relevance, 
trustworthiness, 
and quality of 
chatbot 
responses
​
- Varying 
confidence in 
using AI, 
depending on 
scepticism
51 Zou et al. (2024)
Undergraduate 
education
Quantitative non- 
intervention
​
- A noteworthy 
level of 
awareness 
regarding the 
potential risks 
and limitations
​
- Importance of 
critical thinking 
for evaluating AI 
outputs
- Awareness of 
the ethical 
dilemmas and 
potential risks 
associated with 
using AI- 
- Interest in AI 
training to 
enhance critical 
skills
(continued on next page)
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 21 ---

Table A1 (continued)
Authors 
Methodology 
Gen AI literacy (n out of 51 studies, %)
School level 
Design 
Intervention Domain 
Know and 
understand Gen AI 
(n = 47, 92.2 %) 
Use and apply Gen AI 
(n = 28, 54.9 %) 
Evaluate and 
incorporate Gen AI 
(n = 34, 66.7 %) 
Gen AI ethics (n =
28, 54.9 %) 
Attitudes towards 
Gen AI (n = 42, 
82.3 %)
- Saving time and 
effort and 
improving 
efficiency
generated 
content
References
* Acosta-Enriquez, B. G., Arbulú Ballesteros, M. A., Huamaní Jordan, O., L´opez Roca, C., 
& Saavedra Tirado, K. (2024). Analysis of college students’ attitudes toward the use 
of Chat GPT in their academic activities: Effect of intent to use, verification of 
information and responsible use. BMC Psychology, 12, 255. https://doi.org/10.1186/ 
s40359-024-01764-z.
* Al-Abdullatif, A. M., & Alsubaie, M. A. (2024). Chat GPT in learning: Assessing students’ 
use intentions through the lens of perceived value and the influence of AI literacy. 
Behavioral Sciences, 14, 845. https://doi.org/10.3390/bs14090845.
* Alzubi, A. A. F. (2024). Generative artificial intelligence in the EFL writing context: 
Students’ literacy in perspective. Qubahan Academic Journal, 4(2). https://doi.org/ 
10.48161/qaj.v4n2a506.
Bozkurt, A. (2023). Generative artificial intelligence (AI) powered conversational 
educational agents: The inevitable paradigm shift. Asian Journal of Distance 
Education, 18(1).
Bozkurt, A. (2024). Why generative AI literacy, why now and why it matters in the 
educational landscape?: Kings, queens and Gen AI dragons. Open Praxis, 16(3), 
283–290.
* ˇCerný, M. (2024). University students’ conceptualisation of AI literacy: Theory and 
empirical evidence. Social Sciences, 13, 129. https://doi.org/10.3390/ 
socsci13030129.
* Cahill, C., & Mc Cabe, K. (2024). Context matters: Understanding student usage, skills, 
and attitudes toward AI to inform classroom policies. PS: Political Science & Politics, 
57(4), 1–8. https://doi.org/10.1017/S1049096524000155.
Casal-Otero, L., Catala, A., Fern´andez-Morante, C., Taboada, M., Cebreiro, B., & Barro, S. 
(2023). AI literacy in K-12: A systematic literature review. International Journal of 
STEM Education, 10(1), 29. https://doi.org/10.1186/s40594-023-00418-7
* Casey, D. (2024). Chat GPT in public policy teaching and assessment: An examination of 
opportunities and challenges. Australian Journal of Public Administration. https://doi. 
org/10.1111/1467-8500.12647.
* Chan, C. K. Y., & Hu, W. (2023). Students’ voices on generative AI: Perceptions, 
benefits, and challenges in higher education. International Journal of Educational 
Technology in Higher Education, 20(43). https://doi.org/10.1186/s41239-023-00411- 
8.
* Chan, C. K. Y., & Lee, K. K. W. (2023). The AI generation gap: Are Gen Z students more 
interested in adopting generative AI such as Chat GPT in teaching and learning than 
their Gen X and millennial generation teachers?. Smart Learning Environments, 10 
(60). https://doi.org/10.1186/s40561-023-00269-3.
* Chan, C. K. Y., & Tsi, L. H. Y. (2024). Will generative AI replace teachers in higher 
education? A study of teacher and student perceptions. Studies In Educational 
Evaluation, 83, Article 101395. https://doi.org/10.1016/j.stueduc.2024.101395.
* Chen, K., Tallant, A. C., & Selig, I. (2024). Exploring generative AI literacy in higher 
education: Student adoption, interaction, evaluation and ethical perceptions. 
Information and Learning Sciences, 126(1/2), 132–148. https://doi.org/10.1108/ILS- 
10-2023-0160.
Chan, K. W., Ali, F., Park, J., Sham, K. S. B., Tan, E. Y. T., Chong, F. W. C., … Sze, G. K. 
(2025). Automatic item generation in various STEM subjects using large language 
model prompting. Computers and Education: Artificial Intelligence, 8, 100344. https:// 
doi.org/10.1016/j.caeai.2024.100344
* Chen, B., Zhu, X., & Díaz del Castillo, F. (2023). Integrating generative AI in knowledge 
building. Computers and Education: Artificial Intelligence, 5, Article 100184. https:// 
doi.org/10.1016/j.caeai.2023.100184.
* Cheung, K. K. C., Pun, J. K. H., & Li, W. (2024). Students’ holistic reading of socio- 
scientific texts on climate change in a Chat GPT scenario. Research in Science 
Education, 54, 957–976. https://doi.org/10.1007/s11165-024-10177-2.
* Chiu, T. K. F. (2024). Future research recommendations for transforming higher 
education with generative AI. Computers and Education: Artificial Intelligence, 6, 
Article 100197. https://doi.org/10.1016/j.caeai.2023.100197.
* Chiu, T. K. F., Moorhouse, B. L., Chai, C. S., & Ismailov, M. (2023). Teacher support and 
student motivation to learn with Artificial Intelligence (AI) based chatbot. Interactive 
Learning Environments, 32(7), 3240–3256. https://doi.org/10.1080/ 
10494820.2023.2172044.
* Dai, Y. (2024). Integrating unplugged and plugged activities for holistic AI education: 
An embodied constructionist pedagogical approach. Education and Information 
Technologies, 30, 6741–6764. https://doi.org/10.1007/s10639-024-13043-w.
* Dalgıç, A., Yas¸ar, E., & Demir, M. (2024). Chat GPT and learning outcomes in tourism 
education: The role of digital literacy and individualized learning. Journal of 
hospitality, Leisure. Sport & Tourism Education, 34, Article 100481. https://doi.org/ 
10.1016/j.jhlste.2024.100481.
* Dillon, T. (2024). Korean university students’ prompt literacy training with Chat GPT: 
Investigating language learning strategies. English teaching, 79(3), 123–157. https:// 
doi.org/10.15858/engtea.79.3.202409.123.
* Ding, L., Li, T., Jiang, S., & Gapud, A. (2023). Students’ perceptions of using Chat GPT 
in a physics class as a virtual tutor. International Journal of Educational Technology in 
Higher Education, 20, 63. https://doi.org/10.1186/s41239-023-00434-1.
Dong, L., Tang, X., & Wang, X. (2025). Examining the effect of artificial intelligence in 
relation to students’ academic achievement in classroom: A meta-analysis. Computers 
and Education: Artificial Intelligence. , Article 100400. https://doi.org/10.1016/j. 
caeai.2025.100400
Farrokhnia, M., Banihashem, S. K., Noroozi, O., & Wals, A. (2024). A SWOT analysis of 
Chat GPT: Implications for educational practice and research. Innovations in Education 
& Teaching International, 61(3), 460–474. https://doi.org/10.1080/ 
14703297.2023.2195846
* Folmeg, M., Fekete, I., & Koris, R. (2024). Towards identifying the components of 
students’ AI literacy: An exploratory study based on Hungarian higher education 
students’ perceptions. Journal of University Teaching and Learning Practice, 21(6), 
92–107. https://doi.org/10.53761/wzyrwj33.
* Gasaymeh, A.-M. M., Beirat, M. A., & Abu Qbeita, A. A. (2024). University students’ 
insights of generative artificial intelligence (AI) writing tools. Education Sciences, 14, 
1062. https://doi.org/10.3390/educsci14101062.
Heung, Y. M. E., & Chiu, T. K. (2025). How Chat GPT impacts student engagement from a 
systematic review and meta-analysis study. Computers and Education: Artificial 
Intelligence, 8, Article 100361. https://doi.org/10.1016/j.caeai.2025.100361
Hsain, A., & Housni, H. E. (2024). Large language model-powered chatbots for 
internationalizing student support in higher education. Ar Xiv. https://doi.org/ 
10.48550/arxiv.2403.14702
* Hu, Y.-H., Hsieh, C.-L., & Salac, E. S. N. (2024). Advancing freshman skills in 
information literacy and self-regulation: The role of AI learning companions and 
Mandala chart in academic libraries. The Journal of Academic Librarianship, 50, 
Article 102885. https://doi.org/10.1016/j.acalib.2024.102885.
* Hwang, M., Jeens, R., & Lee, H.-K. (2024). Exploring learner prompting behavior and 
its effect on Chat GPT-assisted English writing revision. The Asia-Pacific Education 
Researcher. https://doi.org/10.1007/s40299-024-00930-6.
* Iwasawa, M., Kobayashi, M., & Otori, K. (2023). Knowledge and attitudes of pharmacy 
students towards artificial intelligence and the Chat GPT. Pharmacy Education, 23(1), 
665–675. https://doi.org/10.46542/pe.2023.231.665675.
* Jang, M. (2024). AI literacy and intention to use text-based Gen AI for learning: The 
case of business students in Korea. Informatics, 11, 54. https://doi.org/10.3390/ 
informatics11030054.
Jeon, J., & Lee, S. (2023). Large language models in education: A focus on the 
complementary relationship between human teachers and Chat GPT. Education and 
Information Technologies, 28(12), 15873–15892. https://doi.org/10.1007/s10639- 
023-11834-1
Jiahong, S., & Weipeng, Y. (2023). Unlocking the power of Chat GPT: A framework for 
applying generative AI in education. ECNU Review of Education, 6(3), 355–366. 
https://doi.org/10.1177/20965311231168423
* Jiang, J., Vetter, M. A., & Lucia, B. (2024). Toward a ‘more-than-digital’ AI literacy: 
Reimagining agency and authorship in the postdigital era with Chat GPT. Postdigital 
Science and Education, 6, 922–939. https://doi.org/10.1007/s42438-024-00477-1.
* Joseph, G. V., Athira, P., Thomas, A. M., Jose, D., Roy, T. V., & Prasad, M. (2024). 
Impact of digital literacy, use of AI tools and peer collaboration on AI assisted 
learning: Perceptions of the university students. Digital Education Review, 45, 43–49. 
https://doi.org/10.1344/der.2024.45.43-49.
* Kajiwara, Y., & Kawabata, K. (2024). AI literacy for ethical use of chatbot: Will students 
accept AI ethics?. Computers and Education: Artificial Intelligence, 6, Article 100251. 
https://doi.org/10.1016/j.caeai.2024.100251.
* Kazanidis, I., & Pellas, N. (2024). Harnessing generative artificial intelligence for 
digital literacy innovation: A comparative study between early childhood education 
and computer science undergraduates. AI, 5(3), 1427–1445. https://doi.org/ 
10.3390/ai5030068.
* Khoudri, I., Zeriouh, M., Fauzan, U., & Khoudri, A. (2024). The use of AI in learning 
English: A comparative study between Moroccan and Indonesian undergraduate 
students from the English department. Edelweiss Applied Science and Technology, 8(4), 
1271–1282. https://doi.org/10.55214/25768484.v8i4.1504.
Knoth, N., Tolzin, A., Janson, A., & Leimeister, J. M. (2024). AI literacy and its 
implications for prompt engineering strategies. Computers and Education: Artificial 
Intelligence, 6, Article 100225. https://doi.org/10.1016/j.caeai.2024.100225
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487 

--- Page 22 ---

* Ko, J., & Song, A. (2024). Youth perceptions of AI ethics: A Q methodology approach. 
Ethics & Behavior. https://doi.org/10.1080/10508422.2024.2396582.
* Laupichler, M. C., Aster, A., Meyerheim, M., Raupach, T., & Mergen, M. (2024). 
Medical students’ AI literacy and attitudes towards AI: A cross-sectional two-center 
study using pre-validated assessment instruments. BMC Medical Education, 24, 401. 
https://doi.org/10.1186/s12909-024-05400-7.
* Lee, S., & Park, G. (2023). Exploring the impact of Chat GPT literacy on user 
satisfaction: The mediating role of user motivations. Cyberpsychology, Behavior, and 
Social Networking, 26(1). https://doi.org/10.1089/cyber.2023.0312.
* Lee, S., & Song, K.-S. (2024). Teachers’ and students’ perceptions of AI-generated 
concept explanations: Implications for integrating generative AI in computer science 
education. Computers and Education: Artificial Intelligence, 7, Article 100283. https:// 
doi.org/10.1016/j.caeai.2024.100283.
* Levine, S., Beck, S. W., Mah, C., Phalen, L., & Pittman, J. (2024). How do students use 
Chat GPT as a writing support?. Journal of Adolescent & Adult Literacy, 68(5), 
445–457. https://doi.org/10.1002/jaal.1373.
* Liu, Y., Park, J., & Mc Minn, S. (2024). Using generative artificial intelligence/Chat GPT 
for academic communication: Students’ perspectives. International Journal of Applied 
Linguistics, 34(4), 1437–1461. https://doi.org/10.1111/ijal.12574.
Liu, M., Zhang, L. J., & Biebricher, C. (2024). Investigating students’ cognitive processes 
in generative AI-assisted digital multimodal composing and traditional writing. 
Computers & Education, 211, Article 104977. https://doi.org/10.1016/j. 
compedu.2023.104977
Long, D., & Magerko, B. (2020). What is AI literacy? Competencies and design 
considerations. In Proceedings of the 2020 CHI conference on human factors in 
computing systems (pp. 1–16). https://doi.org/10.1145/3313831.3376727
Mabrito, M. (2024). Artificial intelligence in the classroom: Conversation design and 
prompt engineering for English majors. The International Journal of Technologies in 
Learning, 31(2), 129–142. https://doi.org/10.18848/2327-0144/cgp/v31i02/129- 

* Mah, C., Walker, H., Phalen, L., Levine, S., Beck, S. W., & Pittman, J. (2024). Beyond 
Cheat Bots: Examining tensions in teachers’ and students’ perceptions of cheating 
and learning with Chat GPT. Education Sciences, 14, 500. https://doi.org/10.3390/ 
educsci14050500.
* Marrone, M., Al Saifi, S., & Trieu, V. H. (2024). Understanding student perceptions of 
artificial intelligence as a teammate. Australasian Journal of Educational Technology, 
40(1), 97–110. https://doi.org/10.14742/ajet.8801.
Martin, P. P., & Graulich, N. (2024). Navigating the data frontier in science assessment: 
Advancing data augmentation strategies for machine learning applications with 
generative artificial intelligence. Computers and Education: Artificial Intelligence, 7, 
Article 100265. https://doi.org/10.1016/j.caeai.2024.100265
* Masa’deh, R., Almajali, D., & Alrowwad, A. (2023). Antecedents of adoption and usage 
of Chat GPT among Jordanian university students: Empirical study. Journal of Open 
Innovation: Technology, Market, and Complexity, 9(4), 241. https://doi.org/10.3390/ 
joitmc9040241.
Miao, F., & Shiohira, K. (2024). AI competency framework for students. Paris, France: 
UNESCO. https://doi.org/10.54675/JKJB9835
Mishra, P., Warr, M., & Islam, R. (2023). TPACK in the age of Chat GPT and generative AI. 
Journal of Digital Learning in Teacher Education, 39(4), 235–251. https://doi.org/ 
10.1080/21532974.2023.2247480
Moher, D., Shamseer, L., Clarke, M., Ghersi, D., Liberati, A., Petticrew, M., Shekelle, P., 
Stewart, L. A., & Group, P.-P. (2015). Preferred reporting items for systematic review 
and meta-analysis protocols (PRISMA-P) 2015 statement. Systematic Reviews, 4(1), 1. 
https://doi.org/10.1186/2046-4053-4-1
* Musyaffi, A., Oktaviani, H., & Hidayat, D. N. (2024). Improving students’ openness to 
artificial intelligence through risk awareness and digital literacy: Evidence from a 
developing country. Education and Information Technologies. https://doi.org/ 
10.1007/s10639-024-13211-y.
* Naamati-Schneider, L. (2024). Enhancing AI competence in health management: 
Students’ experiences with Chat GPT as a learning tool. BMC Medical Education, 24 
(1), 598. https://doi.org/10.1186/s12909-024-05595-9.
* Naamati-Schneider, L., & Alt, D. (2024). Beyond digital literacy: The era of AI-powered 
assistants and evolving user skills. Education and Information Technologies, 29(16), 
21263–21293. https://doi.org/10.1007/s10639-024-12694-z.
Nafar, A., Venable, K. B., & Kordjamshidi, P. (2024). Probabilistic reasoning in 
generative large language models. Ar Xiv. https://doi.org/10.48550/ 
arxiv.2402.09614
Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI 
literacy: An exploratory review. Computers and Education: Artificial Intelligence, 2, 
Article 100041. https://doi.org/10.1016/j.caeai.2021.100041
Ng, D. T. K., Su, J., Leung, J. K. L., & Chu, S. K. W. (2023). Artificial intelligence (AI) 
literacy education in secondary schools: A review. Interactive Learning Environments, 
32(10), 6204–6224. https://doi.org/10.1080/10494820.2023.2255228
Ng, D. T. K., Tan, C. W., & Leung, J. K. L. (2024). Empowering student self-regulated 
learning and science education through Chat GPT: A pioneering pilot study. British 
Journal of Educational Technology, 55(4), 1328–1353. https://doi.org/10.1111/ 
bjet.13454
Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024). Design and 
validation of the AI literacy questionnaire: The affective, behavioural, cognitive and 
ethical approach. British Journal of Educational Technology, 55(3), 1082–1104. 
https://doi.org/10.1111/bjet.13411
* Ngo, T. N., & Hastie, D. (2025). Artificial Intelligence for Academic Purposes (AIAP): 
Integrating AI literacy into an EAP module. English for Specific Purposes, 77, 20–38. 
https://doi.org/10.1016/j.esp.2024.09.001.
* O’Dea, X., Ng, D. T. K., O’Dea, M., & Shkuratskyy, V. (2024). Factors affecting 
university students’ generative AI literacy: Evidence and evaluation in the UK and 
Hong Kong contexts. Policy Futures in Education. https://doi.org/10.1177/ 
14782103241287401.
* Oktarin, I. B., Saputri, M. E. E., Magdalena, B., Hastomo, T., & Maximilian, A. (2024). 
Leveraging Chat GPT to enhance students’ writing skills, engagement, and feedback 
literacy. Edelweiss Applied Science and Technology, 8(4), 2306–2319. https://doi.org/ 
10.55214/25768484.v8i4.1600.
Open AI. (2022). Introducing Chat GPT. https://openai.com/blog/chatgpt.
Open AI. (2023). GPT-4 technical report. ar Xiv preprint ar Xiv:2303.08774.
Park, J., Teo, T. W., Teo, A., Chang, J., Huang, J. S., & Koo, S. (2023). Integrating 
artificial intelligence into science lessons: Teachers’ experiences and views. 
International Journal of STEM Education, 10(1), 61. https://doi.org/10.1186/s40594- 
023-00454-3
Relmasira, S. C., Lai, Y. C., & Donaldson, J. P. (2023). Fostering AI literacy in elementary 
Science, Technology, Engineering, Art, and Mathematics (STEAM) education in the 
age of generative AI. Sustainability, 15, Article 13595. https://doi.org/10.3390/ 
su151813595
* Schiavo, G., Businaro, S., & Zancanaro, M. (2024). Comprehension, apprehension, and 
acceptance: Understanding the influence of literacy and anxiety on acceptance of 
artificial intelligence. Technology in Society, 77, Article 102537. https://doi.org/ 
10.1016/j.techsoc.2024.102537.
Thomas, J., & Harden, A. (2008). Methods for the thematic synthesis of qualitative 
research in systematic reviews. BMC Medical Research Methodology, 8(1), 45. https:// 
doi.org/10.1186/1471-2288-8-45
Touretzky, D., Gardner-Mc Cune, C., Martin, F., & Seehorn, D. (2019). Envisioning AI for 
K-12: What should every child know about AI?. In In proceedings of the AAAI 
conference on artificial intelligence, 33 pp. 9795–9799) AAAI Press. No. 01.
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi`ere, B., 
Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., & Lample, G. 
(2023). LLa MA: Open and efficient foundation language models. Ar Xiv. https://doi. 
org/10.48550/arxiv.2302.13971
* Tsao, J., & Nogues, C. (2024). Beyond the author: Artificial intelligence, creative 
writing and intellectual emancipation. Poetics, 102, Article 101865. https://doi.org/ 
10.1016/j.poetic.2024.101865.
* Vartiainen, H., Kahila, J., Tedre, M., L´opez-Pernas, S., & Pope, N. (2024). Enhancing 
children’s understanding of algorithmic biases in and with text-to-image generative 
AI. New Media & Society, 1–27. https://doi.org/10.1177/14614448241252820.
* Vidaurre, S. M. E., Vel´asquez Rodríguez, N. C., Gambetta Quelopana, R. L., Martinez 
Valdivia, A. N., Leo Rossi, E. A., & Nolasco-Mamani, M. A. (2024). Perceptions of 
artificial intelligence and its impact on academic integrity among university students 
in Peru and Chile: An approach to sustainable education. Sustainability, 16(20), 
9005. https://doi.org/10.3390/su16209005.
* Wang, C. (2024). Exploring students’ generative AI-assisted writing processes: 
Perceptions and experiences from native and nonnative English speakers. 
Technology, Knowledge and Learning. https://doi.org/10.1007/s10758-024-09744-3.
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & 
Zhou, D. (2022). Chain-of-Thought prompting elicits reasoning in large language 
models. Ar Xiv. https://doi.org/10.48550/arxiv.2201.11903
Xu, Z., Jain, S., & Kankanhalli, M. (2024). Hallucination is inevitable: An innate 
limitation of large language models. Ar Xiv. https://doi.org/10.48550/ 
arxiv.2401.11817
Yi, C., Zhu, R., & Wang, Q. (2022). Exploring the interplay between question-answering 
systems and communication with instructors in facilitating learning. Internet 
Research, 32(7), 32–55. https://doi.org/10.1108/intr-08-2020-0459
Yim, I. H. Y. (2024). A critical review of teaching and learning artificial intelligence (AI) 
literacy: Developing an intelligence-based AI literacy framework for primary school 
education. Computers and Education: Artificial Intelligence, 7, Article 100319. https:// 
doi.org/10.1016/j.caeai.2024.100319
* Young, J. D., Dawood, L., & Lewis, S. E. (2024). Chemistry students’ artificial 
intelligence literacy through their critical reflections of chatbot responses. Journal of 
Chemical Education, 101, 2466–2474. https://doi.org/10.1021/acs. 
jchemed.4c00154.
Zamfirescu-Pereira, J. D., Wong, R. Y., Hartmann, B., & Yang, Q. (2023). Why johnny 
can’t prompt: How Non-AI experts try (and fail) to design LLM prompts. Proceedings 
of the 2023 CHI conference on human factors in computing systems https://doi.org/ 
10.1145/3544548.3581388
Zhai, X. (2022). Chat GPT user experience: Implications for education. SSRN Electronic 
Journal. https://doi.org/10.2139/ssrn.4312418
Zhang, P., & Tur, G. (2024). A systematic review of Chat GPT use in K-12 education. 
European Journal of Education, 59(2). https://doi.org/10.1111/ejed.12599
* Zou, X., Su, P., Li, L., & Fu, P. (2024). AI-generated content tools and students’ critical 
thinking: Insights from a Chinese university. IFLA Journal. https://doi.org/10.1177/ 
03400352231214963.
J. Park                                                                                                                                                                                                                                            
Computers and Education: Artiϧcial Intelligence 9 (2025) 100487
